# Complete docs.monad.xyz Documentation

> Scraped from: https://docs.monad.xyz
> Date: 2025-11-27T04:08:09.795Z
> Total pages: 184

---



# Section: developer-essentials

---

## Best Practices for Building High Performance Apps

> Source: https://docs.monad.xyz/developer-essentials/best-practices

On this page

Configure web hosting to keep costs under control​

Vercel and Railway provide convenient serverless platforms for hosting your
application, abstracting away the logistics of web hosting relative to using a
cloud provider directly. You may end up paying a premium for the convenience,
especially at higher volumes.
AWS and other cloud providers offer more flexibility and commodity pricing.
Before choosing any service, check pricing and be aware that many providers
offer loss-leader pricing on lower volumes, but then charge higher rates once
you hit a certain threshold.

For example, suppose there is a $20 plan that includes 1 TB per month of
data transfer, with $0.20 per GB beyond that. Do the math to note that the second TB
(and onward) will cost $200. If the next tier up says "contact us", don't
assume the next tier up will be charging $20 per TB.
If you are building a high-traffic app and you aren't careful about serving
static files more cheaply, it will be easy to exceed the loss-leader tier
and pay much more than you expect.


For production deployments on AWS, consider:

Amazon S3 + CloudFront for static file hosting and CDN
AWS Lambda for serverless functions
Amazon ECS or EKS for containerized applications
Amazon RDS for database needs
This setup typically provides granular cost control and scalability for
high-traffic applications.



Use a hardcoded value instead of eth_estimateGas call if gas usage is static​
Many on-chain actions have a fixed gas cost. The simplest example is that a
transfer of native tokens always costs 21,000 gas, but there are many others.
This makes it unnecessary to call eth_estimateGas for each transaction.
Use a hardcoded value instead, as suggested
here.
Eliminating an eth_estimateGas call substantially speeds up the user workflow
in the wallet, and avoids a potential bad behavior in some wallets when
eth_estimateGas reverts (discussed in the linked page).
Reduce eth_call latency by submitting multiple requests concurrently​
Making multiple eth_call requests serially will introduce unnecessary latency
due to multiple round trips to an RPC node. You can make many eth_calls
concurrently, either by condensing them into a single eth_call or by
submitting a batch of calls. Alternatively, you might find it better to switch
to an indexer.
Condensing multiple eth_calls into one​

Multicall: Multicall is a utility smart contract that allows you to
aggregate multiple read requests (eth_call) into a single one. This is
particularly effective for fetching data points like token balances,
allowances, or contract parameters simultaneously. The standard Multicall3
contract is deployed at
0xcA11bde05977b3631167028862bE2a173976CA11 on both Monad Mainnet and Monad Testnet.
Many libraries offer helper functions to simplify multicall usage, e.g.
viem. Read more about
Multicall3 here.
Custom Batching Contracts: For complex read patterns or scenarios not
easily handled by the standard multicall contract, you can deploy a custom
smart contract that aggregates the required data in a single function, which
can then be invoked via a single eth_call.

noteMulticall executes calls serially as you can see from the code
here.
So while using multicall avoids multiple round trips to an RPC server, it is
still inadvisable to put too many expensive calls into one multicall. A batch
of calls (explained next) can be executed on the RPC in parallel.
Submitting a batch of calls​
Most major libraries support batching multiple RPC requests into a single
message.
For example, viem handles Promise.all() on an array of promises by
submitting them as a single batch:
const resultPromises = Array(BATCH_SIZE)  .fill(null)  .map(async (_, i) => {    return await PUBLIC_CLIENT.simulateContract({        address: ...,        abi: ...,        functionName: ...,        args: [...],      })  })const results = await Promise.all(resultPromises)
Use indexers for read-heavy loads​
If your application frequently queries historical events or derived state,
consider using an indexer, as described next.
Use an indexer instead of repeatedly calling eth_getLogs to listen for your events​
Below is a quickstart guide for the most popular data indexing solutions. Please
view the indexer docs for more details.
Using Allium​
noteSee also: AlliumYou'll need an Allium account, which you can request
here.

Allium Explorer

Blockchain analytics platform that provides SQL-based access to
historical blockchain data (blocks, transactions, logs, traces, and
contracts).
You can create Explorer APIs through the
GUI to query and analyze historical
blockchain data. When creating a Query for an API
here (using the New button),
select Monad Mainnet or Monad Testnet from the chain list.
Relevant docs:

Explorer Documentation
Explorer API




Allium Datastreams

Provides real-time blockchain data streams (including blocks,
transactions, logs, traces, contracts, and balance snapshots) through
Kafka, Pub/Sub, and Amazon SNS.
GUI to create new streams
for onchain data. When creating a stream, select the relevant Monad Mainnet or Monad Testnet topics from the Select topics dropdown.
Relevant docs:

Datastreams Documentation
Getting Started with Google Pub/Sub




Allium Developers

Enables fetching wallet transaction activity and tracking balances
(native, ERC20, ERC721, ERC1155).
For the request's body, use monad_mainnet for Monad Mainnet or monad_testnet for Monad Testnet as the chain parameter.
Relevant docs:

API Key Setup Guide
Wallet APIs Documentation





Using Envio HyperIndex​
noteSee also: Envio
and Guide: How to use Envio HyperIndex to build a token transfer notification bot


Follow the quick start
to create an indexer. In the config.yaml file, use network ID 10143 to
select Monad testnet (used in the example below) or network ID 143 for Monad mainnet.


Example configuration


Sample config.yaml file
config.yaml1234567891011121314151617181920212223name: your-indexers-namenetworks:- id: 10143  # Monad Testnet  # Optional custom RPC configuration - only add if default indexing has issues  # rpc_config:  #   url: YOUR_RPC_URL_HERE  # Replace with your RPC URL (e.g., from Alchemy)  #   interval_ceiling: 50     # Maximum number of blocks to fetch in a single request  #   acceleration_additive: 10  # Speed up factor for block fetching  #   initial_block_interval: 10  # Initial block fetch interval size  start_block: 0  # Replace with the block you want to start indexing from  contracts:  - name: YourContract  # Replace with your contract name    address:    - 0x0000000000000000000000000000000000000000  # Replace with your contract address    # Add more addresses if needed for multiple deployments of the same contract    handler: src/EventHandlers.ts    events:    # Replace with your event signatures    # Format: EventName(paramType paramName, paramType2 paramName2, ...)    # Example: Transfer(address from, address to, uint256 amount)    # Example: OrderCreated(uint40 orderId, address owner, uint96 size, uint32 price, bool isBuy)    - event: EventOne(paramType1 paramName1, paramType2 paramName2)    # Add more events as needed


Sample EventHandlers.ts
EventHandlers.ts12345678910111213141516171819202122import {  YourContract,  YourContract_EventOne,} from "generated";
// Handler for EventOne// Replace parameter types and names based on your event definitionYourContract.EventOne.handler(async ({ event, context }) => {  // Create a unique ID for this event instance  const entity: YourContract_EventOne = {    id: `${event.chainId}_${event.block.number}_${event.logIndex}`,    // Replace these with your actual event parameters    paramName1: event.params.paramName1,    paramName2: event.params.paramName2,    // Add any additional fields you want to store  };
  // Store the event in the database  context.YourContract_EventOne.set(entity);})
// Add more event handlers as needed




Important: The rpc_config section under a network (check config.yaml
sample) is optional and should only be configured if you experience issues
with the default Envio setup. This configuration allows you to:

Use your own RPC endpoint
Configure block fetching parameters for better performance



Relevant docs:

Overview



Using GhostGraph​
noteSee also: Ghost

Relevant docs:

Getting Started
Setting up a GhostGraph Indexer on Monad Testnet



Using Goldsky​
noteSee also: Goldsky

Goldsky Subgraphs

To deploy a Goldsky subgraph follow
this guide.
As the network identifier, use monad-mainnet for Monad Mainnet or monad-testnet for Monad Testnet. For subgraph
configuration examples, refer to The Graph Protocol section
below.
For information about querying Goldsky subgraphs, see the
GraphQL API documentation.


Goldsky Mirror

Enables direct streaming of on-chain data to your database.
For the chain name in the dataset_name field when creating a source
for a pipeline, use monad_mainnet for Monad Mainnet or monad_testnet for Monad Testnet (check below example)
Example pipeline.yaml config file
pipeline.yaml12345678910111213141516171819202122232425262728293031323334name: monad-testnet-erc20-transfersapiVersion: 3sources:  monad_testnet_erc20_transfers:    dataset_name: monad_testnet.erc20_transfers    filter: address = '0x0' # Add erc20 contract address. Multiple addresses can be added with 'OR' operator: address = '0x0' OR address = '0x1'    version: 1.2.0    type: dataset    start_at: earliest
# Data transformation logic (optional)transforms:  select_relevant_fields:    sql: |      SELECT          id,          address,          event_signature,          event_params,          raw_log.block_number as block_number,          raw_log.block_hash as block_hash,          raw_log.transaction_hash as transaction_hash      FROM          ethereum_decoded_logs    primary_key: id
# Sink configuration to specify where data goes eg. DBsinks:  postgres:    type: postgres    table: erc20_transfers    schema: goldsky    secret_name: A_POSTGRESQL_SECRET    from: select_relevant_fields

Relevant docs:

Getting Started with Mirror
Data Streaming Guides





Using QuickNode Streams​
noteSee also: QuickNode Streams

On your QuickNode Dashboard, select Streams > Create Stream. In the create
stream UI, select Monad Mainnet or Monad Testnet under Network. Alternatively, you can use the
Streams REST API
to create and manage streams—use monad-mainnet for Monad Mainnet or monad-testnet for Monad Testnet as the network identifier.
You can consume a Stream by choosing a destination during stream creation.
Supported destinations include Webhooks, S3 buckets, and PostgreSQL
databases. Learn more
here.
Relevant docs:

Getting Started



Using The Graph's Subgraph​
noteSee also: The Graph

Network ID: Use monad-mainnet for Monad Mainnet or monad-testnet for Monad Testnet
Example configuration


Sample subgraph.yaml file
subgraph.yaml1234567891011121314151617181920212223242526272829specVersion: 1.2.0indexerHints:  prune: autoschema:  file: ./schema.graphqldataSources:  - kind: ethereum    name: YourContractName # Replace with your contract name    network: monad-testnet # Monad testnet configuration    source:      address: "0x0000000000000000000000000000000000000000" # Replace with your contract address      abi: YourContractABI # Replace with your contract ABI name      startBlock: 0 # Replace with the block where your contract was deployed/where you want to index from    mapping:      kind: ethereum/events      apiVersion: 0.0.9      language: wasm/assemblyscript      entities:        # List your entities here - these should match those defined in schema.graphql        # - Entity1        # - Entity2      abis:        - name: YourContractABI # Should match the ABI name specified above          file: ./abis/YourContract.json # Path to your contract ABI JSON file      eventHandlers:        # Add your event handlers here, for example:        # - event: EventName(param1Type, param2Type, ...)        #   handler: handleEventName      file: ./src/mapping.ts # Path to your event handler implementations


Sample mappings.ts file
mappings.ts12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import {  // Import your contract events here  // Format: EventName as EventNameEvent  EventOne as EventOneEvent,  // Add more events as needed} from "../generated/YourContractName/YourContractABI" // Replace with your contract name, abi name you supplied in subgraph.yaml
import {  // Import your schema entities here  // These should match the entities defined in schema.graphql  EventOne,  // Add more entities as needed} from "../generated/schema"
/**  * Handler for EventOne  * Update the function parameters and body according to your event structure  */export function handleEventOne(event: EventOneEvent): void {  // Create a unique ID for this entity  let entity = new EventOne(    event.transaction.hash.concatI32(event.logIndex.toI32())  )    // Map event parameters to entity fields  // entity.paramName = event.params.paramName    // Example:  // entity.sender = event.params.sender  // entity.amount = event.params.amount
  // Add metadata fields  entity.blockNumber = event.block.number  entity.blockTimestamp = event.block.timestamp  entity.transactionHash = event.transaction.hash
  // Save the entity to the store  entity.save()}
/**  * Add more event handlers as needed  * Format:  *   * export function handleEventName(event: EventNameEvent): void {  *   let entity = new EventName(  *     event.transaction.hash.concatI32(event.logIndex.toI32())  *   )  *     *   // Map parameters  *   entity.param1 = event.params.param1  *   entity.param2 = event.params.param2  *     *   // Add metadata  *   entity.blockNumber = event.block.number  *   entity.blockTimestamp = event.block.timestamp  *   entity.transactionHash = event.transaction.hash  *     *   entity.save()  * }  */


Sample schema.graphql file
schema.graphql123456789101112131415161718192021222324252627282930313233343536373839404142434445# Define your entities here# These should match the entities listed in your subgraph.yaml
# Example entity for a generic eventtype EventOne @entity(immutable: true) {  id: Bytes!    # Add fields that correspond to your event parameters  # Examples with common parameter types:  # paramId: BigInt!              # uint256, uint64, etc.  # paramAddress: Bytes!          # address  # paramFlag: Boolean!           # bool  # paramAmount: BigInt!          # uint96, etc.  # paramPrice: BigInt!           # uint32, etc.  # paramArray: [BigInt!]!        # uint[] array  # paramString: String!          # string    # Standard metadata fields  blockNumber: BigInt!  blockTimestamp: BigInt!  transactionHash: Bytes!}
# Add more entity types as needed for different events# Example based on Transfer event:# type Transfer @entity(immutable: true) {#   id: Bytes!#   from: Bytes!                  # address#   to: Bytes!                    # address#   tokenId: BigInt!              # uint256#   blockNumber: BigInt!#   blockTimestamp: BigInt!#   transactionHash: Bytes!# }
# Example based on Approval event:# type Approval @entity(immutable: true) {#   id: Bytes!#   owner: Bytes!                 # address#   approved: Bytes!              # address#   tokenId: BigInt!              # uint256#   blockNumber: BigInt!#   blockTimestamp: BigInt!#   transactionHash: Bytes!# }



Relevant docs:

Quickstart



Using thirdweb's Insight API​
noteSee also: thirdweb

REST API offering a wide range of on-chain data, including events, blocks,
transactions, token data (such as transfer transactions, balances, and token
prices), contract details, and more.
Use chain ID 143 for Monad Mainnet or 10143 for Monad Testnet when constructing request URLs.
Relevant docs:

Get started



Manage nonces locally if sending multiple transactions in quick succession​
noteThis only applies if you are setting nonces manually. If you are delegating
this to the wallet, no need to worry about this.

eth_getTransactionCount only updates after a transaction is finalized. If
you have multiple transactions from the same wallet in short succession, you
should implement local nonce tracking.

Submit multiple transactions concurrently​
If you are submitting a series of transactions, instead submitting
sequentially, implement concurrent transaction submission for improved
efficiency.
Before:
1234567891011for (let i = 0; i < TIMES; i++) {  const tx_hash = await WALLET_CLIENT.sendTransaction({    account: ACCOUNT,    to: ACCOUNT_1,    value: parseEther('0.1'),    gasLimit: BigInt(21000),    baseFeePerGas: BigInt(50000000000),    chain: CHAIN,    nonce: nonce + Number(i),  })}
After:
12345678910111213const transactionsPromises = Array(BATCH_SIZE)  .fill(null)  .map(async (_, i) => {    return await WALLET_CLIENT.sendTransaction({      to: ACCOUNT_1,      value: parseEther('0.1'),      gasLimit: BigInt(21000),      baseFeePerGas: BigInt(50000000000),      chain: CHAIN,      nonce: nonce + Number(i),    })  })const hashes = await Promise.all(transactionsPromises)

### Code Examples

```prism
const resultPromises = Array(BATCH_SIZE)  .fill(null)  .map(async (_, i) => {    return await PUBLIC_CLIENT.simulateContract({        address: ...,        abi: ...,        functionName: ...,        args: [...],      })  })const results = await Promise.all(resultPromises)
```

```prism
name: your-indexers-namenetworks:- id: 10143  # Monad Testnet  # Optional custom RPC configuration - only add if default indexing has issues  # rpc_config:  #   url: YOUR_RPC_URL_HERE  # Replace with your RPC URL (e.g., from Alchemy)  #   interval_ceiling: 50     # Maximum number of blocks to fetch in a single request  #   acceleration_additive: 10  # Speed up factor for block fetching  #   initial_block_interval: 10  # Initial block fetch interval size  start_block: 0  # Replace with the block you want to start indexing from  contracts:  - name: YourContract  # Replace with your contract name    address:    - 0x0000000000000000000000000000000000000000  # Replace with your contract address    # Add more addresses if needed for multiple deployments of the same contract    handler: src/EventHandlers.ts    events:    # Replace with your event signatures    # Format: EventName(paramType paramName, paramType2 paramName2, ...)    # Example: Transfer(address from, address to, uint256 amount)    # Example: OrderCreated(uint40 orderId, address owner, uint96 size, uint32 price, bool isBuy)    - event: EventOne(paramType1 paramName1, paramType2 paramName2)    # Add more events as needed
```

```prism
import {  YourContract,  YourContract_EventOne,} from "generated";
// Handler for EventOne// Replace parameter types and names based on your event definitionYourContract.EventOne.handler(async ({ event, context }) => {  // Create a unique ID for this event instance  const entity: YourContract_EventOne = {    id: `${event.chainId}_${event.block.number}_${event.logIndex}`,    // Replace these with your actual event parameters    paramName1: event.params.paramName1,    paramName2: event.params.paramName2,    // Add any additional fields you want to store  };
  // Store the event in the database  context.YourContract_EventOne.set(entity);})
// Add more event handlers as needed
```

```prism
name: monad-testnet-erc20-transfersapiVersion: 3sources:  monad_testnet_erc20_transfers:    dataset_name: monad_testnet.erc20_transfers    filter: address = '0x0' # Add erc20 contract address. Multiple addresses can be added with 'OR' operator: address = '0x0' OR address = '0x1'    version: 1.2.0    type: dataset    start_at: earliest
# Data transformation logic (optional)transforms:  select_relevant_fields:    sql: |      SELECT          id,          address,          event_signature,          event_params,          raw_log.block_number as block_number,          raw_log.block_hash as block_hash,          raw_log.transaction_hash as transaction_hash      FROM          ethereum_decoded_logs    primary_key: id
# Sink configuration to specify where data goes eg. DBsinks:  postgres:    type: postgres    table: erc20_transfers    schema: goldsky    secret_name: A_POSTGRESQL_SECRET    from: select_relevant_fields
```

```prism
specVersion: 1.2.0indexerHints:  prune: autoschema:  file: ./schema.graphqldataSources:  - kind: ethereum    name: YourContractName # Replace with your contract name    network: monad-testnet # Monad testnet configuration    source:      address: "0x0000000000000000000000000000000000000000" # Replace with your contract address      abi: YourContractABI # Replace with your contract ABI name      startBlock: 0 # Replace with the block where your contract was deployed/where you want to index from    mapping:      kind: ethereum/events      apiVersion: 0.0.9      language: wasm/assemblyscript      entities:        # List your entities here - these should match those defined in schema.graphql        # - Entity1        # - Entity2      abis:        - name: YourContractABI # Should match the ABI name specified above          file: ./abis/YourContract.json # Path to your contract ABI JSON file      eventHandlers:        # Add your event handlers here, for example:        # - event: EventName(param1Type, param2Type, ...)        #   handler: handleEventName      file: ./src/mapping.ts # Path to your event handler implementations
```

```prism
import {  // Import your contract events here  // Format: EventName as EventNameEvent  EventOne as EventOneEvent,  // Add more events as needed} from "../generated/YourContractName/YourContractABI" // Replace with your contract name, abi name you supplied in subgraph.yaml
import {  // Import your schema entities here  // These should match the entities defined in schema.graphql  EventOne,  // Add more entities as needed} from "../generated/schema"
/**  * Handler for EventOne  * Update the function parameters and body according to your event structure  */export function handleEventOne(event: EventOneEvent): void {  // Create a unique ID for this entity  let entity = new EventOne(    event.transaction.hash.concatI32(event.logIndex.toI32())  )    // Map event parameters to entity fields  // entity.paramName = event.params.paramName    // Example:  // entity.sender = event.params.sender  // entity.amount = event.params.amount
  // Add metadata fields  entity.blockNumber = event.block.number  entity.blockTimestamp = event.block.timestamp  entity.transactionHash = event.transaction.hash
  // Save the entity to the store  entity.save()}
/**  * Add more event handlers as needed  * Format:  *   * export function handleEventName(event: EventNameEvent): void {  *   let entity = new EventName(  *     event.transaction.hash.concatI32(event.logIndex.toI32())  *   )  *     *   // Map parameters  *   entity.param1 = event.params.param1  *   entity.param2 = event.params.param2  *     *   // Add metadata  *   entity.blockNumber = event.block.number  *   entity.blockTimestamp = event.block.timestamp  *   entity.transactionHash = event.transaction.hash  *     *   entity.save()  * }  */
```

```prism
# Define your entities here# These should match the entities listed in your subgraph.yaml
# Example entity for a generic eventtype EventOne @entity(immutable: true) {  id: Bytes!    # Add fields that correspond to your event parameters  # Examples with common parameter types:  # paramId: BigInt!              # uint256, uint64, etc.  # paramAddress: Bytes!          # address  # paramFlag: Boolean!           # bool  # paramAmount: BigInt!          # uint96, etc.  # paramPrice: BigInt!           # uint32, etc.  # paramArray: [BigInt!]!        # uint[] array  # paramString: String!          # string    # Standard metadata fields  blockNumber: BigInt!  blockTimestamp: BigInt!  transactionHash: Bytes!}
# Add more entity types as needed for different events# Example based on Transfer event:# type Transfer @entity(immutable: true) {#   id: Bytes!#   from: Bytes!                  # address#   to: Bytes!                    # address#   tokenId: BigInt!              # uint256#   blockNumber: BigInt!#   blockTimestamp: BigInt!#   transactionHash: Bytes!# }
# Example based on Approval event:# type Approval @entity(immutable: true) {#   id: Bytes!#   owner: Bytes!                 # address#   approved: Bytes!              # address#   tokenId: BigInt!              # uint256#   blockNumber: BigInt!#   blockTimestamp: BigInt!#   transactionHash: Bytes!# }
```

```prism
for (let i = 0; i < TIMES; i++) {  const tx_hash = await WALLET_CLIENT.sendTransaction({    account: ACCOUNT,    to: ACCOUNT_1,    value: parseEther('0.1'),    gasLimit: BigInt(21000),    baseFeePerGas: BigInt(50000000000),    chain: CHAIN,    nonce: nonce + Number(i),  })}
```

```prism
const transactionsPromises = Array(BATCH_SIZE)  .fill(null)  .map(async (_, i) => {    return await WALLET_CLIENT.sendTransaction({      to: ACCOUNT_1,      value: parseEther('0.1'),      gasLimit: BigInt(21000),      baseFeePerGas: BigInt(50000000000),      chain: CHAIN,      nonce: nonce + Number(i),    })  })const hashes = await Promise.all(transactionsPromises)
```

---

## Deployment Summary for Developers

> Source: https://docs.monad.xyz/developer-essentials/summary

On this page

This page summarizes what you need to know when developing or deploying smart contracts for
Monad.
Start with​

Network Information - for RPC & block explorer URLs, and canonical
contract deployments.
Differences between Monad and Ethereum
protocols repo (add yours!)
token-list repo (add yours!)
RPC API - an interactive reference

Supported Tooling & Infra​
Here are some of the most commonly-requested tools:
ToolStatusNotesTenderly✅Safe✅Monadscan (by Etherscan)✅MonadVision (by Blockvision)✅Foundry✅Use nightly release: foundryup -i nightlyViem✅viem >= 2.40.0

See Tooling and Infra for a complete list of what is supported,
including:
CategoryAA InfraAnalyticsBlock ExplorersCross-ChainCustodyEmbedded WalletsIndexers - Common Data (e.g. token balances, transfers, trades)Indexing Frameworks (incl Subgraphs)OnrampsOraclesRPC Providers
Accounts​
Address spaceSame address space as Ethereum (last 20 bytes of ECDSA public key)EIP-7702Supported. See EIP-7702 reference
Smart Contracts​
For deployment and verification guides, see:

Deploy a Contract
Verify a Contract
MonadVision verification guide

OpcodesAll opcodes as of the Pectra fork are supported.PrecompilesAll Ethereum precompiles as of the Pectra fork (0x01 to 0x11), plus precompile 0x0100 (RIP-7212) are supported. See PrecompilesMax contract size128 kb (up from 24.5 kb in Ethereum)
Transaction types​
Full article: Transactions
Transaction typesSupported:
0 ("legacy")
1 ("EIP-2930")
2 ("EIP-1559", the "default" on Ethereum)
4 ("EIP-7702")
Not supported:
3 ("EIP-4844")
Gas limits​
Per-transaction gas limit30M gasBlock gas limit200M gasBlock gas target80% (160M gas)Gas throughput500M gas/sec (200M gas/block divided by 0.4 sec/block)
Gas pricing​
Full article: Gas pricing
Gas chargedThe gas limit is what is charged. That is: total tokens deducted from the sender's balance is value + gas_price * gas_limit. See discussion.EIP-1559 dynamicsMonad is EIP-1559-compatible; base fee and priority fee work as on Ethereum. EIP-1559 explainerBase feeMin base fee of 100 MON-gwei (100 * 10^-9 MON).The base fee controller is similar to Ethereum's but stays elevated for less time (details).
Opcode pricing​
Full article: Opcode Pricing
Opcode pricing is the same as on Ethereum (see: evm.codes), except
for the below repricings needed to reweight relative scarcities of resources due to Monad
optimizations.
ItemEthereumMonadNotesCold access cost - account2,60010,100Affected opcodes: BALANCE, EXTCODESIZE, EXTCODECOPY, EXTCODEHASH, CALL, CALLCODE, DELEGATECALL, STATICCALL, SELFDESTRUCTSee detailsCold access cost - storage2,1008,100Affected opcodes: SLOAD, SSTORE. See detailsecRecover, ecAdd, ecMul, ecPairing, blake2f, point_eval precompilesSee detailsPrecompiles 0x01, 0x06, 0x07, 0x08, 0x09, 0x0a
Timing considerations​
Block frequency400 msTIMESTAMP opcodeAs in Ethereum, TIMESTAMP is a second-granularity unix timestamp. Since blocks
are every 400 ms, this means that 2-3 blocks will likely have the same timestamp.FinalityBlocks are finalized after two blocks (800 ms). Once a block is finalized, it
cannot be reorged. See
MonadBFT for a fuller discussion.Speculative finalityBlocks can be
speculatively finalized
after one block (400 ms), when it is marked as being in the Voted stage.
Speculative finality can revert under very rare circumstances (see fuller discussion
here), but most frontends
should be able to reflect state based on speculative finality.
Mempool​
Full article: Local Mempool
Monad does not have a global mempool, as this approach is not suitable for high-performance
blockchains.
Each validator maintains a local mempool with transactions that it is aware of. When an RPC
receives a transaction, it forwards it strategically to upcoming leaders, repeating this process
if it doesn't observe the transaction getting included.
Although this is an important part of Monad's design, it is not one that should generally affect
smart contract developers in their system designs.
Parallel Execution and JIT Compilation​
Monad utilizes parallel execution and
JIT compilation for efficiency,
but smart contract developers don't need to change anything to account for this.
In Monad, transactions are still linearly ordered, and the only correct outcome of execution is
the result as if the transactions were serially executed. All aspects of parallel execution can
be treated by smart contract developers as implementation details.
See further discussion.
Asynchronous Execution​
Full article: Asynchronous Execution
Monad utilizes asynchronous execution for efficiency, but most developers shouldn't need to
change anything.
Developers with significant off-chain financial logic (e.g. exchanges, bridges, and
stablecoin/RWA issuers) should wait until blocks reach the
Verified
phase (aka state root finality), three blocks later than
Finalized,
to be sure that the entire network agrees with their own node's local execution of a
finalized block.
Async execution and block stagesAsynchronous execution is a technique that allows Monad to substantially
increase execution throughput by decoupling consensus from execution. In asynchronous execution,
validators vote first, execute later - because once the transaction order is determined, the
state is determined. Afterward, each node executes locally. There is a
delayed merkle root
three blocks later which confirms that the network got the same state trie as local execution.From the developer perspective:
Someone submits a transaction through your frontend which interacts with your smart contract.
You make note of the hash.
The transaction gets included in a block.
The block gets Voted (speculatively finalized)
one block later. (T+1)
The block gets Finalized one block later
(T+2)
The block gets Verified (state root
finalized) three blocks later (T+5)
You listen for transaction receipts by calling
eth_getTransactionReceipt.
Receipts will first be available after a block becomes Voted (speculatively finalized).Your choice of when to update your UI to give feedback to the user depends on risk preference, but
for most applications it is reasonable to do so when the block becomes Voted because speculative
finality reversion is extremely rare. A more conservative approach would be to wait until the
block is Finalized, since then you will never have to handle a reorg. Waiting until Verified
is not generally necessary (except for the aforementioned developers with off-chain financial
logic).
Reserve balance​
Full article: Reserve Balance
Monad introduces the Reserve Balance mechanism to enable Asynchronous Execution.
The Reserve Balance mechanism places light restrictions on when transactions can be included at
consensus time, and imposes some conditions under which transactions will revert at execution time.
The Reserve Balance mechanism is designed to preserve safety under asynchronous execution without
interfering with normal usage patterns. Most users and developers need not worry about the Reserve
Balance constraints.
ParameterValueDefault reserve balance10 MON
EIP-7702​
EIP-7702 is supported; see the full notes here.
There are two caveats:


If an EOA is EIP-7702-delegated, its balance cannot be lowered below 10 MON due to the
Reserve Balance rules. (If the delegation is removed, dipping below 10 MON
is allowed.) Discussion.


If an EOA is EIP-7702-delegated, when it is called as a smart contract, the
CREATE and CREATE2 opcodes are banned. Discussion.


Reading blockchain data​
The following methods are supported for reading blockchain data:
JSON-RPCSee RPC API. Monad supports all standard RPC methods
from Ethereum. Differences are noted in RPC Differences. For rate limits, see here.WebSocketSee the WebSocket Guide.
Monad implements the eth_subscribe method with the following subscription types:
newHeads and logs (for Geth-style subscriptions that wait for finalization)
monadNewHeads and monadLogs (similar, but published as soon as the proposal
is received)
The syncing and newPendingTransactions subscription types are not supported.
For more details see Real-time Data Sources.Execution EventsSee Execution Events.
The Execution Events system allows developers to build high-performance applications
that receive lowest-latency event data from a Monad node via shared memory queue.
You can also use the supported Indexers.
Historic data​
Monad full nodes provide access to all historic ledger data (blocks, transactions, receipts,
events, and traces). Monad full nodes do not provide access to arbitrary historic state as
discussed here.
There is a special RPC service at https://rpc-mainnet.monadinfra.com
that provides access to historical data.
Recommended Open Source Tooling Versions​

foundry nightly (foundryup -i nightly)
viem >= 2.40.0 (just to bring in monad.ts)
alloy-chains >= 0.2.20

The nightly version of foundry is needed right now to ensure foundry uses the RPC to estimate gas
(relevant PR). There is also work in progress
to allow foundry local estimates to incorporate Monad's gas repricing, but this is not complete.
Canonical contract addresses​
See Canonical Contracts
Source code​

monad-bft (consensus)
monad (execution)

Running a full node​
See Node Operations
Need Help?​
Please ask in the developer discord. We are here to help!

---

## Developer Essentials

> Source: https://docs.monad.xyz/developer-essentials/

On this page

Quick Reference​
Network Information - MainnetLinks and canonical deployments for mainnetNetwork Information - TestnetsLinks and canonical deployments for testnetsDeployment SummaryEverything you need to know when deploying on MonadTooling & InfraThird-party infra supporting Monad TestnetRPC ReferenceJSON-RPC APIDifferences between Monad & Ethereum
Finer Details​
TransactionsSupported transaction types and format (TLDR: same as Ethereum,
except no EIP-4844 transaction type)Gas PricingWhy the gas limit is charged + details of the base fee controllerOpcode PricingOpcode pricing adjustmentsPrecompilesPrecompile referenceStakingStaking behavior + staking precompile referenceReserve BalanceHow the reserve balance ensures safety under asynchronous executionEIP-7702EIP-7702 referenceHistorical DataData retention policy for state and ledger data
Best Practices​
Best PracticesRecommendations for building high-performance apps
Monad's Architecture in Depth​
Monad for DevsOne-page summary of Monad architectureMonad Architecture
Changelog​
ChangelogRevision list and changelog
Get Support​
DiscordJoin other Monad developers on DiscordTelegramJoin other Monad developers on Telegram

---

## Differences between Monad and Ethereum

> Source: https://docs.monad.xyz/developer-essentials/differences

On this page

This list assembles notable behavioral differences between Monad and Ethereum from the
perspective of a smart contract developer.
Virtual Machine​


Max contract size is 128kb (up from 24.5kb in Ethereum).


A few opcodes and precompiles are repriced, to reweight relative scarcities of resources due
to Monad optimizations. See Opcode Pricing.


The secp256r1 (P256) verification precompile in
RIP-7212 is supported.
See Precompiles.


Transactions​


Transactions are charged based on gas limit rather than gas usage, i.e. total tokens deducted
from the sender's balance is value + gas_bid * gas_limit. As discussed in
Gas in Monad, this is a DOS-prevention measure for
asynchronous execution.


Consensus and execution utilize the Reserve Balance mechanism to ensure
that all transactions included in consensus can be paid for. This mechanism places light
restrictions on transaction inclusion at consensus time, and defines select conditions under
which a transaction will revert at execution time.


Due to the Reserve Balance mechanism, you may see transactions in the blockchain which
ultimately fail due to trying to spend too much MON relative to account balance.
These transactions still pay for gas and are valid transactions whose result is execution
reversion. This isn't a protocol difference, as many reverting Ethereum transactions are
included in the chain, but it may be different from expectation.
Longer discussion.


Transaction type 3 (EIP-4844 type aka blob transactions) is not supported.


There is no global mempool. For efficiency, transactions are forwarded to the next few leadersas
described in Local Mempool.


EIP-7702 Delegation​


If an EOA is EIP-7702-delegated, its balance cannot be lowered below 10 MON due to the
Reserve Balance rules. (If the delegation is removed, dipping below 10 MON
is allowed.) Discussion.


If an EOA is EIP-7702-delegated, when it is called as a smart contract, the
CREATE and CREATE2 opcodes are banned. Discussion.


Historical Data​

Due to Monad's high throughput, full nodes do not provide access to arbitrary historic state, as
this would require too much storage. See Historical Data for a fuller
discussion.

RPC​
See: RPC Differences

---

## EIP-7702 on Monad

> Source: https://docs.monad.xyz/developer-essentials/eip-7702

On this page

Summary​
EIP-7702
is supported on Monad with the same workflow as in Ethereum: users sign a message
authorizing the delegation to a specific account, which they or someone else can submit
using transaction type 0x04. After that occurs, the EOA becomes "delegated", i.e. it
can be called like a smart contract account with code equal to the account it has delegated to.
EIP-7702-delegated accounts behave the same on Monad as on Ethereum in most cases.
The two main nuances are:

If an EOA is EIP-7702-delegated, its balance cannot be lowered below 10 MON. (If the
delegation is removed, dipping below 10 MON is allowed.) Details
When the EOA is treated like a smart contract, that code cannot call CREATE or CREATE2.
Details

EIP-7702 Primer​
EIP-7702 allows Externally Owned Accounts (EOAs)
to add code to themselves, granting themselves the ability to add new capabilities previously
reserved for smart contract accounts, such as transaction batching, gas sponsorship, and
alternative authentication.
To do this, the EOA signs an authorization designating a specific address as the source
of its code. EIP-7702 introduces a new transaction type (type 0x04) that submits this
authorization. The authorization can be submitted by the EOA themselves, or by anyone else.
EIP-7702 enables account abstraction directly on an EOA. It is an extension of EIP-4337,
which introduced standards for smart contract wallets with flexible validation logic, but which
had to assume a separate UserOp mempool and bundler infrastructure for submitting transactions.
In Ethereum's account-based model, there are two separate roles - "fee payer" (transaction
submitter, i.e. who pays for gas to execute a transaction) and "asset owner" (spend authorizer,
i.e. who holds keys with the power to spend from a balance). Originally, EOAs played both roles.
Under EIP-4337, the roles were split - a smart contract wallet holds title to assets (and has
its own logic for validating that spend was authorized), but fees must still be paid by an
EOA, hence the roles are definitively split.
With EIP-7702, EOAs are allowed to have code, thus allowing the same account to play both roles
again.
In essence, EIP-7702 makes it possible for today's EOAs to gain smart wallet-like powers
such as multisig, social recovery, session keys, and gas sponsorship without abandoning their
current accounts, bridging the gap between the old EOA model and the future of full account
abstraction.
EIP-7702 on Monad​
EIP-7702-delegated accounts behave the same on Monad as on Ethereum in most cases.
The two main nuances are:

If an EOA is EIP-7702-delegated, its balance cannot be lowered below 10 MON. (If the
delegation is removed, dipping below 10 MON is allowed.)
When the EOA is treated like a smart contract, that code cannot call CREATE or CREATE2.

Delegated EOAs can't dip below 10 MON​
In Monad, the Reserve Balance rules carve out a buffer of 10 MON
for consensus-time balance checks. (This is described in greater detail in
Reserve Balance, but the basic reason is that under asynchronous execution,
consensus votes on blocks with a delayed view of state. To defend against DOS attacks where
consensus would mistakenly include transactions from empty accounts, consensus and execution
pre-agree on a set of rules that carve out a budget (10 MON) for consensus to pay gas fees of inflight
transactions. Execution protects that budget by reverting if the balance would dip below 10 MON by an amount greater than the transaction's max gas fee.)
An exception is made to this execution-time policy for undelegated EOAs where a transaction
hasn't been seen from this EOA in several blocks. That exception is what allows undelegated EOAs to
submit transactions that would cause their balance to dip below 10 MON by amounts greater than the transaction's max gas fee.
However, this exception can't be made for EIP-7702-delegated accounts. Delegation
breaks the invariant that an EOA's balance can only be reduced by transactions signed by
that EOA. There is not a reliable way to be sure (at the time of consensus) that another inflight
transaction hasn't spent funds from an EIP-7702-delegated account, therefore the exception made
for undelegated accounts doesn't apply to delegated accounts.
An delegated account may be emptied by undelegating first.
Delegated contract code cannot call CREATE/CREATE2​
There is another difference: when contract code is executing in the context of an
EIP‑7702‑delegated EOA (for example, because a contract CALLs that EOA’s address),
the CREATE and CREATE2 opcodes are not permitted.
Any attempt to execute CREATE or CREATE2 in such a frame causes that call frame to revert,
and the caller (if any) observes the call as failed
(the CALL/DELEGATECALL/CALLCODE returns 0).
This prevents delegated code from changing the EOA’s nonce in ways that would make it
difficult to statically validate transactions from that account.
In contrast, normal contract‑creation transactions sent from a delegated
EOA (transactions with no to field, where the transaction data is treated as init code)
are allowed and behave as on Ethereum.
Other than those differences, EIP-7702-delegated accounts behave normally with respect to both
ordinary transactions sent by the EOA, and transactions that treat the EOA as a
smart contract.
FAQ​
What does an EIP-7702 (set code transaction) look like?An EIP-7702 transaction is an EIP-2718
transaction with TransactionType 0x04.This transaction type is only used to set code; once the code is set for an EOA, subsequent
transactions will most likely use the default transaction type (TransactionType 0x02;
EIP-1559) transactions to interact with the EOA.Here is an example of an EIP-7702 transaction in a block explorer:

Is it necessary for the EIP-7702 type transaction to be initiated by the EOA itself?No, the EOA can sign an "authorization tuple" which can then be used by the sponsoring
entity to send the transaction. This will allow EOAs to behave like smart contracts
without any funds for gas!
How can I find out to which address EOA is currently delegating to?On successful delegation to a smart contract, the following code is deployed at the EOA's
address.0xef0100 (3 bytes) + smart_contract_address (20 bytes)Example: If 0xabc... (EOA) delegates to 0x493... (smart contract), then code at
0xabc... (EOA) is 0xef0100493...Thus, you may determine the delegated address by inspecting the code.
What if the EOA is pointing to another EOA which is also pointing to a smart contract?The chain of delegation is not followed; only the immediate code that the first EOA is
pointing to is used.
How do I clear the delegation on an EOA?Initiate a 0x04 type transaction from the EOA with 0x000... (dead address) as the new
delegated account.
Does the delegation expire?No, the delegation remains valid in perpetuity unless another 0x04 transaction is sent
changing the delegation to a different (or null) account.
Is EIP-7702 compatible with ERC-4337?Yes; after delegating with EIP-7702, any EOA may behave like an EIP-4337 smart account.
Simply initiate a transaction of type 0x04 while pointing to an address containing code
for the 4337-compatible smart account.
What happens if the EOA is pointing to a precompile address for code?When CALL, STATICCALL, DELEGATECALL and CALLCODE opcodes are called with enough gas,
the opcodes proceed with execution as if the EOA has no code.
Can you give me an example of submitting an EIP-7702 transaction using viem?import { createWalletClient, http, parseEther } from 'viem'import { monadTestnet } from 'viem/chains'import { privateKeyToAccount } from 'viem/accounts'
const account = privateKeyToAccount('0x...')
const walletClient = createWalletClient({  account,  chain: monadTestnet,  transport: http(),})
const authorization = await walletClient.signAuthorization({  account,  contractAddress: '0xFBA3912Ca04dd458c843e2EE08967fC04f3579c2'})
const hash = await walletClient.sendTransaction({  authorizationList: [authorization],  data: '0xdeadbeef',  to: walletClient.account.address,})

### Code Examples

```prism
import { createWalletClient, http, parseEther } from 'viem'import { monadTestnet } from 'viem/chains'import { privateKeyToAccount } from 'viem/accounts'
const account = privateKeyToAccount('0x...')
const walletClient = createWalletClient({  account,  chain: monadTestnet,  transport: http(),})
const authorization = await walletClient.signAuthorization({  account,  contractAddress: '0xFBA3912Ca04dd458c843e2EE08967fC04f3579c2'})
const hash = await walletClient.sendTransaction({  authorizationList: [authorization],  data: '0xdeadbeef',  to: walletClient.account.address,})
```

---

## Faucet

> Source: https://docs.monad.xyz/developer-essentials/faucet

On this page
Monad Faucet​
Phantom Faucet​Monad FaucetPhantom Faucet

---

## Gas Pricing

> Source: https://docs.monad.xyz/developer-essentials/gas-pricing

On this page

Summary​
Monad, like Ethereum, charges for processing transactions based on the complexity of the
transaction. Complexity is measured in units of gas.
This page summarizes how gas is charged, i.e. the conversion between the gas of a transaction
and the amount of MON that a user will have to pay.
A separate page, Opcode Pricing, describes how much
each opcode costs in units of gas.
FeatureDetailGas chargedThe gas charged for a transaction is the gas limit. DiscussionPrice per gasEIP-1559-compatible, i.e. price paid per unit of gas is the sum of a system-controlled base fee and a user-specified priority fee. DiscussionBase feeBase fee (aka base_price_per_gas) follows a dynamic controller, similar to the EIP-1559 controller but with slower increases and faster decreases. DetailsMinimum base fee100 MON-gwei (100 * 10^-9 MON)Block gas limit200M gasTransaction gas limit30M gasOpcode pricingSee Opcode PricingTransaction orderingDefault Monad client behavior is to order transactions according to a Priority Gas Auction (descending total gas price).
noteThese changes are covered formally in the
Monad Initial Spec Proposal
Gas definitions​
A common point of confusion among users is the distinction between gas of a transaction (units
of work) and the gas price of a transaction (price in native tokens per unit of work).
FeatureDefinitionGasA unit of work. Gas measures the amount of work the network has to do to process something. Since the network has multiple kinds of resources (network bandwidth, CPU, SSD bandwidth, and state growth), gas is inherently a projection from many dimensions into a single one.Gas price (price_per_gas)The price (in native tokens) paid to process one unit of gas.Gas limitThe maximum number of units of gas that a transaction is allowed to consume.
Gas limit, not gas used​
In Monad, the gas charged for a transaction is the gas limit set in the transaction, rather than
the gas used in the course of execution.
This is a design decision to support asynchronous execution. Under asynchronous execution,
leaders build blocks (and validators vote on block validity) prior to executing.
If the protocol charged gas_used, a user could submit a transaction with a large gas_limit
that actually consumes very little gas. This transaction would take up a lot of space toward the
block gas limit but wouldn't pay very much for taking up that space, opening up a DOS vector.
gas_paid = gas_limit * price_per_gas
EIP-1559 Compatibility​
Monad supports EIP-1559.
EIP-1559 (type 2) transactions have the parameters  priority_price_per_gas and
max_price_per_gas, which, together with base_price_per_gas (a system parameter that changes
each block), determine the gas bid for the transaction:
price_per_gas = min(base_price_per_gas + priority_price_per_gas, max_price_per_gas)
Notes:

base_price_per_gas is a system parameter that changes each block. Every transaction in the
same block will have the same base_price_per_gas
Users specify priority_price_per_gas and max_price_per_gas when signing a transaction
Since everyone in the same block will pay the same base_price_per_gas, the
priority_price_per_gas is a way for users to pay more to prioritize their transactions.
Since users don't determine base_price_per_gas, the max_price_per_gas is a safeguard that
limits the amount they may end up paying. Of course, if that value is set too low, the
transaction will not end up being chosen for inclusion.

This article provides another good explanation
of EIP-1559 gas pricing.
base_price_per_gas controller​
Monad uses a different controller for base_price_per_gas than Ethereum:
block_gask=∑tx∈blockkgas_limittxbase_price_per_gask+1=max⁡{min_base_price_per_gas,base_price_per_gask⋅exp⁡(ηk⋅block_gask−targetblock_gas_limit−target)}ηk=max_step_size⋅ϵϵ+momentk−trendk2trendk+1=β⋅trendk+(1−β)⋅(target−block_gask)momentk+1=β⋅momentk+(1−β)⋅(target−block_gask)2\begin{align*}
\mathrm{block\_gas}_{k} &= \sum\limits_{\mathrm{tx} \in \mathrm{block}_k}\mathrm{gas\_limit}_\mathrm{tx}\\
\mathrm{base\_price\_per\_gas}_{k+1} &= \max\left\{\text{min\_base\_price\_per\_gas}, \mathrm{base\_price\_per\_gas}_k \cdot \exp \left(
\eta_k \cdot \frac{\mathrm{block\_gas}_{k} - \text{target}}{\text{block\_gas\_limit} - \text{target}}
\right) \right\} \\
\eta_k &= \frac{\text{max\_step\_size}\cdot\epsilon}{\epsilon+\sqrt{\mathrm{moment}_k - \mathrm{trend}_k^2}} \\
\mathrm{trend}_{k+1} &= \beta\cdot \mathrm{trend}_k + (1-\beta)\cdot \left(\text{target}-\mathrm{block\_gas}_{k} \right) \\
\mathrm{moment}_{k+1} &= \beta\cdot \mathrm{moment}_k + (1-\beta)\cdot \left(\text{target}-\mathrm{block\_gas}_{k} \right)^2
\end{align*}block_gask​base_price_per_gask+1​ηk​trendk+1​momentk+1​​=tx∈blockk​∑​gas_limittx​=max{min_base_price_per_gas,base_price_per_gask​⋅exp(ηk​⋅block_gas_limit−targetblock_gask​−target​)}=ϵ+momentk​−trendk2​​max_step_size⋅ϵ​=β⋅trendk​+(1−β)⋅(target−block_gask​)=β⋅momentk​+(1−β)⋅(target−block_gask​)2​
This inductive formula starts with
base_price_per_gas0=0moment0=0trend0=0\begin{align*}
\mathrm{base\_price\_per\_gas}_{0} &= 0 \\
\mathrm{moment}_{0} &= 0 \\
\mathrm{trend}_{0} &= 0
\end{align*}base_price_per_gas0​moment0​trend0​​=0=0=0​
and with the following parameters:
max_step_size=1/28target=160M (80% full) β=0.96ϵ=target=160M\begin{align*}
\mathrm{max\_step\_size} &= 1/28 \\
\mathrm{target} &= 160\text{M}\ \text{(80\% full)}\ \\
\beta &= 0.96 \\
\epsilon &= \mathrm{target} = 160\text{M}
\end{align*}max_step_sizetargetβϵ​=1/28=160M (80% full) =0.96=target=160M​
And
min_base_price_per_gas=100 MON-gwei (100×10−9 MON)\text{min\_base\_price\_per\_gas} = 100\ \text{MON-gwei}\ (100 \times 10^{-9}\ \text{MON})min_base_price_per_gas=100 MON-gwei (100×10−9 MON)
Compared to the base_price_per_gas controller in Ethereum, this controller increases more
slowly and decreases more quickly. This is to avoid underutilization of blockspace due to an overpriced base_price_per_gas.
For a more comprehensive discussion of Monad controller design considerations and behavior, check out this blog post from Category Labs.
Recommendations for developers​
Set the gas limit explicitly if it is constant​
Many on-chain actions have a fixed gas cost. The simplest example is that a transfer of native
tokens always costs 21,000 gas, but there are many others.
For actions where the gas cost of the transaction is known ahead of time, it is recommended to set
it directly prior to handing the transaction off to the wallet. This offers several benefits:

It reduces latency and gives users a better experience, since the wallet doesn't have to call
eth_estimateGas and wait for the RPC to respond.
It retains greater control over the user experience, avoiding cases where the wallet sets a high
gas limit in a corner case as described in the warning below.

warningSome wallets, including MetaMask, are known to have the following behavior: when
eth_estimateGas is called and the contract call reverts, they set the gas limit for this
transaction to a very high value.This is the wallet's way of giving up on setting the gas limit and accepting whatever gas usage is
at execution time. However, it doesn't make sense on Monad where the full gas limit is charged.Contract call reversion happens whenever the user is trying to do something impossible. For
example, a user might be trying to mint an NFT that has minted out.If the gas limit is known ahead of time, setting it explicitly is best practice, since it ensures
the wallet won't handle this case unexpectedly.

### Code Examples

```prism
gas_paid = gas_limit * price_per_gas
```

```prism
price_per_gas = min(base_price_per_gas + priority_price_per_gas, max_price_per_gas)
```

---

## Historical Data

> Source: https://docs.monad.xyz/developer-essentials/historical-data

On this page

Summary​
Monad full nodes provide access to all historic transactional data (blocks, transactions, receipts,
events, and traces).
Monad full nodes do not provide access to arbitrary historic state.
solutionThere is a special RPC service at https://rpc-mainnet.monadinfra.com
that provides access to historical data. The following methods at that service support queries
referring to historical state:
debug_traceCall
eth_call
eth_createAccessList
eth_estimateGas
eth_getBalance
eth_getCode
eth_getTransactionCount
eth_getStorageAt

Background​
Blockchains are stateful systems; there are two main kinds of data:

transactional data (the list of transactions and their artifacts); and
state data (the current state of the world, resulting from applying those transactions
sequentially; stored in a merkle trie).

Transactional data consists of

blocks
transactions
receipts produced by executing those transactions
events (logs) emitted by smart contracts in the course of execution
detailed traces from each transaction's execution

State data consists of

for each account, its native token balance
for each smart contract, the storage mapping (which maps storage slots to values)

A typical node in a blockchain holds the current state, which is constantly being updated as new transactions are added. Recent historical states may be available as well, depending on how costly each incremental version is and how much disk space is available.
For reference, imagine maintaining a MySQL or Postgres table, where each INSERT or UPDATE query is a transaction. If the table is small enough, then it may be feasible to cache every new version of the table, but if it's a large table, you would probably expect to only have access to the current version.
The following describes historical data access in Monad:
Transactional data​
Monad full nodes provide access to all historic transactional data (blocks, transactions, receipts, events, and traces).1
State​
In Ethereum, a "full node" offers chain state for the current block and each block up to 128 blocks ago, while an "archive node" offers per-block chain state since genesis. That is, an Ethereum "archive node" is a differently-configured full node, run on a box with a large disk. This terminology is described further here.
In Monad, every "full node" is an "archive node" in the sense that every node maintains as many historical per-block state tries as it can. This means that the lookback depends on the size of disk chosen by the RPC provider. For a 2 TB SSD, this recently has corresponded to about 40,000 blocks, although it depends on the amount of state diffs in each block.
Due to Monad's high throughput, full nodes do not provide access to arbitrary historic state, as this would require too much storage.2
Methods like eth_call may reference recent states up to the point where the state trie was evicted.
When writing smart contracts, it is recommended to use events to log any state that will be needed later, or use a smart contract indexer to compute it off-chain.

Footnotes​


Implementation detail: recent transactional data is stored directly on the node, while older data is stored in a separate archive node as configured and operated by the RPC provider. ↩


With sufficient SSD capacity, a Monad full node would behave similarly to an Ethereum "archive" node in providing access to historical state since genesis. But in practice, due to larger changesets for each block (up to 5,000 transactions per block vs ~200 for Ethereum, i.e. 25x larger blocks) and more frequent blocks (0.4s for Monad vs 12s for Ethereum, i.e. 30x more frequent) no RPC provider is currently offering access to arbitrarily-far-back historical state. ↩

---

## Network Information - Mainnet

> Source: https://docs.monad.xyz/developer-essentials/network-information

On this page

NameValueNetwork NameMonad MainnetChain ID143Currency SymbolMONRPC URLsee belowBlock Explorer (MonadVision)https://monadvision.comBlock Explorer (Monadscan)https://monadscan.comBlock Explorer (Socialscan)https://monad.socialscan.ioNetwork Visualizationhttps://gmonads.comCurrent version / revisionv0.12.2-rc / MONAD_EIGHT
Other block explorers supported:

Detailed traces: Phalcon Explorer and Tenderly
UserOps: Jiffyscan

Public RPC Endpoints​
Public RPC endpoints are rate-limited but should be sufficient for basic usage. If you
need a higher-limit RPC endpoint, please see RPC Providers.
Websocket endpoints start with wss://. See Websocket Reference for
further information.
RPC URLProviderRate LimitsBatch Call LimitNoteshttps://rpc.monad.xyzwss://rpc.monad.xyzQuickNode25 rps100https://rpc1.monad.xyzwss://rpc1.monad.xyzAlchemy15 rps100debug_ and trace_ methods disabledhttps://rpc3.monad.xyzwss://rpc3.monad.xyzAnkr300 per 10s10debug_ methods disabledhttps://rpc-mainnet.monadinfra.comwss://rpc-mainnet.monadinfra.comMF20 rps1historical state lookups (e.g. eth_call) supported; see discussion
See RPC Limits for additional detail on method-specific limits.
Supported Infrastructure​
See the Tooling and Infrastructure page for a list of providers
supporting mainnet.
Canonical Contracts​
NameAddressWrapped MON0x3bd359C1119dA7Da1D913D1C4D2B7c461115433ACreate2Deployer0x13b0D85CcB8bf860b6b79AF3029fCA081AE9beF2CreateX0xba5Ed099633D3B313e4D5F7bdc1305d3c28ba5EdERC-2470 Singleton Factory0xce0042b868300000d44a59004da54a005ffdcf9fERC-4337 EntryPoint v0.60x5FF137D4b0FDCD49DcA30c7CF57E578a026d2789ERC-4337 SenderCreator v0.60x7fc98430eAEdbb6070B35B39D798725049088348ERC-4337 EntryPoint v0.70x0000000071727De22E5E9d8BAf0edAc6f37da032ERC-4337 SenderCreator v0.70xEFC2c1444eBCC4Db75e7613d20C6a62fF67A167CFoundry Deterministic Deployer0x4e59b44847b379578588920ca78fbf26c0b4956cMulticall30xcA11bde05977b3631167028862bE2a173976CA11MultiSend0x998739BFdAAdde7C933B942a68053933098f9EDaMultiSendCallOnly0xA1dabEF33b3B82c7814B6D82A79e50F4AC44102BPermit20x000000000022d473030f116ddee9f6b43ac78ba3Safe0x69f4D1788e39c87893C980c06EdF4b7f686e2938SafeL20xfb1bffC9d739B8D520DaF37dF666da4C687191EASafeSingletonFactory0x914d7Fec6aaC8cd542e72Bca78B30650d45643d7SimpleAccount0x68641DE71cfEa5a5d0D29712449Ee254bb1400C2Simple7702Account0xe6Cae83BdE06E4c305530e199D7217f42808555BSub Zero VanityMarket0x000000000000b361194cfe6312EE3210d53C15AAZoltu Deterministic Deployment Proxy0x7A0D94F55792C434d74a40883C6ed8545E406D12
Ecosystem contract addresses​
See the protocols repo.
Tokens​
See the token-list repo.
Here is a partial list:
NameAddressNotesWMON0x3bd359C1119dA7Da1D913D1C4D2B7c461115433AAUSD0x00000000eFE302BEAA2b3e6e1b18d08D69a9012aUSDC0x754704Bc059F8C67012fEd69BC8A327a5aafb603CCTPUSDT00xe7cd86e13AC4309349F30B3435a9d337750fC82DOFTWBTC0x0555E30da8f98308EdB960aa94C0Db47230d2B9cOFTWETH0xEE8c0E9f1BFFb4Eb878d8f15f368A02a354812422/2 NTT BridgewstETH0x10Aeaf63194db8d453d4D85a06E5eFE1dd0b5417CCIPWSOL0xea17E5a9efEBf1477dB45082d67010E2245217f1WormholeXAUt00x01bFF41798a0BcF287b996046Ca68b395DbC1071OFT
MON on other blockchains​
Partial list of wrapped MON addresses on other blockchainsNameBlockchainAddressNotesWMONSolanaCrAr4RRJMBVwRsZtT62pEhfA9H5utymC2mVx8e7FreP2WMONEthereum0x6917037f8944201b2648198a89906edf863b95172/2 NTT

---

## Network Information - Testnets

> Source: https://docs.monad.xyz/developer-essentials/testnets

On this page

Summary​
NetworkPurposetestnetPrimary testnet environment with hundreds of apps deployedtempnetTransient network subject to resets; used as a sandbox for new features
testnet​
NameValueChain ID10143Network NameMonad TestnetCurrency SymbolMONRPC URLsee belowBlock Explorer (MonadVision)https://testnet.monadvision.comBlock Explorer (Monadscan)https://testnet.monadscan.com/Block Explorer (Socialscan)https://monad-testnet.socialscan.io/Network visualizationhttps://www.gmonads.com/?network=testnetApp hubhttps://testnet.monad.xyz/Faucethttps://faucet.monad.xyzCurrent version / revisionv0.12.2-rc / MONAD_EIGHTChangelog(link)
Public RPC Endpoints​
Websocket endpoints start with wss://. See Websocket Reference for
further information.
RPC URLProviderRate LimitsBatch RequestsArchive SupportNoteshttps://testnet-rpc.monad.xyzwss://testnet-rpc.monad.xyzQuickNode25 rps100✅https://rpc.ankr.com/monad_testnetAnkr300 reqs / 10s12000 reqs / 10 min100❌debug_* methods are not allowedhttps://rpc-testnet.monadinfra.comwss://rpc-testnet.monadinfra.comMonad Foundation20 rpsnot allowed✅eth_getLogs and debug_* methods are not allowed
See RPC Limits for additional detail on method-specific limits.
Canonical Contracts​
NameAddressCreateX0xba5Ed099633D3B313e4D5F7bdc1305d3c28ba5EdFoundry Deterministic Deployer0x4e59b44847b379578588920ca78fbf26c0b4956cEntryPoint v0.60x5FF137D4b0FDCD49DcA30c7CF57E578a026d2789EntryPoint v0.70x0000000071727De22E5E9d8BAf0edAc6f37da032Multicall30xcA11bde05977b3631167028862bE2a173976CA11Permit20x000000000022d473030f116ddee9f6b43ac78ba3SafeSingletonFactory0x914d7Fec6aaC8cd542e72Bca78B30650d45643d7UniswapV2Factory0x733e88f248b742db6c14c0b1713af5ad7fdd59d0UniswapV3Factory0x961235a9020b05c44df1026d956d1f4d78014276UniswapV2Router020xfb8e1c3b833f9e67a71c859a132cf783b645e436Uniswap UniversalRouter0x3ae6d8a282d67893e17aa70ebffb33ee5aa65893WrappedMonad0x760AfE86e5de5fa0Ee542fc7B7B713e1c5425701
See also:

Uniswap deployments

Testnet Tokens (partial list)​
See tokenlist-testnet.json.
tempnet​
tempnet runs the devnet ChainConfig with version v0.12.2-rc.
NameValuePurposeTransient network; sandbox for new features. Currently a sandbox for the Opcode pricing changesChain ID20143RPC URLPlease submit this form. You will need to join the Monad Developer DiscordBlock Explorern/aFaucetPlease submit this form. You will need to join the Monad Developer DiscordCurrent version / revisionv0.12.2-rc / MONAD_EIGHT

---

## Opcode Pricing

> Source: https://docs.monad.xyz/developer-essentials/opcode-pricing

On this page

Summary​
Monad is a highly optimized system that introduces efficiencies across all dimensions -
compute, state access, and bandwidth utilization. However, the multiplier relative to legacy
EVM systems is not equal across all dimensions. As a result, some opcode gas price
changes are needed so that applications can unlock the full potential of the chain.
To minimize the number of gas price changes, rather than adjusting the gas pricing of almost
all opcodes down, Monad instead adjusts a few opcode prices up. This has the same relative
effect as discounting almost all opcodes.
The following costs are changed:

Cold access to state
A few precompiles

All other costs are as on Ethereum; evm.codes is a helpful reference.
noteThese changes are covered formally in the
Monad Initial Spec Proposal
Why are changes needed?​
The EVM's current pricing model needs adaptation to support a high-performance, low-fee regime.
The pricing model assigns a weight (gas amount) to each opcode based on perceived costliness to
the system, then charges the user only based on the calculated sum of weights. As resource
scarcity changes - and especially in the event of a completely new system - those weightings
must be revised.
The changes described in this page make the minimal set of adjustments to allow Monad to
deliver high performance and low fees, while minimizing disruption to users and protecting
the system against DOS attacks.
Cold access cost​
To account for the relatively higher cost of state reads from disk when compared to computation in the Monad execution client,
the cost for "cold" account and storage access costs changes:
Access TypeEthereumMonadAccount260010100Storage21008100
The following opcodes are impacted because of the differed gas costs:

Account access: BALANCE, EXTCODESIZE, EXTCODECOPY, EXTCODEHASH, CALL, CALLCODE,
DELEGATECALL, STATICCALL, SELFDESTRUCT
Storage access: SLOAD, SSTORE

noteGas costs for warm account access (100 gas) and storage access (100 gas) are the same on Monad as on Ethereum.
Precompiles​
A few precompiles have been repriced to accurately reflect their relative costs in execution.
PrecompileAddressEthereumMonadMultiplierecRecover0x01300060002ecAdd0x06150*300*2ecMul0x076000*30,000*5ecPairing0x0845,000*225,000*5blake2f0x09rounds∗1\text{rounds} * 1rounds∗1rounds∗2\text{rounds} * 2rounds∗22point eval0x0a50,000200,0004
∗: Per input/operation, as defined in the respective precompile specification

---

## Precompiles

> Source: https://docs.monad.xyz/developer-essentials/precompiles

All Ethereum precompiles as of the Pectra fork (0x01 to 0x11), plus precompile 0x0100
(RIP-7212;
signature verification of secp256r1 aka P256), are supported.
Some external references are helpful:

For 0x01 to 0x0a, see evm.codes
For 0x0b to 0x11 (BLS12-381 utilities), see EIP-2537
For 0x0100 (secp256r1/P256 signature verification), see RIP-7212

AddressNameGasNotes0x01ecRecover6000ECDSA public key recovery function0x02sha25660 + 12 * word_sizehash function0x03ripemd160600 + 120 * word_sizehash function0x04identity15 + 3 * word_sizereturns the input0x05modexpsee gas detailarbitrary-precision exponentiation under modular arithmetic0x06ecAdd300point addition (ADD) on the elliptic curve alt_bn1280x07ecMul30,000scalar multiplication (MUL) on the elliptic curve alt_bn1280x08ecPairing225,000bilinear function on groups on the elliptic curve alt_bn1280x09blake2frounds * 2compression function F used in the BLAKE2 cryptographic hashing algorithm0x0apoint_eval200,000verify KZG commitments (see description in EIP-4844)0x0bbls12_g1_add375point addition in G1 (curve over base prime field). See EIP-25370x0cbls12_g1_msmsee EIP-2537multi-scalar-multiplication (MSM) in G10x0dbls12_g2_add600point addition in G2 (curve over quadratic extension of the base prime field)0x0ebls12_g2_msmsee EIP-2537MSM in G20x0fbls12_pairing_checksee EIP-2537pairing operation between a set of pairs of (G1, G2) points0x10bls12_map_fp_to_g15500maps base field element into the G1 point0x11bls12_map_fp2_to_g223800maps extension field element into the G2 point0x0100p256_verify6900signature verification of the secp256r1 (aka P256) elliptic curve. See RIP-72120x1000stakingvaries by function callstaking precompile. See staking
Note that a few precompiles (namely 0x01, 0x06, 0x07, 0x08, 0x09, and 0x0a) have been
repriced relative to Ethereum, as discussed here.
See also the source code.

---

## Reserve Balance

> Source: https://docs.monad.xyz/developer-essentials/reserve-balance

On this page

Introduction​
The Reserve Balance mechanism is a set of light constraints - at consensus time on which
transactions can be included, and at execution time on which transactions don't revert - which
allow Monad to simultaneously support asynchronous execution
and EIP-7702.
The Reserve Balance mechanism is designed to preserve safety under asynchronous execution
without interfering with normal usage patterns. Most users and developers need not worry
about the Reserve Balance constraints, however we provide the details here for those
encountering corner cases.
Summary​
Asynchronous execution means that nodes achieve consensus on a block proposal prior to executing
the transactions in that block. Execution is required to be completed in the next k (delay
factor) blocks. (Currently k=3.)
Because consensus operates on a k-block delayed view of the global state, it is necessary
to adjust the consensus and execution rules slightly to allow consensus to safely build
and validate blocks that include only transactions whose gas costs can be paid for.
Monad introduces the Reserve Balance mechanism to allow consensus and execution
to collaborate across a multi-block lag to ensure that all EOAs must have enough MON
in their account to pay for gas for any transaction included in the blockchain.
Inflight transactionThroughout this document, an inflight transaction refers to a transaction that has
been included in a block less than k blocks ago.
Here is a very brief summary of the rules:

From the perspective of a particular EOA, MON spent from that EOA in the course of a transaction
is partitioned into two parts: gas spend and value spend.

In the case where the EOA was the sender, gas spend is gas_price * gas_limit, and
value spend is the value parameter on that transaction
In the case where the EOA wasn't the sender (where they delegated via EIP-7702 and some other
EOA submitted a transaction which called this EOA), gas spend is 0, and value spend
is whatever MON is sent out during the course of executing this EOA's code


Let user_reserve_balance = 10 MON
Execution time: during execution, transactions revert due to value spend when that
account balance dips below user_reserve_balance. An exception is made (i.e. the transaction
does not revert) for accounts that are undelegated and have no inflight transactions within the past k
blocks.
Consensus time: For each account, consensus has a budget for the gas spend for all inflight
transactions; this budget is user_reserve_balance (or the account's balance from the lagged
execution state, whichever is lower). The budget is further reduced if the first inflight
transaction earned the exception mentioned above, by that transaction's value spend.
When performing block validity checks for block n, consensus checks that the budget is not exceeded.

infoSee also the formal definition in the
Monad Initial Spec
proposal from Category Labs.
Parameters​
ParameterValueuser_reserve_balance10 MON
Why is reserve balance needed?​
Monad has asynchronous execution: consensus is allowed to progress with building and
validating blocks without waiting for execution to catch up. Specifically, proposing
and validating consensus block n only requires knowledge of the state obtained after
applying block n-k.
While asynchronous execution has performance benefits, it introduces a novel challenge:
how is consensus supposed to know the validity of a block if it does not have the latest
state?
Let’s illustrate this challenge with an example (for our examples, we will use k = 3):
Consensus is validating block 4, which contains a transaction t from Alice with the
relevant fields as:
sender=Alice, to=Bob, value=100, gas=1
Consensus only has the state that was obtained by executing block 1:
block=1, balances={Alice: 110}
If consensus simply accepts block 4 as valid because Alice appears to have enough
balance, it risks a safety failure. For instance, Alice may have already spent her
balance in transaction t’ in block 2. This creates a denial-of-service (DoS)
vector, as Alice could cause consensus to include many transactions for free.
First attempt at a solution​
One idea is for the consensus client to statically inspect transactions in blocks 2
and later, checking if Alice has spent any value in her transactions. This would let
consensus reject block 4 as invalid if any transaction before t (such as t') in
blocks 2, 3, or 4 originates from Alice and spends some value or gas.
While this is a fine solution on the face of it, it suffers from two shortcomings:


Suppose, as part of smart contract execution in blocks 2 or 3, Alice received a lot
of currency. She would have had enough balance to pay for transaction t despite
t' existing, if only we had the latest state. So, rejecting transactions based
solely on static checks is overly restrictive.


It is not only restrictive, it is also not safe with EIP-7702. With EIP-7702, Alice
could have her account delegated to a smart contract, which can transfer out currency
from Alice’s account in a way that is not statically inspectable by consensus.
Concretely in our example, Alice does not need to send a transaction like t' from
her account in order to spend currency from her account, if her account is delegated.
A spend could potentially be triggered by a transaction submitted by anyone else.
So our static check would not succeed and it may be unsafe to accept block 4 as valid
even if we don’t see any other transaction from Alice in blocks 2, 3 and 4.


Reserve balance as the solution​
Simple version​
Intuitively, the core idea of reserve balance is as follows: if consensus and execution
agree ahead of time that, for each EOA, execution will prevent the account balance from
dropping below a certain pre-determined threshold known to consensus, then consensus
can then safely include transactions whose gas expenditures stay below that threshold,
without knowing the latest state and without being vulnerable to the DoS vector described
above.
In our example, if execution ensures that Alice’s account cannot be drawn below
10 MON (otherwise, the withdrawing transactions are reverted), then consensus can
safely include transaction t, as by definition Alice’s account will have at least
10 MON to pay for transaction t.
This concept can be generalized as follows:

Execution reverts any transaction that causes an account’s balance to dip below
user_reserve_balance, except due to transaction fees.
Consensus accepts transactions from user u after the delayed state s as long as
the sum of the gas fees for all inflight transactions sent by u is below a parameter
called user_reserve_balance.

In Monad, user_reserve_balance is currently set to 10 MON for each EOA.
An additional refinement to improve UX​
One criticism of the above rule is that it is difficult for users with balances
below the reserve to do anything that requires MON other than for gas fees.
For instance, the following behaviors might be desired, but are currently blocked
by the above rule (with user_reserve_balance set to 10 MON):

Alice has a balance of 5 MON and wants to send 4.99 MON to Bob (plus pay 0.01 MON
in gas)
Alice has a balance of 20 MON and wants to swap 18 MON into a memecoin (plus pay
0.01 MON in gas)

To address this, we add some additional conditions where transactions are allowed.
First let's define an "emptying transaction":
Emptying TransactionAn "emptying transaction" is a transaction that (when evaluated at time of execution)
takes the balance below the reserve balance.
Notice that if a user account is not EIP-7702-delegated, then consensus can simply
inspect transactions statically in order to estimate the lowest a user’s balance can
possibly go (since an undelegated user’s account can only be debited due to value transfers
and gas fees specified in the transaction data).
Therefore, we add the following rule:

Execution policy: for each undelegated account sender, if a transaction is the
first inflight transaction from that sender within k blocks, and the transaction would have
otherwise reverted due to taking balance below reserve balance, allow that transaction
to proceed anyway (an "emptying transaction").
Consensus policy: for each undelegated account sender, if a transaction is the
first inflight transaction from that sender within k blocks,
i.e. will end up proceeding as an "emptying transaction" during execution,
then statically inspect that transaction's
total MON needs (i.e. gas_bid * gas_limit + value), and take into account the fact that execution will still
allow this transaction through. This means that for any subsequent transactions in
the next k blocks, the reserve balance that consensus is working with will be lower
by value.

This rule lets execution allow undelegated accounts to dip below the reserve balance
once every k blocks. Since k blocks is 1.2 seconds, this policy should allow most small
accounts to still interact with the blockchain normally.
"Undelegated" means here the account is never delegated in any of the prior k blocks'
interim states, see Full specification for details.
The additional policy allows both of the examples mentioned at the start of this section,
as long as they are the first transaction sent by the sender in k blocks.
Transactions that are included but revert​
Because of the Reserve Balance rules, you may see transactions included in the chain whose
execution reverts, such as transactions trying to transfer out more MON than are in the account
balance.
These transactions are still valid transactions that pay for gas, but the
result of these transactions is nothing except for gas being decremented from the sender.
They are included because at the time of consensus, the proposer cannot be sure that the account
isn't going to receive more MON from someone else, and the sender has the budget to pay for gas.
Ethereum includes many transactions whose execution reverts, so this is not a protocol difference.
However, in practice, Ethereum block builders may screen out transactions with insufficient balance
to process a transfer out, so this behavior may be different from what you're accustomed to seeing.
Full specification​
See the
reserve balance spec
for the formal set of Reserve Balance rules.
Algorithms 1 and 2 implement this check for consensus and execution, respectively.
Algorithm 3 implements the mechanism to detect the dipping into the reserve balance
(Algorithm 2 uses Algorithm 3 to revert transactions that dip).
Algorithm 4 specifies the criteria for emptying transactions:

The sender account must be undelegated in the prior k blocks. This is checked
statically by verifying the account was undelegated in a known state in the past
k blocks, and there has been no change in its delegation status in the last k
blocks (this can be inspected statically).
There must not be another transaction from the same sender in the prior k blocks.

Here is a quick summary of the reserve balance rules at consensus time:
If the account is not delegated and there are no inflight transactions​
If the account is not delegated, and there are no previous inflight transactions, then consensus
checks that the gas fee for this transaction is less than the balance from the lagged state.
gas_fees(tx)≤balance\text{gas\_fees}(\text{tx}) \leq \text{balance}gas_fees(tx)≤balance
If the account is not delegated and has one emptying inflight transaction​
If the account is not delegated, and there is one previous inflight transaction, then
consensus has to take into account the inflight transaction's total MON expenditures
(including value):
let adjusted_balance=balance−(first_tx.value+gas_fees(first_tx))\text{let adjusted\_balance} = \text{balance} - (\text{first\_tx.value} + \text{gas\_fees}(\text{first\_tx}))let adjusted_balance=balance−(first_tx.value+gas_fees(first_tx))
let reserve=min⁡(user_reserve_balance(t.sender),adjusted_balance)\text{let } \text{reserve} = \min(\text{user\_reserve\_balance}(t.\text{sender}), \text{adjusted\_balance}) \quadlet reserve=min(user_reserve_balance(t.sender),adjusted_balance)
A new transaction can only be included if the sum of all inflight transactions' gas fees
(excluding the first one) is less than the reserve:
∑tx∈I[1:]gas_fees(tx)≤reserve\sum_{tx \in I[1:]} \text{gas\_fees}(tx) \leq \text{reserve}tx∈I[1:]∑​gas_fees(tx)≤reserve
All other cases​
The reserve is equal to minimum of systemwide reserve balance (10 MON) or the
account's balance at block n - k:
reserve=min⁡(user_reserve_balance(t.sender),balance)\text{reserve} = \min(\text{user\_reserve\_balance}(t.\text{sender}), \text{balance})reserve=min(user_reserve_balance(t.sender),balance)
A new transaction can only be included if the sum of all inflight transactions' gas fees
is less than the reserve:
∑tx∈Igas_fees(tx)≤reserve\sum_{tx \in I} \text{gas\_fees}(tx) \leq \text{reserve}tx∈I∑​gas_fees(tx)≤reserve
Adjusting the reserve balance​
The reserve balance is currently the same for every account (10 MON).
In a future version, the protocol could allow users, through a stateful precompile, to
customize their reserve balance.
Coq proofs​
The safety of the reserve balance specification has been formally proved in Coq.
The full proofs documentation is available
here.
The consensus check is formalized in Coq as consensusAcceptableTxs. The predicate,
consensusAcceptableTxs s ltx, defines the criteria for the consensus module to accept
the list of transactions ltx on top of state s.
The proof shows that consensusAcceptableTxs s ltx implies that when the execution
module executes all the transactions in ltx one by one on top of s, none of them will
fail due to having insufficient balance to cover gas fees. The proof is by induction
on the list ltx: one can think of this as doing natural induction on the length of ltx.
The proof in the inductive step involves unfolding the definitions of the consensus
and execution checks and considering all the cases. In each case, the estimates of
effective reserve balance in consensus checks is shown to be conservative with respect
to what happens in execution.
Additional examples​
To test your understanding, here are some examples along with the expected outcome.
Each example is independent.
In the following examples, we use start_block = 2, meaning the initial balances
and reserves are after block 1. We also specify the reserve balance parameter for
each example, although it is a constant system wide parameter.
For each transaction, the expected result is indicated by a code:

2: Successfully executed
1: Included but reverted during execution (due to reserve balance dip)
0: Excluded by consensus

Example 1: Basic transaction inclusion​
Initial state:
Alice: balance = 100, reserve = 10Bob: balance = 5, reserve = 10
Transactions:
Block 2: [  Alice: send 1 MON, fee 0.05 — Expected: 2  Bob: send 2 MON, fee 0.05 — Expected: 2]
Final balances:
Alice: 98.95Bob: 2.95
Example 2: Low reserve balance but high balance​
Initial state:
Alice: balance = 100, reserve = 1
Transactions:
Block 2: [  Alice: send 3 MON, fee 2 — Expected: 2 (emptying transaction)  Alice: send 3 MON, fee 2 — Expected: 0 (excluded)]
Final balance:
Alice: 95.0
Example 3: Multi-block, low reserve but high balance​
Initial state:
Alice: balance = 100, reserve = 1
Transactions:
Block 2: [  Alice: send 3 MON, fee 2 — Expected: 2]
Block 5: [  Alice: send 3 MON, fee 2 — Expected: 2]
Final balance:
Alice: 90.0
Example 4: Comprehensive​
Initial state:
Alice: balance = 100, reserve = 1
Transactions:
Block 2: [  Alice: send 99 MON, fee 0.1 — Expected: 2 (large emptying transaction)]
Block 3: [  Alice: send 0.5 MON, fee 0.99 — Expected: 0 (excluded)]
Block 4: [  Alice: send 0.8 MON, fee 0.1 — Expected: 1 (included but reverted)]
Block 5: [  Alice: send 0 MON, fee 0.9 — Expected: 0 (excluded)  Alice: send 5 MON, fee 0.1 — Expected: 1 (included but reverted)  Alice: send 5 MON, fee 0.8 — Expected: 0 (excluded)]
Final balance:
Alice: 0.70
Example 5: Edge case — zero value transactions​
Initial state:
Alice: balance = 2, reserve = 1
Transactions:
Block 2: [  Alice: send 0 MON, fee 0.5 — Expected: 2  Alice: send 0 MON, fee 0.6 — Expected: 2  Alice: send 0 MON, fee 0.5 — Expected: 0 (exceeds reserve)]
Final balance:
Alice: 0.9
Example 6: Reserve balance boundary​
Initial state:
Alice: balance = 10, reserve = 2
Transactions:
Block 2: [  Alice: send 1 MON, fee 2 — Expected: 2 (matches reserve)  Alice: send 0 MON, fee 0.01 — Expected: 2]
Final balance:
Alice: 6.99
Example 7: Account delegated in the interim​
Initial state:
Alice: balance = 15, reserve = 10
Transactions:
Block 1: []
Block 2: [  Alice is delegated  Bob on behalf of Alice's: send 5 MON, fee 0 — Expected: 2 (executed)  Alice is undelegated]
Block 3: [  Alice: send 3 MON, fee 0.1 — Expected: 1 (included but reverted)]
Block 4: []
Block 5: [  Alice: send 0 MON, fee 8 - Expected: 2 (executed)]
Final balance:
Alice: 1.9
NOTE: If execution would not have reverted transaction in Block 3 (by checking delegation
status in prior k blocks), consensus would include transaction in Block 5 which would later run
out of MON for the fee.
Also, consider Block 2 is empty instead. Transaction in Block 3 is then an emptying transaction,
which proceeds with execution, but transaction in Block 5 is excluded as not having enough reserve
for fee.
Example 8: Account receives MON before second inflight tx​
Initial state:
Alice: balance = 15, reserve = 10
Transactions:
Block 1: []
Block 2: [  Alice: send 6 MON, fee 0.1 - Expected: 2 (executed, emptying tx)]
Block 3: [  Alice receives 6 MON from a smart contract   Alice: send 7 MON, fee 0.1 — Expected: 1 (included but reverted, cannot be 2nd emptying so soon)]
Block 4: []
Block 5: [  Alice: send 0 MON, fee 8 - Expected: 2 (executed)]
Final balance:
Alice: 6.8
NOTE: If execution would not have reverted the 2nd transaction in Block 3 (from Alice; by
checking existence of emptying transactions in prior k blocks), consensus would include
transaction in Block 5 which would later run out of MON for the fee.
Also, consider Block 2 is empty instead. Transaction in Block 3 (from Alice) is then an emptying
transaction, which proceeds with execution, but transaction in Block 5 is excluded as one
potentially not having enough reserve for fee - consensus doesn't see Alice being credited in
Block 3.

### Code Examples

```prism
sender=Alice, to=Bob, value=100, gas=1
```

```prism
block=1, balances={Alice: 110}
```

```prism
Alice: balance = 100, reserve = 10Bob: balance = 5, reserve = 10
```

```prism
Block 2: [  Alice: send 1 MON, fee 0.05 — Expected: 2  Bob: send 2 MON, fee 0.05 — Expected: 2]
```

```prism
Alice: 98.95Bob: 2.95
```

```prism
Alice: balance = 100, reserve = 1
```

```prism
Block 2: [  Alice: send 3 MON, fee 2 — Expected: 2 (emptying transaction)  Alice: send 3 MON, fee 2 — Expected: 0 (excluded)]
```

```prism
Alice: 95.0
```

```prism
Alice: balance = 100, reserve = 1
```

```prism
Block 2: [  Alice: send 3 MON, fee 2 — Expected: 2]
Block 5: [  Alice: send 3 MON, fee 2 — Expected: 2]
```

```prism
Alice: 90.0
```

```prism
Alice: balance = 100, reserve = 1
```

```prism
Block 2: [  Alice: send 99 MON, fee 0.1 — Expected: 2 (large emptying transaction)]
Block 3: [  Alice: send 0.5 MON, fee 0.99 — Expected: 0 (excluded)]
Block 4: [  Alice: send 0.8 MON, fee 0.1 — Expected: 1 (included but reverted)]
Block 5: [  Alice: send 0 MON, fee 0.9 — Expected: 0 (excluded)  Alice: send 5 MON, fee 0.1 — Expected: 1 (included but reverted)  Alice: send 5 MON, fee 0.8 — Expected: 0 (excluded)]
```

```prism
Alice: 0.70
```

```prism
Alice: balance = 2, reserve = 1
```

```prism
Block 2: [  Alice: send 0 MON, fee 0.5 — Expected: 2  Alice: send 0 MON, fee 0.6 — Expected: 2  Alice: send 0 MON, fee 0.5 — Expected: 0 (exceeds reserve)]
```

```prism
Alice: 0.9
```

```prism
Alice: balance = 10, reserve = 2
```

```prism
Block 2: [  Alice: send 1 MON, fee 2 — Expected: 2 (matches reserve)  Alice: send 0 MON, fee 0.01 — Expected: 2]
```

```prism
Alice: 6.99
```

```prism
Alice: balance = 15, reserve = 10
```

```prism
Block 1: []
Block 2: [  Alice is delegated  Bob on behalf of Alice's: send 5 MON, fee 0 — Expected: 2 (executed)  Alice is undelegated]
Block 3: [  Alice: send 3 MON, fee 0.1 — Expected: 1 (included but reverted)]
Block 4: []
Block 5: [  Alice: send 0 MON, fee 8 - Expected: 2 (executed)]
```

```prism
Alice: 1.9
```

```prism
Alice: balance = 15, reserve = 10
```

```prism
Block 1: []
Block 2: [  Alice: send 6 MON, fee 0.1 - Expected: 2 (executed, emptying tx)]
Block 3: [  Alice receives 6 MON from a smart contract   Alice: send 7 MON, fee 0.1 — Expected: 1 (included but reverted, cannot be 2nd emptying so soon)]
Block 4: []
Block 5: [  Alice: send 0 MON, fee 8 - Expected: 2 (executed)]
```

```prism
Alice: 6.8
```

---

## Staking

> Source: https://docs.monad.xyz/developer-essentials/staking/

Monad uses staking to determine the voting weights and leader schedule in
MonadBFT. Validators must stake at least a minimum amount,
plus others can delegate to them.
When a block is produced, the leader who produced that block earns a block reward, which is
distributed to each delegator of that leader, pro rata to their portion of that leader's stake,
minus a commission.
Check out the topics below:


Staking Behavior describes how the staking system works. Users should
refer to this page to understand the relevant parameters and time periods.


Staking Precompile describes the interface of the staking precompile.
Developers building functionality that interacts with the trading system should review the
Staking Behavior, then go here.

---

## Staking Behavior

> Source: https://docs.monad.xyz/developer-essentials/staking/staking-behavior

On this page

Overview​
Monad uses staking to determine validator voting weights and each epoch’s leader schedule.
When a block is produced, the leader who produced that block earns a block reward, which is
distributed to each delegator of that leader, pro rata to their portion of that leader's stake,
minus a commission.  Validators must stake at least a minimum amount and others can delegate to them.
FeatureDetailsIn-protocol delegationSupportedValidator commissionEach validator sets a fixed percentage of the block reward to keep for themselves before sharing the rest of the reward prorata by stake.You should choose a validator that you trust whose commission you're happy with.The min commission is 0%, the max commission is 100%.Source of rewardsSuccessful proposal of a block by a leader earns a reward from two components: (1) a fixed reward derived from inflation (REWARD), and (2) the priority fees from all the transactions in the block.Inflationary rewardThe fixed reward (REWARD) is shared among all delegators of that validator after deducting the validator commission.As a delegator, your proportion of the remainder is your proportion of the total stake on that validator.For example: if you have delegated to a validator and comprise 20% of that validator's total stake, the reward for that block is 10 MON, and the commission is 10%, then you would receive 10 MON * 90% * 20% = 1.8 MON.Priority feesCurrently, priority fees only go to the validator. Validators may choose to donate their priority fees back to the delegators (including themselves) by using the externalReward method on the staking precompile.Reward claiming / compoundingEach delegation accumulates rewards. You can choose either to claim or compound any accumulated rewards.Claimed rewards get withdrawn to your account, while compounded rewards are added to your delegation.Active validator setValidators must have self-delegated a minimum amount (MIN_AUTH_ADDRESS_STAKE)must have a total delegation of at least a certain amount (ACTIVE_VALIDATOR_STAKE), andmust be in the top NUM_ACTIVE_VALIDATORS validators by stake weight in order to be part of the active validator set.
Epochs, Boundaries, and Timing​
An epoch uses one set of delegations and leader validators for the entire epoch. While anyone may initiate staking operations like adding validators, or delegation and undelegation of stakes at any time, these actions only take effect at the start of a new epoch.
Every 50,000 blocks (the BOUNDARY_BLOCK_PERIOD) is a boundary block that commits the upcoming staking changes and the associated validator set to be used in the next epoch. Boundary blocks happen approximately every 5.5 hours. The next epoch does not start immediately at the boundary block, but after a 5,000 round delay (the EPOCH_DELAY_ROUNDS) between the boundary block and the end of the current epoch to allow for nodes to all have updated epoch information.

noteA round is not a block. A round increments regardless of missed block proposals. This means that the start of an epoch can be fewer than 5,000 blocks after the boundary. The actual start and end of an epoch cannot be calculated with a modulo operation on block or round number, and you should use getEpoch() to find the current epoch.
Timing examples​
Most staking actions take effect after they are included into a boundary block and then the next epoch starts. However, you can immediately collect rewards as they are earned. (Three publicly callable staking methods take immediate effect: claimRewards(), externalReward(), and changeCommission())
As an example of timing, we’ll look at delegate() in a transaction. Suppose we are currently in epoch #4:

If the delegate() takes place in epoch #4 before the boundary block for epoch #5, then the stake will be included in epoch #5.
If the delegate() transaction is made in the boundary block, then it will not be included in epoch #5, since the snapshot is taken at the start of the block and user transactions during the block take place after the snapshot. However, the delegation will be picked up in the boundary block for epoch #6, and then included in epoch #6.
If the delegate() transaction is after the boundary block and before the end of epoch #4, then the delegation will take effect in #6 since it missed being included in #5.

getEpoch() returns the current epoch and a boolean marking if the boundary snapshot for the next epoch has already happened. So if you call getEpoch(), and it returns (1000, false), then changes will go into the next epoch (1001). If it returns (1000, true), then the boundary has passed, and changes made now will be live two epochs in the future (1002).
Consensus, Snapshot and Execution Views​
The Monad execution component is responsible for the record of validator set and staking delegation. All staking-related state changes are queued and applied deterministically during execution. Monad’s consensus layer then uses these changes during a future epoch.
When validators are added, users make delegation changes, or any other staking transactions happen they immediately update the execution view of the staking system.
At the start of the boundary block, the current execution view is copied into the snapshot view. Any transaction changes after this point will not affect the following epoch. The snapshot now matches what the next epoch will look like.
After the EPOCH_DELAY_ROUNDS of 5,000 rounds from the boundary block, the new epoch starts and the snapshot view is copied into the consensus view. The consensus view always holds the validators and voting stake weights that are being used by the Monad consensus system for this block and the remainder of the epoch.
Slashing​
Robust logging provides accountability for malicious, slashable offenses. However, in-protocol, automated slashing is not currently implemented.
Constants​
ConstantMeaningValueBOUNDARY_BLOCK_PERIODblocks from boundary block to boundary block50,000 blocksEPOCH_DELAY_ROUNDSrounds between the boundary block and the start of each epoch5,000 roundsWITHDRAWAL_DELAYnumber of epochs before unstaked tokens can be withdrawn1 epochMIN_AUTH_ADDRESS_STAKEmin amount of MON self-delegated by a validator for it to be eligible for the active set100,000 MONACTIVE_VALIDATOR_STAKEmin amount of MON staked with a validator for it to be eligible for the active set10,000,000 MONACTIVE_VALSET_SIZEnumber of validators in the active set200REWARDMON reward per block25 MON
The BOUNDARY_BLOCK_PERIOD is denominated in blocks, while EPOCH_DELAY_ROUNDS is denominated in rounds. If perfect consensus is achieved, these will increment at the same rate. However, upon a failed block proposal (e.g. timeout), the round will increment while the block will not.

---

## Staking Precompile

> Source: https://docs.monad.xyz/developer-essentials/staking/staking-precompile

On this page

noteThis page is intended for developers looking to build smart contracts or interfaces
that interact with the staking system.
The entrypoint to the staking system is the stateful staking precompile.
This precompile allows delegators and validators to take actions that
affect the composition of the validator set.

join the validator set (addValidator)
delegate their stake to a validator (delegate)
undelegate their stake from a validator (a multi-step process: undelegate,
wait WITHDRAWAL_DELAY epochs, then withdraw)
compound the rewards they earned as a delegator (i.e. delegate the rewards)
(compound)
claim the rewards they earned as a delegator (claimRewards)

For ease of integration, please see the Solidity Interface
and the ABI JSON.
Although users may delegate or undelegate at any time, stake weight changes only take effect at
epoch boundaries, and stake weight changes made too close to the start of the epoch will be queued until
the next epoch boundary, as described in Staking Behavior.  This is to
allow for the separation of consensus and execution, one of Monad's core design attributes.
noteOnly standard CALLs are allowed to the staking precompile. In particular,
STATICCALL and DELEGATECALL are not allowed.Because the staking system is a precompile and not a smart contract,
you cannot test against it in a forked environment.
Precompile Address and Selectors​
The contract address is 0x0000000000000000000000000000000000001000.
The external functions are identified by the following 4-byte selectors.
External state-modifying methods:

addValidator(bytes,bytes,bytes) - 0xf145204c
delegate(uint64) - 0x84994fec
undelegate(uint64,uint256,uint8) - 0x5cf41514
withdraw(uint64,uint8) - 0xaed2ee73
compound(uint64) - 0xb34fea67
claimRewards(uint64) - 0xa76e2ca5
changeCommission(uint64,uint256) - 0x9bdcc3c8
externalReward(uint64) - 0xe4b3303b

External view methods:

getValidator(uint64) - 0x2b6d639a
getDelegator(uint64,address) - 0x573c1ce0
getWithdrawalRequest(uint64,address,uint8) - 0x56fa2045
getConsensusValidatorSet(uint32) - 0xfb29b729
getSnapshotValidatorSet(uint32) - 0xde66a368
getExecutionValidatorSet(uint32) - 0x7cb074df
getDelegations(address,uint64) - 0x4fd66050
getDelegators(uint64,address) - 0xa0843a26
getEpoch() - 0x757991a8

Syscalls:

syscallOnEpochChange(uint64) - 0x1d4e9f02
syscallReward(address) - 0x791bdcf3
syscallSnapshot() - 0x157eeb21

External State-Modifying Methods​
addValidator​
Function selector​
addValidator(bytes,bytes,bytes) : 0xf145204c
Function signature​
function addValidator(    bytes calldata payload,    bytes calldata signedSecpMessage,    bytes calldata signedBlsMessage) external payable returns (uint64 validatorId);
Parameters​

payload - consists of the following fields, packed together in big endian
(equivalent to abi.encodePacked() in Solidity):

bytes secpPubkey (unique SECP public key used for consensus)
bytes blsPubkey (unique BLS public key used for consensus)
address authAddress (address used for the validator’s delegator account. This address has
withdrawal authority for the validator's staked amount)
uint256 amount (amount the validator is self-staking. Must equal msg.value)
uint256 commission (commission charged to delegators multiplied by 1e18, e.g. 10% = 1e17)


signedSecpMessage - SECP signature over payload
signedBlsMessage - BLS signature over payload

Gas cost​
505,125
Behavior​
This creates a validator with an associated delegator account and returns the resultant validatorId.
The method starts by unpacking the payload to retrieve the secpPubkey, blsPubkey,
authAddress, amount, and commission, then verifying that the signedSecpMessage
and signedBlsMessage correspond to the payload signed by the corresponding SECP and BLS
private keys.

The validator must provide both a unique BLS key and a unique SECP key. Submissions with any
repeated public keys will revert.
Both signatures (signedSecpMessage and signedBlsMessage) must be valid and must sign
over the payload.
Multiple validators may share the same authAddress.
msg.value must be equal or greater than MIN_AUTH_ADDRESS_STAKE or the call will revert.
If the msg.value is also equal or greater than ACTIVE_VALIDATOR_STAKE then the validator
will become active in the future:

If addValidator was called before the boundary block, then in epoch n+1;
Otherwise it will become active in epoch n+2.



Pseudocodesecp_pubkey, bls_pubkey, auth_address, amount, commission = payload
assert amount == msg.value
// increment validator idlast_val_id = last_val_id + 1;
// set uniqueness of keyssecp_to_val_id[secp_eth_address] = last_val_id;bls_to_val_id[bls_eth_address] = last_val_id;
// set validator infoval_execution[last_val_id] = ValExecution{    uint256 stake = msg.value;    uint256 commission = commission;    bytes secp_pubkey = secp_pubkey;    bytes bls_pubkey = bls_pubkey;    uint256 address_flags = set_flags();}
// set authority delegator infodelegator[last_val_id][input.auth_address] = DelInfo{    uint256 delta_stake = set_stake()[0];    uint256 next_delta_stake = set_stake()[1];    uint64 delta_epoch = set_stake()[2];    uint64 next_delta_epoch = set_stake()[3];}
// set delegator accumulatorepoch_acc[last_val_id][getEpoch()] = Accumulator{    uint256 ref_count += 1;}
// set flagsset_flags();
// push validator idif (val_execution[last_val_id].stake() >= ACTIVE_VALIDATOR_STAKE        and last_val_id not in execution_valset):    execution_valset.push(last_val_id);
return last_val_id;
def set_flags():    if msg.value + val_execution[last_val_id].stake() >= ACTIVE_VALIDATOR_STAKE:        return ValidatorFlagsOk;    if msg.value + val_execution[last_val_id].stake() >= MIN_AUTH_ADDRESS_STAKE        return ValidatorFlagsStakeTooLow;
def set_stake():    if in_epoch_delay_rounds:        delta_stake = 0;        next_delta_stake = msg.value;        delta_epoch = 0;        next_delta_epoch = current_epoch + 2;    else:        delta_stake = msg.value;        next_delta_stake = 0;        delta_epoch = current_epoch + 1;        next_delta_epoch = 0;    return [delta_stake, next_delta_stake, delta_epoch, next_delta_epoch];
Usage​
Here is an example of assembling the payload and signing:
def generate_add_validator_call_data_and_sign(    secp_pubkey: bytes,    bls_pubkey: bytes,       auth_address: bytes,     amount: int,      commission: int    secp_privkey: bytes    bls_privkey: bytes) -> bytes:    # 1) Encode    payload_parts = [        secp_pubkey,        bls_pubkey,        auth_address,        toBigEndian32(amount),        toBigEndian32(commission),    ]    payload = b"".join(payload_parts)
    # 2) Sign with both keys    secp_sig = SECP256K1_SIGN(blake3(payload), secp_privkey)     bls_sig  = BLS_SIGN(hash_to_curve(payload), bls_privkey)
    # 3) Solidity encode the payload and two signatures    return eth_abi.encode(['bytes', 'bytes', 'bytes'], [payload, secp_sig, bls_sig])
delegate​
Function selector​
delegate(uint64) : 0x84994fec
Function signature​
function delegate(    uint64 validatorId) external payable returns (bool success);
Parameters​

validatorId - id of the validator that delegator would like to delegate to
msg.value - the amount to delegate

Gas cost​
260,850
Behavior​
This creates a delegator account if it does not exist and increases the delegator's
balance.

The delegator account is determined by msg.sender.
validatorId must correspond to a valid validator.
msg.value must be > 0.
If this delegation causes the validator's total stake to exceed ACTIVE_VALIDATOR_STAKE,
then the validator will be added to execution_valset if not already present.
The delegator stake becomes active

in epoch n+1 if the request is before the boundary block
in epoch n+2 otherwise



Pseudocodevalidator_id = msg.input.val_id;
// set validator informationval_execution[validator_id] =  ValExecution{    uint256 stake += msg.value();}
// set delegator informationDelInfo current_delegator = delegator[validator_id][msg.sender];
// apply get_current_stake() first. This updates the delegator stake// to be inline with the current stake activated in consensus.get_current_stake();
// apply add_stake() second.uint256[4] add_stake_info = add_stake(msg.value());
current_delegator = DelInfo{    uint256 delta_stake = add_stake_info[0];    uint256 next_delta_stake = add_stake_info[1];    uint64 delta_epoch = add_stake_info[2];    uint64 next_delta_epoch = add_stake_info[3];}
// set epoch accumulatorepoch_acc[validator_id][getEpoch()].ref_count += 1;
// set flagsset_flags();
// push validator idif val_execution[validator_id].stake() >= ACTIVE_VALIDATOR_STAKE        and validator_id not in execution_valset:    execution_valset.push(validator_id);
def add_stake(uint256 amount):    uint256 _delta_stake;    uint256 _next_delta_stake;    uint64 _delta_epoch;    uint64 _next_delta_epoch;
    if not in_epoch_delay_rounds:        _delta_stake = current_delegator.delta_stake() + amount;        _next_delta_stake = 0;        _delta_epoch = current_epoch + 1;        _next_delta_epoch = 0;    else:        _delta_stake = 0;        _next_delta_stake = current_delegator.next_delta_stake() + amount;        _delta_epoch = 0;        _next_delta_epoch = current_epoch + 2;    return [_delta_stake, _next_delta_stake, _delta_epoch, _next_delta_epoch];

def maybe_process_next_epoch_state():    """    Helper function to process and update rewards    based on the current epoch state.    """
    if (        epoch_acc[validator_id][current_delegator.delta_epoch()] != 0        and current_epoch > current_delegator.delta_epoch()        and current_delegator.delta_epoch() > 0    ):        // Compute rewards from the last checked epoch.        _rewards += current_delegator.stake() * (            epoch_acc[validator_id][current_delegator.delta_epoch()].val()            - current_delegator.acc()        )
        // Promote stake to active in delegator view.        current_delegator.stake() += current_delegator.delta_stake()        current_delegator.acc() = (            epoch_acc[validator_id][current_delegator.delta_epoch()].val()        )        current_delegator.delta_epoch() = current_delegator.next_delta_epoch()        current_delegator.delta_stake() = current_delegator.next_delta_stake()        current_delegator.next_delta_epoch() = 0        current_delegator.next_delta_stake() = 0
        epoch_acc[validator_id][current_delegator.delta_epoch].ref_count -= 1

def get_current_stake():    uint256 _rewards = 0;
    // Process next epoch rewards and increment stake    maybe_process_next_epoch_state()    // Perform again to capture max two additional epochs    maybe_process_next_epoch_state()
    current_delegator.rewards() += _rewards;    return _rewards;
undelegate​
Function selector​
undelegate(uint64,uint256,uint8) : 0x5cf41514
Function signature​
function undelegate(    uint64 validatorId,    uint256 amount,    uint8 withdrawId) external returns (bool success);
Parameters​

validatorId - id of the validator to which sender previously delegated, from which we are
removing delegation
amount - amount to undelegate, in Monad wei
withdrawId - integer between 0 and 255, inclusive, which serves as the identifier for a
delegator's withdrawal. For each (validator, delegator) tuple, there can be a maximum of 256
in-flight withdrawal requests

Gas cost​
147,750
Behavior​
This deducts amount from the delegator account and moves it to a withdrawal request object,
where it remains in a pending state for WITHDRAWAL_DELAY
epochs before the funds are claimable via the withdraw method.

The delegator account is determined by msg.sender.
validatorId must correspond to a valid validator to which the sender previously delegated
The delegator must have stake >= amount.
If the withdrawal causes Val(validatorId).stake() to drop below ACTIVE_VALIDATOR_STAKE, then the
validator is scheduled to be removed from the valset.
If the authAddress on a validator undelegates enough of their own stake to drop below
MIN_AUTH_ADDRESS_STAKE, then the validator is scheduled to be removed from the valset.
The function will revert if there is a pending withdrawal with the same withdrawId.
withdrawIds can be reused after calling withdraw.
A delegator can only remove a stake after it has been activated. This is the stake field in
the delegator struct. Pending delegations cannot be removed until they are active.
The delegator stake becomes inactive in the valset

in epoch n+1 if the request is before the boundary block
in epoch n+2 otherwise


The delegator stake becomes withdrawable, and thus no longer subject to slashing

in epoch n + 1 + WITHDRAWAL_DELAY if the request is before the boundary block
in epoch n + 2 + WITHDRAWAL_DELAY otherwise



Timeline of withdrawability of stake relative to undelegate command
Pseudocodeuint64 validator_id = msg.input.val_id;uint256 amount = msg.input.amount;uint8 withdraw_id = msg.input.withdraw_id;
ValExecution current_validator = val_execution[validator_id];
// set validator informationcurrent_validator =  ValExecution{    uint256 stake -= amount;}
// apply get_current_stake() first.get_current_stake();
DelInfo current_delegator = delegator[validator_id][msg.sender];// set delegator informationcurrent_delegator = DelInfo{    uint256 stake -= amount;}
// set withdraw requestwithdrawal[validator_id][msg.sender][withdraw_id] = WithdrawalRequest{    uint256 amount = amount;    uint256 acc = current_validator.acc();    uint64 epoch = getEpoch();});
// set epoch accumulatorepoch_acc[validator_id][getEpoch()].ref_count += 1;
// schedule validator to leave setif current_validator.stake < ACTIVE_VALIDATOR_STAKE and validator_id in execution_valset:    current_validator.set_flag(INSUFFICIENT_STAKE);
if (current_delegator.stake <= MIN_AUTH_ADDRESS_STAKE and validator_id in execution_valset) and msg.sender == current_validator.auth_address:    current_validator.set_flag(INSUFFICIENT_VALIDATOR_STAKE);
withdraw​
Function selector​
withdraw(uint64,uint8) : 0xaed2ee73
Function signature​
function withdraw(    uint64 validatorId,    uint8 withdrawId) external returns (bool success);
Parameters​

validatorId - id of the validator to which sender previously delegated, from which we previously
issued an undelegate command
withdrawId - identifier for a delegator's previously created withdrawal; the same id
previously supplied to undelegate. For each (validator, delegator) tuple,
there can be a maximum of 256 in-flight withdrawal requests.

Gas cost​
68,675
Behavior​
This completes an undelegation action (which started with a call to the undelegate function),
sending the amount to msg.sender, provided that sufficient epochs have passed.

The delegator is msg.sender. The withdrawal is identified by msg.sender, validatorId,
and withdrawId
The withdraw action can take place once the undelegation is complete, and the withdraw delay has passed:

in epoch n + 1 + WITHDRAWAL_DELAY if the undelegate request is before the boundary block
in epoch n + 2 + WITHDRAWAL_DELAY otherwise



Pseudocodeuint64 validator_id = msg.input.val_id;uint8 withdraw_id = msg.input.withdraw_id;
WithdrawalRequest current_withdraw = withdrawal[validator_id][msg.sender][withdraw_id];
// Compute any additional rewards and transfer funds to delegatortransfer(msg.sender, current_withdraw.amount + get_withdraw_rewards());
// unset withdraw requestwithdrawal[validator_id][msg.sender][withdraw_id] = WithdrawalRequest{    uint256 amount = 0,    uint256 acc = 0,    uint64 epoch = 0};
def get_withdraw_rewards():    epoch_acc[validator_id][current_withdraw.epoch].ref_count -= 1;    return current_withdraw.amount() * (epoch_acc[validator_id][current_withdraw.epoch()].val() - current_withdraw.acc());
compound​
Function selector​
compound(uint64) : 0xb34fea67
Function signature​
function compound(    uint64 validatorId) external returns (bool success);
Parameters​

validatorId - id of the validator to which sender previously delegated, for which we are
compounding rewards

Gas cost​
285,050
Behavior​
This precompile converts the delegator's accumulated rewards into additional stake.

The account compounded is determined by msg.sender. If a delegator account does not exist, then the call reverts
validatorId must correspond to a valid validator to which the sender previously delegated
The delegator rewards become active in the valset

in epoch n+1 if the request is before the boundary block
in epoch n+2 otherwise.



Pseudocodevalidator_id = msg.input.val_id;
// set delegator informationDelInfo current_delegator = delegator[validator_id][msg.sender];
// apply get_current_stake() first. This updates the delegator stake// to be inline with the current stake activated in consensus.rewards_compounded = get_current_stake();
// apply add_stake() second.uint256[4] add_stake_info = add_stake(rewards_compounded);
// set delegator informationcurrent_delegator = DelInfo{    uint256 delta_stake = add_stake_info[0];    uint256 next_delta_stake = add_stake_info[1];    uint64 delta_epoch = add_stake_info[2];    uint64 next_delta_epoch = add_stake_info[3];    uint256 rewards = 0;}
// set validator informationval_execution[validator_id] = ValExecution{    uint256 stake += rewards_compounded;}
// set accumulatorepoch_acc[validator_id][getEpoch()] = Accumulator{    uint256 ref_count += 1;}
// set flagsset_flags();
// push validator idif val_execution[validator_id].stake() >= ACTIVE_VALIDATOR_STAKE and validator_id not in execution_valset:    execution_valset.push(validator_id);

claimRewards​
Function selector​
claimRewards(uint64) : 0xa76e2ca5
Function signature​
function claimRewards(    uint64 validatorId) external returns (bool success);
Parameters​

validatorId - id of the validator to which sender previously delegated, for which we are
claiming rewards

Gas cost​
155,375
Behavior​
This precompile allows a delegator to claim any rewards instead of compounding them.

validatorId must correspond to a valid validator to which the sender previously delegated
If delegator account does not exist for this (validatorId, msg.sender) tuple, then the call reverts
The delegator's accumulated rewards are transferred to their delegation

Pseudocode// set delegator informationDelInfo current_delegator = delegator[validator_id][msg.sender];
// apply get_current_stake() first.uint256 current_rewards = get_current_stake();
// set delegator informationcurrent_delegator = DelInfo{    uint256 rewards = 0;)
// send rewards to delegatortransfer(msg.sender, current_rewards);
changeCommission​
Function selector​
changeCommission(uint64,uint256) : 0x9bdcc3c8
Function signature​
function changeCommission(    uint64 validatorId,    uint256 commission) external returns (bool success);
Parameters​

validatorId - id of the validator, who would like to change their commission rate
commission - commission rate taken from block rewards, expressed in 1e18 units
(e.g., 10% = 1e17)

Gas cost​
39,475
Behavior​
This allows the authAddress for a validator to modify the commission for the validator.
The commission cannot be set larger than MAX_COMMISSION (currently 100%).

The msg.sender must be the authAddress for the respective validator Id.
The commission cannot be set larger than MAX_COMMISSION (currently 100%).
The change in commission occurs in the following epochs:

in epoch n+1 if request is not in the epoch delay rounds.
in epoch n+2 if request is in the epoch delay rounds.



Pseudocodevalidator_id = msg.input.val_id;

val_execution[validator_id] = ValExecution{    uint256 commission = msg.input.commission;}


externalReward​
Function selector​
externalReward(uint64) : 0xe4b3303b
Function signature​
function externalReward(    uint64 validatorId) external returns (bool success);
Parameters​

validatorId - id of the validator
msg.value - the MON to add to unclaimed rewards

Gas cost​
62,300
Behavior​
This function allows anyone to send extra MON to the stakers of a particular validator. This
typically will be called by the validator themselves to share extra tips to their delegators.
Notes:

This can only be called for a validator currently in the consensus validator set; otherwise
the transaction reverts.
msg.value must be between 1 MON and 1,000,000 MON; otherwise the transaction reverts.
Commission is not deducted from this and diverted to the validator's auth_address. If you
wish for a portion to be deducted, it should be deducted before sending.

Pseudocodevalidator_id = msg.input.val_id;
require(msg.value >= 1e18 && msg.value <= 1e24, "Reward out of bounds");require(val_consensus[validator_id] > 0 , "Validator not active");
val_execution[validator_id].unclaimed_reward += msg.value;val_execution[val_id].acc += msg.value / val_consensus[val_id].stake();

External View Methods​
getValidator​
Function selector​
getValidator(uint64) : 0x2b6d639a
Function signature​
function getValidator(    uint64 validatorId) external view returns (    address authAddress,    uint64 flags,    uint256 stake,    uint256 accRewardPerToken,    uint256 commission,    uint256 unclaimedRewards,    uint256 consensusStake,    uint256 consensusCommission,    uint256 snapshotStake,    uint256 snapshotCommission,    bytes memory secpPubkey,    bytes memory blsPubkey);
Parameters​

validatorId - id of the validator

Gas cost​
97,200
Behavior​
This is the primary method to obtain information about a validator state.
It provides a complete view of the validator’s state across execution, consensus, and snapshot
contexts.
It returns:

ValExecution (execution view)
Stake and commission (consensus view)
Stake and commission (snapshot view)

getDelegator​
Function selector​
getDelegator(uint64,address) : 0x573c1ce0
Function signature​
function getDelegator(    uint64 validatorId,     address delegator) external returns (    uint256 stake,    uint256 accRewardPerToken,    uint256 unclaimedRewards,    uint256 deltaStake,    uint256 nextDeltaStake,    uint64 deltaEpoch,    uint64 nextDeltaEpoch);
Parameters​

validatorId - id of the validator
delegator - address of the delegator about whose stake we are inquiring

Gas cost​
184,900
Behavior​
This returns the delegator’s DelInfo for the specified validator,
providing a view of the delegator’s stake, accumulated rewards and pending changes in stake.
getWithdrawalRequest​
Function selector​
getWithdrawalRequest(uint64,address,uint8) : 0x56fa2045
Function signature​
function getWithdrawalRequest(    uint64 validatorId,    address delegator,    uint8 withdrawId) external returns (    uint256 withdrawalAmount,    uint256 accRewardPerToken,    uint64 withdrawEpoch);
Gas cost​
24,300
Behavior​
This returns the pending WithdrawalRequest for the (validatorId, delegator, withdrawId) tuple.
get*ValidatorSet​
Function selectors​
getConsensusValidatorSet(uint32) : 0xfb29b729getSnapshotValidatorSet(uint32) : 0xde66a368getExecutionValidatorSet(uint32) : 0x7cb074df
Function signatures​
function getConsensusValidatorSet(    uint32 startIndex) external returns (bool isDone, uint32 nextIndex, uint64[] memory valIds);
function getSnapshotValidatorSet(    uint32 startIndex) external returns (bool isDone, uint32 nextIndex, uint64[] memory valIds);
function getExecutionValidatorSet(    uint32 startIndex) external returns (bool isDone, uint32 nextIndex, uint64[] memory valIds);
Parameters​

startIndex - since the list being looked up is potentially very long, each of these functions
is paginated, returning a fixed-length subset of the desired list. Pass startIndex to
indicate where in the list to start.

Gas cost​
814,000 gas (assuming PAGINATED_RESULTS_SIZE = 100).
Behavior​
These functions return the consensus, snapshot, and execution validator ids, respectively.
Each call retrieves up to PAGINATED_RESULTS_SIZE validator ids starting from startIndex and
returns a tuple (bool done, uint32 nextIndex, uint256[] valids).
The bool isDone indicates whether the end of the list was reached. The uint32 nextIndex
is the last slot in the array.
getDelegations​
Function selector​
getDelegations(address,uint64) : 0x4fd66050
Function signature​
function getDelegations(    address delegator,    uint64 startValId) external returns (bool isDone, uint64 nextValId, uint64[] memory valIds);
Parameters​

delegator - the address whose delegations we want to look up
startValId

Gas cost​
814,000
Behavior​
Each call retrieves up to PAGINATED_RESULTS_SIZE validator ids starting from startValId
and returns a tuple (bool isDone, uint64 nextValId, uint64[] valIds) with delegation
from the input delegator address.
The bool isdone indicates whether the end of the list was reached.
The uint64 nextValId is the id after the last element in valIds. Use it as the
startValId for the next call.
If delegator has delegated to over PAGINATED_RESULTS_SIZE validator ids,
multiple calls are required (while isDone is false).
To capture the full set, the make the first function call using startValId = 0.
getDelegators​
Function selector​
getDelegators(uint64,address) : 0xa0843a26
Function signature​
function getDelegators(    uint64 validatorId,    address startDelegator) external returns (bool isDone, address nextDelegator, address[] memory delegators);
Parameters​

validatorId - the id of the validator for which we want to know the delegators
startDelegator

Gas cost​
814,000
Behavior​
Each call retrieves up to PAGINATED_RESULTS_SIZE delegator addresses starting from
startDelegator and returns a tuple (bool isDone, address nextDelegator, address[] delegators)
with delegation to the input validatorId.
The bool isDone indicates the end of the list was reached.
The nextDelegator is the address immediately after the last element in delegators.
Use it as startDelegator for the next call.
To capture the full set, the function should be called with startDelegator = 0.
noteThe number of delegators to a given validator can be very large, so it is recommended to
maintain an updated list via the
events framework, rather
than periodically calling this expensive lookup.
getEpoch​
Function selector​
getEpoch() : 0x757991a8
Function signature​
function getEpoch() external returns (uint64 epoch, bool inEpochDelayPeriod);
Gas cost​
16,200
Behavior​
This function is a handy utility to determine the current epoch and timing within the epoch (before
or after the boundary block).
If inEpochDelayPeriod is false, the boundary block has not been reached yet
and write operations at that time should be effective for epoch + 1.
If inEpochDelayPeriod is true, the network is past the boundary block and
and write operations at that time should be effective for epoch + 2
getProposerValId​
Function selector​
getProposerValId() : 0xfbacb0be
Function signature​
function getProposerValId() external returns (uint64 val_id);
Gas cost​
100
Behavior​
This function returns the validator ID of the current block proposer. Specifically, this validator ID corresponds to the sec_p value of the block author.
Syscalls​
There are currently three syscalls. Users cannot invoke these directly. They are only
triggered through special system transactions.
syscallOnEpochChange​
Function selector​
syscallOnEpochChange(uint64) : 0x1d4e9f02
Function signature​
function syscallOnEpochChange(uint64 epoch) external;
Parameters​

epoch - the new consensus epoch being entered

Behavior​
This syscall is triggered at the end of the epoch delay rounds. It performs the following
actions:

If the validator received a request to change stake in the previous epoch and participated in the previous epoch’s consensus validator set then it saves the corresponding accumulator value
If any validator was active in the previous epoch but becomes inactive in the current epoch,
it also saves their current accumulator value
Sets the current epoch in state

Pseudocodeuint64 current_epoch = msg.input.epoch;
for i in snapshot_valset:    if epoch_acc[i][current_epoch] is not empty:        epoch_acc[i][current_epoch].val() = execution_valset[i].acc()    if epoch_acc[i][current_epoch + 1] is not empty:        epoch_acc[i][current_epoch].val() = execution_valset[i].acc()
in_epoch_delay_rounds = false;epoch = current_epoch;
syscallReward​
Function selector​
syscallReward(address) : 0x791bdcf3
Function signature​
function syscallReward(address blockAuthor) external;
Parameters​

blockAuthor — the address of the validator that produced the block.

Behavior​
This syscall is invoked for every block. It rewards the block-producing validator (and their
delegators) with the configured block reward:

If the validator has a nonzero commission, a portion of the reward is allocated to the
validator’s authAddress.
The remaining reward is claimable to the validator’s delegators.

Note that the commission is calculated as a percentage of the total block reward.
Example
Suppose that a validator's personal stake comprises 20% of the total delegation to
their validator.
The commission is set at 10% of total rewards.
Then the validator receives 10% of the total block reward as their commission. The remaining 90%
of the reward is distributed to the stake pool. Since the validator owns 20% of the pool, they
also receive 20% of that remaining amount.
Pseudocodeuint64 val_id = secp_to_val_id[block_author];DelInfo auth_del = delegator[val_id][val_execution[val_id].auth_address()];uint256 _commission = REWARD * val_execution[val_id].commission / 1e18;uint256 _unclaimed_rewards = REWARD - _commission;
// state updateauth_del.rewards() += _commission;val_execution[val_id].unclaimed_rewards += _unclaimed_rewards;val_execution[val_id].acc += _unclaimed_rewards / val_consensus[val_id].stake();
mint(STAKING_CONTRACT_ADDRESS, REWARD);
syscallSnapshot​
Function selector​
syscallSnapshot() : 0x157eeb21
Function signature​
function syscallSnapshot() external;
Parameters​
(none)
Behavior​
This syscall sorts the current execution-layer validator set. It selects the top N staked
validators as the upcoming consensus validator set. The updated set is stored in state. The
previous consensus set is cleared.
Pseudocode
uint64[] filter_top_n_validators = sort(execution_valset);
for i in snapshot_valset:    val_snapshot[i].stake = 0;    val_snapshot[i].commission = 0;
snapshot_valset = consensus_valset;consensus_valset = filter_top_n_validators;
for i in filter_top_n_validators:    val_consensus[i].stake = val_execution[i].stake;    val_consensus[i].commission = val_execution[i].commission;
Events​
The staking precompiles emit standard events that appear in transaction receipts. These events
provide indexed information about validator and delegator actions.
ValidatorRewarded​
event ValidatorRewarded(        uint64 indexed validatorId,        address indexed from,        uint256 amount,        uint64 epoch);
Emitted when block reward is allocated via syscallReward.
ValidatorCreated​
event ValidatorCreated(    uint64  indexed validatorId,    address indexed authAddress,    uint256 commission);
Emitted when a validator is added via addValidator.
ValidatorStatusChanged​
event ValidatorStatusChanged(    uint64  indexed validatorId,    uint64  flags);
Emitted during addValidator, delegate,
undelegate, or compound. if the validator's flags change.
Delegate​
event Delegate(    uint64  indexed validatorId,    address indexed delegator,    uint256 amount,    uint64  activationEpoch);
Emitted when delegation amount is increased, i.e. during addValidator,
delegate, or compound.
Undelegate​
event Undelegate(    uint64  indexed validatorId,    address indexed delegator,    uint8   withdrawId,    uint256 amount,    uint64  activationEpoch);
Emitted when a delegator calls undelegate.
Withdraw​
event Withdraw(    uint64 indexed validatorId,    address indexed delegator,    uint8   withdrawId,    uint256 amount,    uint64  withdrawEpoch);
Emitted when a delegator executes withdraw successfully.
ClaimRewards​
event ClaimRewards(    uint64 indexed validatorId,    address indexed delegator,    uint256 amount,    uint64 epoch);
Emitted when a delegator claims rewards via claimRewards.
CommissionChanged​
event CommissionChanged(    uint64 indexed validatorId,    uint256 oldCommission,    uint256 newCommission);
Emitted when a validator changes commission via changeCommission.
EpochChanged​
    event EpochChanged(        uint64 oldEpoch,        uint64 newEpoch    );
Emitted when epoch changes via syscallOnEpochChange.
Precompile Internals​

Constants
Validator structs
Delegator structs
State variables
Mappings

Constants​
// Minimum stake required from validator's own account// to be eligible to join the valset, in Monad weiuint256 MIN_AUTH_ADDRESS_STAKE;
// Min stake required (including delegation) for validator// to be eligible to join the valset, in Monad wei.// note that ACTIVE_VALIDATOR_STAKE > MIN_AUTH_ADDRESS_STAKEuint256 ACTIVE_VALIDATOR_STAKE;
// Block Rewarduint256 REWARD;
// Accumulator unit multiplier. Chosen to preserve accuracyuint256 ACCUMULATOR_DENOMINATOR = 1e36;
// Staking precompile addressAddress STAKING_CONTRACT_ADDRESS = 0x0000000000000000000000000000000000001000;
// Withdrawal delay, needed to facilitate slashinguint8 WITHDRAWAL_DELAY = 1;
// Controls the maximum number of results returned by individual// calls to valset-getters, get_delegators, and get_delegationsuint64 PAGINATED_RESULTS_SIZE = 100;
Validator structs​
struct ValExecution             // Realtime execution state for one validator{    uint256 stake;              // Upcoming stake pool balance    uint256 acc;                // Current accumulator value for validator    uint256 commission;         // Proportion of block reward charged as commission, times 1e18; 10% = 1e17    bytes   secp_pubkey;        // Secp256k1 public key used by consensus    bytes   bls_pubkey;         // Bls public key used by consensus    uint256 address_flags;      // Flags to represent validators' current state    uint256 unclaimed_rewards;  // Unclaimed rewards    address auth_address;       // Delegator address with authority over validator stake}
struct ValConsensus             // A subset of validator state for the consensus system{    uint256 stake;              // Current active stake    uint256 commission;         // Commission rate for current epoch    bytes   secp_pubkey;        // Secp256k1 public key used by consensus    bytes   bls_pubkey;         // Bls public key used by consensus}
Delegator structs​
struct DelInfo{    uint256 stake;               // Current active stake    uint256 acc;                 // Last checked accumulator    uint256 rewards;             // Last checked rewards    uint256 delta_stake;         // Stake to be activated next epoch    uint256 next_delta_stake;    // Stake to be activated in 2 epochs    uint64 delta_epoch;          // Epoch when delta_stake becomes active    uint64 next_delta_epoch;     // Epoch when next_delta_stake becomes active}
struct WithdrawalRequest{    uint256 amount;              // Amount to undelegate from validator    uint256 acc;                 // Validator accumulator when undelegate was called    uint64 epoch;                // Epoch when undelegate stake deactivates};
struct Accumulator{    uint256 val;               // Current accumulator value    uint256 refcount;            // Reference count for this accumulator value};
State variables​
// Current consensus epochuint64 epoch;
// Flag indicating if currently in epoch delay roundsbool in_epoch_delay_rounds;
// Counter for validator idsuint64 last_val_id;
// Current execution view of validator setStorageArray<uint64> execution_valset;
// Previous consensus view of validator setStorageArray<uint64> snapshot_valset;
// Current consensus view of validator setStorageArray<uint64> consensus_valset;
Mappings​
//These mappings only exist to ensure the SECP/BLS Keys are uniquemapping (secp_eth_address => uint64) secp_to_val_id;mapping (bls_eth_address => uint64) bls_to_val_id;
// Keys(val_id, epoch) => Value(acc)// making note of the validator accumulator at start of epoch.mapping(uint64 => mapping(uint64 => Accumulator)) epoch_acc;
// Key(val_id)// Contains the validator info for the execution view. Changes to stake// or commission are reflected immediately.mapping(uint64 => ValExecution) val_execution;
// Key(val_id)// Contains a subset of the validator info relevant to consensus. Changes to// stake or commission are reflected in the following epoch. This is referenced// by the reward system call *before* the epoch delay rounds.mapping(uint64 => ValConsensus) val_consensus;
// Key(val_id)// Contains a subset of the validator info relevant to consensus. Changes to// stake or commission are reflected in the following epoch. This is referenced// by the reward system call *during* the epoch delay rounds.mapping(uint64 => ValConsensus) val_snapshot;
// Keys(val_id,msg.sender) => DelInfomapping(uint64 => mapping(address => DelInfo)) delegator;
// Keys(val_id,msg.sender,withdrawal_id) => WithdrawalRequestmapping(uint64 => mapping(address => mapping (uint8 => WithdrawalRequest))) withdrawal;
Solidity Staking Interface​
To copy to clipboard, click the button in the top right of the code block.
// SPDX-License-Identifier: MITpragma solidity ^0.8.15;
interface IMonadStaking {    function addValidator(        bytes calldata payload,        bytes calldata signedSecpMessage,        bytes calldata signedBlsMessage    ) external payable returns (uint64 validatorId);
    function delegate(        uint64 validatorId    ) external payable returns (bool success);
    function undelegate(        uint64 validatorId,        uint256 amount,        uint8 withdrawId    ) external returns (bool success);
    function compound(        uint64 validatorId    ) external returns (bool success);
    function withdraw(        uint64 validatorId,        uint8 withdrawId    ) external returns (bool success);
    function claimRewards(        uint64 validatorId    ) external returns (bool success);
    function changeCommission(        uint64 validatorId,        uint256 commission    ) external returns (bool success);
    function externalReward(        uint64 validatorId    ) external returns (bool success);

    function getValidator(        uint64 validatorId    ) external view returns (        address authAddress,        uint64 flags,        uint256 stake,        uint256 accRewardPerToken,        uint256 commission,        uint256 unclaimedRewards,        uint256 consensusStake,        uint256 consensusCommission,        uint256 snapshotStake,        uint256 snapshotCommission,        bytes memory secpPubkey,        bytes memory blsPubkey    );
    function getDelegator(        uint64 validatorId,         address delegator    ) external returns (        uint256 stake,        uint256 accRewardPerToken,        uint256 unclaimedRewards,        uint256 deltaStake,        uint256 nextDeltaStake,        uint64 deltaEpoch,        uint64 nextDeltaEpoch    );
    function getWithdrawalRequest(        uint64 validatorId,        address delegator,        uint8 withdrawId    ) external returns (        uint256 withdrawalAmount,        uint256 accRewardPerToken,        uint64 withdrawEpoch    );
    function getConsensusValidatorSet(        uint32 startIndex    ) external returns (bool isDone, uint32 nextIndex, uint64[] memory valIds);
    function getSnapshotValidatorSet(        uint32 startIndex    ) external returns (bool isDone, uint32 nextIndex, uint64[] memory valIds);
    function getExecutionValidatorSet(        uint32 startIndex    ) external returns (bool isDone, uint32 nextIndex, uint64[] memory valIds);
    function getDelegations(        address delegator,        uint64 startValId    ) external returns (bool isDone, uint64 nextValId, uint64[] memory valIds);
    function getDelegators(        uint64 validatorId,        address startDelegator    ) external returns (bool isDone, address nextDelegator, address[] memory delegators);
    function getEpoch() external returns (uint64 epoch, bool inEpochDelayPeriod);
    function getProposerValId() external returns (uint64 val_id);
    function syscallOnEpochChange(uint64 epoch) external;
    function syscallReward(address blockAuthor) external;
    function syscallSnapshot() external;
     event ValidatorRewarded(        uint64 indexed validatorId,        address indexed from,        uint256 amount,        uint64 epoch    );    event ValidatorCreated(        uint64  indexed validatorId,        address indexed authAddress,        uint256 commission
    );    event ValidatorStatusChanged(        uint64  indexed validatorId,        uint64  flags    );    event Delegate(        uint64  indexed validatorId,        address indexed delegator,        uint256 amount,        uint64  activationEpoch    );    event Undelegate(        uint64  indexed validatorId,        address indexed delegator,        uint8   withdrawId,        uint256 amount,        uint64  activationEpoch    );    event Withdraw(        uint64 indexed validatorId,        address indexed delegator,        uint8   withdrawId,        uint256 amount,        uint64  withdrawEpoch    );    event ClaimRewards(        uint64 indexed validatorId,        address indexed delegator,        uint256 amount,        uint64  epoch    );    event CommissionChanged(        uint64 indexed validatorId,        uint256 oldCommission,        uint256 newCommission    );    event EpochChanged(        uint64 oldEpoch,        uint64 newEpoch    );}
Staking ABI JSON​
To copy to clipboard, click the button in the top right of the code block.
[  {"type":"function","name":"addValidator","inputs":[{"name":"payload","type":"bytes","internalType":"bytes"},{"name":"signedSecpMessage","type":"bytes","internalType":"bytes"},{"name":"signedBlsMessage","type":"bytes","internalType":"bytes"}],"outputs":[{"name":"validatorId","type":"uint64","internalType":"uint64"}],"stateMutability":"payable"},  {"type":"function","name":"changeCommission","inputs":[{"name":"validatorId","type":"uint64","internalType":"uint64"},{"name":"commission","type":"uint256","internalType":"uint256"}],"outputs":[{"name":"success","type":"bool","internalType":"bool"}],"stateMutability":"nonpayable"},  {"type":"function","name":"claimRewards","inputs":[{"name":"validatorId","type":"uint64","internalType":"uint64"}],"outputs":[{"name":"success","type":"bool","internalType":"bool"}],"stateMutability":"nonpayable"},  {"type":"function","name":"compound","inputs":[{"name":"validatorId","type":"uint64","internalType":"uint64"}],"outputs":[{"name":"success","type":"bool","internalType":"bool"}],"stateMutability":"nonpayable"},  {"type":"function","name":"delegate","inputs":[{"name":"validatorId","type":"uint64","internalType":"uint64"}],"outputs":[{"name":"success","type":"bool","internalType":"bool"}],"stateMutability":"payable"},  {"type":"function","name":"externalReward","inputs":[{"name":"validatorId","type":"uint64","internalType":"uint64"}],"outputs":[{"name":"success","type":"bool","internalType":"bool"}],"stateMutability":"nonpayable"},  {"type":"function","name":"getConsensusValidatorSet","inputs":[{"name":"startIndex","type":"uint32","internalType":"uint32"}],"outputs":[{"name":"isDone","type":"bool","internalType":"bool"},{"name":"nextIndex","type":"uint32","internalType":"uint32"},{"name":"valIds","type":"uint64[]","internalType":"uint64[]"}],"stateMutability":"nonpayable"},  {"type":"function","name":"getDelegations","inputs":[{"name":"delegator","type":"address","internalType":"address"},{"name":"startValId","type":"uint64","internalType":"uint64"}],"outputs":[{"name":"isDone","type":"bool","internalType":"bool"},{"name":"nextValId","type":"uint64","internalType":"uint64"},{"name":"valIds","type":"uint64[]","internalType":"uint64[]"}],"stateMutability":"nonpayable"},  {"type":"function","name":"getDelegator","inputs":[{"name":"validatorId","type":"uint64","internalType":"uint64"},{"name":"delegator","type":"address","internalType":"address"}],"outputs":[{"name":"stake","type":"uint256","internalType":"uint256"},{"name":"accRewardPerToken","type":"uint256","internalType":"uint256"},{"name":"unclaimedRewards","type":"uint256","internalType":"uint256"},{"name":"deltaStake","type":"uint256","internalType":"uint256"},{"name":"nextDeltaStake","type":"uint256","internalType":"uint256"},{"name":"deltaEpoch","type":"uint64","internalType":"uint64"},{"name":"nextDeltaEpoch","type":"uint64","internalType":"uint64"}],"stateMutability":"nonpayable"},  {"type":"function","name":"getDelegators","inputs":[{"name":"validatorId","type":"uint64","internalType":"uint64"},{"name":"startDelegator","type":"address","internalType":"address"}],"outputs":[{"name":"isDone","type":"bool","internalType":"bool"},{"name":"nextDelegator","type":"address","internalType":"address"},{"name":"delegators","type":"address[]","internalType":"address[]"}],"stateMutability":"nonpayable"},  {"type":"function","name":"getEpoch","inputs":[],"outputs":[{"name":"epoch","type":"uint64","internalType":"uint64"},{"name":"inEpochDelayPeriod","type":"bool","internalType":"bool"}],"stateMutability":"nonpayable"},  {"type":"function","name":"getProposerValId","inputs":[],"outputs":[{"name":"val_id","type":"uint64","internalType": "uint64"}],  "stateMutability":"nonpayable"},   {"type":"function","name":"getExecutionValidatorSet","inputs":[{"name":"startIndex","type":"uint32","internalType":"uint32"}],"outputs":[{"name":"isDone","type":"bool","internalType":"bool"},{"name":"nextIndex","type":"uint32","internalType":"uint32"},{"name":"valIds","type":"uint64[]","internalType":"uint64[]"}],"stateMutability":"nonpayable"},  {"type":"function","name":"getSnapshotValidatorSet","inputs":[{"name":"startIndex","type":"uint32","internalType":"uint32"}],"outputs":[{"name":"isDone","type":"bool","internalType":"bool"},{"name":"nextIndex","type":"uint32","internalType":"uint32"},{"name":"valIds","type":"uint64[]","internalType":"uint64[]"}],"stateMutability":"nonpayable"},  {"type":"function","name":"getValidator","inputs":[{"name":"validatorId","type":"uint64","internalType":"uint64"}],"outputs":[{"name":"authAddress","type":"address","internalType":"address"},{"name":"flags","type":"uint64","internalType":"uint64"},{"name":"stake","type":"uint256","internalType":"uint256"},{"name":"accRewardPerToken","type":"uint256","internalType":"uint256"},{"name":"commission","type":"uint256","internalType":"uint256"},{"name":"unclaimedRewards","type":"uint256","internalType":"uint256"},{"name":"consensusStake","type":"uint256","internalType":"uint256"},{"name":"consensusCommission","type":"uint256","internalType":"uint256"},{"name":"snapshotStake","type":"uint256","internalType":"uint256"},{"name":"snapshotCommission","type":"uint256","internalType":"uint256"},{"name":"secpPubkey","type":"bytes","internalType":"bytes"},{"name":"blsPubkey","type":"bytes","internalType":"bytes"}],"stateMutability":"view"},  {"type":"function","name":"getWithdrawalRequest","inputs":[{"name":"validatorId","type":"uint64","internalType":"uint64"},{"name":"delegator","type":"address","internalType":"address"},{"name":"withdrawId","type":"uint8","internalType":"uint8"}],"outputs":[{"name":"withdrawalAmount","type":"uint256","internalType":"uint256"},{"name":"accRewardPerToken","type":"uint256","internalType":"uint256"},{"name":"withdrawEpoch","type":"uint64","internalType":"uint64"}],"stateMutability":"nonpayable"},  {"type":"function","name":"syscallOnEpochChange","inputs":[{"name":"epoch","type":"uint64","internalType":"uint64"}],"outputs":[],"stateMutability":"nonpayable"},  {"type":"function","name":"syscallReward","inputs":[{"name":"blockAuthor","type":"address","internalType":"address"}],"outputs":[],"stateMutability":"nonpayable"},  {"type":"function","name":"syscallSnapshot","inputs":[],"outputs":[],"stateMutability":"nonpayable"},  {"type":"function","name":"undelegate","inputs":[{"name":"validatorId","type":"uint64","internalType":"uint64"},{"name":"amount","type":"uint256","internalType":"uint256"},{"name":"withdrawId","type":"uint8","internalType":"uint8"}],"outputs":[{"name":"success","type":"bool","internalType":"bool"}],"stateMutability":"nonpayable"},  {"type":"function","name":"withdraw","inputs":[{"name":"validatorId","type":"uint64","internalType":"uint64"},{"name":"withdrawId","type":"uint8","internalType":"uint8"}],"outputs":[{"name":"success","type":"bool","internalType":"bool"}],"stateMutability":"nonpayable"},  {"type":"event","name":"ClaimRewards","inputs":[{"name":"validatorId","type":"uint64","indexed":true,"internalType":"uint64"},{"name":"delegator","type":"address","indexed":true,"internalType":"address"},{"name":"amount","type":"uint256","indexed":false,"internalType":"uint256"},{"name":"epoch","type":"uint64","indexed":false,"internalType":"uint64"}],"anonymous":false},  {"type":"event","name":"CommissionChanged","inputs":[{"name":"validatorId","type":"uint64","indexed":true,"internalType":"uint64"},{"name":"oldCommission","type":"uint256","indexed":false,"internalType":"uint256"},{"name":"newCommission","type":"uint256","indexed":false,"internalType":"uint256"}],"anonymous":false},  {"type":"event","name":"Delegate","inputs":[{"name":"validatorId","type":"uint64","indexed":true,"internalType":"uint64"},{"name":"delegator","type":"address","indexed":true,"internalType":"address"},{"name":"amount","type":"uint256","indexed":false,"internalType":"uint256"},{"name":"activationEpoch","type":"uint64","indexed":false,"internalType":"uint64"}],"anonymous":false},  {"type":"event","name":"EpochChanged","inputs":[{"name":"oldEpoch","type":"uint64","indexed":false,"internalType":"uint64"},{"name":"newEpoch","type":"uint64","indexed":false,"internalType":"uint64"}],"anonymous":false},  {"type":"event","name":"Undelegate","inputs":[{"name":"validatorId","type":"uint64","indexed":true,"internalType":"uint64"},{"name":"delegator","type":"address","indexed":true,"internalType":"address"},{"name":"withdrawId","type":"uint8","indexed":false,"internalType":"uint8"},{"name":"amount","type":"uint256","indexed":false,"internalType":"uint256"},{"name":"activationEpoch","type":"uint64","indexed":false,"internalType":"uint64"}],"anonymous":false},  {"type":"event","name":"ValidatorCreated","inputs":[{"name":"validatorId","type":"uint64","indexed":true,"internalType":"uint64"},{"name":"authAddress","type":"address","indexed":true,"internalType":"address"},{"name":"commission","type":"uint256","indexed":false,"internalType":"uint256"}],"anonymous":false},  {"type":"event","name":"ValidatorRewarded","inputs":[{"name":"validatorId","type":"uint64","indexed":true,"internalType":"uint64"},{"name":"from","type":"address","indexed":true,"internalType":"address"},{"name":"amount","type":"uint256","indexed":false,"internalType":"uint256"},{"name":"epoch","type":"uint64","indexed":false,"internalType":"uint64"}],"anonymous":false},  {"type":"event","name":"ValidatorStatusChanged","inputs":[{"name":"validatorId","type":"uint64","indexed":true,"internalType":"uint64"},{"name":"flags","type":"uint64","indexed":false,"internalType":"uint64"}],"anonymous":false},  {"type":"event","name":"Withdraw","inputs":[{"name":"validatorId","type":"uint64","indexed":true,"internalType":"uint64"},{"name":"delegator","type":"address","indexed":true,"internalType":"address"},{"name":"withdrawId","type":"uint8","indexed":false,"internalType":"uint8"},{"name":"amount","type":"uint256","indexed":false,"internalType":"uint256"},{"name":"withdrawEpoch","type":"uint64","indexed":false,"internalType":"uint64"}],"anonymous":false}]
FAQ​
Is there a removeValidator function?There is no direct removeValidator function. Instead, if a validator’s auth_account removes
enough stake through undelegate, the validator is removed from the consensus set
in a future epoch.This occurs in either epoch n+1 or epoch n+2, depending on whether the undelegate
occurred within the epoch delay rounds.Even when not active, a validator’s information is always retained. Validator ids are permanent since
other delegators may still be delegating and need to reference that val_id to undelegate/withdraw.
How does a validator change their commission?A validator can change their commission by calling changeCommission.
What methods give visibility into the list of validator ids?See the valset getters.
What methods give visibility into a validator's state?See getValidator.
What methods give visibility into a delegator's delegation to one particular validator?See getDelegator.For pending withdrawals by that delegator from that validator, see getWithdrawalRequest.

### Code Examples

```prism
addValidator(bytes,bytes,bytes) : 0xf145204c
```

```prism
function addValidator(    bytes calldata payload,    bytes calldata signedSecpMessage,    bytes calldata signedBlsMessage) external payable returns (uint64 validatorId);
```

```prism
secp_pubkey, bls_pubkey, auth_address, amount, commission = payload
assert amount == msg.value
// increment validator idlast_val_id = last_val_id + 1;
// set uniqueness of keyssecp_to_val_id[secp_eth_address] = last_val_id;bls_to_val_id[bls_eth_address] = last_val_id;
// set validator infoval_execution[last_val_id] = ValExecution{    uint256 stake = msg.value;    uint256 commission = commission;    bytes secp_pubkey = secp_pubkey;    bytes bls_pubkey = bls_pubkey;    uint256 address_flags = set_flags();}
// set authority delegator infodelegator[last_val_id][input.auth_address] = DelInfo{    uint256 delta_stake = set_stake()[0];    uint256 next_delta_stake = set_stake()[1];    uint64 delta_epoch = set_stake()[2];    uint64 next_delta_epoch = set_stake()[3];}
// set delegator accumulatorepoch_acc[last_val_id][getEpoch()] = Accumulator{    uint256 ref_count += 1;}
// set flagsset_flags();
// push validator idif (val_execution[last_val_id].stake() >= ACTIVE_VALIDATOR_STAKE        and last_val_id not in execution_valset):    execution_valset.push(last_val_id);
return last_val_id;
def set_flags():    if msg.value + val_execution[last_val_id].stake() >= ACTIVE_VALIDATOR_STAKE:        return ValidatorFlagsOk;    if msg.value + val_execution[last_val_id].stake() >= MIN_AUTH_ADDRESS_STAKE        return ValidatorFlagsStakeTooLow;
def set_stake():    if in_epoch_delay_rounds:        delta_stake = 0;        next_delta_stake = msg.value;        delta_epoch = 0;        next_delta_epoch = current_epoch + 2;    else:        delta_stake = msg.value;        next_delta_stake = 0;        delta_epoch = current_epoch + 1;        next_delta_epoch = 0;    return [delta_stake, next_delta_stake, delta_epoch, next_delta_epoch];
```

```prism
def generate_add_validator_call_data_and_sign(    secp_pubkey: bytes,    bls_pubkey: bytes,       auth_address: bytes,     amount: int,      commission: int    secp_privkey: bytes    bls_privkey: bytes) -> bytes:    # 1) Encode    payload_parts = [        secp_pubkey,        bls_pubkey,        auth_address,        toBigEndian32(amount),        toBigEndian32(commission),    ]    payload = b"".join(payload_parts)
    # 2) Sign with both keys    secp_sig = SECP256K1_SIGN(blake3(payload), secp_privkey)     bls_sig  = BLS_SIGN(hash_to_curve(payload), bls_privkey)
    # 3) Solidity encode the payload and two signatures    return eth_abi.encode(['bytes', 'bytes', 'bytes'], [payload, secp_sig, bls_sig])
```

```prism
delegate(uint64) : 0x84994fec
```

```prism
function delegate(    uint64 validatorId) external payable returns (bool success);
```

```prism
validator_id = msg.input.val_id;
// set validator informationval_execution[validator_id] =  ValExecution{    uint256 stake += msg.value();}
// set delegator informationDelInfo current_delegator = delegator[validator_id][msg.sender];
// apply get_current_stake() first. This updates the delegator stake// to be inline with the current stake activated in consensus.get_current_stake();
// apply add_stake() second.uint256[4] add_stake_info = add_stake(msg.value());
current_delegator = DelInfo{    uint256 delta_stake = add_stake_info[0];    uint256 next_delta_stake = add_stake_info[1];    uint64 delta_epoch = add_stake_info[2];    uint64 next_delta_epoch = add_stake_info[3];}
// set epoch accumulatorepoch_acc[validator_id][getEpoch()].ref_count += 1;
// set flagsset_flags();
// push validator idif val_execution[validator_id].stake() >= ACTIVE_VALIDATOR_STAKE        and validator_id not in execution_valset:    execution_valset.push(validator_id);
def add_stake(uint256 amount):    uint256 _delta_stake;    uint256 _next_delta_stake;    uint64 _delta_epoch;    uint64 _next_delta_epoch;
    if not in_epoch_delay_rounds:        _delta_stake = current_delegator.delta_stake() + amount;        _next_delta_stake = 0;        _delta_epoch = current_epoch + 1;        _next_delta_epoch = 0;    else:        _delta_stake = 0;        _next_delta_stake = current_delegator.next_delta_stake() + amount;        _delta_epoch = 0;        _next_delta_epoch = current_epoch + 2;    return [_delta_stake, _next_delta_stake, _delta_epoch, _next_delta_epoch];

def maybe_process_next_epoch_state():    """    Helper function to process and update rewards    based on the current epoch state.    """
    if (        epoch_acc[validator_id][current_delegator.delta_epoch()] != 0        and current_epoch > current_delegator.delta_epoch()        and current_delegator.delta_epoch() > 0    ):        // Compute rewards from the last checked epoch.        _rewards += current_delegator.stake() * (            epoch_acc[validator_id][current_delegator.delta_epoch()].val()            - current_delegator.acc()        )
        // Promote stake to active in delegator view.        current_delegator.stake() += current_delegator.delta_stake()        current_delegator.acc() = (            epoch_acc[validator_id][current_delegator.delta_epoch()].val()        )        current_delegator.delta_epoch() = current_delegator.next_delta_epoch()        current_delegator.delta_stake() = current_delegator.next_delta_stake()        current_delegator.next_delta_epoch() = 0        current_delegator.next_delta_stake() = 0
        epoch_acc[validator_id][current_delegator.delta_epoch].ref_count -= 1

def get_current_stake():    uint256 _rewards = 0;
    // Process next epoch rewards and increment stake    maybe_process_next_epoch_state()    // Perform again to capture max two additional epochs    maybe_process_next_epoch_state()
    current_delegator.rewards() += _rewards;    return _rewards;
```

```prism
undelegate(uint64,uint256,uint8) : 0x5cf41514
```

```prism
function undelegate(    uint64 validatorId,    uint256 amount,    uint8 withdrawId) external returns (bool success);
```

```prism
uint64 validator_id = msg.input.val_id;uint256 amount = msg.input.amount;uint8 withdraw_id = msg.input.withdraw_id;
ValExecution current_validator = val_execution[validator_id];
// set validator informationcurrent_validator =  ValExecution{    uint256 stake -= amount;}
// apply get_current_stake() first.get_current_stake();
DelInfo current_delegator = delegator[validator_id][msg.sender];// set delegator informationcurrent_delegator = DelInfo{    uint256 stake -= amount;}
// set withdraw requestwithdrawal[validator_id][msg.sender][withdraw_id] = WithdrawalRequest{    uint256 amount = amount;    uint256 acc = current_validator.acc();    uint64 epoch = getEpoch();});
// set epoch accumulatorepoch_acc[validator_id][getEpoch()].ref_count += 1;
// schedule validator to leave setif current_validator.stake < ACTIVE_VALIDATOR_STAKE and validator_id in execution_valset:    current_validator.set_flag(INSUFFICIENT_STAKE);
if (current_delegator.stake <= MIN_AUTH_ADDRESS_STAKE and validator_id in execution_valset) and msg.sender == current_validator.auth_address:    current_validator.set_flag(INSUFFICIENT_VALIDATOR_STAKE);
```

```prism
withdraw(uint64,uint8) : 0xaed2ee73
```

```prism
function withdraw(    uint64 validatorId,    uint8 withdrawId) external returns (bool success);
```

```prism
uint64 validator_id = msg.input.val_id;uint8 withdraw_id = msg.input.withdraw_id;
WithdrawalRequest current_withdraw = withdrawal[validator_id][msg.sender][withdraw_id];
// Compute any additional rewards and transfer funds to delegatortransfer(msg.sender, current_withdraw.amount + get_withdraw_rewards());
// unset withdraw requestwithdrawal[validator_id][msg.sender][withdraw_id] = WithdrawalRequest{    uint256 amount = 0,    uint256 acc = 0,    uint64 epoch = 0};
def get_withdraw_rewards():    epoch_acc[validator_id][current_withdraw.epoch].ref_count -= 1;    return current_withdraw.amount() * (epoch_acc[validator_id][current_withdraw.epoch()].val() - current_withdraw.acc());
```

```prism
compound(uint64) : 0xb34fea67
```

```prism
function compound(    uint64 validatorId) external returns (bool success);
```

```prism
validator_id = msg.input.val_id;
// set delegator informationDelInfo current_delegator = delegator[validator_id][msg.sender];
// apply get_current_stake() first. This updates the delegator stake// to be inline with the current stake activated in consensus.rewards_compounded = get_current_stake();
// apply add_stake() second.uint256[4] add_stake_info = add_stake(rewards_compounded);
// set delegator informationcurrent_delegator = DelInfo{    uint256 delta_stake = add_stake_info[0];    uint256 next_delta_stake = add_stake_info[1];    uint64 delta_epoch = add_stake_info[2];    uint64 next_delta_epoch = add_stake_info[3];    uint256 rewards = 0;}
// set validator informationval_execution[validator_id] = ValExecution{    uint256 stake += rewards_compounded;}
// set accumulatorepoch_acc[validator_id][getEpoch()] = Accumulator{    uint256 ref_count += 1;}
// set flagsset_flags();
// push validator idif val_execution[validator_id].stake() >= ACTIVE_VALIDATOR_STAKE and validator_id not in execution_valset:    execution_valset.push(validator_id);
```

```prism
claimRewards(uint64) : 0xa76e2ca5
```

```prism
function claimRewards(    uint64 validatorId) external returns (bool success);
```

```prism
// set delegator informationDelInfo current_delegator = delegator[validator_id][msg.sender];
// apply get_current_stake() first.uint256 current_rewards = get_current_stake();
// set delegator informationcurrent_delegator = DelInfo{    uint256 rewards = 0;)
// send rewards to delegatortransfer(msg.sender, current_rewards);
```

```prism
changeCommission(uint64,uint256) : 0x9bdcc3c8
```

```prism
function changeCommission(    uint64 validatorId,    uint256 commission) external returns (bool success);
```

```prism
validator_id = msg.input.val_id;

val_execution[validator_id] = ValExecution{    uint256 commission = msg.input.commission;}
```

```prism
externalReward(uint64) : 0xe4b3303b
```

```prism
function externalReward(    uint64 validatorId) external returns (bool success);
```

```prism
validator_id = msg.input.val_id;
require(msg.value >= 1e18 && msg.value <= 1e24, "Reward out of bounds");require(val_consensus[validator_id] > 0 , "Validator not active");
val_execution[validator_id].unclaimed_reward += msg.value;val_execution[val_id].acc += msg.value / val_consensus[val_id].stake();
```

```prism
getValidator(uint64) : 0x2b6d639a
```

```prism
function getValidator(    uint64 validatorId) external view returns (    address authAddress,    uint64 flags,    uint256 stake,    uint256 accRewardPerToken,    uint256 commission,    uint256 unclaimedRewards,    uint256 consensusStake,    uint256 consensusCommission,    uint256 snapshotStake,    uint256 snapshotCommission,    bytes memory secpPubkey,    bytes memory blsPubkey);
```

```prism
getDelegator(uint64,address) : 0x573c1ce0
```

```prism
function getDelegator(    uint64 validatorId,     address delegator) external returns (    uint256 stake,    uint256 accRewardPerToken,    uint256 unclaimedRewards,    uint256 deltaStake,    uint256 nextDeltaStake,    uint64 deltaEpoch,    uint64 nextDeltaEpoch);
```

```prism
getWithdrawalRequest(uint64,address,uint8) : 0x56fa2045
```

```prism
function getWithdrawalRequest(    uint64 validatorId,    address delegator,    uint8 withdrawId) external returns (    uint256 withdrawalAmount,    uint256 accRewardPerToken,    uint64 withdrawEpoch);
```

```prism
getConsensusValidatorSet(uint32) : 0xfb29b729getSnapshotValidatorSet(uint32) : 0xde66a368getExecutionValidatorSet(uint32) : 0x7cb074df
```

```prism
function getConsensusValidatorSet(    uint32 startIndex) external returns (bool isDone, uint32 nextIndex, uint64[] memory valIds);
function getSnapshotValidatorSet(    uint32 startIndex) external returns (bool isDone, uint32 nextIndex, uint64[] memory valIds);
function getExecutionValidatorSet(    uint32 startIndex) external returns (bool isDone, uint32 nextIndex, uint64[] memory valIds);
```

```prism
getDelegations(address,uint64) : 0x4fd66050
```

```prism
function getDelegations(    address delegator,    uint64 startValId) external returns (bool isDone, uint64 nextValId, uint64[] memory valIds);
```

```prism
getDelegators(uint64,address) : 0xa0843a26
```

```prism
function getDelegators(    uint64 validatorId,    address startDelegator) external returns (bool isDone, address nextDelegator, address[] memory delegators);
```

```prism
getEpoch() : 0x757991a8
```

```prism
function getEpoch() external returns (uint64 epoch, bool inEpochDelayPeriod);
```

```prism
getProposerValId() : 0xfbacb0be
```

```prism
function getProposerValId() external returns (uint64 val_id);
```

```prism
syscallOnEpochChange(uint64) : 0x1d4e9f02
```

```prism
function syscallOnEpochChange(uint64 epoch) external;
```

```prism
uint64 current_epoch = msg.input.epoch;
for i in snapshot_valset:    if epoch_acc[i][current_epoch] is not empty:        epoch_acc[i][current_epoch].val() = execution_valset[i].acc()    if epoch_acc[i][current_epoch + 1] is not empty:        epoch_acc[i][current_epoch].val() = execution_valset[i].acc()
in_epoch_delay_rounds = false;epoch = current_epoch;
```

```prism
syscallReward(address) : 0x791bdcf3
```

```prism
function syscallReward(address blockAuthor) external;
```

```prism
uint64 val_id = secp_to_val_id[block_author];DelInfo auth_del = delegator[val_id][val_execution[val_id].auth_address()];uint256 _commission = REWARD * val_execution[val_id].commission / 1e18;uint256 _unclaimed_rewards = REWARD - _commission;
// state updateauth_del.rewards() += _commission;val_execution[val_id].unclaimed_rewards += _unclaimed_rewards;val_execution[val_id].acc += _unclaimed_rewards / val_consensus[val_id].stake();
mint(STAKING_CONTRACT_ADDRESS, REWARD);
```

```prism
syscallSnapshot() : 0x157eeb21
```

```prism
function syscallSnapshot() external;
```

```prism
uint64[] filter_top_n_validators = sort(execution_valset);
for i in snapshot_valset:    val_snapshot[i].stake = 0;    val_snapshot[i].commission = 0;
snapshot_valset = consensus_valset;consensus_valset = filter_top_n_validators;
for i in filter_top_n_validators:    val_consensus[i].stake = val_execution[i].stake;    val_consensus[i].commission = val_execution[i].commission;
```

```prism
event ValidatorRewarded(        uint64 indexed validatorId,        address indexed from,        uint256 amount,        uint64 epoch);
```

```prism
event ValidatorCreated(    uint64  indexed validatorId,    address indexed authAddress,    uint256 commission);
```

```prism
event ValidatorStatusChanged(    uint64  indexed validatorId,    uint64  flags);
```

```prism
event Delegate(    uint64  indexed validatorId,    address indexed delegator,    uint256 amount,    uint64  activationEpoch);
```

```prism
event Undelegate(    uint64  indexed validatorId,    address indexed delegator,    uint8   withdrawId,    uint256 amount,    uint64  activationEpoch);
```

```prism
event Withdraw(    uint64 indexed validatorId,    address indexed delegator,    uint8   withdrawId,    uint256 amount,    uint64  withdrawEpoch);
```

```prism
event ClaimRewards(    uint64 indexed validatorId,    address indexed delegator,    uint256 amount,    uint64 epoch);
```

```prism
event CommissionChanged(    uint64 indexed validatorId,    uint256 oldCommission,    uint256 newCommission);
```

```prism
event EpochChanged(        uint64 oldEpoch,        uint64 newEpoch    );
```

```prism
// Minimum stake required from validator's own account// to be eligible to join the valset, in Monad weiuint256 MIN_AUTH_ADDRESS_STAKE;
// Min stake required (including delegation) for validator// to be eligible to join the valset, in Monad wei.// note that ACTIVE_VALIDATOR_STAKE > MIN_AUTH_ADDRESS_STAKEuint256 ACTIVE_VALIDATOR_STAKE;
// Block Rewarduint256 REWARD;
// Accumulator unit multiplier. Chosen to preserve accuracyuint256 ACCUMULATOR_DENOMINATOR = 1e36;
// Staking precompile addressAddress STAKING_CONTRACT_ADDRESS = 0x0000000000000000000000000000000000001000;
// Withdrawal delay, needed to facilitate slashinguint8 WITHDRAWAL_DELAY = 1;
// Controls the maximum number of results returned by individual// calls to valset-getters, get_delegators, and get_delegationsuint64 PAGINATED_RESULTS_SIZE = 100;
```

```prism
struct ValExecution             // Realtime execution state for one validator{    uint256 stake;              // Upcoming stake pool balance    uint256 acc;                // Current accumulator value for validator    uint256 commission;         // Proportion of block reward charged as commission, times 1e18; 10% = 1e17    bytes   secp_pubkey;        // Secp256k1 public key used by consensus    bytes   bls_pubkey;         // Bls public key used by consensus    uint256 address_flags;      // Flags to represent validators' current state    uint256 unclaimed_rewards;  // Unclaimed rewards    address auth_address;       // Delegator address with authority over validator stake}
struct ValConsensus             // A subset of validator state for the consensus system{    uint256 stake;              // Current active stake    uint256 commission;         // Commission rate for current epoch    bytes   secp_pubkey;        // Secp256k1 public key used by consensus    bytes   bls_pubkey;         // Bls public key used by consensus}
```

```prism
struct DelInfo{    uint256 stake;               // Current active stake    uint256 acc;                 // Last checked accumulator    uint256 rewards;             // Last checked rewards    uint256 delta_stake;         // Stake to be activated next epoch    uint256 next_delta_stake;    // Stake to be activated in 2 epochs    uint64 delta_epoch;          // Epoch when delta_stake becomes active    uint64 next_delta_epoch;     // Epoch when next_delta_stake becomes active}
struct WithdrawalRequest{    uint256 amount;              // Amount to undelegate from validator    uint256 acc;                 // Validator accumulator when undelegate was called    uint64 epoch;                // Epoch when undelegate stake deactivates};
struct Accumulator{    uint256 val;               // Current accumulator value    uint256 refcount;            // Reference count for this accumulator value};
```

```prism
// Current consensus epochuint64 epoch;
// Flag indicating if currently in epoch delay roundsbool in_epoch_delay_rounds;
// Counter for validator idsuint64 last_val_id;
// Current execution view of validator setStorageArray<uint64> execution_valset;
// Previous consensus view of validator setStorageArray<uint64> snapshot_valset;
// Current consensus view of validator setStorageArray<uint64> consensus_valset;
```

```prism
//These mappings only exist to ensure the SECP/BLS Keys are uniquemapping (secp_eth_address => uint64) secp_to_val_id;mapping (bls_eth_address => uint64) bls_to_val_id;
// Keys(val_id, epoch) => Value(acc)// making note of the validator accumulator at start of epoch.mapping(uint64 => mapping(uint64 => Accumulator)) epoch_acc;
// Key(val_id)// Contains the validator info for the execution view. Changes to stake// or commission are reflected immediately.mapping(uint64 => ValExecution) val_execution;
// Key(val_id)// Contains a subset of the validator info relevant to consensus. Changes to// stake or commission are reflected in the following epoch. This is referenced// by the reward system call *before* the epoch delay rounds.mapping(uint64 => ValConsensus) val_consensus;
// Key(val_id)// Contains a subset of the validator info relevant to consensus. Changes to// stake or commission are reflected in the following epoch. This is referenced// by the reward system call *during* the epoch delay rounds.mapping(uint64 => ValConsensus) val_snapshot;
// Keys(val_id,msg.sender) => DelInfomapping(uint64 => mapping(address => DelInfo)) delegator;
// Keys(val_id,msg.sender,withdrawal_id) => WithdrawalRequestmapping(uint64 => mapping(address => mapping (uint8 => WithdrawalRequest))) withdrawal;
```

```prism
// SPDX-License-Identifier: MITpragma solidity ^0.8.15;
interface IMonadStaking {    function addValidator(        bytes calldata payload,        bytes calldata signedSecpMessage,        bytes calldata signedBlsMessage    ) external payable returns (uint64 validatorId);
    function delegate(        uint64 validatorId    ) external payable returns (bool success);
    function undelegate(        uint64 validatorId,        uint256 amount,        uint8 withdrawId    ) external returns (bool success);
    function compound(        uint64 validatorId    ) external returns (bool success);
    function withdraw(        uint64 validatorId,        uint8 withdrawId    ) external returns (bool success);
    function claimRewards(        uint64 validatorId    ) external returns (bool success);
    function changeCommission(        uint64 validatorId,        uint256 commission    ) external returns (bool success);
    function externalReward(        uint64 validatorId    ) external returns (bool success);

    function getValidator(        uint64 validatorId    ) external view returns (        address authAddress,        uint64 flags,        uint256 stake,        uint256 accRewardPerToken,        uint256 commission,        uint256 unclaimedRewards,        uint256 consensusStake,        uint256 consensusCommission,        uint256 snapshotStake,        uint256 snapshotCommission,        bytes memory secpPubkey,        bytes memory blsPubkey    );
    function getDelegator(        uint64 validatorId,         address delegator    ) external returns (        uint256 stake,        uint256 accRewardPerToken,        uint256 unclaimedRewards,        uint256 deltaStake,        uint256 nextDeltaStake,        uint64 deltaEpoch,        uint64 nextDeltaEpoch    );
    function getWithdrawalRequest(        uint64 validatorId,        address delegator,        uint8 withdrawId    ) external returns (        uint256 withdrawalAmount,        uint256 accRewardPerToken,        uint64 withdrawEpoch    );
    function getConsensusValidatorSet(        uint32 startIndex    ) external returns (bool isDone, uint32 nextIndex, uint64[] memory valIds);
    function getSnapshotValidatorSet(        uint32 startIndex    ) external returns (bool isDone, uint32 nextIndex, uint64[] memory valIds);
    function getExecutionValidatorSet(        uint32 startIndex    ) external returns (bool isDone, uint32 nextIndex, uint64[] memory valIds);
    function getDelegations(        address delegator,        uint64 startValId    ) external returns (bool isDone, uint64 nextValId, uint64[] memory valIds);
    function getDelegators(        uint64 validatorId,        address startDelegator    ) external returns (bool isDone, address nextDelegator, address[] memory delegators);
    function getEpoch() external returns (uint64 epoch, bool inEpochDelayPeriod);
    function getProposerValId() external returns (uint64 val_id);
    function syscallOnEpochChange(uint64 epoch) external;
    function syscallReward(address blockAuthor) external;
    function syscallSnapshot() external;
     event ValidatorRewarded(        uint64 indexed validatorId,        address indexed from,        uint256 amount,        uint64 epoch    );    event ValidatorCreated(        uint64  indexed validatorId,        address indexed authAddress,        uint256 commission
    );    event ValidatorStatusChanged(        uint64  indexed validatorId,        uint64  flags    );    event Delegate(        uint64  indexed validatorId,        address indexed delegator,        uint256 amount,        uint64  activationEpoch    );    event Undelegate(        uint64  indexed validatorId,        address indexed delegator,        uint8   withdrawId,        uint256 amount,        uint64  activationEpoch    );    event Withdraw(        uint64 indexed validatorId,        address indexed delegator,        uint8   withdrawId,        uint256 amount,        uint64  withdrawEpoch    );    event ClaimRewards(        uint64 indexed validatorId,        address indexed delegator,        uint256 amount,        uint64  epoch    );    event CommissionChanged(        uint64 indexed validatorId,        uint256 oldCommission,        uint256 newCommission    );    event EpochChanged(        uint64 oldEpoch,        uint64 newEpoch    );}
```

```prism
[  {"type":"function","name":"addValidator","inputs":[{"name":"payload","type":"bytes","internalType":"bytes"},{"name":"signedSecpMessage","type":"bytes","internalType":"bytes"},{"name":"signedBlsMessage","type":"bytes","internalType":"bytes"}],"outputs":[{"name":"validatorId","type":"uint64","internalType":"uint64"}],"stateMutability":"payable"},  {"type":"function","name":"changeCommission","inputs":[{"name":"validatorId","type":"uint64","internalType":"uint64"},{"name":"commission","type":"uint256","internalType":"uint256"}],"outputs":[{"name":"success","type":"bool","internalType":"bool"}],"stateMutability":"nonpayable"},  {"type":"function","name":"claimRewards","inputs":[{"name":"validatorId","type":"uint64","internalType":"uint64"}],"outputs":[{"name":"success","type":"bool","internalType":"bool"}],"stateMutability":"nonpayable"},  {"type":"function","name":"compound","inputs":[{"name":"validatorId","type":"uint64","internalType":"uint64"}],"outputs":[{"name":"success","type":"bool","internalType":"bool"}],"stateMutability":"nonpayable"},  {"type":"function","name":"delegate","inputs":[{"name":"validatorId","type":"uint64","internalType":"uint64"}],"outputs":[{"name":"success","type":"bool","internalType":"bool"}],"stateMutability":"payable"},  {"type":"function","name":"externalReward","inputs":[{"name":"validatorId","type":"uint64","internalType":"uint64"}],"outputs":[{"name":"success","type":"bool","internalType":"bool"}],"stateMutability":"nonpayable"},  {"type":"function","name":"getConsensusValidatorSet","inputs":[{"name":"startIndex","type":"uint32","internalType":"uint32"}],"outputs":[{"name":"isDone","type":"bool","internalType":"bool"},{"name":"nextIndex","type":"uint32","internalType":"uint32"},{"name":"valIds","type":"uint64[]","internalType":"uint64[]"}],"stateMutability":"nonpayable"},  {"type":"function","name":"getDelegations","inputs":[{"name":"delegator","type":"address","internalType":"address"},{"name":"startValId","type":"uint64","internalType":"uint64"}],"outputs":[{"name":"isDone","type":"bool","internalType":"bool"},{"name":"nextValId","type":"uint64","internalType":"uint64"},{"name":"valIds","type":"uint64[]","internalType":"uint64[]"}],"stateMutability":"nonpayable"},  {"type":"function","name":"getDelegator","inputs":[{"name":"validatorId","type":"uint64","internalType":"uint64"},{"name":"delegator","type":"address","internalType":"address"}],"outputs":[{"name":"stake","type":"uint256","internalType":"uint256"},{"name":"accRewardPerToken","type":"uint256","internalType":"uint256"},{"name":"unclaimedRewards","type":"uint256","internalType":"uint256"},{"name":"deltaStake","type":"uint256","internalType":"uint256"},{"name":"nextDeltaStake","type":"uint256","internalType":"uint256"},{"name":"deltaEpoch","type":"uint64","internalType":"uint64"},{"name":"nextDeltaEpoch","type":"uint64","internalType":"uint64"}],"stateMutability":"nonpayable"},  {"type":"function","name":"getDelegators","inputs":[{"name":"validatorId","type":"uint64","internalType":"uint64"},{"name":"startDelegator","type":"address","internalType":"address"}],"outputs":[{"name":"isDone","type":"bool","internalType":"bool"},{"name":"nextDelegator","type":"address","internalType":"address"},{"name":"delegators","type":"address[]","internalType":"address[]"}],"stateMutability":"nonpayable"},  {"type":"function","name":"getEpoch","inputs":[],"outputs":[{"name":"epoch","type":"uint64","internalType":"uint64"},{"name":"inEpochDelayPeriod","type":"bool","internalType":"bool"}],"stateMutability":"nonpayable"},  {"type":"function","name":"getProposerValId","inputs":[],"outputs":[{"name":"val_id","type":"uint64","internalType": "uint64"}],  "stateMutability":"nonpayable"},   {"type":"function","name":"getExecutionValidatorSet","inputs":[{"name":"startIndex","type":"uint32","internalType":"uint32"}],"outputs":[{"name":"isDone","type":"bool","internalType":"bool"},{"name":"nextIndex","type":"uint32","internalType":"uint32"},{"name":"valIds","type":"uint64[]","internalType":"uint64[]"}],"stateMutability":"nonpayable"},  {"type":"function","name":"getSnapshotValidatorSet","inputs":[{"name":"startIndex","type":"uint32","internalType":"uint32"}],"outputs":[{"name":"isDone","type":"bool","internalType":"bool"},{"name":"nextIndex","type":"uint32","internalType":"uint32"},{"name":"valIds","type":"uint64[]","internalType":"uint64[]"}],"stateMutability":"nonpayable"},  {"type":"function","name":"getValidator","inputs":[{"name":"validatorId","type":"uint64","internalType":"uint64"}],"outputs":[{"name":"authAddress","type":"address","internalType":"address"},{"name":"flags","type":"uint64","internalType":"uint64"},{"name":"stake","type":"uint256","internalType":"uint256"},{"name":"accRewardPerToken","type":"uint256","internalType":"uint256"},{"name":"commission","type":"uint256","internalType":"uint256"},{"name":"unclaimedRewards","type":"uint256","internalType":"uint256"},{"name":"consensusStake","type":"uint256","internalType":"uint256"},{"name":"consensusCommission","type":"uint256","internalType":"uint256"},{"name":"snapshotStake","type":"uint256","internalType":"uint256"},{"name":"snapshotCommission","type":"uint256","internalType":"uint256"},{"name":"secpPubkey","type":"bytes","internalType":"bytes"},{"name":"blsPubkey","type":"bytes","internalType":"bytes"}],"stateMutability":"view"},  {"type":"function","name":"getWithdrawalRequest","inputs":[{"name":"validatorId","type":"uint64","internalType":"uint64"},{"name":"delegator","type":"address","internalType":"address"},{"name":"withdrawId","type":"uint8","internalType":"uint8"}],"outputs":[{"name":"withdrawalAmount","type":"uint256","internalType":"uint256"},{"name":"accRewardPerToken","type":"uint256","internalType":"uint256"},{"name":"withdrawEpoch","type":"uint64","internalType":"uint64"}],"stateMutability":"nonpayable"},  {"type":"function","name":"syscallOnEpochChange","inputs":[{"name":"epoch","type":"uint64","internalType":"uint64"}],"outputs":[],"stateMutability":"nonpayable"},  {"type":"function","name":"syscallReward","inputs":[{"name":"blockAuthor","type":"address","internalType":"address"}],"outputs":[],"stateMutability":"nonpayable"},  {"type":"function","name":"syscallSnapshot","inputs":[],"outputs":[],"stateMutability":"nonpayable"},  {"type":"function","name":"undelegate","inputs":[{"name":"validatorId","type":"uint64","internalType":"uint64"},{"name":"amount","type":"uint256","internalType":"uint256"},{"name":"withdrawId","type":"uint8","internalType":"uint8"}],"outputs":[{"name":"success","type":"bool","internalType":"bool"}],"stateMutability":"nonpayable"},  {"type":"function","name":"withdraw","inputs":[{"name":"validatorId","type":"uint64","internalType":"uint64"},{"name":"withdrawId","type":"uint8","internalType":"uint8"}],"outputs":[{"name":"success","type":"bool","internalType":"bool"}],"stateMutability":"nonpayable"},  {"type":"event","name":"ClaimRewards","inputs":[{"name":"validatorId","type":"uint64","indexed":true,"internalType":"uint64"},{"name":"delegator","type":"address","indexed":true,"internalType":"address"},{"name":"amount","type":"uint256","indexed":false,"internalType":"uint256"},{"name":"epoch","type":"uint64","indexed":false,"internalType":"uint64"}],"anonymous":false},  {"type":"event","name":"CommissionChanged","inputs":[{"name":"validatorId","type":"uint64","indexed":true,"internalType":"uint64"},{"name":"oldCommission","type":"uint256","indexed":false,"internalType":"uint256"},{"name":"newCommission","type":"uint256","indexed":false,"internalType":"uint256"}],"anonymous":false},  {"type":"event","name":"Delegate","inputs":[{"name":"validatorId","type":"uint64","indexed":true,"internalType":"uint64"},{"name":"delegator","type":"address","indexed":true,"internalType":"address"},{"name":"amount","type":"uint256","indexed":false,"internalType":"uint256"},{"name":"activationEpoch","type":"uint64","indexed":false,"internalType":"uint64"}],"anonymous":false},  {"type":"event","name":"EpochChanged","inputs":[{"name":"oldEpoch","type":"uint64","indexed":false,"internalType":"uint64"},{"name":"newEpoch","type":"uint64","indexed":false,"internalType":"uint64"}],"anonymous":false},  {"type":"event","name":"Undelegate","inputs":[{"name":"validatorId","type":"uint64","indexed":true,"internalType":"uint64"},{"name":"delegator","type":"address","indexed":true,"internalType":"address"},{"name":"withdrawId","type":"uint8","indexed":false,"internalType":"uint8"},{"name":"amount","type":"uint256","indexed":false,"internalType":"uint256"},{"name":"activationEpoch","type":"uint64","indexed":false,"internalType":"uint64"}],"anonymous":false},  {"type":"event","name":"ValidatorCreated","inputs":[{"name":"validatorId","type":"uint64","indexed":true,"internalType":"uint64"},{"name":"authAddress","type":"address","indexed":true,"internalType":"address"},{"name":"commission","type":"uint256","indexed":false,"internalType":"uint256"}],"anonymous":false},  {"type":"event","name":"ValidatorRewarded","inputs":[{"name":"validatorId","type":"uint64","indexed":true,"internalType":"uint64"},{"name":"from","type":"address","indexed":true,"internalType":"address"},{"name":"amount","type":"uint256","indexed":false,"internalType":"uint256"},{"name":"epoch","type":"uint64","indexed":false,"internalType":"uint64"}],"anonymous":false},  {"type":"event","name":"ValidatorStatusChanged","inputs":[{"name":"validatorId","type":"uint64","indexed":true,"internalType":"uint64"},{"name":"flags","type":"uint64","indexed":false,"internalType":"uint64"}],"anonymous":false},  {"type":"event","name":"Withdraw","inputs":[{"name":"validatorId","type":"uint64","indexed":true,"internalType":"uint64"},{"name":"delegator","type":"address","indexed":true,"internalType":"address"},{"name":"withdrawId","type":"uint8","indexed":false,"internalType":"uint8"},{"name":"amount","type":"uint256","indexed":false,"internalType":"uint256"},{"name":"withdrawEpoch","type":"uint64","indexed":false,"internalType":"uint64"}],"anonymous":false}]
```

---

## Transactions

> Source: https://docs.monad.xyz/developer-essentials/transactions

On this page

Summary​

Same address space and transaction format/fields as Ethereum, so the same wallet software is
supported.
Transaction types 0 ("legacy"), 1 ("EIP-2930"), 2 ("EIP-1559"), and 4 ("EIP-7702") are currently supported.
Pre-EIP-155 transactions are allowed on the protocol
level, as in Ethereum and many other EVM-compatible blockchains. As a result, users are
discouraged from using an Ethereum address that had previously sent pre-EIP-155 transactions.

Address space​
Same address space as Ethereum (last 20 bytes of ECDSA public key)
Transaction format​
Same as Ethereum. Monad transactions use
the same typed transaction envelope introduced in
EIP-2718, encoded with
RLP.
Transaction types​
These transaction types
are supported:

Type 0 ("legacy")
Type 1 ("EIP-2930")
Type 2 ("EIP-1559"; the default in Ethereum)
Type 4 ("EIP-7702") (see EIP-7702 on Monad)

These types are not supported:

Type 3 ("EIP-4844")

Access lists​
Access lists (EIP-2930) are supported but not required.
Transactions without a chain_id​
EIP-155 introduced a transaction standard that includes a
chain id, to prevent transactions from one blockchain from being replayed on another one.
Transactions on Monad should always set the chain id, except for one very specific corner case:
noteThe corner case: Some standard smart contracts such as ERC-1820 use a keyless deployment method
(also known as Nick's method) that exploits replayability, as discussed
here. In this method, a transaction is
submitted on Ethereum but is intended to be replayed on other chains in order to have the contract
deployed at the same address on other blockchains.
In order to support this use case, pre-EIP-155 transactions are still allowed on the protocol level
(i.e. according to consensus rules) on Monad. This makes Monad consistent with most blockchains
including Ethereum. (Blockchains that have tried disallowing pre-EIP-155 transactions at the
protocol level have typically ended up reversing course, e.g.
Celo.)
However, because of this, please heed the following warning:
warningBecause replay of pre-EIP-155 transactions is allowed, it is discouraged to send funds to an
Ethereum address that had previously sent pre-EIP-155 transactions.

---



# Section: execution-events

---

## Advanced topics

> Source: https://docs.monad.xyz/execution-events/advanced

On this page

When are events published?​
Execution events are recorded roughly "as they are happening" inside the
execution daemon: you see a BLOCK_START event at roughly the same moment
that the execution daemon beings processing a new block, followed by the
start of the first transaction (a TXN_HEADER_START event) about 1 millisecond
later. Most transaction-related events are recorded less than one
microsecond after the transaction they describe has completed.
Execution of a typical transaction will emit a few dozen events, but large
transactions can emit hundreds of events. The TXN_EVM_OUTPUT event -- which
is recorded as soon as the transaction is finished -- provides a summary
accounting of how many more events related to that transaction will follow
(how many logs, how many call frames, etc.), so that memory to store the
subsequent event data can be preallocated. For example in Rust,
Vec::reserve
is often called here. An event like TXN_EVM_OUTPUT is referred as a "header
event" in the documentation: it is an event whose content describes some summary
information and the number of subsequent, related events that will be recorded
later with more details.
All these events are recorded as soon as the transaction is "committed" to the
currently-executing block. This happens before the block has finished
executing, and should not be confused with the unrelated notion of "commitment"
in the consensus algorithm. Although there are complex speculative execution
optimizations inside the execution daemon, the recording of a transaction takes
place when all work on a particular transaction has finished. This is referred
to as "transaction commit" time.
This is a different than the block-at-a-time style update you would see in,
for example, the Geth real-time events WebSocket protocol (which our RPC server
also supports). Certain properties of the block
(its hash, its state root, etc.) are not known at the time you see a
transaction's events, because the rest of the block is still executing. If you
would like block-at-a-time updates, the Rust SDK contains
some utilities
which will aggregate the events back into complete, block-oriented updates.
One thing to be careful of: although transactions are always committed to a
block in index order, they might be recorded out of order. That is, you must
assume that the set of execution events that make up transactions 2 and 3
could be "mixed together" in any order. This is because of optimizations in
the event recording code path.
However, for a particular transaction (e.g., transaction 3) events pertaining
to that transaction are always recorded in the same order: first all of the
logs, then all the call frames, then all the state access records. Each of
these is recorded in index order, i.e., log 2 is always recorded before
log 3.
Consider the following diagram:
  ╔═Events═════════════════════════════╗  ║                                    ║  ║ ┌───────────────────────────────┐  ║  ║ │ event type:  TXN_EVM_OUTPUT   │  ║  ║ │ transaction: 1                │  ║  ║ │ log count:   2                │  ║  ║ └───────────────────────────────┘  ║  ║                                    ║  ║ ┌───────────────────────────────┐  ║  ║ │ event type:  TXN_LOG          │  ║  ║ │ transaction: 1                │  ║  ║ │ log index:   0                │  ║  ║ │ <log details>                 │  ║  ║ └───────────────────────────────┘  ║  ║                                    ║  ║ ┌───────────────────────────────┐  ║  ║ │ event type:  TXN_EVM_OUTPUT   │  ║  ║ │ transaction: 0                │  ║  ║ │ log count:   3                │  ║  ║ └───────────────────────────────┘  ║  ║                                    ║  ║ ┌───────────────────────────────┐  ║  ║ │ event type:  TXN_LOG          │  ║  ║ │ transaction: 0                │  ║  ║ │ log index:   0                │  ║  ║ │ <log details>                 │  ║  ║ └───────────────────────────────┘  ║  ║                                    ║  ║ ┌───────────────────────────────┐  ║  ║ │ event type:  TXN_LOG          │  ║  ║ │ transaction: 0                │  ║  ║ │ log index:   1                │  ║  ║ │ <log details>                 │  ║  ║ └───────────────────────────────┘  ║  ║                                    ║  ║ ┌───────────────────────────────┐  ║  ║ │ event type:  TXN_LOG          │  ║  ║ │ transaction: 1                │  ║  ║ │ log index:   1                │  ║  ║ │ <log details>                 │  ║  ║ └───────────────────────────────┘  ║  ║                                    ║  ║ ┌───────────────────────────────┐  ║  ║ │ event type:  TXN_LOG          │  ║  ║ │ transaction: 0                │  ║  ║ │ log index:   2                │  ║  ║ │ <log details>                 │  ║  ║ └───────────────────────────────┘  ║  ║                                    ║  ╚════════════════════════════════════╝
A few things to note here:


Unlike most diagrams in the documentation, the events are shown in a
simplified, "merged" form; in real events, some of this information is
stored in the event descriptor and some is stored in the event payload,
but they're combined to make the diagram simpler


It shows two transactions, with transaction indices 0 and 1. Although
transaction 0 completes first in the EVM, its TXN_EVM_OUTPUT event is
recorded after than the TXN_EVM_OUTPUT of transaction 1


Events from the transactions are interleaved: sometimes the next one relates
to transaction 0, sometimes to transaction 1, and there is no meaningful order
between them


Despite the transactions being out-of-order with respect to each other,
all the events associated with a particular transaction are always in relative
order, i.e., the log indicies for a particular transaction will always be seen
in log_index order, as above


This is easy to understand if you imagine all of a transaction's events being
recorded by a different thread. For a particular transaction, its thread always
records that transaction's events in order, but the "transaction threads"
themselves race against each other, recording in a non-deterministic order.
This is similar to what really happens, except the transactions are recorded on
fibers rather than
full threads.
Sequence numbers and the lifetime detection algorithm​
All event descriptors are tagged with an incrementing sequence number
starting at 1. Sequence numbers are 64-bit unsigned integers which do not
repeat unless the execution daemon is restarted. Zero is not valid sequence
number.
Also note that the sequence number modulo the descriptor array size equals
the array index where the next event descriptor will be located. This is
shown below with a concrete example where the descriptor array size is 64.
Note that the last valid index in the array is 63, then access wraps around
to the beginning of the array at index 0.
                                                         ◇                                                         │  ╔═...═════════════════════════Event descriptor array═══╬═══════════════════...═╗  ║                                                      │                       ║  ║     ┌─Event────────┐┌─Event────────┐┌─Event────────┐ │ ┌─Event─────────┐     ║  ║     │              ││              ││              │ │ │               │     ║  ║     │ seqnum = 318 ││ seqnum = 319 ││ seqnum = 320 │ │ │ seqnum = 256  │     ║  ║     │              ││              ││              │ │ │               │     ║  ║     └──────────────┘└──▲───────────┘└──────────────┘ │ └───────────────┘     ║  ║            61          │   62              63        │         0             ║  ╚═...════════════════════╬═════════════════════════════╬═══════════════════...═╝                           │                             │                           ■                             ◇                           Next event                    Ring buffer                                                         wrap-around to      ┌──────────────────────────────┐                   zero is here      │last read sequence number     │      │(last_seqno) is initially 318 │      └──────────────────────────────┘
In this example:


We keep track of the "last seen sequence number" (last_seqno) which has
value 318 to start; being the "last" sequence number means we have already
finished reading the event with this sequence number, which lives at array
index 61


318 % 64 is 62, so we will find the potential next event at that index
if it has been produced


Observe that the sequence number of the item at index 62 is 319, which
is the last seen sequence number plus 1 (319 == 318 + 1). This means that
event 319 has been produced, and its data can be safely read from that
slot


When we're ready to advance to the next event, the last seen sequence
number will be incremented to 319. As before, we can find the next
event (if it has been produced) at 319 % 64 == 63. The event at this
index bears the sequence number 320, which is again the last seen
sequence number + 1, therefore this event is also valid


When advancing a second time, we increment the last seen sequence number
to 320. This time, the event at index 320 % 64 == 0 is not 321,
but is a smaller number, 256. This means the next event has not been
written yet, and we are seeing an older event in the same slot. We've
seen all of the currently available events, and will need to check again
later once a new event is written


Alternatively we might have seen a much larger sequence number, like
384 (320 + 64). This would mean that we consumed events too slowly, so
slowly that the 63 events in the range [321, 384) were produced in the
meantime. These were subsequently overwritten, and are now lost. They can
be replayed using services external to event ring API, but within the
event ring API itself there is no way to recover them


Lifetime of an event payload, zero copy vs. memcpy APIs​
Because of the descriptor overwrite behavior, an event descriptor might be
overwritten by the execution daemon while a reader is still examining its
data. To deal with this, the reader API makes a copy of the event descriptor.
If it detects that the event descriptor changed during the copy operation, it
reports a gap. Copying an event descriptor is fast, because it is only a
single cache line in size.
This is not the case for event payloads, which could potentially be very
large. This means a memcpy(3) of an event payload could be expensive, and
it would be advantageous to read the payload bytes directly from the payload
buffer's shared memory segment: a "zero-copy" API. This exposes the user to
the possibility that the event payload could be overwritten while still
using it, so two solutions are provided:


A simple detection mechanism allows payload overwrite to be detected at
any time: the writer keeps track of the minimum payload offset value
(before modular arithmetic is applied) that is still valid. If the
offset value in the event descriptor is smaller than this, it is no
longer safe to read the event payload


A payload memcpy-style API is also provided. This uses the detection
mechanism above in the following way: first, the payload is copied to
a user-provided buffer. Before returning, it checks if the lifetime
remained valid after the copy finished. If so, then an overwrite did not
occur during the copy, so the copy must be valid. Otherwise, the copy is
invalid


The reason to prefer the zero-copy APIs is that they do less work. The
reason to prefer memcpy APIs is that it is not always easy (or possible) to
"undo" the work you did if you find out later that the event payload was
corrupted by an overwrite while you were working with it. The most logical
thing to do in that case is start by copying the data to stable location,
and if the copy isn't valid, to never start the operation.
An example user of the zero-copy API is the eventwatch example C program,
which can turn events into printed strings that are sent to stdout. The
expensive work of formatting a hexdump of the event payload is performed
using the original payload memory. If an overwrite happened during the
string formatting, the hexdump output buffer will be wrong, but that is OK:
it will not be sent to stdout until the end. Once formatting is complete,
eventwatch checks if the payload expired and if so, writes an error to
stderr instead of writing the formatted buffer to stdout.
Whether you should copy or not depends on the characteristics of the reader,
namely how easily it can deal with "aborting" processing.
Location of event ring files​
For performance reasons, we prefer that event ring files be created on a
hugetlbfs
in-memory filesystem. Files created on such a filesystem will be backed by
physically-contiguous large pages, which improves performance by about 15% in
internal benchmarks.
This can be a hassle though: it is unusual for a program to require that a
file be placed on a particular kind of filesystem, and this requirement adds
some overhead. In practice, this means additional configuration steps that a
system administrator must perform when setting up a Monad node, and some
additional concepts that SDK users must learn about.
The issues are:


A hugetlbfs filesystem must be mounted somewhere on the host; usually by
default (e.g., on a Ubuntu default installation) there will not be a
hugetlbfs filesystem already present


Whomever configures a hugetlbfs filesystem must make sure that any user
that needs to open the event ring file has the appropriate permissions


The path to the event ring file (which will be somewhere on that filesystem)
must be passed into all programs that need to open it; since we don't know
where the administrator will mount the filesystem, we can't easily hard-code
a location for it in either the documentation or the source code


To simplify the developer experience as much as possible, we follow three
conventions. Each convention adds more "convenience default behavior" so that
everything will "just work" for most users, but you are free to ignore any of
the conventions and do things in your own way.
hugetlbfs is not requiredThe event ring library does not require a hugetlbfs filesystem: it can work
with any kind of regular file.  The C function that maps an event ring's
shared memory segments -- monad_event_ring_mmap -- only takes a file
descriptor, and does not know or care where this descriptor comes from. The
only constraints on it are those placed by the mmap(2) system call itself.These conventions are about adding a reasonable default for how the mount
point is set up, and helper functions for finding event ring files in that
location. You should try to use them because they provide a performance
benefit, but you are free to come up with a file descriptor in any way you
wish and it will work with monad_event_ring_mmap.
Convention 1: libhugetlbfs in the node setup guide​
The
official guide
for setting up a local Monad node for execution events recommends the use
of libhugetlbfs.
libhugetlbfs is both a C library and a set of admin tools using that
library that follow a particular configuration convention. The idea is to
standardize some rules for how mount points and permissions are managed for
hugetlbfs filesystems. There are three parts to the basic idea:


Each user (or group if you want to do it that way) gets its own
separately-mounted hugetlbfs filesystem. The mount point is located in a
well-defined place under /var/lib/hugetlbfs/user/<user-name>1


hugeadm, a program that a system administrator runs, is a configuration
front-end for tasks like listing hugetlbfs mounts, creating new mounts, etc.


The C library, libhugetlbfs, helps client programs "find" hugetlbfs mounts
that the current user has permission to access


The setup guide for the Monad node tells the user to install the libhugetlbfs
command line tools and to set up a "user mount" for the monad user. The guide
also recommends that all users be given access to enter this directory, so that
data consumer applications that run as non-monad users can open the file.
Convention 2: "default" event ring directory​
The event ring library introduces the concept of a "default event ring
directory."  This is the default directory where event ring files should be
created, and thus where reader applications should look for them. This default
can come from one of two places:


You can provide it manually OR


If you don't provide it, the library will use a conventional location


The conventional location is a subdirectory called event-rings, created
directly under whatever hugetlbfs mount point is returned by libhugeltbfs2,
i.e., it is:
<libhugeltbfs-computed-mount-point>/event-rings
If you follow the setup guide to the letter, this should be:
/var/lib/hugetlbfs/user/monad/pagesize-2MB/event-rings
But depending on how your system is setup, libhugetlbfs could return a
different path. For example, you might see something like this:
/dev/hugepages/event-rings
This is because libhugeltbfs scrapes the contents of /proc/mounts and
returns only one path that the current user has
access
to. What if the user has access to multiple hugetlbfs mounts? There is no
logic to prefer one flavor of path over another, it only depends on their
relative ordering in the /proc/mounts file.
Providing the default event ring directory manually​
You may wish to use this "open from the default directory" configuration idiom
while by-passing libhugetlbfs. The two reasons to do that are:


If you don't want the event ring file to be present on a hugetlbfs file
system at all; this is usually when you want to create an event ring file
larger than the hugetlbfs mount point (or the system's underlying pool of
huge pages) would allow


If you do not want to use libhugetlbfs as a library dependency of your
project, in which case you will want to set the CMake
MONAD_EVENT_USE_LIBHUGETLBFS option to OFF


Convention 3: event ring filename resolution​
The "default directory" concept is used in the final convention, which is a
"convenience" API call for turning user input for an event ring file into
the path where your program will attempt to open that file.
It allows users to specify a filename such as xyz and have it be translated
to a full (and ugly) path like this:
/var/lib/hugetlbfs/user/monad/pagesize-2MB/event-rings/xyz
while still allowing the user to be able to specify any file, including one
not in the default directory, if they wish.
Here is how event ring file inputs are resolved by the the C function
monad_event_ring_resolve_file and the Rust function EventRingPath::resolve:


If a "pure" filename is provided (i.e., a filename with no / character),
it is resolved relative to a provided default_path directory


Otherwise (i.e., if the file contains any / character), it is resolved
relative to the current working directory; if / is the first character,
it is resolved as an absolute path


This is similar to how a UNIX shell resolves a command name. A "pure" name
with no path characters is resolved relative to the entries in the $PATH
environment variable (i.e., it searches the default command directories). The
presence of a path-separator character causes the input to be treated like a
specific path relative to the current directory, which disables this "search".
This familiar principal applies here.
Furthermore:


In C you usually pass the sentinel value MONAD_EVENT_DEFAULT_HUGETLBFS
(which is just an alias for nullptr) as the default_path parameter; this
causes libhugetlbfs to figure out what the default hugetlbfs root path
should be3; in Rust this is just EventRingPath::resolve


You can provide your own default_path value, which can be on any path on
any filesystem; this is required if you don't want libhugetlbfs as a
dependency; in Rust this is EventRingPath::resolve_with_default_path


Resolution is only about generating path namesResolution does not try to open a file: it just standardizes the convention for
how to build a path string from the two inputs. Namely, it does not check
whether the computed file path exists or not.Remember that the event ring library itself only cares about file descriptors,
and none of its APIs (even the "helper" APIs) attempt to
open(2) a file. They just
provide "reasonable default" ways of locating files that programs can opt into.
If your host needs to set up your filesystem mounts differently, you are free to
do that.
Examples​
The table below shows how the C function monad_event_ring_resolve_file
behaves. <cwd> is the process' current working directory and <htlbfs>
is the mount point returned by libhugetlbfs.
default_path valueinput valueresolve file returns...NotesMONAD_EVENT_DEFAULT_HUGETLBFS"xyz""<htlbfs>/event-rings/xyz"MONAD_EVENT_DEFAULT_HUGETLBFS"a/b/c""<cwd>/a/b/c"default_path only affects "pure" file namesMONAD_EVENT_DEFAULT_HUGETLBFS  "/d/e/f""/d/e/f"absolute paths always remain absoluteMONAD_EVENT_DEFAULT_HUGETLBFS"monad-exec-events""<htlbfs>/event-rings/monad-exec-events"the default event ring file name used by the execution daemon"/tmp/my-event-ring-path""xyz""/tmp/my-event-ring-path/xyz"intermediate directories will be created if not existing"/tmp/my-event-ring-path""a/b/c""<cwd>/a/b/c""/tmp/my-event-ring-path""/d/e/f""/d/e/f"
In Rust, EventRingPath::resolve behaves like the MONAD_EVENT_DEFAULT_HUGETLBFS
rows, and EventRingPath::resolve_with_default_path takes an explicit
basepath argument and behaves like the bottom three rows.

Footnotes​


Other configuration schemes are possible too, see
man hugeadm ↩


The exact path might be user-dependent, and is determined by the
function hugetlbfs_find_path_for_size ↩


The actual function used is the event ring library's utility function
monad_event_open_hugetlbfs_dir_fd, which adds in the event-rings
subdirectory path component and creates it if it does not already exist ↩

### Code Examples

```prism
╔═Events═════════════════════════════╗  ║                                    ║  ║ ┌───────────────────────────────┐  ║  ║ │ event type:  TXN_EVM_OUTPUT   │  ║  ║ │ transaction: 1                │  ║  ║ │ log count:   2                │  ║  ║ └───────────────────────────────┘  ║  ║                                    ║  ║ ┌───────────────────────────────┐  ║  ║ │ event type:  TXN_LOG          │  ║  ║ │ transaction: 1                │  ║  ║ │ log index:   0                │  ║  ║ │ <log details>                 │  ║  ║ └───────────────────────────────┘  ║  ║                                    ║  ║ ┌───────────────────────────────┐  ║  ║ │ event type:  TXN_EVM_OUTPUT   │  ║  ║ │ transaction: 0                │  ║  ║ │ log count:   3                │  ║  ║ └───────────────────────────────┘  ║  ║                                    ║  ║ ┌───────────────────────────────┐  ║  ║ │ event type:  TXN_LOG          │  ║  ║ │ transaction: 0                │  ║  ║ │ log index:   0                │  ║  ║ │ <log details>                 │  ║  ║ └───────────────────────────────┘  ║  ║                                    ║  ║ ┌───────────────────────────────┐  ║  ║ │ event type:  TXN_LOG          │  ║  ║ │ transaction: 0                │  ║  ║ │ log index:   1                │  ║  ║ │ <log details>                 │  ║  ║ └───────────────────────────────┘  ║  ║                                    ║  ║ ┌───────────────────────────────┐  ║  ║ │ event type:  TXN_LOG          │  ║  ║ │ transaction: 1                │  ║  ║ │ log index:   1                │  ║  ║ │ <log details>                 │  ║  ║ └───────────────────────────────┘  ║  ║                                    ║  ║ ┌───────────────────────────────┐  ║  ║ │ event type:  TXN_LOG          │  ║  ║ │ transaction: 0                │  ║  ║ │ log index:   2                │  ║  ║ │ <log details>                 │  ║  ║ └───────────────────────────────┘  ║  ║                                    ║  ╚════════════════════════════════════╝
```

```prism
◇                                                         │  ╔═...═════════════════════════Event descriptor array═══╬═══════════════════...═╗  ║                                                      │                       ║  ║     ┌─Event────────┐┌─Event────────┐┌─Event────────┐ │ ┌─Event─────────┐     ║  ║     │              ││              ││              │ │ │               │     ║  ║     │ seqnum = 318 ││ seqnum = 319 ││ seqnum = 320 │ │ │ seqnum = 256  │     ║  ║     │              ││              ││              │ │ │               │     ║  ║     └──────────────┘└──▲───────────┘└──────────────┘ │ └───────────────┘     ║  ║            61          │   62              63        │         0             ║  ╚═...════════════════════╬═════════════════════════════╬═══════════════════...═╝                           │                             │                           ■                             ◇                           Next event                    Ring buffer                                                         wrap-around to      ┌──────────────────────────────┐                   zero is here      │last read sequence number     │      │(last_seqno) is initially 318 │      └──────────────────────────────┘
```

```prism
<libhugeltbfs-computed-mount-point>/event-rings
```

```prism
/var/lib/hugetlbfs/user/monad/pagesize-2MB/event-rings
```

```prism
/dev/hugepages/event-rings
```

```prism
/var/lib/hugetlbfs/user/monad/pagesize-2MB/event-rings/xyz
```

---

## Building the C example program

> Source: https://docs.monad.xyz/execution-events/getting-started/c

On this page

The C and C++ languages do not have a standard package manager, so using a
third-party library requires the programmer to come up with their own
dependency management scheme.
Before we perform the first step of the guide, we'll discuss the options the
user has for integrating the SDK library dependency into their project. Then
we'll pick one of these options and build the example program using that
method. A second method will be briefly shown at the end.
infoIf you are not familiar with CMake, you may want to read CMake's
"Using Dependencies Guide"
first
Where is the SDK source code?​
The execution event C SDK lives in the same source code repository as the
execution daemon (here), in the
subdirectory category/event.
It has a separate CMakeLists.txt file that can act as a top-level project
file, so that users do not need to build the full execution project in order
to compile it.
The SDK's build system produces a library called libmonad_event.a, or
libmonad_event.so if you prefer shared libraries. You will also need the
public header files.
How can my code use libmonad_event.a?​
Here are three different options:

Precompiled library - you could build the library yourself and store
the library file (and its headers) somewhere, then import it into your
build system manually. The SDK build system also creates a CMake "config"
file for use with
find_package
to help import it, if you are also using CMake

The other two options assume your project is also using CMake:


CMake subproject integration - your CMake project can include the SDK
as a subproject. In this case, you download the source code of the execution
repository as part of your own project, and call the CMake function:
add_subdirectory(<path-to-monad-repo>/category/event)
This will add the SDK's library target (called monad_event) into your
parent CMake project. One way to add the SDK code to your build is to use a
git submodule.
Another way is to use CMake's
FetchContent
module. The three main differences between these approaches are:

By default, FetchContent will clone a git repository into your CMake
build tree at build configuration time, whereas a git submodule
integrates into your source tree at the repository level
With FetchContent, the version you check out is specified by the
GIT_TAG you specify in a CMakeLists.txt file; for git submodule,
it is managed via git commands
If the content you are fetching has its own CMake buildsystem (as the
C SDK does), FetchContent will automatically call add_subdirectory
to add it to the current project; in the git submodule approach, you
need to do this manually



CMake ExternalProject integration - CMake's
ExternalProject
module is similar to FetchContent, but is more isolated; this will build
and install the SDK into a "staging" directory somewhere in your CMake build
tree. This uses a completely separate CMake invocation, so it will not add
the SDK's CMake project into your own. This means, for example, that you will
not automatically have a monad_event library target in your own CMake
project -- you would need to create one as an imported target.
ExternalProject helps isolate your build system from the SDK's build
system, ensuring that CMake configuration and variables from the SDK can't
"leak" into your parent project


In this guide, we'll use the FetchContent approach. This encapsulates the
entire process as a simple, all-in-one CMakeLists.txt file, and we comment
that file to explain everything you need to know.
This is the clear best choice for our tiny "Getting started" example program,
but it might not be best for your real project. At the end of this guide, an
alternative method using find_package is briefly shown.
Building the example program with FetchContent​
Step 1: install prerequisite development packages​
In addition to CMake (at least version 3.23) and git, we will need a recent C
compiler and two third-party libraries. We will also use
curl
to download some files.
Required C compiler​
The C SDK uses some recent features from C23, and requires either gcc-13 or
clang-19. If the default compiler found by CMake is too old, you will need
to specify an alternative C compiler by setting the CC environment variable
or using a CMake toolchain file.
The default compiler chosen by CMake is usually the one reported by the output
of the command cc -v. If you need to use a different one, you can use the
bash syntax VAR=VALUE <command> for setting an environment variable in the
scope of the following command, e.g.:
$ CC=gcc-15 cmake <args>
Required C++ compiler​
C++ is not used in this example, but there are some optional C++ components in
the CMake project. Consequently, you must have a C++ compiler installed or the
CMake configuration step will fail.
C++ in the SDKThe SDK is written in pure C, except for some C++ header files that can be used
to "pretty-print" event types using the <format> library. These are not part
of the example program, and they require full C++23 support for formatting
ranges  (the __cpp_lib_format_ranges feature test macro) which added to
libstdc++ in gcc version 15.2. This was very recently released: the first
time gcc 15.2 appeared in the Ubuntu package repositories was in Ubuntu 25.10.You can also use clang with libc++, the LLVM implementation of the C++ standard
library, which has had range formatting support since version 19. An example of
building a C++ program with clang-19 is shown as the optional last step of the
"Getting started" guide, when we build the eventcap utility.
Required third-party libraries​
RequirementUbuntu package nameWhat is it used for?zstd librarylibzstd-devSnapshot event ring files are compressed with zstd; libzstd is needed to decompress themlibhugetlbfslibhugetlbfs-devlibhugetlbfs is used to locate the optimal hugetlbfs mount point to create event ring shared memory files
libzstd is a hard requirement; libhugetlbfs is optional but is expected
by default on Linux. It can be turned off manually by setting the CMake option
MONAD_EVENT_USE_LIBHUGETLBFS to OFF.
macOS compatiblityAlthough real-time data requires a Linux host (because the execution daemon
itself does), you can compile and run the example on historical snapshot data
using macOS.In this case, you do not need libhugetlbfs (which is a Linux-only library),
but you will need libzstd, CMake, and at least clang-19. The former two
are not included in the default development tools, and the default system
compiler in any recently-released macOS version too old, so you'll probably
want to use
Homebrew or
MacPorts to
get these onto your system.
Step 2: download the example program​
First, create a new directory and download the example program source file
into it. We'll use the example directory ~/src/event-sdk-example-c
$ mkdir -p ~/src/event-sdk-example-c$ cd ~/src/event-sdk-example-c$ curl -O https://raw.githubusercontent.com/category-labs/monad/refs/tags/release/exec-events-sdk-v1.0/category/event/example/eventwatch.c
You should now have a file called eventwatch.c in your new directory.
Step 3: add a CMakeLists.txt build file​
Create a CMakeLists.txt file in the directory alongside eventwatch.c and
copy these contents into it:
cmake_minimum_required(VERSION 3.23)
project(eventwatch LANGUAGES C)
## SDK setup#
include(FetchContent)
FetchContent_Declare(exec_events_c_sdk    # The execution events C SDK is kept in the same git repository as the    # execution daemon itself    GIT_REPOSITORY https://github.com/category-labs/monad.git
    # The latest version of the SDK is available on a special release branch    # of the execution repository    GIT_TAG release/exec-events-sdk-v1.0
    # This will only download the SDK branch    GIT_SHALLOW TRUE
    # This will disable the checkout of all git submodules; they are needed    # for the full execution daemon to build, but not the SDK    GIT_SUBMODULES ""
    # The top-level CMakeLists.txt builds the entire execution daemon; we don't    # want that, so we specify SOURCE_SUBDIR to choose a CMakeLists.txt file    # in a sudirectory to treat as the "top-level" file for the external    # project; this only creates the monad_event library    SOURCE_SUBDIR category/event)
# The SDK's build system also builds the same example we're building now, using# the same target name ('eventwatch'). This is done as a CI check to ensure# that the upstream project doesn't break the example program. We have to# disable it, because it will conflict with the eventwatch target we're going# to add below (CMake does not allow two targets with the same name)set(MONAD_EVENT_BUILD_EXAMPLE OFF CACHE INTERNAL "")
# This will download the source code and call add_subdirectory, which will add# the `monad_event` library target; this is the SDK target we need to linkFetchContent_MakeAvailable(exec_events_c_sdk)
## eventwatch example program target#
add_executable(eventwatch eventwatch.c)target_compile_options(eventwatch PRIVATE -Wall -Wextra -Wconversion -Werror)target_link_libraries(eventwatch PRIVATE monad_event)
Step 4: run CMake and build​
CMake with make and the default compiler:​
$ cmake -S ~/src/event-sdk-example-c -B ~/src/event-sdk-example-c/build$ cd ~/src/event-sdk-example-c/build$ make
CMake with ninja and an alternate compiler:​
Here is another possible invocation, which sets an alternative C compiler using
the CC environment variable and uses the Ninja
build tool:
$ CC=clang-19 cmake -S ~/src/event-sdk-example-c -B ~/src/event-sdk-example-c/build -G Ninja$ cd ~/src/event-sdk-example-c/build$ ninja
The compilation should produce an executable file called eventwatch. Try
running it with the -h flag to print the help.
$ ./eventwatch -husage: eventwatch [-h] [<exec-event-ring>]
execution event observer example program
Options:  -h | --help   print this message
Positional arguments:  <exec-event-ring>   path of execution event ring shared memory file                        [default: monad-exec-events]
If all was successful, continue on to the next step in the guide
or if you are also interested in Rust, build the
Rust example program. The Rust example program prints more
interesting output than the C version, thanks to Rust's
#[derive(Debug)]
attribute, so the "Getting started" experience is better in Rust. You can do
an equivalent thing in C++ by using the aformentioned std::formatter
specializations, but they're not in the tutorial.
You can also continue on to the next section on this page, which shows a
different way of integrating with the C library.
Alternative: install locally, find with find_package​
Now that you have seen the "all-in-one" tutorial, which explains the source
code organization, where the SDK's CMakeLists.txt file is, etc., it is
easy to show an alternative kind of build system without as much commentary.
In this section we will:


Install the SDK to the temporary directory /tmp/sdk-install-demo, which
will have the traditional include and lib directory structure, but
also a lib/cmake/category-labs directory containing the config files for
CMake's find_package


Compile eventwatch.c again, this time using find_package which will be
instructed to look in /tmp/sdk-install-demo


Step 1: build and install libmonad_event.a​
$ git clone -b release/exec-events-sdk-v1.0 https://github.com/category-labs/monad.git \  ~/src/monad-exec-events-sdk$ cmake -S ~/src/monad-exec-events-sdk/category/event \  -B ~/build/monad-exec-events-sdk-v1-release \  -DCMAKE_INSTALL_PREFIX=/tmp/sdk-install-demo -DCMAKE_BUILD_TYPE=RelWithDebInfo$ cmake --build ~/build/monad-exec-events-sdk-v1-release$ cmake --install ~/build/monad-exec-events-sdk-v1-release
If all is successful, you should have a populated /tmp/sdk-install-demo
directory.
Step 2: create a new directory and download eventwatch.c​
$ mkdir -p ~/src/event-sdk-example-c-find-package$ cd ~/src/event-sdk-example-c-find-package$ curl -O https://raw.githubusercontent.com/category-labs/monad/refs/tags/release/exec-events-sdk-v1.0/category/event/example/eventwatch.c
Step 3: create CMakeLists.txt​
Add a CMakeLists.txt file with this content:
cmake_minimum_required(VERSION 3.23)
project(eventwatch LANGUAGES C)
find_package(monad_exec_events_sdk REQUIRED             PATHS /tmp/sdk-install-demo/lib/cmake/category-labs)
add_executable(eventwatch eventwatch.c)target_compile_options(eventwatch PRIVATE -Wall -Wextra -Wconversion -Werror)target_link_libraries(eventwatch PRIVATE monad_event)
Step 4: build and run​
$ cmake -S . -B build$ cmake --build build$ build/eventwatch -h

### Code Examples

```prism
add_subdirectory(<path-to-monad-repo>/category/event)
```

```prism
$ CC=gcc-15 cmake <args>
```

```prism
$ mkdir -p ~/src/event-sdk-example-c$ cd ~/src/event-sdk-example-c$ curl -O https://raw.githubusercontent.com/category-labs/monad/refs/tags/release/exec-events-sdk-v1.0/category/event/example/eventwatch.c
```

```prism
cmake_minimum_required(VERSION 3.23)
project(eventwatch LANGUAGES C)
## SDK setup#
include(FetchContent)
FetchContent_Declare(exec_events_c_sdk    # The execution events C SDK is kept in the same git repository as the    # execution daemon itself    GIT_REPOSITORY https://github.com/category-labs/monad.git
    # The latest version of the SDK is available on a special release branch    # of the execution repository    GIT_TAG release/exec-events-sdk-v1.0
    # This will only download the SDK branch    GIT_SHALLOW TRUE
    # This will disable the checkout of all git submodules; they are needed    # for the full execution daemon to build, but not the SDK    GIT_SUBMODULES ""
    # The top-level CMakeLists.txt builds the entire execution daemon; we don't    # want that, so we specify SOURCE_SUBDIR to choose a CMakeLists.txt file    # in a sudirectory to treat as the "top-level" file for the external    # project; this only creates the monad_event library    SOURCE_SUBDIR category/event)
# The SDK's build system also builds the same example we're building now, using# the same target name ('eventwatch'). This is done as a CI check to ensure# that the upstream project doesn't break the example program. We have to# disable it, because it will conflict with the eventwatch target we're going# to add below (CMake does not allow two targets with the same name)set(MONAD_EVENT_BUILD_EXAMPLE OFF CACHE INTERNAL "")
# This will download the source code and call add_subdirectory, which will add# the `monad_event` library target; this is the SDK target we need to linkFetchContent_MakeAvailable(exec_events_c_sdk)
## eventwatch example program target#
add_executable(eventwatch eventwatch.c)target_compile_options(eventwatch PRIVATE -Wall -Wextra -Wconversion -Werror)target_link_libraries(eventwatch PRIVATE monad_event)
```

```prism
$ cmake -S ~/src/event-sdk-example-c -B ~/src/event-sdk-example-c/build$ cd ~/src/event-sdk-example-c/build$ make
```

```prism
$ CC=clang-19 cmake -S ~/src/event-sdk-example-c -B ~/src/event-sdk-example-c/build -G Ninja$ cd ~/src/event-sdk-example-c/build$ ninja
```

```prism
$ ./eventwatch -husage: eventwatch [-h] [<exec-event-ring>]
execution event observer example program
Options:  -h | --help   print this message
Positional arguments:  <exec-event-ring>   path of execution event ring shared memory file                        [default: monad-exec-events]
```

```prism
$ git clone -b release/exec-events-sdk-v1.0 https://github.com/category-labs/monad.git \  ~/src/monad-exec-events-sdk$ cmake -S ~/src/monad-exec-events-sdk/category/event \  -B ~/build/monad-exec-events-sdk-v1-release \  -DCMAKE_INSTALL_PREFIX=/tmp/sdk-install-demo -DCMAKE_BUILD_TYPE=RelWithDebInfo$ cmake --build ~/build/monad-exec-events-sdk-v1-release$ cmake --install ~/build/monad-exec-events-sdk-v1-release
```

```prism
$ mkdir -p ~/src/event-sdk-example-c-find-package$ cd ~/src/event-sdk-example-c-find-package$ curl -O https://raw.githubusercontent.com/category-labs/monad/refs/tags/release/exec-events-sdk-v1.0/category/event/example/eventwatch.c
```

```prism
cmake_minimum_required(VERSION 3.23)
project(eventwatch LANGUAGES C)
find_package(monad_exec_events_sdk REQUIRED             PATHS /tmp/sdk-install-demo/lib/cmake/category-labs)
add_executable(eventwatch eventwatch.c)target_compile_options(eventwatch PRIVATE -Wall -Wextra -Wconversion -Werror)target_link_libraries(eventwatch PRIVATE monad_event)
```

```prism
$ cmake -S . -B build$ cmake --build build$ build/eventwatch -h
```

---

## Building the Rust example program

> Source: https://docs.monad.xyz/execution-events/getting-started/rust

On this page

The execution event SDK is made up of two packages, called monad-event-ring
and monad-exec-events. These are described in more detail in the
Rust API guide,
but for now it's enough to just know their names.
In the future, Category Labs may publish these packages to
crates.io,
but that is not how the SDK is currently distributed.
Instead, the user's Cargo.toml file declares the upstream source of these
dependencies to be a particular release tag of the git repository where the
SDK source code is located. Dependencies which are sourced from git rather
than crates.io are explained in
this section
of the Cargo Book.
Where is the Rust SDK source code?​
The execution event Rust SDK lives in the monad-bft
git repository, the same repository as the consensus daemon and the JSON-RPC
server. Despite being the "execution events SDK," it does not live in
execution repository alongside the C SDK, for several reasons:


All the code in the execution repository is written in C and C++, whereas
everything in monad-bft is written in Rust


The execution (C++) repository is a dependency of the BFT (Rust) one. The
Rust project uses some C and C++ functionality (via extern "C" FFI APIs)
but the reverse is not true: C never calls Rust functions with C linkage.
For this reason, all the cross-language interop machinery is in the Rust
repository, and defining the Rust SDK in this repository keeps it that way


However, the C ecosystem still affects Rust: some of the functions in the
execution events C SDK are reused by Rust, via an FFI interface. The main
way this affects the Rust build is that you must ensure that a recent enough
C compiler is selected when CMake and bindgen are run from Cargo.
The C SDK uses some recent C23 language features, and requires either gcc-13 or
clang-19. If you run cc -v and it reports an older compiler, you will need to
set the CC environment variable to tell CMake to select a newer compiler.
Building the example program​
Step 1: install prerequisite development packages​
You might already have some of these installed, but make sure you have at least
the minimum required version (newer versions will probably work, but are not
explicitly tested).
In addition to a Rust toolchain, you will need:
RequirementUbuntu package nameMinimum versionWhat is it used for?C compilergcc-13 or clang-19see package namesThe core event library (libmonad_event.a) is written in C, and is used by the Rust libraryC++ compilerg++-13 or clang-19see package namesThe optional C++ components are not used by Rust, but the CMake configure step will report an error if it cannot find a C++ compilerCMakecmakeCMake 3.23libmonad_event.a is built with CMake, via build.rs integration with cargozstd librarylibzstd-devanySnapshot event ring files are compressed with zstd; this library is needed to decompress themlibhugetlbfslibhugetlbfs-devanylibhugetlbfs is used to locate the default hugetlbfs mount point that holds event ring shared memory fileslibclangclang-19clang-19Rust's bindgen requires the a recent version of the libclang library
We will also need git and curl.
macOS compatiblityAlthough real-time data requires a Linux host (because the execution daemon
itself does), you can compile and run the example on historical snapshot data
using macOS.In this case, you do not need libhugetlbfs (which is a Linux-only library),
but you will need libzstd, CMake, and at least clang-19. The former two
are not included in the default development tools, and the default system
compiler in any recently-released macOS version too old, so you'll probably
want to use
Homebrew or
MacPorts to
get these onto your system.
To install all of these in one shot on Ubuntu 24.04 or higher, you can
run this command (feel free to use more recent verions, e.g., clang-20):
$ sudo apt install git curl gcc g++ cmake clang-19 libzstd-dev libhugetlbfs-dev
libclang and clang versionsEven if you compile libmonad_event.a with gcc, the Rust
bindgen utility still uses the
libclang tool to
programmatically generate Rust bindings to C code. Technically you should
not need the full clang compiler, just the libclang package, but some users
have reported trouble without installing it.The reason you need version 19 (or greater) is that clang-19 was the first
version to support enough features from the C23 language standard to be able
to compile the SDK. If you see errors that imply that bindgen cannot understand
the constexpr keyword, then bindgen has automatically selected a libclang
version that is too old.If you have multiple libclang versions on the system (the default clang is
version 18 on Ubuntu 24.04), installing a newer version may not help, if the
underlying problem is that bindgen is selecting the wrong one by default. This
is a common problem on macOS, where cargo wants to select the much older
libclang that is part of the standard macOS developer SDK. During the compile
step, we'll explain more about how to deal with this.
Step 2: create a new package and copy the example code into it​
First, create the new package:
$ cargo new --bin event-sdk-example-rust$ cd event-sdk-example-rust
Next, we'll overwrite the default "Hello world" main.rs source file with the
example program code, downloaded from github:
$ curl https://raw.githubusercontent.com/category-labs/monad-bft/refs/tags/release/exec-events-sdk-v1.0/monad-exec-events/examples/eventwatch.rs > src/main.rs
Step 3: integrating with the SDK packages​
Create the following Cargo.toml file:
[package]name = "event-sdk-example-rust"version = "0.1.0"edition = "2021"
[dependencies]chrono = "0.4.34"clap = { version = "4.2", features = ["derive"] }lazy_static = "1.5.0"zstd-sys = "2.0.16"
[dependencies.monad-exec-events]git = "https://github.com/category-labs/monad-bft"tag = "release/exec-events-sdk-v1.0"
[dependencies.monad-event-ring]git = "https://github.com/category-labs/monad-bft"tag = "release/exec-events-sdk-v1.0"
Step 4: build the project​
cargo build
The first time you build will be slow, because it will fetch the monad-bft
repository and all transitive git submodules. Almost none of them are needed
for the SDK, but cargo checks them out by default.
You may need to pass a more recent compiler to CMake, and you can do so using
bash's terse syntax for setting environment variables in the scope of command
to be run, for example:
CC=clang-19 cargo build
If you encounter errors...The most common source of errors when building is when bindgen selects an
outdated libclang version, as explained earlier. This typically appears
as either:
An error explicitly mentioning libclang OR
A message that includes the text "Unable to generate bindings"
Setting the environment variable CC=clang-19 only influences the compiler
that CMake uses to build the C SDK library, libmonad_event.a. Namely, it
does not the affect the libclang version that is used by bindgen to generate
the bindings.There are a number of environment variables that control the behavior of how
libclang is located and configured, and they're documented in the "Environment
Variables" section of
this page.Some advice we have found works well:

Setting LLVM_CONFIG_PATH to point to the full path to the llvm-config
binary is the best option; this command bakes in a lot of details about
how LLVM was built and installed on the system, to make it easier for
users of LLVM (such as bindgen) to find the configuration they need


In some unusual cases, you may select the right libclang but it may
be configured strangely, so that it cannot find the basic libc header
files anymore (typical culprits are claims that stddef.h, assert.h,
or string.h are missing); you can can figure out the location of these
files on the system and pass them as system include directories (the
-isystem clang option) to libclang through bindgen using the
BINDGEN_EXTRA_CLANG_ARGS environment variable; on macOS this looks like:
BINDGEN_EXTRA_CLANG_ARGS="-isystem $(xcrun --show-sdk-path)/usr/include"
or on Ubuntu 24.04 LTS:
BINDGEN_EXTRA_CLANG_ARGS="-isystem /usr/include"


After you have solved any issues, the compilation should produce an executable
file. Try running it with the -h flag to print the help:
cargo run -- -h
If all was successful, continue on to the next step in the guide.

### Code Examples

```prism
$ sudo apt install git curl gcc g++ cmake clang-19 libzstd-dev libhugetlbfs-dev
```

```prism
$ cargo new --bin event-sdk-example-rust$ cd event-sdk-example-rust
```

```prism
$ curl https://raw.githubusercontent.com/category-labs/monad-bft/refs/tags/release/exec-events-sdk-v1.0/monad-exec-events/examples/eventwatch.rs > src/main.rs
```

```prism
[package]name = "event-sdk-example-rust"version = "0.1.0"edition = "2021"
[dependencies]chrono = "0.4.34"clap = { version = "4.2", features = ["derive"] }lazy_static = "1.5.0"zstd-sys = "2.0.16"
[dependencies.monad-exec-events]git = "https://github.com/category-labs/monad-bft"tag = "release/exec-events-sdk-v1.0"
[dependencies.monad-event-ring]git = "https://github.com/category-labs/monad-bft"tag = "release/exec-events-sdk-v1.0"
```

```prism
cargo build
```

```prism
CC=clang-19 cargo build
```

```prism
BINDGEN_EXTRA_CLANG_ARGS="-isystem $(xcrun --show-sdk-path)/usr/include"
```

```prism
BINDGEN_EXTRA_CLANG_ARGS="-isystem /usr/include"
```

```prism
cargo run -- -h
```

---

## C API

> Source: https://docs.monad.xyz/execution-events/c-api

On this page

Core concepts​
There are two central objects in the event ring C API. They are:

struct monad_event_ring - represents an event ring whose shared memory
segments have been mapped into the address space of the current process;
the primary thing the client does with this object is use it to initialize
iterators that point into the event ring, using the
monad_event_ring_init_iterator function
struct monad_event_iterator - the star of the show: this iterator
object is used to read sequential events. The iterator's try_next
operation copies the current event descriptor (if it is available) and
if successful, advances the iterator. Conceptually, it behaves like the
expression descriptor = *i++, if an event descriptor is ready immediately
(it does nothing otherwise)

The easiest way to understand the API is to compile and run the included
eventwatch example program. This program dumps ASCII representations of
execution events to stdout, as they are written by a execution daemon
running on the same host.
In eventwatch, the event descriptors are fully decoded, but the event
payloads are only shown in hexdump form, because this simple program that does
not include pretty-printing logic for all event payload types. The program is
only 250 lines of code, and reading through it should explain how the various
API calls fit together.
The SDK also includes C++20
std::formatter
specializations which can fully decode event payloads into human-readable form.
These are used by the eventcap utility program.
Using the API in your project​
libmonad_event is designed for third party integration, so it does not have
any library dependencies aside from a recent version of glibc. This also means
it has no dependency on the rest of the monad repository or on its build
system: the sole requirement is a C compiler supporting C23.
The "Getting start" guide to building the C example program
discusses several ways
to use the SDK library as a third-party dependency in your code. Alternatively,
the source files that make up the library target can be copied into your own
codebase. A Rust client library is also available.
API overview​
Event ring APIs​
APIPurposemonad_event_ring_mmapGiven a file descriptor to an open event ring file, map its shared memory segments into the current process, initializing a struct monad_event_ringmonad_event_ring_init_iteratorGiven a pointer to a struct monad_event_ring, initialize an iterator that can read from the event ringmonad_event_ring_try_copyGiven a specific sequence number, try to copy the event descriptor for it, if it hasn't been overwrittenmonad_event_ring_payload_peekGet a zero-copy pointer to an event payloadmonad_event_ring_payload_checkCheck if an event payload referred to by a zero-copy pointer has been overwrittenmonad_event_ring_memcpymemcpy the event payload to a buffer, succeeding only if the payload is not expiredmonad_event_ring_get_last_errorReturn a human-readable string describing the last error that occurred on this thread
All functions which can fail will return an errno(3) domain error code
diagnosing the reason for failure. The function
monad_event_ring_get_last_error can be called to provide a human-readable
string explanation of what failed.
Event iterator APIs​
APIPurposemonad_event_iterator_try_nextIf an event descriptor if is available, copy it and advance the iterator; behaves like *i++, but only if *i is readymonad_event_iterator_try_copyCopy the event descriptor at the current iteration point, without advancing the iteratormonad_event_iterator_resetReset the iterator to point to the most recently produced event descriptor; used for gap recoverymonad_exec_iter_consensus_prevRewinds an iterator to the previous consensus event (BLOCK_START, BLOCK_QC, BLOCK_FINALIZED, or BLOCK_VERIFIED)monad_exec_iter_block_number_prevRewinds an iterator to the previous consensus event for the given block numbermonad_exec_iter_block_id_prevRewinds an iterator to the previous consensus event for the given block IDmonad_exec_iter_rewind_for_simple_replayRewinds an iterator to replay events you may have missed, based on the last finalized block you saw
Event ring utility APIs​
APIPurposemonad_event_ring_check_content_typeCheck if the binary layouts of event definitions used by the library match what is recorded in a mapped event ringmonad_event_ring_find_writer_pidsFind processes that have opened an event ring file descriptor for writing; used for detecting publisher exitmonad_check_path_supports_map_hugetlbCheck if a path is on a filesystem that allows its files to be mmap'ed with MAP_HUGETLBmonad_event_open_hugetlbfs_dir_fdOpen the default hugetlbfs directory where event ring files are created1monad_event_resolve_ring_fileIf a path contains no / character (i.e., if it is a "pure" filename), resolve it relative to some default event ring directory2monad_event_is_snapshot_fileCheck if a path refers to an event ring snapshot filemonad_event_decompress_snapshot_fdDecompress the event ring snapshot contained in the given file descriptormonad_event_decompress_snapshot_memDecompress the event ring snapshot contained in the given memory buffer
Library organization​
Event ring files in libmonad_event:
FileContainsevent_ring.{h,c}Definitions of core shared memory structures for event rings, and the API that initializes and mmaps event ring filesevent_iterator.hDefines the basic event iterator object and its APIevent_iterator_inline.hDefinitions of the event_iterator.h functions, all of which are inlined for performance reasonsevent_metadata.hStructures that describe event metadata (string names of events, descriptions of events, etc.)exec_iter_help.hAPI for rewinding the the iterator to point to block executions or consensus events
Execution event files in libmonad_event:
FileContainsbase_ctypes.hDefinitions of basic vocabulary types common in Ethereum data (e.g., 256 bit integer types, etc).eth_ctypes.hDefinitions of structures used in the Ethereum virtual machineexec_event_ctypes.hDefinition of execution event payload structures, and the event type enumeration enum monad_exec_event_typeexec_event_ctypes_metadata.cDefines static metadata about execution events, and the schema hash value arraymonad_ctypes.hDefinitions of Monad blockchain extensions to Ethereum
Supporting files in libmonad_event:
FileContainsevent_ring_util.{h,c}Convenience functions that are useful in most event ring programs, but which are not part of the core APIformat_err.{h,c}Helper utility from the execution codebase used to implement the monad_event_ring_get_last_error() functionsrcloc.hHelper utility used with the format_err.h API, for capturing source code locations in C
Other files in the SDK:
FileContentseventwatch.cA sample program that shows how to use the API*_fmt.hpp filesFiles ending in _fmt.hpp are used with C++ <format> and contain std::formatter specializations for SDK typeshex.hpp<format> hexdump utility used by the _fmt.hpp files to dump uint8_t[] values

Footnotes​


By default, this returns the a path on a hugetlbfs mount, as computed by
libhugetlbfs ↩


If compiling with MONAD_EVENT_USE_LIBHUGETLBFS=OFF, a default event
ring directory must be specified; see
here for details ↩

---

## Consensus events

> Source: https://docs.monad.xyz/execution-events/consensus-events

On this page

As explained here,
Monad's consensus and execution services are decoupled, and execution is
asynchronous with the respect to consensus: the two don't have to move in
lock step, and can working on different blocks. Also, execution can
speculatively execute
blocks whose consensus outcome is not yet known.
Execution events are "trace" information reported directly from the EVM during
execution, so they report real-time data on speculative basis: the event data
may relate to a block that is never finalized.
Dealing with real-time data on a speculative basis is discussed in detail on
this page. The "takeaway"
from that part of the documentation is the following: if you consume
speculative real-time data, then you need to understand
block commit states and how the
real-time data protocol you're using communicates the changes in block states.
For example, for the Monad WebSocket extension feeds,
this section
explains how the block IDs and commit states are announced for the
monadNewHeads subscription. This documentation page explains how it
is done with execution events.
Block tags​
As explained
here,
blocks must be identified by their unique ID prior to finalization. Even so,
it is often useful to know what the proposed block number is, even before we
know if the block will committed with that number or not. The following
structure -- called a "block tag" -- appears as a field in several execution
event payload types, to communicate the block ID and the (proposed) block
number together.
struct monad_exec_block_tag{    monad_c_bytes32 id;    ///< Monad consensus unique ID for block    uint64_t block_number; ///< Proposal is to become this block};
The four consensus events​
The four block commit states
correspond to four execution event types. Events of these types are published
to announce that a particular block is moving to a new commit state.
First consensus event: BLOCK_START (proposed state)​
/// Event recorded at the start of block executionstruct monad_exec_block_start{    struct monad_exec_block_tag        block_tag;                      ///< Execution is for this block    uint64_t block_round;               ///< Round when block was proposed    uint64_t epoch;                     ///< Epoch when block was proposed    monad_c_bytes32 parent_eth_hash;    ///< Hash of Ethereum parent block    monad_c_uint256_ne chain_id;        ///< Block chain we're associated with    struct monad_c_eth_block_exec_input        exec_input;                     ///< Ethereum execution inputs};
The first event recorded by the EVM is a BLOCK_START event, whose event
payload contains a block_tag field that introduces the unique ID for the
block and the block number it will eventually have, if it gets finalized.
Almost all execution events (transaction logs, call frames, receipts, etc.)
occur between the BLOCK_START and BLOCK_END events. In the current
implementation, block execution is never pipelined, so all events between
BLOCK_START and BLOCK_END pertain to a single block, and there will not
be another BLOCK_START until the current block is ended.
Unlike the other events in this list, BLOCK_START is both a "consensus
event" (it means the associated block is in proposed state) and an "EVM event,"
because execution information about the block is being made available to you.
The other events in this list are not like that. They are "pure" consensus
events: they tell you what happened to a proposed block in the consensus
algorithm, after you've already seen all of its EVM events.
To understand the implications of this state, see
here.
noteThere's no reason why a block has to start in the proposed state. If
execution is lagging behind consensus, it's possible that a block might have
advanced to a later state in the consensus algorithm. For example, suppose
consensus has been working on a block for a while, and by the time execution
finally sees it, perhaps consensus knows that it has progressed to voted.In the current implementation, however, execution will not know this. It
implicitly considers everything it executes to only be proposed. This is only
literally true if execution is not lagging behind.
Second consensus event: BLOCK_QC (voted state)​
/// Event recorded when a proposed block obtains a quorum certificatestruct monad_exec_block_qc{    struct monad_exec_block_tag        block_tag;              ///< QC for proposal with this block    uint64_t round;             ///< Round of proposal vote    uint64_t epoch;             ///< Epoch of proposal vote};
When a block with the given tag is voted, an event of this type is published
to announce it. To understand all the implications of seeing this event, see
here.
Third consensus event: BLOCK_FINALIZED​
/// Event recorded when consensus finalizes a blocktypedef struct monad_exec_block_tag monad_exec_block_finalized;
The finalized event payload does not have any information that isn't already
part of the block tag, so the payload is just the tag of the block that gets
finalized. To understand all the implications of seeing this event, see
here.
Fourth consensus event: BLOCK_VERIFIED​
/// Event recorded when consensus verifies the state root of a finalized blockstruct monad_exec_block_verified{    uint64_t block_number; ///< Number of verified block};
The consensus algorithm produces one last event for a block, called
BLOCK_VERIFIED. This time, it is sufficient to identify the block only by
its block number. Because verified blocks are already finalized, they are
part of the canonical blockchain and cannot be reverted without a hard fork.
Thus, we no longer need the block tag.
To understand all the implications of seeing this event, see
here.

### Code Examples

```prism
struct monad_exec_block_tag{    monad_c_bytes32 id;    ///< Monad consensus unique ID for block    uint64_t block_number; ///< Proposal is to become this block};
```

```prism
/// Event recorded at the start of block executionstruct monad_exec_block_start{    struct monad_exec_block_tag        block_tag;                      ///< Execution is for this block    uint64_t block_round;               ///< Round when block was proposed    uint64_t epoch;                     ///< Epoch when block was proposed    monad_c_bytes32 parent_eth_hash;    ///< Hash of Ethereum parent block    monad_c_uint256_ne chain_id;        ///< Block chain we're associated with    struct monad_c_eth_block_exec_input        exec_input;                     ///< Ethereum execution inputs};
```

```prism
/// Event recorded when a proposed block obtains a quorum certificatestruct monad_exec_block_qc{    struct monad_exec_block_tag        block_tag;              ///< QC for proposal with this block    uint64_t round;             ///< Round of proposal vote    uint64_t epoch;             ///< Epoch of proposal vote};
```

```prism
/// Event recorded when consensus finalizes a blocktypedef struct monad_exec_block_tag monad_exec_block_finalized;
```

```prism
/// Event recorded when consensus verifies the state root of a finalized blockstruct monad_exec_block_verified{    uint64_t block_number; ///< Number of verified block};
```

---

## Event rings in detail

> Source: https://docs.monad.xyz/execution-events/event-ring

On this page

Event ring files and content types​
Event rings are made up of four shared memory segments. Two of these -- the
event descriptor array and payload buffer -- are described in the
overview documentation.
The third shared memory segment contains a header that describes metadata
about the event ring. The fourth (the "context area") is a special feature
that is not needed for execution events.
The shared memory segments are mapped into a process' address space using
mmap(2). This means
that the event ring's data structures live in a file somewhere, and that
shared access to it is obtained by creating shared memory mappings of that
file.
Most of the time an event ring is a regular file, created on a special
in-memory file system called
hugetlbfs. hugetlbfs is similar to the
tmpfs in-memory
filesystem, but supports the creation of files backed by large page sizes.
The use of large pages is just an
optimization: event ring files may be
created on any file system. If the execution daemon is told to create an
event ring file on a filesystem without hugetlb mmap support, it will log a
performance warning but will still create the file. To learn more about
hugetlbfs and how it is used, read
this page.
Event ring configuration​
To use execution events, the execution daemon must be started with the command
line parameter:
--exec-event-ring [<event-ring-configuration-string>]
Without this command line parameter, execution will not publish any events.
This command line parameter (and mounting a hugetlbfs filesystem, for that
matter) are not part of the default configuration instructions for the
execution daemon. A
separate guide
covers mounting a hugetlbfs filesystem and modifying the command line in
the systemd unit configuration files.
Note that the configuration string is optional; if you pass --exec-event-ring
without an argument (which is the recommended thing to do), this is equivalent
to passing --exec-event-ring monad-exec-events, where monad-exec-events is
the default execution event ring file name.
The event ring configuration string has the form:
<ring-name-or-file-path>[:<descriptor-shift>:<payload-buffer-shift>]
In other words, the configuration string consists of three :-separated
fields; the first field is required but the second two are optional. Here
is an example of the command line parameter, with just the first field:
--exec-event-ring /var/lib/hugetlbfs/user/monad/pagesize-2MB/event-rings/monad-exec-events
and another example, with all three:
--exec-event-ring monad-exec-events:21:29
The first field is the name of the event ring file. The execution daemon
interprets this field in two different ways:


If it is purely a file name -- i.e., if the path does not contain any /
characters -- then it is interpreted as a file living in the default
event ring file directory; this is the directory returned by the API
function monad_event_open_ring_dir_fd; it uses
libhugetlbfs to locate
the most suitable mount point for a hugetlbfs file system, and automatically
creates subdirectory called event-rings underneath that, if it does not
already exist (see here for
more information); the event ring file will be created in that event-rings
subdirectory


If the path has multiple path components -- i.e., if it contains at least
one / character -- then this path will be used as written even if it is
not resident on a hugetlbfs file system; the rationale for why someone
might want this is explained below


The "shift" parameters are power-of-two exponents that determine the event
ring's size.1 A <descriptor-shift> of 21 means there will be 2^21
descriptors in the ring's event descriptor array. This means approximately 2
million events can be written before the descriptor ring buffer wraps around
and overwrites older event descriptors.
A <payload-buffer-shift> of 29 means there will be 2^29 bytes in the payload
buffer array. This means 512 MiB worth of event payloads can be recorded before
the payload buffer wraps around and overwrites an older event's payload.
If the event ring size parameters are not specified, then default values are
used. Why might you increase these values from their defaults? If your reader
program crashes, but execution does not, then you will likely miss some events
during the time when your program is not running. Your application might not
care about lost events for old blocks, but if it does, you'll need to retrieve
them somehow.
If not much time has gone by, chances are good that the events you are missing
are still sitting there in the event ring memory, i.e., are not overwritten
yet. The default sizes are large enough to hold several minutes worth of
blocks at 10k TPS. Increasing these values allows you to rewind further back
in time.
Be aware that there is a fixed-size pool of huge pages. The pool size can be
changed by modifying the system's configuration, see the discussion of
/proc/sys/vm/nr_hugepages
here.
If an event ring is created on a hugetlbfs mount, and its size exceeds the
number of available huge pages, then the execution daemon will exit with an
error message that reports a "no space left on device" error. For example,
here we tried to allocate an event ring with a one terabyte payload buffer:
LOG_ERROR  event library error -- monad_event_ring_init_simple@event_ring_util.c:78:posix_fallocate failed for event ring file `/dev/hugepages/monad-exec-events`, size 1099647942656: No space left on device (28)
If you happen to have multiple terabytes of main memory available, you
could pass a file path containing a / character to a file on a tmpfs
mount and it would work, e.g., --exec-event-ring /my-giant-tmpfs/monad-exec-events.
If you need to rewind back especially far -- or if you are missing events
because execution itself has crashed -- then you will need to use alternative
recovery methods described elsewhere.2
Event ring file format​
The event ring file format is simple: all four sections are laid out
sequentially and aligned to a large page boundary, and the header describes
the size of each section.
╔═Event ring file══╗║ ┌──────────────┐ ║║ │              │ ║║ │    Header    │ ║║ │              │ ║║ ├──────────────┤ ║║ │              │ ║║ │    Event     │ ║║ │  Descriptor  │ ║║ │    Array     │ ║║ │              │ ║║ ├──────────────┤ ║║ │              │ ║║ │              │ ║║ │              │ ║║ │              │ ║║ │   Payload    │ ║║ │    Buffer    │ ║║ │              │ ║║ │              │ ║║ │              │ ║║ │              │ ║║ │              │ ║║ ├──────────────┤ ║║ │              │ ║║ │   Context    │ ║║ │     Area     │ ║║ │              │ ║║ └──────────────┘ ║╚══════════════════╝
The descriptor array is a just an array of struct monad_event_descriptor
objects, and the payload buffer is a flat byte array (i.e., it has type
uint8_t[]). The header structure is defined this way:
/// Event ring shared memory files start with this header structurestruct monad_event_ring_header{    char magic[6];                           ///< 'RINGvv', vv = version number    enum monad_event_content_type        content_type;                        ///< Kind of events in this ring    uint8_t schema_hash[32];                 ///< Ensure event definitions match    struct monad_event_ring_size size;       ///< Size of following structures    struct monad_event_ring_control control; ///< Tracks ring's state/status};
Event content types​
The content_type header field is needed because the event ring library --
both the reader and writer APIs -- performs unstructured I/O: the functions
read and write raw uint8_t[] event payloads, and the event descriptors
contain plain uint16_t numerical event codes. Much like the UNIX read(2)
and write(2) file I/O system calls, the event ring API functions do not
inherently know the format of data they are working with. This is the
reason why the event_type field in the event descriptor is the generic
integer type uint16_t instead of enum monad_exec_event_type.
The assumption here is that the reader and writer know the binary format of
the data they're both working with, and they treat the raw data as if it has
this format by type-casting it when needed, e.g.,
const struct monad_exec_block_start *block_start = nullptr;
// We assume that the event ring file we opened contains execution events,// and thus further assume that it makes sense to compare `event->event_type`// to a value of type `enum monad_exec_event_type`if (event->event_type == MONAD_EXEC_BLOCK_START) {    // Since this is MONAD_EXEC_BLOCK_START, we can cast the `const void *`    // payload to a `const struct monad_exec_block_start *` payload.    // Note: implicit type-casting from `void *` is allowed in C, but not C++    block_start = monad_event_ring_payload_peek(event_ring, event);}
We need some kind of error-detection mechanism to ensure this is safe to do.
The event ring file header contains a "content type" enumeration constant
explaining what kind of event data it contains:
enum monad_event_content_type : uint16_t{    MONAD_EVENT_CONTENT_TYPE_NONE,  ///< An invalid value    MONAD_EVENT_CONTENT_TYPE_TEST,  ///< Used in simple automated tests    MONAD_EVENT_CONTENT_TYPE_EXEC,  ///< Core execution events    MONAD_EVENT_CONTENT_TYPE_PERF,  ///< Performance tracer events    MONAD_EVENT_CONTENT_TYPE_COUNT  ///< Total number of known event rings};
The execution events are always recorded to a ring with content_type
equal to MONAD_EVENT_CONTENT_TYPE_EXEC.
Binary schema versioning: the schema_hash field​
If content_type is equal to MONAD_EVENT_CONTENT_TYPE_EXEC, then we know a
ring is supposed to execution events, but what if the event payload definitions
change? Or what if the enumeration constants in enum monad_exec_event_type
change?
Suppose that a user compiles their application with a particular version
of exec_event_ctypes.h, the file which defines the execution event payloads
and the event type enumeration.
Now imagine that some time later, the user deploys a new version of the
execution node, which was compiled with a different version of
exec_event_ctypes.h, causing the memory representation of the event payloads
to be different.
If the reader does not remember to recompile their application with the new
header, it could misinterpret the bytes in the event payloads, assuming they
have the old layout from their old (compile-time) version of
exec_event_ctypes.h.
To prevent these kinds of errors, the binary layout of all event payloads is
summarized by a hash value which changes any time a change is made to any event
payload for that content type. In addition to payload changes, any change to
enum monad_exec_event_type will also generate a new hash.
This mechanism is called the "schema hash", and the hash value is present as
a global, read-only byte array inside the library code (defined in
exec_event_ctypes_metadata.c).
If the hash value in this array does not match the hash value in the event ring
file header, then the binary formats are incompatible.
A helper function called monad_event_ring_check_content_type is used to
check that an event ring file has both the expected content type, and the
expected schema hash for that content type. Here is an example of it being
called in the eventwatch.c sample program:
struct monad_event_ring exec_ring;
/* initialization of `exec_ring` not shown */
if (monad_event_ring_check_content_type(        &exec_ring,        MONAD_EVENT_CONTENT_TYPE_EXEC,        g_monad_exec_event_schema_hash) != 0) {    errx(EX_SOFTWARE, "event library error -- %s",         monad_event_ring_get_last_error());}
If the type of event ring is not MONAD_EVENT_CONTENT_TYPE_EXEC or if the
schema_hash in the file header does not match the value contained in the
global array uint8_t g_monad_exec_event_schema_hash[32], this function will
return the errno(3) domain code EPROTO.
Event descriptors in detail​
Binary format​
The event descriptor is defined this way:
struct monad_event_descriptor{    alignas(64) uint64_t seqno;  ///< Sequence number, for gap/liveness check    uint16_t event_type;         ///< What kind of event this is    uint16_t : 16;               ///< Unused tail padding    uint32_t payload_size;       ///< Size of event payload    uint64_t record_epoch_nanos; ///< Time event was recorded    uint64_t payload_buf_offset; ///< Unwrapped offset of payload in p. buf    uint64_t content_ext[4];     ///< Extensions for particular content types};
Flow tags: the content_ext fields in execution event rings​
For each content type, we may want to publish additional data directly in the
event descriptor, e.g., if that data is common to every payload type or if it
would help the reader quickly filter out events they are not interested in,
without needing to examine the event payload. This additional data is stored
in the content_ext ("content extensions") array, and its meaning is defined
by the content_type.
For execution event rings, the first three values of the content_ext array
are sometimes filled in. The value at each index in the array has the semantic
meaning described by the following enumeration type, which is defined in
exec_event_ctypes.h:
/// Stored in event descriptor's `content_ext` array to tag the/// block & transaction context of eventenum monad_exec_flow_type : uint8_t{    MONAD_FLOW_BLOCK_SEQNO = 0,    MONAD_FLOW_TXN_ID = 1,    MONAD_FLOW_ACCOUNT_INDEX = 2,};
For example, if we have an event descriptor
struct monad_event_descriptor event;
And its contents are initialized by a call to monad_event_iterator_try_next,
then event.content_ext[MONAD_FLOW_TXN_ID] will contains the "transaction ID"
for that event. The transaction ID is equal to the transaction index plus one,
and it is zero if the event has no associated transaction (e.g., the start of
a new block).
The idea behind the "flow" tags is that they tag events with the context they
belong to. For example, when a transaction accesses a particular account
storage key, a STORAGE_ACCESS event is emitted.
By looking at the content_ext array for the STORAGE_ACCESS event descriptor,
the reader can tell it is a storage access made (1) by the transaction with
index event.content_ext[MONAD_FLOW_TXN_ID] - 1 and (2) to the account with
index event.content_ext[MONAD_FLOW_ACCOUNT_INDEX] (this index is related to
an earlier ACCOUNT_ACCESS event series that will have already been seen).
Flow tags are used for two reasons:


Fast filtering - if we are processing 10,000 transactions per second,
and there are at least a dozen events per transaction, then we only have
about 10 microseconds to process each event or we'll eventually fall behind
and gap. At timescales like these, even touching the memory containing the
event payload is expensive, on a relative basis. The event payload lives on
a different cache line -- one that is not yet warm in the reader's CPU --
and the cache line ownership must first be changed in the cache coherence
protocol (because it was recently exclusively owned by the writer, and now
must be shared with the reading CPU, causing cross-core bus traffic). For
most applications, the user can identify transactions IDs they are
interested in at the time of the TXN_HEADER_START event, and then any
event without an interesting ID can be ignored. Because the IDs are a dense
set of integers, a simple array of type bool[TXN_COUNT + 1] can be
used to efficiently look up whether subsequent events associated with that
transaction are interesting (this can be made even more efficient using
a single bit instead of a full bool per transaction)


Compression - the account of a STORAGE_ACCESS is referred to by an
index (which refers to an earlier ACCOUNT_ACCESS event) because an
account address is 20 bytes: large enough that it cannot fit in the two
remaining content_ext array slots


The compression technique is also used for storing the block associated with
an event, in event.content_ext[MONAD_FLOW_BLOCK_SEQNO]. The flow tag in this
case is the sequence number of the BLOCK_START event that started the
associated block. A few things to note about this flow tag:


Sometimes it is zero (an invalid sequence number), which means the event
is not associated with any block; although most events are scoped to a
block, the consensus state change events (BLOCK_QC, BLOCK_FINALIZED,
and BLOCK_VERIFIED) do not occur inside a block


Note that the block flow tag is not the block number. This is because
at the time events are seen, the blocks are in the "proposed" state, and
the consensus algorithm has not finished voting on whether or not the block
will be included in the canonical blockchain (this is discussed extensively
in the next section). Until a block becomes finalized, the only unambiguous
way to refer to it is by its unique ID, which is 32-byte hash value (which
can be read from the BLOCK_START payload); thus the block flow tag is also
a form of compression


Having the sequence number allows us to rewind the iterator to the start
of the block, if we start observing the event sequence in the middle of
a block (e.g., if the reader starts up after the execution daemon). An
example of this (and a detailed explanation of it) can be found in the
eventwatch.c example program, in the find_initial_iteration_point
function



Footnotes​


They are called "shifts" because 1UL << x is equal to 2^x ↩


The alternative recovery methods are still in development and will be
available in the next SDK release ↩

### Code Examples

```prism
--exec-event-ring [<event-ring-configuration-string>]
```

```prism
<ring-name-or-file-path>[:<descriptor-shift>:<payload-buffer-shift>]
```

```prism
--exec-event-ring /var/lib/hugetlbfs/user/monad/pagesize-2MB/event-rings/monad-exec-events
```

```prism
--exec-event-ring monad-exec-events:21:29
```

```prism
LOG_ERROR  event library error -- monad_event_ring_init_simple@event_ring_util.c:78:posix_fallocate failed for event ring file `/dev/hugepages/monad-exec-events`, size 1099647942656: No space left on device (28)
```

```prism
╔═Event ring file══╗║ ┌──────────────┐ ║║ │              │ ║║ │    Header    │ ║║ │              │ ║║ ├──────────────┤ ║║ │              │ ║║ │    Event     │ ║║ │  Descriptor  │ ║║ │    Array     │ ║║ │              │ ║║ ├──────────────┤ ║║ │              │ ║║ │              │ ║║ │              │ ║║ │              │ ║║ │   Payload    │ ║║ │    Buffer    │ ║║ │              │ ║║ │              │ ║║ │              │ ║║ │              │ ║║ │              │ ║║ ├──────────────┤ ║║ │              │ ║║ │   Context    │ ║║ │     Area     │ ║║ │              │ ║║ └──────────────┘ ║╚══════════════════╝
```

```prism
/// Event ring shared memory files start with this header structurestruct monad_event_ring_header{    char magic[6];                           ///< 'RINGvv', vv = version number    enum monad_event_content_type        content_type;                        ///< Kind of events in this ring    uint8_t schema_hash[32];                 ///< Ensure event definitions match    struct monad_event_ring_size size;       ///< Size of following structures    struct monad_event_ring_control control; ///< Tracks ring's state/status};
```

```prism
const struct monad_exec_block_start *block_start = nullptr;
// We assume that the event ring file we opened contains execution events,// and thus further assume that it makes sense to compare `event->event_type`// to a value of type `enum monad_exec_event_type`if (event->event_type == MONAD_EXEC_BLOCK_START) {    // Since this is MONAD_EXEC_BLOCK_START, we can cast the `const void *`    // payload to a `const struct monad_exec_block_start *` payload.    // Note: implicit type-casting from `void *` is allowed in C, but not C++    block_start = monad_event_ring_payload_peek(event_ring, event);}
```

```prism
enum monad_event_content_type : uint16_t{    MONAD_EVENT_CONTENT_TYPE_NONE,  ///< An invalid value    MONAD_EVENT_CONTENT_TYPE_TEST,  ///< Used in simple automated tests    MONAD_EVENT_CONTENT_TYPE_EXEC,  ///< Core execution events    MONAD_EVENT_CONTENT_TYPE_PERF,  ///< Performance tracer events    MONAD_EVENT_CONTENT_TYPE_COUNT  ///< Total number of known event rings};
```

```prism
struct monad_event_ring exec_ring;
/* initialization of `exec_ring` not shown */
if (monad_event_ring_check_content_type(        &exec_ring,        MONAD_EVENT_CONTENT_TYPE_EXEC,        g_monad_exec_event_schema_hash) != 0) {    errx(EX_SOFTWARE, "event library error -- %s",         monad_event_ring_get_last_error());}
```

```prism
struct monad_event_descriptor{    alignas(64) uint64_t seqno;  ///< Sequence number, for gap/liveness check    uint16_t event_type;         ///< What kind of event this is    uint16_t : 16;               ///< Unused tail padding    uint32_t payload_size;       ///< Size of event payload    uint64_t record_epoch_nanos; ///< Time event was recorded    uint64_t payload_buf_offset; ///< Unwrapped offset of payload in p. buf    uint64_t content_ext[4];     ///< Extensions for particular content types};
```

```prism
/// Stored in event descriptor's `content_ext` array to tag the/// block & transaction context of eventenum monad_exec_flow_type : uint8_t{    MONAD_FLOW_BLOCK_SEQNO = 0,    MONAD_FLOW_TXN_ID = 1,    MONAD_FLOW_ACCOUNT_INDEX = 2,};
```

```prism
struct monad_event_descriptor event;
```

---

## Execution Events

> Source: https://docs.monad.xyz/execution-events/

On this page

The Execution Events system allows developers to build high-performance
applications that receive lowest-latency event data from a Monad node via
shared memory queue.
To consume this real-time data, you write some data processing software in C,
C++, or Rust using the software development kit described on this page, and
run it on a host running the
Monad node software built by Category Labs.
This would be overkill for simple data processing use cases; see the
alternatives section for more convenient
ways to consume Monad blockchain data.
For comparisons to other systems such as Reth's ExEx or Solana Geyser, see
the comparisons section.
What are "execution events"?​
The Category Labs
execution daemon
contains a shared-memory communication
system that publishes data about most actions taken by the EVM during
transaction execution. The raw binary records of these EVM actions are
called "execution events".
Third-party applications that need the highest performance can run on the
same host as the node software, and directly consume the execution event
records from shared memory. To read this data, your third-party application
calls functions in the execution event SDK, our real-time data library.
Execution events documentation​

Release notes - see what's new in the latest
release of the SDK
Getting started - describes
how to build and run a simple example program
Events overview - explains the core
concepts in the execution events system
Event rings in detail - documents
event ring files and protocol versioning
API documentation - overview of our programming libraries, which are
provided for several programming languages

C API
Rust API


Consensus events - execution
publishes some information from consensus that is essential for
understanding real-time data
Advanced topics - documentation for
advanced users and for software developers who contribute to the execution
source code

Alternatives to execution events​
Category Labs' node software includes an RPC server component. The RPC server
supports two easier ways to read blockchain data:

The typical JSON RPC endpoints supported by
most EVM-compatible blockchain nodes (e.g., Geth)
The Geth real-time events
WebSocket protocol (i.e., eth_subscribe) is also supported, along with
some Monad-specific extensions for better performance; see the
WebSocket guide for more information

Both of these access methods are standardized across EVM-compatible blockchains
and are simpler to use than execution events. The execution events system is
designed for specialized applications, such as running an indexer platform or
applications that need the lowest latency possible (e.g., market making).
It is also where the RPC server itself gets its real-time data.
Comparisons with other data systems​
A brief comparison with low latency systems in other blockchain
software:

Geth Live Tracing
(link) - "hook"
based API: your code is loaded into the Geth node as a plugin, and is run synchronously
(via callbacks) during execution
Reth ExEx (link) and
(link) - async function based API:
your code is loaded into a Reth node; execution sees events after the fact
rather than synchronously
Solana Geyser (link) - "hook" based API, a plugin that runs inside
a Solana validator and invokes callbacks during execution

All three of these are different from the Execution Events approach. In our approach:

You are seeing events "as-they-happen", as in the Geth Live Tracer and
Solana Geyser. Unlike these approaches, your code is not running as a
plugin inside the execution engine, but in parallel (about one
microsecond later) in a separate process
Like the Geth Live Tracer (but unlike Reth's ExEx) you see each "piece"
of the transaction -- each log, each balance change, etc. -- as a
separate event
Unlike the Geth Live Tracer or Geyser, you do not install "hooks" and
receive callbacks; instead you continuously poll for new event records,
iterating through any new events that are returned to you (and ignoring
events that you are not interested in)
Because the system is based on shared memory ring buffers, you can lose
data if your consumer is too slow -- you must keep up!

---

## Execution events overview

> Source: https://docs.monad.xyz/execution-events/overview

On this page

The execution daemon includes a system for recording events that occur during
transaction processing. An "execution event" is a notification that the EVM has
performed some action, such as "an account balance has been updated" or "a new
block has started executing." These EVM events can be observed by external
third-party applications, using a high-performance inter-process communication
(IPC) channel.
The execution daemon publishes event data to shared memory, and external
applications read from this same shared memory region to observe the events.
Your application can read events using the C library libmonad_event or the
Rust package monad-exec-events.
This page provides an overview of the basic concepts used in both the C
and Rust APIs.
Event rings vs. execution events​
Although the real-time data system and its SDK are often called "execution
events," there are two different parts of the SDK:


Event ring API - "event ring" is the name of a shared memory data
structure and the API for reading and writing to it. Event rings are a
general purpose, IPC broadcast utility for publishing events to any number
of reading processes. The event ring API works with unstructured I/O: like
the UNIX
read(2)
and
write(2)
file I/O system calls, the event ring API sees all data as raw byte arrays


Execution event definitions - the actual "execution events" are the
standardized binary formats that the execution daemons writes to represent
particular EVM actions. It can be thought of as a protocol, a schema, or a
serialization format. Continuing the analogy, if the event ring API is like
the UNIX read(2) and write(2) file APIs, then "execution events" are
like a "file format" that defines what a particular file contains


In the Rust SDK, these two parts are in different packages: monad-event-ring
and monad-exec-events.
The C SDK is a single library, but the header files for the two different
parts live in different directories: the event ring headers live in the
category/core/event subdirectory, and the execution event files live in
category/execution/ethereum.
Event ring basics​
What is an event?​
Events are made up of two components:

The event descriptor is a fixed-size (currently 64 byte) object describing
the common fields of an event that has happened. It contains the event's
type, a sequence number, a timestamp, and some internal book-keeping
information
The event payload is a variably-sized piece of extra data about the event,
which is specific to the event type. For example, a "transaction log" event
describes a single EVM log record emitted by a transaction. While the
descriptor tells us the event's type (i.e., that it is "log event"), the
payload tells us all the details: the contract address, the log topics, and
the log data. Some of the fields in the event descriptor not already
mentioned are used to communicate where in shared memory the payload bytes
are located, and the payload's length

noteRemember that at the event ring API level, an event payload is just an
unstructured byte buffer; the reader must know the format of what they are
reading, and interpret it accordingly
Where do events live?​
When an event occurs, an event descriptor is written into a ring buffer that
lives in a shared memory segment. This ring buffer is the "event descriptor
array" in the diagram below.
Event payloads are stored in a different array (in a separate shared memory
segment) called the "payload buffer."
  ╔═Event descriptor array══════════════...═════════════════════════════════════╗  ║                                                                             ║  ║ ┌───────────────┐ ┌───────────────┐     ┌───────────────┐ ┌───────────────┐ ║  ║ │     Event     │ │     Event     │     │     Event     │ │░░░░░░░░░░░░░░░│ ║  ║ │  descriptor   │ │  descriptor   │     │  descriptor   │ │░░░░ empty ░░░░│ ║  ║ │       1       │ │       2       │     │       N       │ │░░░░░░░░░░░░░░░│ ║  ║ └┬──────────────┘ └┬──────────────┘     └┬──────────────┘ └───────────────┘ ║  ╚══╬═════════════════╬════════════════...══╬══════════════════════════════════╝     │                 │                     │     │                 │                     │     │         ┌───────┘                     └─┐     │         │                               │     │         │                               │   ╔═╬═════════╬═══════════════════════════...═╬═══════════════════════════════╗   ║ │         │                               │                               ║   ║ ▼───────┐ ▼─────────────────────────┐     ▼─────────────┐ ┌─────────────┐ ║   ║ │Event 1│ │         Event 2         │     │   Event N   │ │░░░░free░░░░░│ ║   ║ │payload│ │         payload         │     │   payload   │ │░░░░space░░░░│ ║   ║ └───────┘ └─────────────────────────┘     └─────────────┘ └─────────────┘ ║   ╚═Payload buffer════════════════════════...═════════════════════════════════╝
Keep in mind that real event payloads are typically much larger (in terms of
number of bytes) than the event descriptors, even though they don't appear that
way in this simple diagram. The diagram is primarily trying to show that:

Event descriptors are fixed-size and event payloads are variably-sized
An event descriptor refers / "points to" the location of its payload
Event descriptors and payloads live in different contiguous arrays of shared
memory

Although there are two different ring buffers in this system -- the descriptor
array and payload byte buffer -- we call the entire combined data structure an
"event ring."
A few properties about the style of communication chosen:


It supports broadcast semantics: multiple readers may read from the event
ring simultaneously, and each reader maintains its own iterator position
within the ring


As in typical broadcast protocols, the writer is not aware of the readers --
events are written regardless of whether anyone is reading them or not.
Because the writer does not even know what the readers are doing, it cannot
wait for a reader if it is slow. Readers must iterate through events quickly,
or events will be lost: descriptor and payload memory can be overwritten by
later events. Conceptually the event sequence is a queue (it has FIFO
semantics) but is it called a ring to emphasize its overwrite-upon-overflow
semantics


A sequence number is included in the event descriptor to detect gaps (missing
events due to slow readers), and a similar strategy is used to detect when
payload buffer contents are overwritten


Execution event basics​
As mentioned, the event ring API works with unstructured I/O. When working
with a particular event ring, the reader assumes it has some known format. For
the remainder of the overview, we'll look at an example execution event.
Example: the "transaction start" event​
One particularly important kind of event is the "start of transaction header"
event, which is recorded shortly after a new transaction is decoded by the EVM.
It contains most of the transaction information (encoded as a C structure) as
its event payload. The payload structure is defined in exec_event_ctypes.h
as:
/// First event recorded when transaction processing startsstruct monad_exec_txn_header_start {    monad_c_bytes32 txn_hash;     ///< Keccak hash of transaction RLP    monad_c_address sender;       ///< Recovered sender address    struct monad_c_eth_txn_header        txn_header;               ///< Transaction header};
The nested monad_c_eth_txn_header structure contains most of the interesting
information -- it is defined in eth_ctypes.h as follows:
/// Fields of an Ethereum transaction that are recognized by the monad EVM/// implementation.////// This type contains the fixed-size fields present in any supported/// transaction type. If a transaction type does not support a particular field,/// it will be zero-initialized.struct monad_c_eth_txn_header {    enum monad_c_transaction_type        txn_type;                        ///< EIP-2718 transaction type    monad_c_uint256_ne chain_id;         ///< T_c: EIP-155 blockchain identifier    uint64_t nonce;                      ///< T_n: num txns sent by this sender    uint64_t gas_limit;                  ///< T_g: max usable gas (upfront xfer)    monad_c_uint256_ne max_fee_per_gas;  ///< T_m in EIP-1559 txns or T_p (gasPrice)    monad_c_uint256_ne        max_priority_fee_per_gas;        ///< T_f in EIP-1559 txns, 0 otherwise    monad_c_uint256_ne value;            ///< T_v: wei xfered or contract endowment    monad_c_address to;                  ///< T_t: recipient    bool is_contract_creation;           ///< True -> interpret T_t == 0 as null    monad_c_uint256_ne r;                ///< T_r: r value of ECDSA signature    monad_c_uint256_ne s;                ///< T_s: s value of ECDSA signature    bool y_parity;                       ///< Signature Y parity (see YP App. F)    monad_c_uint256_ne        max_fee_per_blob_gas;            ///< EIP-4844 contribution to max fee    uint32_t data_length;                ///< Length of trailing `data` array    uint32_t blob_versioned_hash_length; ///< Length of trailing `blob_versioned_hashes` array    uint32_t access_list_count;          ///< # of EIP-2930 AccessList entries    uint32_t auth_list_count;            ///< # of EIP-7702 AuthorizationList entries};
The formal nomenclature in the comments (e.g., T_n and T_c) are references
to variable names in the
Ethereum Yellow Paper.
The type monad_c_uint256_ne ("native endian") is a 256-bit integer that is
stored as a uint64_t[4] in the
limb format
common in most "big integer" libraries that have good performance.
noteIf you are using the Rust SDK, struct types with the same names (and the same
binary layouts, courtesy of a #[repr(C)] attribute) are generated by
bindgen when the monad-exec-events
package is built. The defining characteristic of the execution event payloads
is that they rely on the "natural" interoperability of simple C data
structures.Most popular programming languages have a defined foreign function interface
for working with C code, and this usually also entails some way to "naturally"
work with C structure types. Although C's data representation is not portable,
these objects live in shared memory, therefore both the reader and writer must
be on the same host, and must follow the same C ABI.
Variable-length trailing arrays and subsequent events​
The struct monad_exec_txn_header_start object is not the only piece of data
in the event payload:


The transaction's variably-sized data byte array, whose length is specified
by the data_length field, is also part of the event payload and immediately
follows the struct monad_exec_txn_header_start object


If this is an EIP-4844 transaction, a blob_versioned_hashes array will
immediately follow the data array


Both of these are examples of "variable-length trailing" (VLT) array payload
data; "trailing" means a simple variable-length array is recorded after a
fixed-size payload structure which (among other things) must contain a field
that describes length of the array; if there is more than VLT array, they
are recorded in the same order that their corresponding _length fields are
listed in the fixed-size structure


The EIP-2930 and EIP-7702 lists are also variable-length items in a
transaction, but they are not recorded as in the payload of the "start of
transaction header" event.
Instead of being recording in trailing arrays, a unique event will be recorded
for each EIP-2930 access list entry and each EIP-7702 authorization tuple. The
number of these events is published in the "start of transaction header"
event payload (see the access_list_count and auth_list_count fields), so
that the reader will know how many more events to expect.
Execution event properties in the descriptor​
So far we've talked about the payload for a "start of transaction" event, but
the common properties of the event are recorded directly in the event
descriptor. Most importantly, these include the numeric code that identifies
the type of event, so we know we're supposed to interpret the unstructured
payload bytes as a struct monad_exec_txn_header_start in the first place.
An event descriptor is defined this way:
struct monad_event_descriptor{    alignas(64) uint64_t seqno;  ///< Sequence number, for gap/liveness check    uint16_t event_type;         ///< What kind of event this is    uint16_t : 16;               ///< Unused tail padding    uint32_t payload_size;       ///< Size of event payload    uint64_t record_epoch_nanos; ///< Time event was recorded    uint64_t payload_buf_offset; ///< Unwrapped offset of payload in p. buf    uint64_t content_ext[4];     ///< Extensions for particular content types};
For a "start of transaction header" event, the event_type field will be set
to the value of the C enumeration constant MONAD_EXEC_TXN_HEADER_START, a
value in enum monad_exec_event_type. This tells the user that it is
appropriate to cast the const uint8_t * pointing to the start of the event
payload to a const struct monad_event_txn_header_start *.
All the C enumeration constants start with a MONAD_EXEC_ prefix, but
typically the documentation refers to event types without the prefix, e.g.,
TXN_HEADER_START.
Note that the transaction number is not included in the payload structure.
Because of their importance in the blockchain protocol, transaction numbers
are encoded directly in the event descriptor (this encoding and the rationale
for storing it in the descriptor is described elsewhere in the documentation,
in the section describing
flow tags).
The potential presence of subsequent EIP-2930 and EIP-7702 events is also why
this event is called the start of the transaction header. A corresponding
event called TXN_HEADER_END is emitted after all the transaction header
information has been seen. It has no payload, and only serves to announce
that all events related to the header have been recorded. Such an event is
called a "marker event" in the documentation.
Finally, the reason it is called a "header" in the first place, is that there
are many more events related to transactions. The various "header" just
describe all the inputs that were in the block. Most of the events relate to
transaction outputs: the logs, the call frames, the state changes, and the
receipt.
Example in-memory layout​
The following diagram illustrates everything explained above about a
transaction header's variable-length trailing arrays, related subsequent
events, and its terminating marker event. This example transaction has two
accounts in its EIP-2930 access list, and no EIP-7702 entries. Each address in
an EIP-2930 list records a separate TXN_ACCESS_LIST_ENTRY event, with a
variable-length trailing array of potentially-accessed storage keys.
                                      ╔═Payload buffer══════════════════════════════╗                                      ║                                             ║                                      ║  ┏━━━━━━━TXN_HEADER_START payload━━━━━━━━┓  ║                                      ║  ┃░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░┃  ║                                  ┌───╬──╋─▶─monad_exec_txn_header_start───────┐░┃  ║                                  │   ║  ┃░│                                   │░┃  ║                                  │   ║  ┃░│ monad_c_bytes32 txn_hash;         │░┃  ║                                  │   ║  ┃░│ monad_c_address sender;           │░┃  ║                                  │   ║  ┃░│ struct monad_c_eth_txn_header     │░┃  ║  ╔═Event descriptor array════╗   │   ║  ┃░│     txn_header;                   │░┃  ║  ║                           ║   │   ║  ┃░├───────────────────────────────────┤░┃  ║  ║ ┌───────────────────────┐ ║   │   ║  ┃░│                                   │░┃  ║  ║ │ seqno: 1              □─╬───┘   ║  ┃░│     Transaction data variable     │░┃  ║  ║ │ TXN_HEADER_START      │ ║       ║  ┃░│       length trailing array       │░┃  ║  ║ └───────────────────────┘ ║       ║  ┃░│                                   │░┃  ║  ║                           ║       ║  ┃░│                                   │░┃  ║  ║ ┌───────────────────────┐ ║       ║  ┃░└───────────────────────────────────┘░┃  ║  ║ │ seqno: 2              □─╬────┐  ║  ┃░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░┃  ║  ║ │ TXN_ACCESS_LIST_ENTRY │ ║    │  ║  ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛  ║  ║ └───────────────────────┘ ║    │  ║                                             ║  ║                           ║    │  ║  ┏━━━━━TXN_ACCESS_LIST_ENTRY payload━━━━━┓  ║  ║ ┌───────────────────────┐ ║    │  ║  ┃░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░┃  ║  ║ │ seqno: 3              │ ║    └──╬──╋─▶─monad_exec_txn_access_list_entry──┐░┃  ║  ║ │ TXN_ACCESS_LIST_ENTRY □─╬────┐  ║  ┃░│                                   │░┃  ║  ║ └───────────────────────┘ ║    │  ║  ┃░│ uint32_t index;                   │░┃  ║  ║                           ║    │  ║  ┃░│ struct monad_c_access_list_entry  │░┃  ║  ║ ┌───────────────────────┐ ║    │  ║  ┃░│     entry;                        │░┃  ║  ║ │ seqno: 4              │ ║    │  ║  ┃░├───────────────────────────────────┤░┃  ║  ║ │ TXN_HEADER_END        │ ║    │  ║  ┃░│       Storage key variable        │░┃  ║  ║ └───────────────────────┘ ║    │  ║  ┃░│       length trailing array       │░┃  ║  ║                           ║    │  ║  ┃░└───────────────────────────────────┘░┃  ║  ║                           ║    │  ║  ┃░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░┃  ║  ║                           ║    │  ║  ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛  ║  ║                           ║    │  ║                                             ║  ║                           ║    │  ║  ┏━━━━━TXN_ACCESS_LIST_ENTRY payload━━━━━┓  ║  ║                           ║    │  ║  ┃░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░┃  ║  ║                           ║    └──╬──╋─▶─monad_exec_txn_access_list_entry──┐░┃  ║  ║                           ║       ║  ┃░│                                   │░┃  ║  ║                           ║       ║  ┃░│ uint32_t index;                   │░┃  ║  ╚═══════════════════════════╝       ║  ┃░│ struct monad_c_access_list_entry  │░┃  ║                                      ║  ┃░│     entry;                        │░┃  ║                                      ║  ┃░├───────────────────────────────────┤░┃  ║                                      ║  ┃░│                                   │░┃  ║                                      ║  ┃░│       Storage key variable        │░┃  ║                                      ║  ┃░│       length trailing array       │░┃  ║                                      ║  ┃░│      (this has more storage       │░┃  ║                                      ║  ┃░│        keys and is larger)        │░┃  ║                                      ║  ┃░│                                   │░┃  ║                                      ║  ┃░└───────────────────────────────────┘░┃  ║                                      ║  ┃░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░┃  ║                                      ║  ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛  ║                                      ║                                             ║                                      .                                             .                                      .                                             .                                      .                                             .                                      ║                                             ║                                      ╚═════════════════════════════════════════════╝
Patterns in execution event serialization​
Why are EIP-2930 entries recorded as separate events instead of as
variable-length trailing arrays? Because there are two levels of
variable-length information involved. There are a variable number of EIP-2930
accounts, and then for each account, a variable-length number of associated
storage keys.
The event serialization protocol tries to be very simple: the only time a
variable length trailing array will be recorded is when the array element
type is fixed size. If there are multiple dimensions to the variability, they
are "factored out" by using more distinct events. The trade-off is between
fewer events with a more complex encoding, v.s. more events which "unfold" the
data into a "flatter" shape.
Technically, the EIP-7702 authorization list could be represented as a
variable-length trailing array, since the authorization tuples are fixed-size.
However, as a design decision, variable-length trailing arrays are only allowed
to have simple element types like u8 or uint256, and there cannot be too
many of them.
The decoding logic of VLT arrays tends to be error prone; it looks confusing
because it is harder to "see" in the code exactly what the serialization rules
are. "Unfolding" the data into more events is more self-documenting: distinct
typed objects are created rather than relying on implicit parsing rules for
reinterpreting unstructured trailing data.
Consequently, VLT arrays are only used when their use seems "obvious", e.g.,
the storage key arrays in each EIP-2930 access list entry.

### Code Examples

```prism
╔═Event descriptor array══════════════...═════════════════════════════════════╗  ║                                                                             ║  ║ ┌───────────────┐ ┌───────────────┐     ┌───────────────┐ ┌───────────────┐ ║  ║ │     Event     │ │     Event     │     │     Event     │ │░░░░░░░░░░░░░░░│ ║  ║ │  descriptor   │ │  descriptor   │     │  descriptor   │ │░░░░ empty ░░░░│ ║  ║ │       1       │ │       2       │     │       N       │ │░░░░░░░░░░░░░░░│ ║  ║ └┬──────────────┘ └┬──────────────┘     └┬──────────────┘ └───────────────┘ ║  ╚══╬═════════════════╬════════════════...══╬══════════════════════════════════╝     │                 │                     │     │                 │                     │     │         ┌───────┘                     └─┐     │         │                               │     │         │                               │   ╔═╬═════════╬═══════════════════════════...═╬═══════════════════════════════╗   ║ │         │                               │                               ║   ║ ▼───────┐ ▼─────────────────────────┐     ▼─────────────┐ ┌─────────────┐ ║   ║ │Event 1│ │         Event 2         │     │   Event N   │ │░░░░free░░░░░│ ║   ║ │payload│ │         payload         │     │   payload   │ │░░░░space░░░░│ ║   ║ └───────┘ └─────────────────────────┘     └─────────────┘ └─────────────┘ ║   ╚═Payload buffer════════════════════════...═════════════════════════════════╝
```

```prism
/// First event recorded when transaction processing startsstruct monad_exec_txn_header_start {    monad_c_bytes32 txn_hash;     ///< Keccak hash of transaction RLP    monad_c_address sender;       ///< Recovered sender address    struct monad_c_eth_txn_header        txn_header;               ///< Transaction header};
```

```prism
/// Fields of an Ethereum transaction that are recognized by the monad EVM/// implementation.////// This type contains the fixed-size fields present in any supported/// transaction type. If a transaction type does not support a particular field,/// it will be zero-initialized.struct monad_c_eth_txn_header {    enum monad_c_transaction_type        txn_type;                        ///< EIP-2718 transaction type    monad_c_uint256_ne chain_id;         ///< T_c: EIP-155 blockchain identifier    uint64_t nonce;                      ///< T_n: num txns sent by this sender    uint64_t gas_limit;                  ///< T_g: max usable gas (upfront xfer)    monad_c_uint256_ne max_fee_per_gas;  ///< T_m in EIP-1559 txns or T_p (gasPrice)    monad_c_uint256_ne        max_priority_fee_per_gas;        ///< T_f in EIP-1559 txns, 0 otherwise    monad_c_uint256_ne value;            ///< T_v: wei xfered or contract endowment    monad_c_address to;                  ///< T_t: recipient    bool is_contract_creation;           ///< True -> interpret T_t == 0 as null    monad_c_uint256_ne r;                ///< T_r: r value of ECDSA signature    monad_c_uint256_ne s;                ///< T_s: s value of ECDSA signature    bool y_parity;                       ///< Signature Y parity (see YP App. F)    monad_c_uint256_ne        max_fee_per_blob_gas;            ///< EIP-4844 contribution to max fee    uint32_t data_length;                ///< Length of trailing `data` array    uint32_t blob_versioned_hash_length; ///< Length of trailing `blob_versioned_hashes` array    uint32_t access_list_count;          ///< # of EIP-2930 AccessList entries    uint32_t auth_list_count;            ///< # of EIP-7702 AuthorizationList entries};
```

```prism
struct monad_event_descriptor{    alignas(64) uint64_t seqno;  ///< Sequence number, for gap/liveness check    uint16_t event_type;         ///< What kind of event this is    uint16_t : 16;               ///< Unused tail padding    uint32_t payload_size;       ///< Size of event payload    uint64_t record_epoch_nanos; ///< Time event was recorded    uint64_t payload_buf_offset; ///< Unwrapped offset of payload in p. buf    uint64_t content_ext[4];     ///< Extensions for particular content types};
```

```prism
╔═Payload buffer══════════════════════════════╗                                      ║                                             ║                                      ║  ┏━━━━━━━TXN_HEADER_START payload━━━━━━━━┓  ║                                      ║  ┃░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░┃  ║                                  ┌───╬──╋─▶─monad_exec_txn_header_start───────┐░┃  ║                                  │   ║  ┃░│                                   │░┃  ║                                  │   ║  ┃░│ monad_c_bytes32 txn_hash;         │░┃  ║                                  │   ║  ┃░│ monad_c_address sender;           │░┃  ║                                  │   ║  ┃░│ struct monad_c_eth_txn_header     │░┃  ║  ╔═Event descriptor array════╗   │   ║  ┃░│     txn_header;                   │░┃  ║  ║                           ║   │   ║  ┃░├───────────────────────────────────┤░┃  ║  ║ ┌───────────────────────┐ ║   │   ║  ┃░│                                   │░┃  ║  ║ │ seqno: 1              □─╬───┘   ║  ┃░│     Transaction data variable     │░┃  ║  ║ │ TXN_HEADER_START      │ ║       ║  ┃░│       length trailing array       │░┃  ║  ║ └───────────────────────┘ ║       ║  ┃░│                                   │░┃  ║  ║                           ║       ║  ┃░│                                   │░┃  ║  ║ ┌───────────────────────┐ ║       ║  ┃░└───────────────────────────────────┘░┃  ║  ║ │ seqno: 2              □─╬────┐  ║  ┃░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░┃  ║  ║ │ TXN_ACCESS_LIST_ENTRY │ ║    │  ║  ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛  ║  ║ └───────────────────────┘ ║    │  ║                                             ║  ║                           ║    │  ║  ┏━━━━━TXN_ACCESS_LIST_ENTRY payload━━━━━┓  ║  ║ ┌───────────────────────┐ ║    │  ║  ┃░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░┃  ║  ║ │ seqno: 3              │ ║    └──╬──╋─▶─monad_exec_txn_access_list_entry──┐░┃  ║  ║ │ TXN_ACCESS_LIST_ENTRY □─╬────┐  ║  ┃░│                                   │░┃  ║  ║ └───────────────────────┘ ║    │  ║  ┃░│ uint32_t index;                   │░┃  ║  ║                           ║    │  ║  ┃░│ struct monad_c_access_list_entry  │░┃  ║  ║ ┌───────────────────────┐ ║    │  ║  ┃░│     entry;                        │░┃  ║  ║ │ seqno: 4              │ ║    │  ║  ┃░├───────────────────────────────────┤░┃  ║  ║ │ TXN_HEADER_END        │ ║    │  ║  ┃░│       Storage key variable        │░┃  ║  ║ └───────────────────────┘ ║    │  ║  ┃░│       length trailing array       │░┃  ║  ║                           ║    │  ║  ┃░└───────────────────────────────────┘░┃  ║  ║                           ║    │  ║  ┃░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░┃  ║  ║                           ║    │  ║  ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛  ║  ║                           ║    │  ║                                             ║  ║                           ║    │  ║  ┏━━━━━TXN_ACCESS_LIST_ENTRY payload━━━━━┓  ║  ║                           ║    │  ║  ┃░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░┃  ║  ║                           ║    └──╬──╋─▶─monad_exec_txn_access_list_entry──┐░┃  ║  ║                           ║       ║  ┃░│                                   │░┃  ║  ║                           ║       ║  ┃░│ uint32_t index;                   │░┃  ║  ╚═══════════════════════════╝       ║  ┃░│ struct monad_c_access_list_entry  │░┃  ║                                      ║  ┃░│     entry;                        │░┃  ║                                      ║  ┃░├───────────────────────────────────┤░┃  ║                                      ║  ┃░│                                   │░┃  ║                                      ║  ┃░│       Storage key variable        │░┃  ║                                      ║  ┃░│       length trailing array       │░┃  ║                                      ║  ┃░│      (this has more storage       │░┃  ║                                      ║  ┃░│        keys and is larger)        │░┃  ║                                      ║  ┃░│                                   │░┃  ║                                      ║  ┃░└───────────────────────────────────┘░┃  ║                                      ║  ┃░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░┃  ║                                      ║  ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛  ║                                      ║                                             ║                                      .                                             .                                      .                                             .                                      .                                             .                                      ║                                             ║                                      ╚═════════════════════════════════════════════╝
```

---

## Getting started

> Source: https://docs.monad.xyz/execution-events/getting-started/

In this guide, we will:

Compile an example program, which will involve building code with the
execution event SDK as a dependency. The SDK is offered for both the C
and Rust programming languages. Each language has its own guide, so
follow the instructions for your language of choice

C guide
Rust guide


Run the example program on some historical data,
which prints ASCII representations of execution events to stdout
Set up and run our own Monad node,
so that we have a local execution process publishing real-time data
Run the example program again, this time using our Monad node;
this will again print execution events to stdout, but this time the
source will be real-time data from our local node

Linux required, but with some macOS supportThis guide has been tested on a clean Ubuntu 24.04 LTS install, but should
work on any recent Linux distribution, although the names of the required
packages might be different. The distribution will need to provide a recent
enough C compiler, either gcc-13 or clang-19.The first two steps of the guide, which involve looking at historical data
instead of real-time data, will also work on a macOS installation that is
configured for software development. This may make it easier for some developers
to try out the SDK on a development workstation or laptop, without the need to
set up a Linux host first.Unlike the SDK, the Monad node itself only runs on Linux so the later steps of
the guide -- which actually consume real-time data -- require a full Linux host
running your own Monad node.

---

## Release notes

> Source: https://docs.monad.xyz/execution-events/release-notes

On this page

v1.0​
Initial release of the execution event SDK

---

## Running the example program on live data, and next steps

> Source: https://docs.monad.xyz/execution-events/getting-started/final

On this page

If you're following this guide in order, you should have already built one
of the example programs (in C or Rust), ran it with a
snapshot file, and installed your own local
Monad node.
Now we'll run the example program again, but this time it will print the
real-time events published by our local Monad node.
Running with live data​
Step 1: preparing the Monad node​
Before running, make sure the execution daemon is running and that
execution events are enabled.
in particular, make sure you have passed the command line argument
--exec-event-ring to the execution daemon
Step 2: run the example program​
In the snapshot example, we passed the name of the snapshot file to the
program as a command line argument. In both the C and Rust example programs,
if we do not pass any filename at all, it will use default filename used by
the execution daemon, connecting us to the live event stream.


For C, run eventwatch with no arguments


For Rust, run the command cargo run -- -d


You will see similar data to the snapshot case, but as it is being published
by execution. If you stop the execution daemon, the example program will
detect that the source of data is gone, and exit.
Next steps​
This completes the getting started guide! If you're interested in developing
your own real-time data processing software with the SDK, where should
you go from here?
Here is a recommended list of resources, in roughly the order that will be
most helpful in developing real applications:


If you haven't already, read the overview and the
source code for the example program you just ran


Once you understand the basic ideas in the example,
the rest of the SDK documentation
should be easy to follow


Before using the SDK, make sure you understand the
consensus events and what they
mean


Try out a more sophisticated program and look at the source code for it


For Rust, try the "Block Explorer" TUI example in the upstream
monad-bft repository.
You can run it with cargo run -p monad-exec-events --example explorer
and then browse the source code in explorer.rs


For C, look at the code for the eventcap program in the upstream
monad
repository; this program is the "tcpdump" of the execution event system,
and shows several different uses of the API. You may also want to read
the next section about compiling the eventcap program




Optional: build the eventcap program​
eventcap is a useful utility for working with the event system. Like the Rust
eventwatch example, eventcap can decode execution event payloads into
human-readable form. It does several other tasks which are useful in the
developer workflow, e.g., recording captures of events and creating snapshot
event ring files for test cases.
warningeventcap requires gcc 15.2 or higher, and will not build with gcc 15.1.
The only Ubuntu release that ships with gcc 15.2 in its package repositories
is Ubuntu 25.10, which was recently released at the time this guide was written.If your Linux distribution does not provide gcc 15.2 and you do not want to
install it manually, you can instead use clang-19 (or more recent) but using
libc++ instead of libstdc++. The default on Linux is for clang to use the gcc
C++ standard library (libstdc++).If you specify -stdlib=libc++ it will use the LLVM standard library instead,
which has the needed <format> support. You may have to install it, since in
some distributions it is not part of the clang package. In Ubuntu, the clang-19
libc++ runtime and development packages will be added when you install
libc++-19-dev.When using libc++-19, you must also specify the -fexperimental-library
compiler flag to enable C++20 time zone support in <chrono>; eventcap uses
this for printing the event timestamp in local time. In some future version of
libc++ this will no longer be needed.
To build eventcap, you will also need the
CLI11
C++ command-line parser library and the OpenSSL development files. Although it
is optional, you should also install the development files for
GNU multiple-precision library
so that uint256 values print in decimal form.
The instructions also use the
ninja
build tool. You can install everything on Ubuntu with:
$ sudo apt install libcli11-dev libssl-dev libgmp-dev ninja-build
Now clone the
execution repository and
check out the branch release/exec-events-sdk-v1.0, then build the CMake
project rooted at cmd/eventcap.
Using clang-19 with libc++ and the above options:
$ git clone -b release/exec-events-sdk-v1.0 https://github.com/category-labs/monad.git \  ~/src/monad-eventcap$ CC=clang-19 CFLAGS="-march=x86-64-v4" \  CXX=clang++-19 CXXFLAGS="-stdlib=libc++ -fexperimental-library -march=x86-64-v4" cmake \  -S ~/src/monad-eventcap/cmd/eventcap -B ~/build/monad-eventcap-release -G Ninja \  -DCMAKE_BUILD_TYPE=RelWithDebInfo$ cmake --build ~/build/monad-eventcap-release
You should now be able to run:
$ ~/build/monad-eventcap-release/eventcap --help
noteThe -march=x86-64-v4 is needed to enable certain atomic operations at the
CPU instruction level, to avoid needing to link with libatomic.a; without this,
a performance warning is emitted, which becomes a compilation error due to
-Werror
To simplify running cmake with all these settings, you might want to create a
CMake toolchain file instead of using environment variables. To do this, create
a file called clang19-libcxx.cmake with these contents:
set(CMAKE_C_COMPILER clang-19)set(CMAKE_CXX_COMPILER clang++-19)set(CMAKE_ASM_FLAGS_INIT -march=x86-64-v4)set(CMAKE_C_FLAGS_INIT -march=x86-64-v4)set(CMAKE_CXX_FLAGS_INIT "-march=x86-64-v4 -stdlib=libc++ -fexperimental-library")
Now can you run this slightly cleaner command:
$ cmake --toolchain <path-to-toolchain-file> -S ~/src/monad-eventcap/cmd/eventcap \  -B ~/build/monad-eventcap-release -G Ninja -DCMAKE_BUILD_TYPE=RelWithDebInfo

### Code Examples

```prism
$ sudo apt install libcli11-dev libssl-dev libgmp-dev ninja-build
```

```prism
$ git clone -b release/exec-events-sdk-v1.0 https://github.com/category-labs/monad.git \  ~/src/monad-eventcap$ CC=clang-19 CFLAGS="-march=x86-64-v4" \  CXX=clang++-19 CXXFLAGS="-stdlib=libc++ -fexperimental-library -march=x86-64-v4" cmake \  -S ~/src/monad-eventcap/cmd/eventcap -B ~/build/monad-eventcap-release -G Ninja \  -DCMAKE_BUILD_TYPE=RelWithDebInfo$ cmake --build ~/build/monad-eventcap-release
```

```prism
$ ~/build/monad-eventcap-release/eventcap --help
```

```prism
set(CMAKE_C_COMPILER clang-19)set(CMAKE_CXX_COMPILER clang++-19)set(CMAKE_ASM_FLAGS_INIT -march=x86-64-v4)set(CMAKE_C_FLAGS_INIT -march=x86-64-v4)set(CMAKE_CXX_FLAGS_INIT "-march=x86-64-v4 -stdlib=libc++ -fexperimental-library")
```

```prism
$ cmake --toolchain <path-to-toolchain-file> -S ~/src/monad-eventcap/cmd/eventcap \  -B ~/build/monad-eventcap-release -G Ninja -DCMAKE_BUILD_TYPE=RelWithDebInfo
```

---

## Running the example program on snapshot data

> Source: https://docs.monad.xyz/execution-events/getting-started/snapshot

On this page

The easiest way to get acquainted with the execution event system is to
try out the example program and read the code, although you may want to
read the quick overview explaining
the basic concepts first.
If you're following this guide in order you should have already built one
of the example programs. If you have not built one yet, choose the
appropriate guide for your language or choice (either
C or
Rust), and then return to this page.
Live event rings vs. snapshot event rings​
The event ring's shared memory data structures typically live inside of a
regular file. Any process that wants shared access to an event ring, first
locates it via the filesystem, then maps a shared view of it into the
process' virtual memory map using the
mmap(2) system call.
Event ring files come in two flavors:


"Live" event ring files -- these are the "normal" event ring files that
are the source of real-time data. The whole point of the SDK is to read
real-time events from these files, but they're not very convenient for most
day-to-day software development tasks. Suppose, for example, you wanted to
write a test for your data processing program. The SDK is mostly designed
around reading events, so to test it with a live event ring, you'd need
to write some dummy event publishing code just to have events to read. For
execution events, the live event ring file is populated by the execution
daemon, which we have not even installed at this point in the tutorial!
A lot of development headaches are solved by the second kind of event ring
file.


"Snapshot" event ring files -- these are compressed snapshots taken of a
live event ring file as it existed at a particular moment in time. Typically
they are "rewound" to the oldest event in the circular event queue, and are
used to replay a fixed set of historical execution events. Snapshot files are
useful for testing and development workflows, because you do not need to be
running an active publisher to use them. Because they're so useful for
development, snapshots are the first data source we'll use, before trying the
example program on a live node.


Running the example program on a snapshot file​
Step 1: download a snapshot file​
Run this command to download a snapshot:
$ curl https://raw.githubusercontent.com/category-labs/monad-bft/refs/tags/release/exec-events-sdk-v1.0/monad-exec-events/test/data/exec-events-emn-30b-15m/snapshot.zst > /tmp/exec-events-emn-30b-15m.zst
The emn-30b-15m part of the filename means "Ethereum mainnet replay for 30
blocks starting after block 15 million". In other words, this contains the
execution events emitted during a historical replay of the Ethereum blockchain
(chain ID 1), from block 15,000,001 to block 15,000,031.
The Category Labs execution daemon is able to execute blocks from Monad
blockchains (the EVM chain ID 143 or any of its test networks), but also from
other EVM-compatible networks. Historical replay of the Ethereum mainnet is
used as an execution "conformance test", to make sure the node software remains
as Ethereum compatible as possible.
We use an Ethereum chain snapshot in the tutorial under the assumption that
many developers are already familiar with the Ethereum ecosystem, but might be
new to Monad. You can check that all of the data captured in the snapshot file
matches the data published by your favorite Ethereum data provider. For example,
you'll be able to check that the data shown here matches what is reported by
websites like Etherscan.
Why /tmp?Our example curl command placed the snapshot file in /tmp for a reason.
Although the file can be placed anywhere, we encourage users not to place it
in the same directory they are already in, to ensure they won't encounter a
confusing error the first time they run the program.If the file is placed in the current working directory, and you specified it as
exec-events-emn-30b-15m.zst, an error would occur. That error would go away
if you instead referred to the file as ./exec-events-emn-30b-15m.zst. The
leading ./ "fixes" the problem in a way you've seen before: when you want to
run a command in your UNIX shell which is not on the $PATH, you often add a
./ to suppress the default automatic path search. Any / character marks the
input as an actual file path and not a "command name" to be searched for.A similar thing happens with event ring files, where file inputs without / are
translated in an automatic way. The file would not be "searched for" in the
current directory unless the name contains a ./ to communicate that the input
is a path. "Pure" filenames are only searched for in a special directory called
the "default event ring directory." The rationale is explained fully in the
"Location of event ring files"
section of the SDK.
Step 2: run the SDK example program you built previously​
The command is slightly different for each programming language.
For C, run:
$ eventwatch /tmp/exec-events-emn-30b-15m.zst
For Rust, run:
cargo run -- --event-ring-path /tmp/exec-events-emn-30b-15m.zst -d
The Rust example program output is more informative than the C output. Both
programs "pretty-print" the event descriptor information, but the C example
program can only hexdump the event payloads, whereas the Rust program is able
to debug-print them, thanks to Rust's #[derive(Debug)] feature. The -d
parameter in the Rust command line tells the program to print this "debug"
form.
noteFull pretty-printers do exist in the SDK for the C language family, but they
are only available for C++ and are based on the standard C++ <format> library
Step 3: analyze the data (Rust only)​
If you're running the Rust example program -- and this step of the guide
assumes you are -- you will see a text dump of all event data. We'll look
at a few specific events to give you a sense of what kind of data the SDK
produces, and what you can do with it.
The first two lines printed by the Rust example program look like this:
16:26:14.354056730 BLOCK_START [2 0x2] SEQ: 1 BLK: 15000001Payload: BlockStart(monad_exec_block_start { <block-start-details> })
Let's break down the first line:


16:26:14.354056730 -- this is the nanosecond-resolution timestamp when the
original event was recorded; since we're looking at a snapshot and not live
data, this will always be the same number, and it's from a long time ago; the
actual "date" portion of the timestamp is omitted when we print it, since the
typical use-case for the SDK is for real-time data (where the date is usually
"today")


BLOCK_START - this is the type of the event that occurred inside of the
EVM; a BLOCK_START event is recorded when a new block is first seen by
the execution daemon, and its payload describes all the execution inputs
that are known at the start of execution processing; this mostly corresponds
to the fields in the Ethereum block header which are known prior to execution


[2 0x2] - this is the numerical code that corresponds to the BLOCK_START
event type, in both decimal and hexidecimal


SEQ: 1 - the sequence number (a monotonic counter of the number of
events published so far) is 1; in a live event ring, these are used
for gap / overwrite detection


BLK: 15000001 - this event is part of block number 15,000,001


The second line is produced by this Rust statement:
println!("Payload: {exec_event:x?}");
Because it's a very long line (there is no line-wrapping in Rust's
#[derive(Debug)] output) it was abbreviated in our example output text. We'll
look at parts of it in a moment, but we'll pause here to explain some things
about this println!("Payload: {exec_event:x?}") statement.
exec_event is a value of Rust enum type ExecEvent. Here is how that
enum is defined:
pub enum ExecEvent {    RecordError(monad_event_record_error),    BlockStart(monad_exec_block_start),    BlockReject(monad_exec_block_reject),    BlockPerfEvmEnter,    BlockPerfEvmExit,    BlockEnd(monad_exec_block_end),    BlockQC(monad_exec_block_qc),    BlockFinalized(monad_exec_block_finalized),    BlockVerified(monad_exec_block_verified),    TxnHeaderStart {        txn_index: usize,        txn_header_start: monad_exec_txn_header_start,        data_bytes: Box<[u8]>,        blob_bytes: Box<[u8]>,    },    // ... more enum variants follow, full definition not shown}


The debug output starts with BlockStart(...), so exec_event has the
ExecEvent::BlockStart enum variant


It seems like we already knew that from the earlier BLOCK_START [2 0x2]
print-out, but there's a subtle difference. The first line prints information
found in the event descriptor, which is like a header containing the the
common fields of an event. At the point in the program where the descriptor
line is printed, it has not yet decoded the event payload to construct the
exec_event variant. Suppose we were only interested in block 15,000,002.
In that case, we could look at just the descriptor, notice it relates to
block 15,000,001, and skip over this event (and all other events for that
block), i.e., we would not bother decoding it


The value associated with an ExecEvent::BlockStart variant if of type
struct monad_exec_block_start; notice that this type does not follow the
normal Rust code-formatting style: it uses lower_case_snake_case instead of
UpperCamelCase and has a seemingly-unnecessary prefix (all the variant
value types start with monad_exec_). This is because the payload types
are defined as C language structures, and their Rust equivalents are
generated using bindgen. The C-style spelling helps indicate that. The
definition of monad_exec_block_start comes from the C header file
exec_event_ctypes.h, where it is defined like this:


/// Event recorded at the start of EVM executionstruct monad_exec_block_start{    struct monad_exec_block_tag block_tag;          ///< Proposal is for this block    uint64_t round;                                 ///< Round when block was proposed    uint64_t epoch;                                 ///< Epoch when block was proposed    __uint128_t proposal_epoch_nanos;               ///< UNIX epoch nanosecond timestamp    monad_c_uint256_ne chain_id;                    ///< Blockchain we're associated with    struct monad_c_secp256k1_pubkey author;         ///< Public key of block author    monad_c_bytes32 parent_eth_hash;                ///< Hash of Ethereum parent block    struct monad_c_eth_block_input eth_block_input; ///< Ethereum execution inputs    struct monad_c_native_block_input monad_block_input; ///< Monad execution inputs};
The Ethereum execution inputs field eth_block_input is the field that
corresponds to the parts of the Ethereum block header which are known at
the start of execution.
Some of this output is difficult to read, since Rust's #[derive(Debug)] is
meant for ease of debugging and doesn't always "pretty-print" data in the best
way for readability. Other fields are clear though, for example, the gas_limit
of the block is shown as a hexidecimal value:
monad_c_eth_block_input { <not shown...> gas_limit: 1c9c380 <...not shown> }
0x1c9c380 corresponds to the decimal number 30,000,000, a number we expect
to see for a mainnet Ethereum gas limit.
infoReal pretty-printing of events is done with a developer tool called eventcap,
which is part of the SDK. This example is meant to be as simple and short as
possible, to help with learning the API. When debugging real event programs,
you will probably prefer developer tools like eventcap. The build instructions
for it are in the final step of the "Getting start" guide
(here).
Now let's look for something a little more interesting, to get a sense of a
what a real SDK consumer might do with this data.
If you search the output for the string TXN_EVM_OUTPUT, the first match
will be this event (with some formatting differences):
16:26:14.376725676 TXN_EVM_OUTPUT [17 0x11] SEQ: 236 BLK: 15000001 TXN: 0Payload: TxnEvmOutput { txn_index: 0, output: monad_exec_txn_evm_output {    receipt: monad_c_eth_txn_receipt { status: false, log_count: 0, gas_used: 765c },    call_frame_count: 1} }
This is the first event that describes the output of transaction zero in block
15,000,001 -- note the TXN: 0 in the descriptor and txn_index: 0 in the
payload. We say "first event" because the output for any particular transaction
usually spans several events: each log, call frame, state change, and state
access is recorded as a separate event.
The first event is always of type TXN_EVM_OUTPUT. It contains a basic summary
of what happened, and an indication of how many more output-related events will
follow. You can see that this particular transaction emitted zero logs, and one
call frame trace. The call frame information is recorded in the next event,
on the line below this one.
As it turns out, the very first transaction is also somewhat interesting: it
failed to execute after using 30,300 gas (0x765c). The transaction's failure is
recorded by status field. As you can see, it is set to false.
Why did it fail? To figure it out, we'll use the information in the
TXN_CALL_FRAME event that follows this one. The evmc_status_code field in
that event has the value 2, which is the numeric value of the
EVMC_REVERT
status code. This tells us that the revert was requested by the contract code
itself, i.e., it executed a
REVERT instruction. In other words,
this was not a VM-initiated exceptional halt such as "out of gas" or "illegal
instruction, but something the contract itself decided to do.
Because this is a Solidity contract, we can decode richer error information
from the call frame. The REVERT instruction can pass arbitrary-length return
data back to the caller. This return data is recorded in the call frame, in the
return_bytes array.
Observe that the first 4 bytes of return_bytes are 0x8c379a0. This is how
Solidity represents a revert that carries a string explanation. The details of
how this string is encoded is
here,
but the upshot is that we can decode the last 32 bytes of this return_bytes
array as an ASCII string. If you try this yourself, you'll discover that it
says:
Ownable: caller is not the owner
This error string ultimately comes from
here,
in OpenZeppelin's abstract "Ownable" contract. This was used as a third-party
library in the implementation of this smart contract, to provide some simple
access controls.
In an earlier event (called TXN_HEADER_START) we can find the transaction's
Keccak hash, which is
0xaedb8ef26125d8ad6e0c5f19fc9cbdd7f4a42eb82de88686b39090b8abcfeb8f. If
we look up information about this transaction on
Etherscan,
using the hash, we can see that Etherscan agrees. The Status: field reads:
Fail with error 'Ownable: caller is not the owner'
Feel free to double-check this result using your favorite tool for exploring
Ethereum mainnet data!
Step 4: Learn how it works​
The source code for the example program you just ran has a lot of comments,
and it is designed to teach you how to use the API. The best way to learn about
the SDK is to read through it, but if you haven't read the
overview yet, you may want to do that first.
You can either do that now, or continue on to the next step, where we'll
install our own local Monad node. Once we have our own
node, we can run this same example program but make it consume real-time
Monad blockchain data instead of snapshot data.

### Code Examples

```prism
$ curl https://raw.githubusercontent.com/category-labs/monad-bft/refs/tags/release/exec-events-sdk-v1.0/monad-exec-events/test/data/exec-events-emn-30b-15m/snapshot.zst > /tmp/exec-events-emn-30b-15m.zst
```

```prism
$ eventwatch /tmp/exec-events-emn-30b-15m.zst
```

```prism
cargo run -- --event-ring-path /tmp/exec-events-emn-30b-15m.zst -d
```

```prism
16:26:14.354056730 BLOCK_START [2 0x2] SEQ: 1 BLK: 15000001Payload: BlockStart(monad_exec_block_start { <block-start-details> })
```

```prism
println!("Payload: {exec_event:x?}");
```

```prism
pub enum ExecEvent {    RecordError(monad_event_record_error),    BlockStart(monad_exec_block_start),    BlockReject(monad_exec_block_reject),    BlockPerfEvmEnter,    BlockPerfEvmExit,    BlockEnd(monad_exec_block_end),    BlockQC(monad_exec_block_qc),    BlockFinalized(monad_exec_block_finalized),    BlockVerified(monad_exec_block_verified),    TxnHeaderStart {        txn_index: usize,        txn_header_start: monad_exec_txn_header_start,        data_bytes: Box<[u8]>,        blob_bytes: Box<[u8]>,    },    // ... more enum variants follow, full definition not shown}
```

```prism
/// Event recorded at the start of EVM executionstruct monad_exec_block_start{    struct monad_exec_block_tag block_tag;          ///< Proposal is for this block    uint64_t round;                                 ///< Round when block was proposed    uint64_t epoch;                                 ///< Epoch when block was proposed    __uint128_t proposal_epoch_nanos;               ///< UNIX epoch nanosecond timestamp    monad_c_uint256_ne chain_id;                    ///< Blockchain we're associated with    struct monad_c_secp256k1_pubkey author;         ///< Public key of block author    monad_c_bytes32 parent_eth_hash;                ///< Hash of Ethereum parent block    struct monad_c_eth_block_input eth_block_input; ///< Ethereum execution inputs    struct monad_c_native_block_input monad_block_input; ///< Monad execution inputs};
```

```prism
monad_c_eth_block_input { <not shown...> gas_limit: 1c9c380 <...not shown> }
```

```prism
16:26:14.376725676 TXN_EVM_OUTPUT [17 0x11] SEQ: 236 BLK: 15000001 TXN: 0Payload: TxnEvmOutput { txn_index: 0, output: monad_exec_txn_evm_output {    receipt: monad_c_eth_txn_receipt { status: false, log_count: 0, gas_used: 765c },    call_frame_count: 1} }
```

```prism
Ownable: caller is not the owner
```

```prism
Fail with error 'Ownable: caller is not the owner'
```

---

## Rust API

> Source: https://docs.monad.xyz/execution-events/rust-api

On this page

Modules​
The Rust execution events API is split across two library packages:


monad-event-ring - this package provides the core event ring
functionality. Recall that event rings are a generic broadcast utility
based on shared memory communication, and are agnostic about what kind
of event data they contain. Consequently, this package does not include
the definitions of the execution event types (nor any other event types)


monad-exec-events - the execution event data types are defined in this
library, along with some helpful utilities for writing real-time data
applications


These libraries fit together in a more structured way than they do in C.
In the C API, the event ring API works with unstructured data, e.g., event
numerical codes are uint16_t values and event payloads are raw byte arrays.
The reader performs unchecked type casts to reinterpret the meaning of those
bytes. There are some
safety mechanisms
to check if an event ring file appears to contain the right kind of data,
but the content types are not strongly represented in the type system.
In the Rust API, the event ring is not just "generic" in the general sense
of the word; it is a literal generic type:
struct EventRing<D: EventDecoder>
Event rings are explicitly parameterized by a "decoder". The decoder knows
how to interpret the raw bytes for a particular event content type, e.g.,
execution events.
Core concepts​
Event enumeration type​
Consider how decoding works in the C API: it's typically a "giant switch
statement" pattern, where we examine the numerical code of an event and
reinterpret the raw bytes as the appropriate payload type via an unchecked
type cast:
const void *payload = monad_event_ring_payload_peek(&exec_ring, &event);
switch (event.event_type) {case BLOCK_START:    handle_block_start((const struct monad_exec_block_start *)payload);    break;
case BLOCK_END:    handle_block_end((const struct monad_exec_block_end *)payload);    break;
// ... more event types handled here}
The Rust way of expressing this is to use an enum type: the different kinds
of event payloads become the enum's variants, and the switch logic is
replaced by a more-powerful match.
In Rust, decoding produces a value of enumeration type ExecEvent, which is
defined like this:
#[derive(Clone, Debug)]pub enum ExecEvent {    BlockStart(monad_exec_block_start),    BlockReject(monad_exec_block_reject),    BlockEnd(monad_exec_block_end),    // more variants follow
Notice that each variant of ExecEvent holds a value whose type name resembles
the C event payload structures. For example, struct monad_exec_block_start is
the event payload structure definition in the C API. It's recorded when a new
block starts, and is defined in the file exec_event_ctypes.h.
The use of these exact same C structure names -- including the monad_exec
prefix and  lower-case, snake-case spelling -- is designed to alert you to the
fact that the payload types have exactly the same in-memory representation
as their C API counterparts. They are generated by
bindgen and are layout-compatible
(via a #[repr(C)] attribute) with the C types of the same names.
Event rings and the 'ring reference lifetime​
EventRing is an RAII-handle type: when you create an EventRing instance,
new shared memory mapping are added to your process for that event ring file.
Likewise, when EventRing::drop is called, those shared memory mappings are
removed. Any pointers or references pointing into shared memory would need to
be invalidated at that point.
We rely on Rust's builtin reference lifetime analysis framework to express
this. References to data that lives in event ring shared memory always carries
a reference lifetime called 'ring. This lifetime corresponds to the lifetime
of the EventRing object itself.  Since an EventRing pins the shared memory
mappings in place by being alive, the true meaning of 'ring can usually be
thought of as the "shared memory lifetime", which is the same.
Zero-copy APIs and the "event reference" enumeration type​
In a previous section, we discussed the decoded execution event type,
enum ExecEvent. There is a second type with a similar design called
enum ExecEventRef<'ring>; it is used for the zero copy API.
To compare the two, here is the ExecEvent type:
#[derive(Clone, Debug)]pub enum ExecEvent {    BlockStart(monad_exec_block_start),    BlockReject(monad_exec_block_reject),    BlockEnd(monad_exec_block_end),    // more variants follow
And here is the ExecEventRef<'ring> type:
#[derive(Clone, Debug)]pub enum ExecEventRef<'ring> {    BlockStart(&'ring monad_exec_block_start),    BlockReject(&'ring monad_exec_block_reject),    BlockEnd(&'ring monad_exec_block_end),    // more variants follow
The former contains copies of event payloads, whereas the latter directly
references the bytes living in the shared memory payload buffer. By working
with ExecEventRef<'ring>, you avoid avoid copying a potentially large amount
of data, e.g., especially large EVM logs or call frames. This is valuable
if you are filtering out most events anyway.
The "event reference" enum type offers better performance, but it comes with
two drawbacks:


Because it has a reference lifetime as a generic parameter, it can be more
difficult to work with (i.e., more running afoul of the borrow checker)


Data that lives directly in the payload buffer can be overwritten at any
time, so you shouldn't rely on it still being there long after you first
look at it


Copying vs. zero-copy payload APIs​
The copy vs. zero-copy decision only applies to event payloads; event
descriptors are small, and are always copied. There are two ways to read an
event's payload once you have its descriptor:


Copying style EventDescriptor::try_read - this will return an
EventPayloadResult enum type, which either contains the "success" variant
(EventPayloadResult::Ready) or the "failure" variant
(EventPayloadResult::Expired); the former contains a ExecEvent payload
value, and the latter indicates that the payload was lost


Zero-copy style EventDescriptor::try_filter_map - you pass a
non-capturing closure to this method, and it is called back with an
ExecEventRef<'ring> reference pointing to the event payload in shared
memory; since your closure can't capture anything, the only way for you to
react to the event payload is to return some value v of type T;
EventDescriptor::try_filter_map itself returns an Option<T>, which is
used in the following way:


If the payload has expired prior to calling your closure, then your
closure is never called, and the try_filter_map returns Option::None


Otherwise your closure is run and its return value v: T is moved into
the try_filter_map function


If the payload is still valid after your closure has run, then the value
is transferred to the caller by returning Option::Some(v), otherwise
Option::None is returned




Why non-capturing closures?​
The pattern of zero-copy APIs generally works like this:


Create a reference to the data in the event ring payload buffer
(e: &'ring E) and check for expiration; if not expired ...


... compute something based on the event payload value, i.e., compute
let v = f(&e)


Once f finishes, check again if the payload expired; if it is expired
now, then it may have become expired sometime during the computation
of v = f(&e); the only safe thing we can do is discard the computed value
v, since we have no way of knowing exactly when the expiration happened


If you were permitted to capture variables in the zero-copy closure, you could
"smuggle out" computations out-of-band from the library's payload expiration
detection checks. That is, if the library later detects that the payload was
overwritten sometime during when your closure was running, it would have no
guaranteed way to "poison" your smuggled out value. It could only advise you
not to trust it, but that is error prone.
Idiomatic Rust tends to follow a "correct by default" style, and guards against
these kinds of unsafe patterns. In the zero-copy API, you can communicate only
through return values since you cannot capture anything. This way, the library
can decide not to propagate the return value back to you at all, if it later
discovers that the payload it gave you as input has expired.
Important types in the Rust API​
There are six core types in the API:


Event ring EventRing<D: EventDecoder> - given a path to an event
ring file, you create one of these to gain access to the shared memory
segments of the event ring in that file; you typically use the type alias
ExecEventRing, which is syntactic sugar for EventRing<ExecEventDecoder>


Event reader EventReader<'ring, D: EventDecoder> - this is the
iterator-like type that is used to read events; it's called a "reader" rather
than an "iterator" because Iterator
already has a specific meaning in Rust; the event reader has a more complex
return type than a Rust iterator because it has a "polling" style: its
equivalent  of next() -- called next_descriptor() -- can return an
event descriptor, report a gap, or indicate that no new event is ready
yet


Event descriptor EventDescriptor<'ring, D: EventDecoder> - the event
reader produces one of these if the next event is read successfully; recall
that the event descriptor contains the common fields of the event, and stores
the necessary data to read the event payload and check if it's expired; in
the Rust API, reading payloads is done using methods defined on the event
descriptor


Event decoder trait EventDecoder - you don't use this directly, but
a type that implements this trait -- ExecEventDecoder in the case of an
execution event ring -- contains all the logic for how to decode event
payloads


Event enumeration types (associated types EventDecoder::Event and
EventDecoder::EventRef) - these give the "copy" and "zero-copy" decoded
forms of events; in the case of the ExecEventDecoder, ExecEvent is the
"copy" type and ExecEventRef<'ring> is the zero-copy (shared-memory
reference) type


Execution event payload types (monad_exec_block_start, and others) -
these are bindgen-generated, #[repr(C)] event payload types that match
their C API counterparts


Block-level utilities​
ExecutedBlockBuilder​
Execution events are granular: most actions taken by the EVM will publish a
single event describing that one action, e.g., every EVM log emitted is
published as as a separate ExecEvent::TxnLog event. The events are streamed
to consumers almost as soon as they are available, so the real-time data of a
block comes in "a piece at a time."
A utility called the ExecutedBlockBuilder will aggregate these events back
into a single, block-oriented update, if the user prefers working with complete
blocks. The data types in the block representation are also
alloy_primitives types
which are more ergonomic to work with in Rust.
CommitStateBlockBuilder​
As explained in the section on
speculative real-time data,
the EVM publishes execution events as soon as it is able to, which means it
is usually publishing data about blocks that are speculatively executed.
We do not know if these blocks will be appended to the blockchain or not,
since the consensus decision is occurring in parallel with (and will finish
later than) the block's execution.
CommitStateBlockBuilder builds on the ExecutedBlockBuilder by also
tracking the commit state of the block as it moves through the consensus
life cycle. The block update itself is passed around via an
Arc<ExecutedBlock>, so that it is cheap to copy references to it. As the
block commit state changes, you receive updates describing the new state,
along with another reference to the Arc<ExecutedBlock> itself.
The speculative real-time data guide often points out that block abandonment
is not explicitly communicated by the event system (e.g.,
here and
here).
The CommitStateBlockBuilder however, does report explicit abandonment of
failed proposals, because it is a higher level, user-friendly utility.

### Code Examples

```prism
struct EventRing<D: EventDecoder>
```

```prism
const void *payload = monad_event_ring_payload_peek(&exec_ring, &event);
switch (event.event_type) {case BLOCK_START:    handle_block_start((const struct monad_exec_block_start *)payload);    break;
case BLOCK_END:    handle_block_end((const struct monad_exec_block_end *)payload);    break;
// ... more event types handled here}
```

```prism
#[derive(Clone, Debug)]pub enum ExecEvent {    BlockStart(monad_exec_block_start),    BlockReject(monad_exec_block_reject),    BlockEnd(monad_exec_block_end),    // more variants follow
```

```prism
#[derive(Clone, Debug)]pub enum ExecEvent {    BlockStart(monad_exec_block_start),    BlockReject(monad_exec_block_reject),    BlockEnd(monad_exec_block_end),    // more variants follow
```

```prism
#[derive(Clone, Debug)]pub enum ExecEventRef<'ring> {    BlockStart(&'ring monad_exec_block_start),    BlockReject(&'ring monad_exec_block_reject),    BlockEnd(&'ring monad_exec_block_end),    // more variants follow
```

---

## Setting up your Monad node

> Source: https://docs.monad.xyz/execution-events/getting-started/setup-node

The execution events SDK relies on a shared memory communication system,
in which the node's EVM execution daemon acts a publisher. Thus, in order to
use it, you need to (i) run your own Monad node and (ii) run your data
processing application on the same host as the node, so it can read the
data from shared memory.
Follow the guides on the node operations page,
which cover how to install and configure a full node, and how to reset it
when problems occur. You will also need to follow some
extra configuration steps
to prepare the node for use with execution events.

---



# Section: faq

---

## Frequently Asked Questions

> Source: https://docs.monad.xyz/faq

On this page

Execution​
Are there any differences in opcode pricing?A few opcodes and precompiles have been repriced to more correclty account for their relative
cost. See details here.
How does Monad's optimistic parallel execution manage interdependent transactions?In Monad, like in Ethereum, transactions are ordered linearly within a block. The guarantee
that Monad provides is that the result at the end of each block will be as if the transactions
were executed serially, even though under the hood there was work done in parallel.Monad handles interdependent transactions gracefully by separating the concerns of
computation (which can be done in parallel) from commitment (which is still done
serially).Transactions are computed in parallel optimistically (i.e. assuming that any storage slots read
in during execution are correct), generating a pending result for each transaction. A pending
result consists of the set of input storage slots (and their values) and output storage slots
(and their values).Pending results are committed serially in the original order of the transactions, checking
each input for correctness at the time of commitment. (An input will be incorrect if it was
mutated by one of the previously-committed pending results.) If a pending result has any
incorrect inputs, it will be re-executed; no other pending results can be committed until
that completes.Committing pending results serially ensures that correctness is always preserved.noteAn example illustrates this best. Suppose that at the start of a block, Alice, Bob, and
Charlie each have a balance of 100 USDC. These are the first two transactions:Transaction #What happens0Alice sends Bob 5 USDC1Bob sends Charlie 10 USDCWhen transactions 0 and 1 are executed in parallel, they produce the following pending results:Pending Result #InputsOutputs0Alice: 100 Bob: 100Alice: 95 Bob: 1051Bob: 100 Charlie: 100Bob: 90 Charlie: 110Now we commit the pending results serially. Pending result 0 gets committed. When we try to
commit pending result 1, we notice that one of the inputs is wrong - Bob's balance was expected
to be 100, but it is actually 105. This re-triggers execution for transaction 1. No other
transactions can be committed until transaction 1 is re-executed.
In optimistic parallel execution, transactions get re-executed if their first execution
was done with inputs that subsequently were mutated. What if there is a long list of serially
dependent transactions?(Note: This question is asking about re-execution as discussed here.)While it's true that having to re-execute a pending result is slower than immediately committing
it, re-execution is also typically much faster than the original execution because inputs are
stored in cache (RAM). Also note that every transaction will be executed at most twice: once
initially, and once on re-execution.More generally, you can think of optimistic parallel execution as a two-pass strategy. The first
pass begins executing many transactions in parallel, thus surfacing many storage slot
dependencies in parallel and pulling them all into cache. The second pass iterates over the
transactions serially, either committing the pending result immediately or re-executing it (but
from a position where most storage slots are cached). This strategy, combined with efficient SSD
lookups from MonadDb, delivers a workload that uses the full
SSD throughput more efficiently.
Do I need to change my code to take advantage of Monad’s parallelism? Would it make
sense to split my contract into many contracts to reduce the probability of two transactions
touching the same contract?No, no need! Transactions interacting with your smart contract behave as if every transaction
is being executed serially. Parallel execution is strictly an implementation detail.Also, it is important to note that all state contention is evaluated on a slot-by-slot basis.
So for example, suppose that transaction 1 involves Alice sending USDC to Bob, and transaction
2 involves Charlie sending USDC to David. It doesn't matter that both transactions involve the
same smart contract (the USDC ERC-20 contract); the two affected storage slots in transaction
1 are completely independent from the two affected storage slots in transaction 2.
What specific optimizations does MonadDB introduce over traditional databases for EVM
state storage?MonadDb stores Merkle Patricia Trie data natively, rather than embedding the trie inside a
generic database (like LevelDB or RocksDB) which have their own logic for mapping database
entries to locations on disk. This eliminates a level of indirection and substantially reduces
the number of IOPS and page reads to look up one value. Trie operations such as recomputing the
merkle root at the end of each block are much more efficient.MonadDb further reduces latency and increases throughput by implementing asynchronous I/O using
io_uring and by bypassing the filesystem.  io_uring is a new linux kernel technology that
allows execution threads to issue I/O requests without stalling or tieing up threads. This allows
many I/O requests to be issued in parallel, sequenced by the kernel, and serviced by the first
available thread on return.Finally, in MonadDb, each node in the trie is versioned, allowing for intuitive maintenance of
the merkle trie and efficient state synchronization algorithms. Only the necessary trie
components are sent during statesync, making bootstrapping and recovery faster.
Why doesn't Monad make EIP-2930 access lists mandatory? Wouldn’t it make execution more
efficient?

Usage of access lists generally increases the size of transactions; long-term we think that
bandwidth is the biggest bottleneck


In Ethereum, the workflow for a user to submit using access lists is: simulate the
transaction, note which storage slots are accessed, then submit the transaction with these
slots mentioned in the access list. However, the state of the world may change between
simulation and the real execution; we feel that it's the job of the system to handle this
gracefully under the hood.


It would break integrations with existing wallets which don't support EIP-2930.


Note that EIP-2930 access lists are actually underspecified, at least from the perspective
of anticipating state contention. If two transactions both read from the same storage slot
(but neither writes to it) then, with respect to that storage slot, there is no state
contention - neither transaction can invalidate the other's computation. Contention only
occurs when an earlier transaction writes to a storage slot that a later transaction will
read. EIP-2930 access lists mention which storage slots are accessed, but don't make note
of whether the transaction will read from or write to that storage slot.


Consensus​
How are leaders selected?The leader schedule is constructed by a deterministic, stake-weighted process that is computed
once per epoch:
An epoch occurs roughly every 5.5 hours (50000 blocks). Validator stake weights are locked in
one epoch ahead (i.e. any changes for epoch N+1 must be registered prior to the start of epoch N).
At the start of each epoch, each validator computes the leader schedule based on running a
deterministic pseudorandom function on the stake weights. Since the function is deterministic,
everyone arrives at the same leader schedule.

How many nodes can participate in consensus? Is participation permissionless?The client codebase has a parameter called ACTIVE_VALSET_SIZE
which is currently set to 200.
Thus, the top 200 validators (ordered by stake weight) can participate directly in consensus.
This parameter is likely to change over time.Participation is permissionless; one simply needs to be in the top ACTIVE_VALSET_SIZE
validators.
Raptorcast​
Where can I find a detailed description of RaptorCast?Check this blog post!
Why was UDP chosen instead of TCP in RaptorCast?See the discussion in this
blog post. UDP was selected, accepting  lossyness but alleviating it by adding additional data
integrity (Raptor codes) and message authentication (signatures over merkle roots), because the
combination of those strategies over UDP is substantially more efficient than using TCP.
What is the difference between Raptorcast and the propagation methods in Ethereum,
Solana, or L2s?Ethereum is using libp2p. It is gossip based
(each node propagates its message to a set of peers) which is a lot less efficient (more
duplicate messages and a more meandering process for getting the word out). As a result,
Ethereum budgets several seconds for the block to propagate throughout the network.Solana uses Turbine.
Turbine and RaptorCast are similar in the sense that they both use erasure coding, cut packets
into MTU-sized chunks, and send transactions through a broadcast tree for efficiency. Some of
the differences include:
Monad uses Raptor codes while Turbine uses Reed-Solomon
Monad uses a 2-level broadcast tree with every other validator as a level-1 node while Solana
uses a deeper, less structured broadcast tree with fewer level-1 nodes and more complex logic
for determining the broadcast tree. There aren't BFT guarantees on block delivery the way that
there are for Monad.
In L2s there's only 1 sequencer so there isn't a notion of block propagation for consensus.
The sequencer just pushes transaction batches occasionally to L1.
Mempool​
If there is a gap in nonces, will transactions after the gap be preserved in the
mempool?For example, if my EOA currently has nonce 0, and I send a transaction with nonce 3, then I
send transactions with nonce 0, 1, and 2. Will the transaction with nonce 3 be executed or
dropped?Answer: Transaction 3 will be executed.
Block States and Finality​
When can a node start executing a block?A node can start executing speculatively
as soon as a new block proposal is received. Executing a block just generates new states and a
new merkle trie root - but the official pointer is still to the old one. This is like receiving
a possible piece of homework from your teacher which will be finalized soon - you can start
working on it on a new piece of paper, and just throw it away if it turns out that the homework
isn't needed.
When can a node be sure about the state?As soon as a block enters the Finalized state, the
merkle root for the speculative execution of that block becomes the official local merkle root
for that block. That merkle root won't be verified by consensus for another D=3 blocks, but
it is still known locally because state is deterministic given a fixed ordering of transactions.If you want to be certain that your local node did not make a computation error (e.g. due to
cosmic rays), you may wait D=3 blocks for the delayed merkle root, which makes the block in
question enter the Verified state.
RPC​
When calling eth_call with an old block number, I received this response: Block   requested not found. Request might be querying historical state that is not available. If   possible, reformulate query to point to more recent blocks. What's going on?Due to Monad's high throughput, full nodes do not provide access to arbitrarily old state,
as this would require too much storage. See
Historical Data for a fuller discussion.When writing smart contracts, it is recommended to use events to log any state that will
be needed later, or use a smart contract indexer
to compute it off-chain.
Features​
Is EIP-7702 supported?Yes, EIP-7702 is supported.Note that when accounts are delegated under EIP-7702, their treatment under Monad's
Reserve Balance rules changes slightly.
You can learn more about it here.
Is EIP-7212 supported?Yes, it is precompile 0x0100. See Precompiles for
more details.
Miscellaneous​
What is the point of low validator hardware requirements (32 GB RAM, 2x 2TB SSD,
16-core CPU), if there will only be 100-200 voting nodes?Monad's north star is decentralization. If it's really expensive to run a node, only professional
validation companies with a large amount of stake will be able to justify the cost. Making nodes
economical is crucial to making it feasible for anyone to run a full node, as well as to
supporting a large validator set - the Day-1 mainnet target of 100-200 nodes is just a starting
point.
Why was rust chosen for the consensus client and C++ for execution?Rust and C++ are both great high-performance languages. C++ was selected for the database and
execution system to get finer control over the filesystem and to use libraries like io_uring
and boost::fibers. Rust was selected for consensus to take advantage of stricter memory safety
given that consensus concerns itself with slightly higher-level systems engineering problems.

---



# Section: guides

---

## Add Monad Mainnet to Wallet

> Source: https://docs.monad.xyz/guides/add-monad-to-wallet/mainnet

Follow this quick guide to add Monad Mainnet to your wallet.
Add Monad Mainnet automaticallyAdd Monad Mainnet manuallyClick the button below to automatically add Monad Mainnet to your wallet:Add Monad Mainnet to WalletTo manually add Monad Mainnet to your wallet, navigate to your wallet's network settings and add
a custom network with the following details:Network Details:
RPC URL: https://rpc.monad.xyz
Chain ID: 143
Currency Symbol: MON
Block Explorer: https://monadvision.com

---

## Add Monad Testnet to Wallet

> Source: https://docs.monad.xyz/guides/add-monad-to-wallet/testnet

Follow this quick guide to add Monad Testnet to your wallet.
Add Monad Testnet automaticallyAdd Monad Testnet manuallyClick the button below to automatically add Monad Testnet to your wallet:Add Monad Testnet to WalletTo manually add Monad Testnet to your wallet, navigate to your wallet's network settings and add a custom network with the following details:Network Details:
RPC URL: https://testnet-rpc.monad.xyz
Chain ID: 10143
Currency Symbol: MON
Block Explorer: https://testnet.monadvision.com

---

## Add Monad to Wallet

> Source: https://docs.monad.xyz/guides/add-monad-to-wallet/

MainnetAdd Monad MainnetTestnetAdd Monad Testnet

---

## Deploy a Contract

> Source: https://docs.monad.xyz/guides/deploy-smart-contract/

FoundryDeploy a smart contract on Monad using FoundryHardhatDeploy a smart contract on Monad using HardhatRemixDeploy a smart contract on Monad using Remix

---

## Deploy a smart contract on Monad using Foundry

> Source: https://docs.monad.xyz/guides/deploy-smart-contract/foundry

On this page

Foundry is a blazing fast, portable and modular toolkit for Ethereum application development written in Rust.
Requirements​
Before you begin, you need to install the following tools:

Rust

1. Installing foundryup​
Foundryup is the official installer for the Foundry toolchain.
curl -L https://foundry.paradigm.xyz | bash
This will install Foundryup. Simply follow the on-screen instructions, and the foundryup command will become available in your CLI.
2. Installing forge, cast, anvil and chisel binaries​
foundryup
noteIf you're on Windows, you'll need to use WSL, since Foundry currently doesn't work natively on Windows. Please follow this link to learn more about WSL.
3. Create a new foundry project​
tipYou can use foundry-monad template to create a new project.Foundry-Monad is a Foundry template with Monad configuration.
The below command uses foundry-monad to create a new foundry project:
forge init --template monad-developers/foundry-monad [project_name]
Alternatively, you can create a foundry project using the command below:
forge init [project_name]
4. Modify Foundry configuration​
Update the foundry.toml file to add Monad Testnet configuration.
foundry.toml1234567[profile.default]src = "src"out = "out"libs = ["lib"]# Monad Testnet Configurationeth-rpc-url="https://testnet-rpc.monad.xyz"chain_id = 10143
5. Write a smart contract​
You can write your smart contracts under the src folder. There is already a Counter contract in the project located at src/Counter.sol.
Counter.solsrc1234567891011121314// SPDX-License-Identifier: UNLICENSEDpragma solidity ^0.8.13;
contract Counter {    uint256 public number;
    function setNumber(uint256 newNumber) public {        number = newNumber;    }
    function increment() public {        number++;    }}
6. Compile the smart contract​
forge compile
Compilation process output can be found in the newly created out directory, which includes contract ABI and bytecode.
7. Deploy the smart contract​
noteFor deploying contracts, we recommend using keystores instead of private keys.
Get testnet funds​
Deploying smart contracts requires testnet funds. Claim testnet funds via a faucet.
Deploy smart contract​
Using a Keystore (Recommended)Using a Private Key (Not Recommended)Using a keystore is much safer than using a private key because keystore encrypts the private key and can later be referenced in any commands that require a private key.Create a new keystore by importing a newly generated private key with the command below.cast wallet import monad-deployer --private-key $(cast wallet new | grep 'Private key:' | awk '{print $3}')Here is what the command above does, step by step:
Generates a new private key
Imports the private key into a keystore file named monad-deployer
Prints the address of the newly created wallet to the console
After creating the keystore, you can read its address using:cast wallet address --account monad-deployerProvide a password to encrypt the keystore file when prompted and do not forget it.Run the below command to deploy your smart contractsforge create src/Counter.sol:Counter --account monad-deployer --broadcastUse the below command to deploy a smart contract by directly pasting the private key in the terminal.warningUsing a private key is not recommended. You should not be copying and pasting private keys into your terminal. Please use a keystore instead.forge create --private-key <your_private_key> src/Counter.sol:Counter --broadcast
On successful deployment of the smart contract, the output should be similar to the following:
[⠊] Compiling...Deployer: 0xB1aB62fdFC104512F594fCa0EF6ddd93FcEAF67bDeployed to: 0x67329e4dc233512f06c16cF362EC3D44Cdc800e0Transaction hash: 0xa0a40c299170c9077d321a93ec20c71e91b8aff54dd9fa33f08d6b61f8953ee0
Next Steps​
Check out how to verify the deployed smart contract on MonadVision.

### Code Examples

```prism
curl -L https://foundry.paradigm.xyz | bash
```

```prism
foundryup
```

```prism
forge init --template monad-developers/foundry-monad [project_name]
```

```prism
forge init [project_name]
```

```prism
[profile.default]src = "src"out = "out"libs = ["lib"]# Monad Testnet Configurationeth-rpc-url="https://testnet-rpc.monad.xyz"chain_id = 10143
```

```prism
// SPDX-License-Identifier: UNLICENSEDpragma solidity ^0.8.13;
contract Counter {    uint256 public number;
    function setNumber(uint256 newNumber) public {        number = newNumber;    }
    function increment() public {        number++;    }}
```

```prism
forge compile
```

```prism
cast wallet import monad-deployer --private-key $(cast wallet new | grep 'Private key:' | awk '{print $3}')
```

```prism
cast wallet address --account monad-deployer
```

```prism
forge create src/Counter.sol:Counter --account monad-deployer --broadcast
```

```prism
forge create --private-key <your_private_key> src/Counter.sol:Counter --broadcast
```

```prism
[⠊] Compiling...Deployer: 0xB1aB62fdFC104512F594fCa0EF6ddd93FcEAF67bDeployed to: 0x67329e4dc233512f06c16cF362EC3D44Cdc800e0Transaction hash: 0xa0a40c299170c9077d321a93ec20c71e91b8aff54dd9fa33f08d6b61f8953ee0
```

---

## Deploy a smart contract on Monad using Hardhat

> Source: https://docs.monad.xyz/guides/deploy-smart-contract/hardhat

On this page

Hardhat is a comprehensive development environment consisting of different components for editing, compiling, debugging, and deploying your smart contracts.
Requirements​
Before you begin, you need to install the following dependencies:

Node.js v18.0.0 or later

noteIf you are on Windows, we strongly recommend using WSL 2 when following this guide.
Hardhat 2Hardhat31. Create a new Hardhat project​tipYou can use the hardhat-monad template to create a new project with Monad configuration already set up.hardhat-monad is a Hardhat template with Monad configuration.Clone the repository to your machine using the command below:git clone https://github.com/monad-developers/hardhat-monad.gitcd hardhat-monad2. Install dependencies​npm install3. Create an .env file​cp .env.example .envEdit the .env file with your private key:PRIVATE_KEY=your_private_key_herewarningProtect your private key carefully. Never commit it to version control, share it in public repositories, or expose it in client-side code. Your private key provides full access to your funds.4. Deploy the smart contract​The following commands use Hardhat Ignition:Deploying to the local hardhat node​Run hardhat node by running:npx hardhat nodeTo deploy the example contract to the local hardhat node, run the following command in a separate terminal:npx hardhat ignition deploy ignition/modules/Counter.tsDeploying to Monad Testnet​Ensure your private key is set in the .env file.Deploy the contract to Monad Testnet:npx hardhat ignition deploy ignition/modules/Counter.ts --network monadTestnetRedeploy the same code to a different address:npx hardhat ignition deploy ignition/modules/Counter.ts --network monadTestnet --resetDeploying to Monad Mainnet​Ensure your private key is set in the .env file.Deploy the contract to Monad Mainnet:npx hardhat ignition deploy ignition/modules/Counter.ts --network monadMainnetRedeploy the same code to a different address:npx hardhat ignition deploy ignition/modules/Counter.ts --network monadMainnet --reset1. Create a new Hardhat3 project​tipYou can use the hardhat3-monad template to create a new project with Monad configuration already set up for Hardhat3.hardhat3-monad is a Hardhat3 template with Monad configuration.To learn more about Hardhat3, please visit the Getting Started guide.Clone the repository to your machine using the command below:git clone https://github.com/monad-developers/hardhat3-monad.gitcd hardhat3-monad2. Install dependencies​npm install3. Set up your private key​Create a .env file in the project root:PRIVATE_KEY=your_private_key_hereETHERSCAN_API_KEY=your_etherscan_api_key_herewarningProtect your private key carefully. Never commit your .env file or expose your private key. Your private key provides full access to your funds.4. Deploy the smart contract​The following commands use Hardhat Ignition:Deploying to a local chain​npx hardhat ignition deploy ignition/modules/Counter.tsDeploying to Monad Testnet​Ensure your .env file is set up with your private key.npx hardhat ignition deploy ignition/modules/Counter.ts --network monadTestnetDeploying to Monad Mainnet​Ensure your .env file is set up with your private key.npx hardhat ignition deploy ignition/modules/Counter.ts --network monadMainnet
Next Steps​
Check out how to verify the deployed smart contract on MonadVision.

### Code Examples

```prism
git clone https://github.com/monad-developers/hardhat-monad.gitcd hardhat-monad
```

```prism
npm install
```

```prism
cp .env.example .env
```

```prism
PRIVATE_KEY=your_private_key_here
```

```prism
npx hardhat node
```

```prism
npx hardhat ignition deploy ignition/modules/Counter.ts
```

```prism
npx hardhat ignition deploy ignition/modules/Counter.ts --network monadTestnet
```

```prism
npx hardhat ignition deploy ignition/modules/Counter.ts --network monadTestnet --reset
```

```prism
npx hardhat ignition deploy ignition/modules/Counter.ts --network monadMainnet
```

```prism
npx hardhat ignition deploy ignition/modules/Counter.ts --network monadMainnet --reset
```

```prism
git clone https://github.com/monad-developers/hardhat3-monad.gitcd hardhat3-monad
```

```prism
npm install
```

```prism
PRIVATE_KEY=your_private_key_hereETHERSCAN_API_KEY=your_etherscan_api_key_here
```

```prism
npx hardhat ignition deploy ignition/modules/Counter.ts
```

```prism
npx hardhat ignition deploy ignition/modules/Counter.ts --network monadTestnet
```

```prism
npx hardhat ignition deploy ignition/modules/Counter.ts --network monadMainnet
```

---

## Deploy a smart contract on Monad using Remix

> Source: https://docs.monad.xyz/guides/deploy-smart-contract/remix

On this page

Remix IDE is a browser-based IDE that can be used for the entire journey of smart contract development by users at every knowledge level. It requires no setup, fosters a fast development cycle, and has a rich set of plugins with intuitive GUIs.
In this guide you will learn how to deploy and interact with a simple Greeting smart contract on Monad Testnet using Remix IDE.
Requirements​

You need to have the Monad Testnet network added to your wallet.

Deploying the smart contract​
Head over to Remix IDE in your browser. Click 'Start Coding' to create a new project template.

Make sure the 'contracts' folder is selected, then create a new file using the "Create new file" button on top left corner.

Name the new file "Gmonad.sol" and add the following code to it
Gmonad.solsrc12345678910111213141516// SPDX-License-Identifier: MIT
// Make sure the compiler version is below 0.8.24 since Cancun compiler is not supported just yetpragma solidity >=0.8.0 <=0.8.24;
contract Gmonad {     string public greeting;
    constructor(string memory _greeting) {        greeting = _greeting;    }
    function setGreeting(string calldata _greeting) external {        greeting = _greeting;    }}
Note: You may see a red squiggly line underneath the pragma solidity... line; this is because the default compiler version is outside of the range specified in the contract. We'll fix that in the next step.

Let's compile the smart contract. Navigate to the compiler view by clicking the "Solidity compiler" tab on the far left. Then select the right compiler version (0.8.24).

Once you have the right compiler version selected, click on the "Compile Gmonad.sol" button. If succesful, you will see a green check mark on the "Solidity compiler" tab icon.

Now we can deploy the smart contract! Navigate to the deploy view using the "Deploy & run transactions" tab on the far left.

Using the "Environment" dropdown, select "Injected Provider" to connect to your wallet.
The screenshot below says "Injected Provider - Metamask"; in case you are using some wallet other than Metamask you may see an appropriate option.

Your wallet should pop up asking for permission to connect to Remix, click "Connect".

Once connected you should be able to see your address with your balance in the "Account" dropdown.
Make sure you also see the correct chain id under the "Environment" dropdown.
Now let's deploy the contract. Gmonad.sol requires a greeting message to be passed to the constructor before it can be deployed; choose the greeting message of your choice (in this example it is "gmonad").
Now you can deploy the smart contract by clicking the "Deploy" button.

You should see a wallet popup asking for confirmation to deploy the smart contract. Click "Confirm".

Once the transaction is confirmed you will see the smart contract address in the "Deployed Contracts" section on the bottom left.

Interacting with the smart contract​
You can expand the smart contract to see the functions available.
There you will find a greeting button which can be used to read the current greeting message stored in the smart contract.
Click the "greeting" button to call the greeting() method (which outputs the current greeting message). You'll need to click the expand arrow in the terminal output to see the decoded output.
infoThis "greeting" button is a getter function which is automatically created for the public greeting state variable in the smart contract.

You can change the greeting message by using the setGreeting function.
In this example, we will change the greeting message to "gmonad molandak".
Once again, click the "transact" button to initiate the transaction.
You should see a wallet popup asking for confirmation to change the greeting message. Click "Confirm".

Once the transaction is confirmed you can view the updated greeting message using the greeting button.

Congratulations! You have successfully deployed and interacted with a smart contract on Monad  Testnet using Remix IDE.

### Code Examples

```prism
// SPDX-License-Identifier: MIT
// Make sure the compiler version is below 0.8.24 since Cancun compiler is not supported just yetpragma solidity >=0.8.0 <=0.8.24;
contract Gmonad {     string public greeting;
    constructor(string memory _greeting) {        greeting = _greeting;    }
    function setGreeting(string calldata _greeting) external {        greeting = _greeting;    }}
```

---

## EVM Behavior

> Source: https://docs.monad.xyz/guides/evm-resources/evm-behavior

On this page

EVM Behavioral Specification​

Notes on the EVM: straightforward technical specification of the EVM plus some behavioral examples
EVM: From Solidity to bytecode, memory and storage: a 90-minute talk from Peter Robinson and David Hyland-Wood
EVM illustrated: an excellent set of diagrams for confirming your mental model
EVM Deep Dives: The Path to Shadowy Super-Coder

Opcode Reference​
noteOpcode pricing on Monad has been changed to reflect their relative costs in execution, learn more about it here
evm.codes: opcode reference and an interactive sandbox for stepping through bytecode execution
Solidity Storage Layout​
The EVM allows smart contracts to store data in 32-byte words ("storage slots"), however the details of how complex datastructures such as lists or mappings is left as an implementation detail to the higher-level language.  Solidity has a specific way of assigning variables to storage slots, described below:

Official docs on storage layout
Storage patterns in Solidity

---

## EVM Resources

> Source: https://docs.monad.xyz/guides/evm-resources

📄️ EVM BehaviorEVM Behavioral Specification📄️ Solidity ResourcesMonad is fully EVM bytecode-compatible, with all supported opcodes and precompiles as of the Cancun fork. Monad also preserves the standard Ethereum JSON-RPC interfaces.🗃️ Other Languages3 items

📄️ EVM BehaviorEVM Behavioral Specification

📄️ Solidity ResourcesMonad is fully EVM bytecode-compatible, with all supported opcodes and precompiles as of the Cancun fork. Monad also preserves the standard Ethereum JSON-RPC interfaces.

🗃️ Other Languages3 items

---

## EVM Resources

> Source: https://docs.monad.xyz/guides/evm-resources/

📄️ EVM BehaviorEVM Behavioral Specification📄️ Solidity ResourcesMonad is fully EVM bytecode-compatible, with all supported opcodes and precompiles as of the Cancun fork. Monad also preserves the standard Ethereum JSON-RPC interfaces.🗃️ Other Languages3 items

📄️ EVM BehaviorEVM Behavioral Specification

📄️ Solidity ResourcesMonad is fully EVM bytecode-compatible, with all supported opcodes and precompiles as of the Cancun fork. Monad also preserves the standard Ethereum JSON-RPC interfaces.

🗃️ Other Languages3 items

---

## Getting Started with Reown AppKit on Monad Testnet using AppKit CLI

> Source: https://docs.monad.xyz/guides/reown-guide

On this page

This guide shows you how to use Reown AppKit to enable wallet connections and interact with the Monad network. AppKit provides seamless wallet connections, including email/social logins, smart accounts, one-click authentication, and wallet notifications.
For this tutorial, we'll be using Next.js, though you can use any other framework compatible
with AppKit.
noteAppKit is available on eight frameworks, including React, Next.js, Vue, JavaScript, React
Native, Flutter, Android, iOS, and Unity.
What you'll learn:

Set up a new project using AppKit CLI
Configure the project for Monad Testnet
Connect wallets to your application

Time to complete: ~5 minutes
Prerequisites​

Node.js installed on your system

Step 1: Create a New Project​
Run the AppKit CLI to create a new project configured with Reown AppKit:
npx @reown/appkit-cli
When prompted, provide:

Project Name: Choose a name (e.g., my-monad-appkit-app)
Framework: Select Next.js (or your preferred framework)
Blockchain Library: Choose whether you want to install Wagmi, Ethers, Solana,
or Multichain (EVM + Solana). In this case, you need to either pick Wagmi or Ethers since
Monad is an EVM compatible blockchain. We will be choosing Wagmi for the sake of this
tutorial.

The CLI will create a minimal AppKit example with your selected configuration.
Step 2: Set Up the Project​
Navigate to your project directory and install dependencies:
cd my-monad-appkit-appnpm install
noteYou can also use other package managers such as yarn, bun, pnpm, etc.
Step 3: Get Your Project ID​
The example is pre-configured with a projectId that will only work on localhost. To fully configure your project, you will need to get a projectId from the Reown Dashboard, as described below:

Go to dashboard.reown.com and sign in
Navigate to your team's Cloud Dashboard
Click "+ Project"



If prompted to choose a product type, select "AppKit" (otherwise ignore this step)



Choose a project name
Click "Create"



Copy the generated Project ID from the bottom of the page


Step 4: Configure Environment Variables​
Create a .env file in your project root:
.envNEXT_PUBLIC_PROJECT_ID="YOUR_PROJECT_ID_HERE"
Replace YOUR_PROJECT_ID_HERE with the Project ID you copied in the previous step.
warningEnvironment variables starting with NEXT_PUBLIC_ are exposed to the client. Only include non-sensitive configuration data.
Step 5: Configure for Monad Testnet​
Update /src/config/index.ts to use Monad Testnet:
index.tssrc > config123import { mainnet, monadTestnet } from '@reown/appkit/networks'
export const networks = [monadTestnet] as [AppKitNetwork, ...AppKitNetwork[]]
This configures your app to use Monad Testnet instead of the default networks.
Step 6: Run Your Application​
Start the development server:
npm run dev
Your app will be available at http://localhost:3000.
noteIf you are using alternative package managers, you can try either of these commands - yarn dev, pnpm dev, or bun dev.
Conclusion​
You have now learned how to create a simple app using AppKit CLI that allows users to connect their wallet and interact with Monad Testnet.
Reown AppKit is a powerful solution for developers looking to integrate wallet connections and other Web3 functionalities into their apps on any EVM chain. In just a few simple steps, you can provide your users with seamless wallet access, one-click authentication, social logins, and notifications—streamlining their experience while enabling advanced features like on-ramp functionality and smart accounts.
What's Next?​

Explore the Reown blog
Check out the complete example: Reown AppKit EVM

### Code Examples

```prism
npx @reown/appkit-cli
```

```prism
cd my-monad-appkit-appnpm install
```

```prism
NEXT_PUBLIC_PROJECT_ID="YOUR_PROJECT_ID_HERE"
```

```prism
import { mainnet, monadTestnet } from '@reown/appkit/networks'
export const networks = [monadTestnet] as [AppKitNetwork, ...AppKitNetwork[]]
```

```prism
npm run dev
```

---

## Guides

> Source: https://docs.monad.xyz/guides/

On this page

Start building smart contracts and applications on Monad with our quickstart guides.
Get a wallet​
PhantomMetamask
Deploy Smart Contract​
FoundryDeploy a smart contract on Monad using FoundryHardhatDeploy a smart contract on Monad using HardhatRemixDeploy a smart contract on Monad using Remix
Verify Smart Contract​
FoundryVerify a smart contract on Monad using FoundryHardhatVerify a smart contract on Monad using Hardhat
Indexing​
GhostGraphIndex transfers with GhostGraphEnvioIndex transfers for a telegram bot using EnvioQuickNode StreamsIndex transfers using QuickNode Streams


Connectivity​
Reown AppKitConnect a wallet to your app with Reown AppKitBlinksBuild a donation blink
AI​
MCP ServerBuild an MCP server to interact with Monad Testnet

---

## How to build a basic dApp with Scaffold-ETH

> Source: https://docs.monad.xyz/guides/scaffold-eth

On this page

In this guide, you will learn how to use Scaffold-ETH 2 to quickly build a new dapp project.
Requirements​
Before you begin, you need to install the following tools:

Node (>= v18.18)
Yarn (v1 or v2+)
Git

Get funds on Monad Testnet​
You will need funds on Monad Testnet in order to deploy smart contracts, you can get funds from the Monad Faucet.
Working with Scaffold-ETH​
Scaffold-ETH can have two different solidity development frameworks: Foundry and Hardhat.
In this guide you can choose between Foundry and Hardhat.
FoundryHardhatClone the scaffold-monad-foundry repo​git clone https://github.com/monad-developers/scaffold-monad-foundry.gitOpen the project directory and install dependencies​cd scaffold-monad-foundry && yarn installStart your local blockchain node​yarn chainDeploy your smart contract to your local blockchain node​yarn deployThis command deploys YourContract.sol to your local blockchain node. The contract is located in packages/foundry/contracts and can be modified to suit your needs.The yarn deploy command uses the deploy script located in packages/foundry/deploy to deploy the contract to the network. You can also customize the deploy script.Start your NextJS app​yarn startVisit your app on: http://localhost:3000.You can interact with your smart contract using the Debug Contracts page. You can tweak the app config in packages/nextjs/scaffold.config.ts.Deploy your smart contract to Monad Testnet​yarn deploy --network monadTestnetThis command deploys YourContract.sol to Monad Testnet. The contract is located in packages/foundry/contracts and can be modified to suit your needs.Verify your smart contract on Monad Testnet​yarn verify --network monadTestnetThis command verifies YourContract.sol on Monad Testnet.Clone the scaffold-monad-hardhat repo​git clone https://github.com/monad-developers/scaffold-monad-hardhat.gitOpen the project directory and install dependencies​cd scaffold-monad-hardhat && yarn installStart your local blockchain node​yarn chainDeploy your smart contract to your local blockchain node​yarn deployThis command deploys YourContract.sol to your local blockchain node. The contract is located in packages/hardhat/contracts and can be modified to suit your needs.The yarn deploy command uses the deploy script located in packages/hardhat/deploy to deploy the contract to the network. You can also customize the deploy script.Start your NextJS app​yarn startVisit your app on: http://localhost:3000.You can interact with your smart contract using the Debug Contracts page. You can tweak the app config in packages/nextjs/scaffold.config.ts.Generate a deployer account​yarn generateThis command will create a new deployer account. Remember the password you create as you'll need it for deployments.Deploy your smart contract to Monad Testnet​yarn deploy --network monadTestnetThis command deploys YourContract.sol to Monad Testnet. The contract is located in packages/hardhat/contracts and can be modified to suit your needs.Verify your smart contract on Monad Testnet​yarn verify --network monadTestnetThis command verifies YourContract.sol on Monad Testnet.
Next steps​

Explore the Debug Contracts page to interact with your deployed contract.
Modify YourContract.sol to build your own functionality.
Learn more about Scaffold-ETH.

### Code Examples

```prism
git clone https://github.com/monad-developers/scaffold-monad-foundry.git
```

```prism
cd scaffold-monad-foundry && yarn install
```

```prism
yarn chain
```

```prism
yarn deploy
```

```prism
yarn start
```

```prism
yarn deploy --network monadTestnet
```

```prism
yarn verify --network monadTestnet
```

```prism
git clone https://github.com/monad-developers/scaffold-monad-hardhat.git
```

```prism
cd scaffold-monad-hardhat && yarn install
```

```prism
yarn chain
```

```prism
yarn deploy
```

```prism
yarn start
```

```prism
yarn generate
```

```prism
yarn deploy --network monadTestnet
```

```prism
yarn verify --network monadTestnet
```

---

## How to build a donation blink

> Source: https://docs.monad.xyz/guides/blinks-guide

On this page

In this guide, you will learn how to build a Blink that allows people to donate MON with a single click.
Prerequisites​

Code Editor of your choice (Cursor or Visual Studio Code recommended).
Node 18.x.x or above.
Basic TypeScript knowledge.
Testnet MON (Faucet).

Initial setup​
Initialize the project​
npx create-next-app@14 blink-starter-monad && cd blink-starter-monad
When prompted, configure your project with these settings:

✓ Ok to proceed? → Yes
✓ Would you like to use TypeScript? → Yes
✓ Would you like to use ESLint? → Yes
✓ Would you like to use Tailwind CSS? → Yes
✓ Would you like your code inside a src/ directory? → Yes
✓ Would you like to use App Router? → Yes
✓ Would you like to customize the import alias (@/* by default)? → No

Install dependencies​
npm install @solana/actions wagmi viem@2.x
Start development server​
The development server is used to start a local test environment that runs on your computer. It is perfect to test and develop your blink, before you ship it to production.
npm run dev
Building the Blink​
Now that we have our basic setup finished, it is time to start building the blink.
Create an endpoint​
To write a blink provider, you have to create an endpoint. Thanks to NextJS, this all works pretty straightforward. All you have to do is to create the following folder structure:
src/└── app/    └── api/            └── actions/                └── donate-mon/                    └── route.ts
Create actions.json​
Create a route in app folder for the actions.json file which will be hosted in the root directory of our application. This file is needed to tell other applications which blink providers are available on your website. Think of it as a sitemap for blinks.
You can read more about the actions.json in the official Dialect documentation.
src/└── app/    └── actions.json/        └── route.ts
route.tssrc > app > actions.json1234567891011121314151617181920212223242526import { ACTIONS_CORS_HEADERS, ActionsJson } from "@solana/actions";
export const GET = async () => {  const payload: ActionsJson = {    rules: [      // map all root level routes to an action      {        pathPattern: "/*",        apiPath: "/api/actions/*",      },      // idempotent rule as the fallback      {        pathPattern: "/api/actions/**",        apiPath: "/api/actions/**",      },    ],  };
  return Response.json(payload, {    headers: ACTIONS_CORS_HEADERS,  });};
// DO NOT FORGET TO INCLUDE THE `OPTIONS` HTTP METHOD// THIS WILL ENSURE CORS WORKS FOR BLINKSexport const OPTIONS = GET;
Add an image for the blink​
Every blink has an image that is rendered on top. If you have your image already hosted somewhere, you can skip this step but if you haven't you can just create a public folder in your NextJS project and paste an image there.
In our example we will paste a file called donate-mon.png into this public folder. You can right-click and save the image below.


OPTIONS endpoint and headers​
This enables CORS for cross-origin requests and standard headers for the API endpoints. This is standard configuration you do for every Blink.
route.tssrc > app > api > actions > donate-mon12345678910111213141516171819// CAIP-2 format for Monadconst blockchain = `eip155:10143`;
// Create headers with CAIP blockchain IDconst headers = {  "Access-Control-Allow-Origin": "*",  "Access-Control-Allow-Methods": "GET, POST, OPTIONS",  "Access-Control-Allow-Headers":  "Content-Type, x-blockchain-ids, x-action-version",  "Content-Type": "application/json",  "x-blockchain-ids": blockchain,  "x-action-version": "2.0",};
// OPTIONS endpoint is required for CORS preflight requests// Your Blink won't render if you don't add thisexport const OPTIONS = async () => {  return new Response(null, { headers });};
GET endpoint​
GET returns the Blink metadata and UI configuration.
It describes:

How the Action appears in Blink clients
What parameters users need to provide
How the Action should be executed

route.tssrc > app > api > actions > donate-mon123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import {  ActionGetResponse,} from "@solana/actions";
// GET endpoint returns the Blink metadata (JSON) and UI configurationexport const GET = async (req: Request) => {  // This JSON is used to render the Blink UI  const response: ActionGetResponse = {    type: "action",    icon: `${new URL("/donate-mon.png", req.url).toString()}`,    label: "1 MON",    title: "Donate MON",    description:      "This Blink demonstrates how to donate MON on the Monad blockchain. It is a part of the official Blink Starter Guides by Dialect Labs.  \n\nLearn how to build this Blink: https://dialect.to/docs/guides/donate-mon",    // Links is used if you have multiple actions or if you need more than one params    links: {      actions: [        {          // Defines this as a blockchain transaction          type: "transaction",          label: "0.01 MON",          // This is the endpoint for the POST request          href: `/api/actions/donate-mon?amount=0.01`,        },        {          type: "transaction",          label: "0.05 MON",          href: `/api/actions/donate-mon?amount=0.05`,        },        {          type: "transaction",          label: "0.1 MON",          href: `/api/actions/donate-mon?amount=0.1`,        },        {          // Example for a custom input field          type: "transaction",          href: `/api/actions/donate-mon?amount={amount}`,          label: "Donate",          parameters: [            {              name: "amount",              label: "Enter a custom MON amount",              type: "number",            },          ],        },      ],    },  };
  // Return the response with proper headers  return new Response(JSON.stringify(response), {    status: 200,    headers,  });};
Testing the Blink​
Visit dial.to and type in the link to your blink to see if it works. If your server runs on localhost:3000 the url should be like this: http://localhost:3000/api/actions/donate-mon
infodial.to currently supports only GET previews for EVM. To test your POST endpoint, we need to build a Blink Client.

POST endpoint​
POST handles the actual MON transfer transaction.
POST request to the endpoint​
Create the post request structure and add the necessary imports as well as the donationWallet on top of the file.
route.tssrc > app > api > actions > donate-mon123456789101112131415161718192021222324// Update the importsimport { ActionGetResponse, ActionPostResponse } from "@solana/actions";import { serialize } from "wagmi";import { parseEther } from "viem";
// Wallet address that will receive the donationsconst donationWallet = `<RECEIVER_ADDRESS>`;

// POST endpoint handles the actual transaction creationexport const POST = async (req: Request) => {  try {    // Code that goes here is in the next step    } catch (error) {    // Log and return an error response    console.error("Error processing request:", error);    return new Response(JSON.stringify({ error: "Internal server error" }), {      status: 500,      headers,    });  }};
Extract data from request​
The request contains the URL and the account (PublicKey) from the payer.
route.tssrc > app > api > actions > donate-mon12345678910111213141516// POST endpoint handles the actual transaction creationexport const POST = async (req: Request) => {  try {    // Step 1    // Extract amount from URL    const url = new URL(req.url);    const amount = url.searchParams.get("amount");
    if (!amount) {        throw new Error("Amount is required");    }
  } catch (error) {    // Error handling  }}
Create the transaction​
Create a new transaction with all the necessary data and add it below in the POST request.
route.tssrc > app > api > actions > donate-mon12345678910111213141516171819// POST endpoint handles the actual transaction creationexport const POST = async (req: Request) => {  try {
    // ... previous code from step        // Build the transaction    const transaction = {        to: donationWallet,        value: parseEther(amount).toString(),        chainId: 10143,    };
    const transactionJson = serialize(transaction);    } catch (error) {    // Error handling  }}
Return the transaction in response.​
Create ActionPostResponse and return it to the client.
route.tssrc > app > api > actions > donate-mon123456789101112131415161718192021export const POST = async (req: Request) => {  try {    // ... previous code from step 1 and 2        // Build ActionPostResponse    const response: ActionPostResponse = {        type: "transaction",        transaction: transactionJson,        message: "Donate MON",    };
    // Return the response with proper headers    return new Response(JSON.stringify(response), {        status: 200,        headers,    });
  } catch (error) {    // Error handling  }}
Full code in route.ts​
route.tssrc > app > api > actions > donate-mon123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122import { ActionGetResponse, ActionPostResponse } from "@solana/actions";import { serialize } from "wagmi";import { parseEther } from "viem";
// CAIP-2 format for Monadconst blockchain = `eip155:10143`;
// Wallet address that will receive the donationsconst donationWallet = `<RECEIVER_ADDRESS>`;
// Create headers with CAIP blockchain IDconst headers = {  "Access-Control-Allow-Origin": "*",  "Access-Control-Allow-Methods": "GET, POST, OPTIONS",  "Access-Control-Allow-Headers":  "Content-Type, x-blockchain-ids, x-action-version",  "Content-Type": "application/json",  "x-blockchain-ids": blockchain,  "x-action-version": "2.0",};
// OPTIONS endpoint is required for CORS preflight requests// Your Blink won't render if you don't add thisexport const OPTIONS = async () => {  return new Response(null, { headers });};
// GET endpoint returns the Blink metadata (JSON) and UI configurationexport const GET = async (req: Request) => {  // This JSON is used to render the Blink UI  const response: ActionGetResponse = {    type: "action",    icon: `${new URL("/donate-mon.png", req.url).toString()}`,    label: "1 MON",    title: "Donate MON",    description:      "This Blink demonstrates how to donate MON on the Monad blockchain. It is a part of the official Blink Starter Guides by Dialect Labs.  \n\nLearn how to build this Blink: https://dialect.to/docs/guides/donate-mon",    // Links is used if you have multiple actions or if you need more than one params    links: {      actions: [        {          // Defines this as a blockchain transaction          type: "transaction",          label: "0.01 MON",          // This is the endpoint for the POST request          href: `/api/actions/donate-mon?amount=0.01`,        },        {          type: "transaction",          label: "0.05 MON",          href: `/api/actions/donate-mon?amount=0.05`,        },        {          type: "transaction",          label: "0.1 MON",          href: `/api/actions/donate-mon?amount=0.1`,        },        {          // Example for a custom input field          type: "transaction",          href: `/api/actions/donate-mon?amount={amount}`,          label: "Donate",          parameters: [            {              name: "amount",              label: "Enter a custom MON amount",              type: "number",            },          ],        },      ],    },  };
  // Return the response with proper headers  return new Response(JSON.stringify(response), {    status: 200,    headers,  });};
// POST endpoint handles the actual transaction creationexport const POST = async (req: Request) => {    try {      // Extract amount from URL      const url = new URL(req.url);      const amount = url.searchParams.get("amount");
      if (!amount) {          throw new Error("Amount is required");      }
      // Build the transaction      const transaction = {          to: donationWallet,          value: parseEther(amount).toString(),          chainId: 10143,      };
      const transactionJson = serialize(transaction);
      // Build ActionPostResponse      const response: ActionPostResponse = {          type: "transaction",          transaction: transactionJson,          message: "Donate MON",      };
      // Return the response with proper headers      return new Response(JSON.stringify(response), {          status: 200,          headers,      });    } catch (error) {      // Log and return an error response      console.error("Error processing request:", error);      return new Response(JSON.stringify({ error: "Internal server error" }), {        status: 500,        headers,      });  }};
At this point the Blink is ready, but we need a Blink client since dial.to does not support EVM wallets.
Implementing the Blink client​
In this step you will learn to implement the blink client, which is the visual representation of a blink.
Install dependencies​
npm install connectkit @tanstack/react-query @dialectlabs/blinks
Implement the provider​
The provider is necessary to trigger wallet actions in the blink.
Create config for WagmiProvider​
This file is used to set the proper configurations for the WagmiProvider in the next step.
config.tssrc123456789import { http, createConfig } from "wagmi";import { monadTestnet } from "wagmi/chains";
export const config = createConfig({  chains: [monadTestnet],  transports: {    [monadTestnet.id]: http(),  },});
Create the wallet connection context providers​
Create the provider that we can use to wrap around our app. Don't forget to use the “use client”; at the top of the file if you are in a NextJS project.
infoIn this project, we are using ConnectKit but you can use other alternatives as well (Eg: RainbowKit)
provider.tsxsrc12345678910111213141516171819"use client";
import { QueryClient, QueryClientProvider } from "@tanstack/react-query";import { ConnectKitProvider } from "connectkit";import { type PropsWithChildren } from "react";import { WagmiProvider } from "wagmi";import { config } from "@/config";
const queryClient = new QueryClient();
export const Providers = ({ children }: PropsWithChildren) => {  return (    <WagmiProvider config={config}>      <QueryClientProvider client={queryClient}>        <ConnectKitProvider>{children}</ConnectKitProvider>      </QueryClientProvider>    </WagmiProvider>  );};
Wrap the app with context provider​
If you want your provider to be accessible throughout your app, it is recommended to wrap it around the children element in your layout.tsx.
layout.tsxsrc > app1234567891011121314151617181920// additional importimport { Providers } from "@/provider";
// other code in the file ...
export default function RootLayout({  children,}: Readonly<{  children: React.ReactNode;}>) {  return (    <html lang="en">      <body      className={`${geistSans.variable} ${geistMono.variable} antialiased`}      >          <Providers>{children}</Providers>      </body>    </html>  );}
Using the Blink component​
Now that we have everything wrapped, we can start with the implementation of the blink renderer.
To do so open the page.tsx file in your /src/app folder.
page.tsxsrc > app1234567891011121314151617181920212223242526272829303132333435363738394041424344454647"use client";
import {  Blink,  useBlink,  useActionsRegistryInterval,} from "@dialectlabs/blinks";
import "@dialectlabs/blinks/index.css";
import { useEvmWagmiAdapter } from "@dialectlabs/blinks/hooks/evm";
import { ConnectKitButton, useModal } from "connectkit";
export default function Home() {  // Actions registry interval  useActionsRegistryInterval();
  // ConnectKit modal  const { setOpen } = useModal();
  // Wagmi adapter, used to connect to the wallet  const { adapter } = useEvmWagmiAdapter({    onConnectWalletRequest: async () => {      setOpen(true);    },  });
  // Action we want to execute in the Blink  const { blink, isLoading } = useBlink({    url: "evm-action:http://localhost:3000/api/actions/donate-mon",  });
  return (    <main className="flex flex-col items-center justify-center">      <ConnectKitButton />      <div className="w-1/2 lg:px-4 lg:p-8">        {isLoading || !blink ? (          <span>Loading</span>        ) : (          // Blink component, used to execute the action          <Blink blink={blink} adapter={adapter} securityLevel="all" />        )}      </div>    </main>  );}
Make a transaction​
That's it. To test it, visit localhost:3000 and click on a button or enter a custom amount that you want to donate.

Conclusion​
In this tutorial, you learned how you can create a blink that sends MON to another wallet from scratch using a NextJS project. Besides the basic project setup there were two important things that we built.
The first thing was the blink provider. This provider works as an API for the blink and handles how the blink is rendered in the fronend (GET request) and executes the blockchain transaction (POST request).
The second implementation was the blink client. This client serves as the visual representation of the blink and is what the user sees and uses to interact with the blink provider.
These are two separate parts, which means you can build a blink without worrying about the client implementation and you can implement clients for existing blinks without the need to build your own blink.

### Code Examples

```prism
npx create-next-app@14 blink-starter-monad && cd blink-starter-monad
```

```prism
npm install @solana/actions wagmi viem@2.x
```

```prism
npm run dev
```

```prism
src/└── app/    └── api/            └── actions/                └── donate-mon/                    └── route.ts
```

```prism
src/└── app/    └── actions.json/        └── route.ts
```

```prism
import { ACTIONS_CORS_HEADERS, ActionsJson } from "@solana/actions";
export const GET = async () => {  const payload: ActionsJson = {    rules: [      // map all root level routes to an action      {        pathPattern: "/*",        apiPath: "/api/actions/*",      },      // idempotent rule as the fallback      {        pathPattern: "/api/actions/**",        apiPath: "/api/actions/**",      },    ],  };
  return Response.json(payload, {    headers: ACTIONS_CORS_HEADERS,  });};
// DO NOT FORGET TO INCLUDE THE `OPTIONS` HTTP METHOD// THIS WILL ENSURE CORS WORKS FOR BLINKSexport const OPTIONS = GET;
```

```prism
// CAIP-2 format for Monadconst blockchain = `eip155:10143`;
// Create headers with CAIP blockchain IDconst headers = {  "Access-Control-Allow-Origin": "*",  "Access-Control-Allow-Methods": "GET, POST, OPTIONS",  "Access-Control-Allow-Headers":  "Content-Type, x-blockchain-ids, x-action-version",  "Content-Type": "application/json",  "x-blockchain-ids": blockchain,  "x-action-version": "2.0",};
// OPTIONS endpoint is required for CORS preflight requests// Your Blink won't render if you don't add thisexport const OPTIONS = async () => {  return new Response(null, { headers });};
```

```prism
import {  ActionGetResponse,} from "@solana/actions";
// GET endpoint returns the Blink metadata (JSON) and UI configurationexport const GET = async (req: Request) => {  // This JSON is used to render the Blink UI  const response: ActionGetResponse = {    type: "action",    icon: `${new URL("/donate-mon.png", req.url).toString()}`,    label: "1 MON",    title: "Donate MON",    description:      "This Blink demonstrates how to donate MON on the Monad blockchain. It is a part of the official Blink Starter Guides by Dialect Labs.  \n\nLearn how to build this Blink: https://dialect.to/docs/guides/donate-mon",    // Links is used if you have multiple actions or if you need more than one params    links: {      actions: [        {          // Defines this as a blockchain transaction          type: "transaction",          label: "0.01 MON",          // This is the endpoint for the POST request          href: `/api/actions/donate-mon?amount=0.01`,        },        {          type: "transaction",          label: "0.05 MON",          href: `/api/actions/donate-mon?amount=0.05`,        },        {          type: "transaction",          label: "0.1 MON",          href: `/api/actions/donate-mon?amount=0.1`,        },        {          // Example for a custom input field          type: "transaction",          href: `/api/actions/donate-mon?amount={amount}`,          label: "Donate",          parameters: [            {              name: "amount",              label: "Enter a custom MON amount",              type: "number",            },          ],        },      ],    },  };
  // Return the response with proper headers  return new Response(JSON.stringify(response), {    status: 200,    headers,  });};
```

```prism
// Update the importsimport { ActionGetResponse, ActionPostResponse } from "@solana/actions";import { serialize } from "wagmi";import { parseEther } from "viem";
// Wallet address that will receive the donationsconst donationWallet = `<RECEIVER_ADDRESS>`;

// POST endpoint handles the actual transaction creationexport const POST = async (req: Request) => {  try {    // Code that goes here is in the next step    } catch (error) {    // Log and return an error response    console.error("Error processing request:", error);    return new Response(JSON.stringify({ error: "Internal server error" }), {      status: 500,      headers,    });  }};
```

```prism
// POST endpoint handles the actual transaction creationexport const POST = async (req: Request) => {  try {    // Step 1    // Extract amount from URL    const url = new URL(req.url);    const amount = url.searchParams.get("amount");
    if (!amount) {        throw new Error("Amount is required");    }
  } catch (error) {    // Error handling  }}
```

```prism
// POST endpoint handles the actual transaction creationexport const POST = async (req: Request) => {  try {
    // ... previous code from step        // Build the transaction    const transaction = {        to: donationWallet,        value: parseEther(amount).toString(),        chainId: 10143,    };
    const transactionJson = serialize(transaction);    } catch (error) {    // Error handling  }}
```

```prism
export const POST = async (req: Request) => {  try {    // ... previous code from step 1 and 2        // Build ActionPostResponse    const response: ActionPostResponse = {        type: "transaction",        transaction: transactionJson,        message: "Donate MON",    };
    // Return the response with proper headers    return new Response(JSON.stringify(response), {        status: 200,        headers,    });
  } catch (error) {    // Error handling  }}
```

```prism
import { ActionGetResponse, ActionPostResponse } from "@solana/actions";import { serialize } from "wagmi";import { parseEther } from "viem";
// CAIP-2 format for Monadconst blockchain = `eip155:10143`;
// Wallet address that will receive the donationsconst donationWallet = `<RECEIVER_ADDRESS>`;
// Create headers with CAIP blockchain IDconst headers = {  "Access-Control-Allow-Origin": "*",  "Access-Control-Allow-Methods": "GET, POST, OPTIONS",  "Access-Control-Allow-Headers":  "Content-Type, x-blockchain-ids, x-action-version",  "Content-Type": "application/json",  "x-blockchain-ids": blockchain,  "x-action-version": "2.0",};
// OPTIONS endpoint is required for CORS preflight requests// Your Blink won't render if you don't add thisexport const OPTIONS = async () => {  return new Response(null, { headers });};
// GET endpoint returns the Blink metadata (JSON) and UI configurationexport const GET = async (req: Request) => {  // This JSON is used to render the Blink UI  const response: ActionGetResponse = {    type: "action",    icon: `${new URL("/donate-mon.png", req.url).toString()}`,    label: "1 MON",    title: "Donate MON",    description:      "This Blink demonstrates how to donate MON on the Monad blockchain. It is a part of the official Blink Starter Guides by Dialect Labs.  \n\nLearn how to build this Blink: https://dialect.to/docs/guides/donate-mon",    // Links is used if you have multiple actions or if you need more than one params    links: {      actions: [        {          // Defines this as a blockchain transaction          type: "transaction",          label: "0.01 MON",          // This is the endpoint for the POST request          href: `/api/actions/donate-mon?amount=0.01`,        },        {          type: "transaction",          label: "0.05 MON",          href: `/api/actions/donate-mon?amount=0.05`,        },        {          type: "transaction",          label: "0.1 MON",          href: `/api/actions/donate-mon?amount=0.1`,        },        {          // Example for a custom input field          type: "transaction",          href: `/api/actions/donate-mon?amount={amount}`,          label: "Donate",          parameters: [            {              name: "amount",              label: "Enter a custom MON amount",              type: "number",            },          ],        },      ],    },  };
  // Return the response with proper headers  return new Response(JSON.stringify(response), {    status: 200,    headers,  });};
// POST endpoint handles the actual transaction creationexport const POST = async (req: Request) => {    try {      // Extract amount from URL      const url = new URL(req.url);      const amount = url.searchParams.get("amount");
      if (!amount) {          throw new Error("Amount is required");      }
      // Build the transaction      const transaction = {          to: donationWallet,          value: parseEther(amount).toString(),          chainId: 10143,      };
      const transactionJson = serialize(transaction);
      // Build ActionPostResponse      const response: ActionPostResponse = {          type: "transaction",          transaction: transactionJson,          message: "Donate MON",      };
      // Return the response with proper headers      return new Response(JSON.stringify(response), {          status: 200,          headers,      });    } catch (error) {      // Log and return an error response      console.error("Error processing request:", error);      return new Response(JSON.stringify({ error: "Internal server error" }), {        status: 500,        headers,      });  }};
```

```prism
npm install connectkit @tanstack/react-query @dialectlabs/blinks
```

```prism
import { http, createConfig } from "wagmi";import { monadTestnet } from "wagmi/chains";
export const config = createConfig({  chains: [monadTestnet],  transports: {    [monadTestnet.id]: http(),  },});
```

```prism
"use client";
import { QueryClient, QueryClientProvider } from "@tanstack/react-query";import { ConnectKitProvider } from "connectkit";import { type PropsWithChildren } from "react";import { WagmiProvider } from "wagmi";import { config } from "@/config";
const queryClient = new QueryClient();
export const Providers = ({ children }: PropsWithChildren) => {  return (    <WagmiProvider config={config}>      <QueryClientProvider client={queryClient}>        <ConnectKitProvider>{children}</ConnectKitProvider>      </QueryClientProvider>    </WagmiProvider>  );};
```

```prism
// additional importimport { Providers } from "@/provider";
// other code in the file ...
export default function RootLayout({  children,}: Readonly<{  children: React.ReactNode;}>) {  return (    <html lang="en">      <body      className={`${geistSans.variable} ${geistMono.variable} antialiased`}      >          <Providers>{children}</Providers>      </body>    </html>  );}
```

```prism
"use client";
import {  Blink,  useBlink,  useActionsRegistryInterval,} from "@dialectlabs/blinks";
import "@dialectlabs/blinks/index.css";
import { useEvmWagmiAdapter } from "@dialectlabs/blinks/hooks/evm";
import { ConnectKitButton, useModal } from "connectkit";
export default function Home() {  // Actions registry interval  useActionsRegistryInterval();
  // ConnectKit modal  const { setOpen } = useModal();
  // Wagmi adapter, used to connect to the wallet  const { adapter } = useEvmWagmiAdapter({    onConnectWalletRequest: async () => {      setOpen(true);    },  });
  // Action we want to execute in the Blink  const { blink, isLoading } = useBlink({    url: "evm-action:http://localhost:3000/api/actions/donate-mon",  });
  return (    <main className="flex flex-col items-center justify-center">      <ConnectKitButton />      <div className="w-1/2 lg:px-4 lg:p-8">        {isLoading || !blink ? (          <span>Loading</span>        ) : (          // Blink component, used to execute the action          <Blink blink={blink} adapter={adapter} securityLevel="all" />        )}      </div>    </main>  );}
```

---

## How to build a transfer notification bot with Envio HyperIndex

> Source: https://docs.monad.xyz/guides/indexers/tg-bot-using-envio

On this page

In this guide, you will learn how to use Envio HyperIndex to create a Telegram bot that sends notifications whenever WMON tokens are transferred on the Monad Testnet. We'll walk through setting up both the indexer and the Telegram bot.
Envio HyperIndex is an open development framework for building blockchain application backends. It offers real-time indexing, automatic indexer generation from contract addresses, and triggers for external API calls.
Prerequisites​
You'll need the following installed:

Node.js v18 or newer
pnpm v8 or newer
Docker Desktop (required for running the Envio indexer locally)

Setting up the project​
First, create and enter a new directory:
mkdir envio-mon && cd envio-mon
Get the contract ABI​

Create an abi.json file:

touch abi.json

Copy the WrappedMonad ABI from the explorer



Paste the ABI into your abi.json file

Initialize the project​
Run the initialization command:
pnpx envio init
Follow the prompts:

Press Enter when asked for a folder name (to use current directory)
Select TypeScript as your language
Choose Evm as the blockchain ecosystem
Select Contract Import for initialization
Choose Local ABI as the import method
Enter ./abi.json as the path to your ABI file
Select only the Transfer event to index
Choose <Enter Network Id> and input 10143 (Monad Testnet chain ID)
Enter WrappedMonad as the contract name
Input the contract address: 0x760AfE86e5de5fa0Ee542fc7B7B713e1c5425701
Select I'm finished since we're only indexing one contract
Choose whether to create or add an existing API token. If you choose to create a new token, you'll be taken to a page that looks like this:


Once the project is initialized, you should see the following project structure in your project directory.

Add the following code to config.yaml file, to make transaction hash available in event handler:
config.yaml1234# default config...field_selection:    transaction_fields:      - hash
More details about the field_selection config here
Starting the indexer​
Start Docker Desktop.
To start the indexer run the following command in the project directory:
pnpx envio dev
You should see something similar to the below image in your terminal; this means that the indexer is syncing and will eventually reach the tip of the chain.

You will also see this page open in your browser automatically, the password is testing.

We can use this interface to query the indexer using GraphQL. Results will depend on the sync progress:

Currently, the indexer is catching up to the tip of the chain. Once syncing is complete the indexer will be able to identify latest WMON transfers.
We can shut down the indexer for now, so we can proceed with Telegram integration.
Creating the Telegram bot​

Visit BotFather to create your bot and get an API token
Add these environment variables to your .env file:

ENVIO_BOT_TOKEN=<your_bot_token>ENVIO_TELEGRAM_CHAT_ID=<your_chat_id>
To get your chat ID:

Create a Telegram group and add your bot
Send /start to the bot: @YourBot /start
Visit https://api.telegram.org/bot<YourBOTToken>/getUpdates
Look for the channel chat ID (it should start with "-")

noteIf you don't see the chat ID, try removing and re-adding the bot to the group.
The Telegram bot is now ready.
Integrating Telegram API to HyperIndex Event Handler​
Create a folder libs inside src folder in the project directory, create a file inside it telegram.ts and add the following code
telegram.tssrc > libs12345678910111213141516import axios from "axios";import { CHAT_ID, BOT_TOKEN } from "../constants";
export const sendMessageToTelegram = async (message: string): Promise<void> => {  try {    const apiUrl = `https://api.telegram.org/bot${BOT_TOKEN}/sendMessage`;
    await axios.post(apiUrl, {      chat_id: CHAT_ID,      text: message,      parse_mode: "HTML",    });  } catch (error) {    console.error("Error sending message:", error);  }};
You will come across some errors, let's fix them.
Install axios package
pnpm i axios
Create a file in src folder called constants.ts and add the following code:
constants.tssrc123456789101112131415export const EXPLORER_URL_MONAD = "https://testnet.monadvision.com/";
// Threshold for WMON transfer amount above which the bot sends a notificationexport const THRESHOLD_WEI: string = process.env.ENVIO_THRESHOLD_WEI ?? "1000000000000000000"; // in wei
export const BOT_TOKEN = process.env.ENVIO_BOT_TOKEN; // Telegram bot tokenexport const CHAT_ID = process.env.ENVIO_TELEGRAM_CHAT_ID; // WMON Transfers Notification Channel ID
// Function to get explorer url for the provided addressexport const explorerUrlAddress = (address: string) =>  EXPLORER_URL_MONAD + "address/" + address;
// Function to get explorer url for the provided transaction hashexport const explorerUrlTx = (txHash: string) =>  EXPLORER_URL_MONAD + "tx/" + txHash;
We can now edit the EventHandlers.ts in src folder, to add the code for sending the telegram message:
EventHandlers.tssrc1234567891011121314151617181920212223242526import {  WrappedMonad,} from "generated";import { isIndexingAtHead, weiToEth } from "./libs/helpers";import { sendMessageToTelegram } from "./libs/telegram";import { THRESHOLD_WEI, explorerUrlAddress, explorerUrlTx } from "./constants";
// Other event handlers can be removed...
WrappedMonad.Transfer.handler(async ({ event, context }) => {    const from_address = event.params.src;    const to_address = event.params.dst;
  if (isIndexingAtHead(event.block.timestamp) && event.params.wad >= BigInt(THRESHOLD_WEI)) {    // Only send a message when the indexer is indexing event from the time it was started and not historical transfers, and only message if the transfer amount is greater than or equal to THRESHOLD_WEI.
    // Example message    // WMON Transfer ALERT: A new transfer has been made by 0x65C3564f1DD63eA81C11D8FE9a93F8FFb5615233 to 0xBA5Cf1c0c1238F60832618Ec49FC81e8C7C0CF01 for 2.0000 WMON! 🔥 - View on Explorer
    const msg = `WMON Transfer ALERT: A new transfer has been made by <a href="${explorerUrlAddress(from_address)}">${from_address}</a> to <a href="${explorerUrlAddress(to_address)}">${to_address}</a> for ${weiToEth(event.params.wad)} WMON! 🔥 - <a href="${explorerUrlTx(      event.transaction.hash    )}">View on Explorer</a>`;
    await sendMessageToTelegram(msg);  }});
Let us now fix the import error.
Create a file called helpers.ts in src/libs folder, paste the following code in it:
helpers.tssrc > libs12345678910111213141516171819202122232425262728293031// Used to ensure notifications are only sent while indexing at the head and not historical syncconst INDEXER_START_TIMESTAMP = Math.floor(new Date().getTime() / 1000);
export const isIndexingAtHead = (timestamp: number): boolean => {    return timestamp >= INDEXER_START_TIMESTAMP;}
// Convert wei to ether for human readabilityexport const weiToEth = (bigIntNumber: bigint): string => {  // Convert BigInt to string  const numberString = bigIntNumber.toString();
  const decimalPointsInEth = 18;
  // Extract integer part and decimal part  const integerPart = numberString.substring(    0,    numberString.length - decimalPointsInEth  );
  const decimalPart = numberString.slice(-decimalPointsInEth);
  // Insert decimal point  const decimalString =    (integerPart ? integerPart : "0") +    "." +    decimalPart.padStart(decimalPointsInEth, "0");
  // Add negative sign if necessary  return decimalString.slice(0, -14);};
That's it! We can now run the indexer, and the telegram bot will start sending messages in the telegram channel when the indexer detects a WMON transfer!

Note: Screenshot was taken before message format was changed. The message will be slightly different if you followed the guide.
noteYou may not immediately start seeing messages because the indexer take some time to catch up to the tip of the the recent blocks.The bot will only send notifications for transfers when the indexer detects a WMON transfer in finalized blocks, with timestamp greater than or equal to the indexer start time.

### Code Examples

```prism
mkdir envio-mon && cd envio-mon
```

```prism
touch abi.json
```

```prism
pnpx envio init
```

```prism
# default config...field_selection:    transaction_fields:      - hash
```

```prism
pnpx envio dev
```

```prism
ENVIO_BOT_TOKEN=<your_bot_token>ENVIO_TELEGRAM_CHAT_ID=<your_chat_id>
```

```prism
import axios from "axios";import { CHAT_ID, BOT_TOKEN } from "../constants";
export const sendMessageToTelegram = async (message: string): Promise<void> => {  try {    const apiUrl = `https://api.telegram.org/bot${BOT_TOKEN}/sendMessage`;
    await axios.post(apiUrl, {      chat_id: CHAT_ID,      text: message,      parse_mode: "HTML",    });  } catch (error) {    console.error("Error sending message:", error);  }};
```

```prism
pnpm i axios
```

```prism
export const EXPLORER_URL_MONAD = "https://testnet.monadvision.com/";
// Threshold for WMON transfer amount above which the bot sends a notificationexport const THRESHOLD_WEI: string = process.env.ENVIO_THRESHOLD_WEI ?? "1000000000000000000"; // in wei
export const BOT_TOKEN = process.env.ENVIO_BOT_TOKEN; // Telegram bot tokenexport const CHAT_ID = process.env.ENVIO_TELEGRAM_CHAT_ID; // WMON Transfers Notification Channel ID
// Function to get explorer url for the provided addressexport const explorerUrlAddress = (address: string) =>  EXPLORER_URL_MONAD + "address/" + address;
// Function to get explorer url for the provided transaction hashexport const explorerUrlTx = (txHash: string) =>  EXPLORER_URL_MONAD + "tx/" + txHash;
```

```prism
import {  WrappedMonad,} from "generated";import { isIndexingAtHead, weiToEth } from "./libs/helpers";import { sendMessageToTelegram } from "./libs/telegram";import { THRESHOLD_WEI, explorerUrlAddress, explorerUrlTx } from "./constants";
// Other event handlers can be removed...
WrappedMonad.Transfer.handler(async ({ event, context }) => {    const from_address = event.params.src;    const to_address = event.params.dst;
  if (isIndexingAtHead(event.block.timestamp) && event.params.wad >= BigInt(THRESHOLD_WEI)) {    // Only send a message when the indexer is indexing event from the time it was started and not historical transfers, and only message if the transfer amount is greater than or equal to THRESHOLD_WEI.
    // Example message    // WMON Transfer ALERT: A new transfer has been made by 0x65C3564f1DD63eA81C11D8FE9a93F8FFb5615233 to 0xBA5Cf1c0c1238F60832618Ec49FC81e8C7C0CF01 for 2.0000 WMON! 🔥 - View on Explorer
    const msg = `WMON Transfer ALERT: A new transfer has been made by <a href="${explorerUrlAddress(from_address)}">${from_address}</a> to <a href="${explorerUrlAddress(to_address)}">${to_address}</a> for ${weiToEth(event.params.wad)} WMON! 🔥 - <a href="${explorerUrlTx(      event.transaction.hash    )}">View on Explorer</a>`;
    await sendMessageToTelegram(msg);  }});
```

```prism
// Used to ensure notifications are only sent while indexing at the head and not historical syncconst INDEXER_START_TIMESTAMP = Math.floor(new Date().getTime() / 1000);
export const isIndexingAtHead = (timestamp: number): boolean => {    return timestamp >= INDEXER_START_TIMESTAMP;}
// Convert wei to ether for human readabilityexport const weiToEth = (bigIntNumber: bigint): string => {  // Convert BigInt to string  const numberString = bigIntNumber.toString();
  const decimalPointsInEth = 18;
  // Extract integer part and decimal part  const integerPart = numberString.substring(    0,    numberString.length - decimalPointsInEth  );
  const decimalPart = numberString.slice(-decimalPointsInEth);
  // Insert decimal point  const decimalString =    (integerPart ? integerPart : "0") +    "." +    decimalPart.padStart(decimalPointsInEth, "0");
  // Add negative sign if necessary  return decimalString.slice(0, -14);};
```

---

## How to build an MCP server that can interact with Monad Testnet

> Source: https://docs.monad.xyz/guides/monad-mcp

On this page

In this guide, you will learn how to build a Model Context Protocol (MCP) server that allows an MCP Client (Claude Desktop) to query Monad Testnet to check the MON balance of an account.
What is MCP?​
The Model Context Protocol (MCP) is a standard that allows AI models to interact with external tools and services.
Prerequisites​

Node.js (v16 or later)
npm or yarn
Claude Desktop

Getting started​

Clone the monad-mcp-tutorial repository. This repository has some code that can help you get started quickly.

git clone https://github.com/monad-developers/monad-mcp-tutorial.git

Install dependencies:

npm install
Building the MCP server​
Monad Testnet-related configuration is already added to index.ts in the src folder.
Define the server instance​
index.tssrc1234567// Create a new MCP server instanceconst server = new McpServer({  name: "monad-mcp-tutorial",  version: "0.0.1",  // Array of supported tool names that clients can call  capabilities: ["get-mon-balance"]});
Define the MON balance tool​
Below is the scaffold of the get-mon-balance tool:
index.tssrc1234567891011121314server.tool(    // Tool ID     "get-mon-balance",    // Description of what the tool does    "Get MON balance for an address on Monad testnet",    // Input schema    {        address: z.string().describe("Monad testnet address to check balance for"),    },    // Tool implementation    async ({ address }) => {        // code to check MON balance    });
Let's add the MON balance check implementation to the tool:
index.tssrc1234567891011121314151617181920212223242526272829303132333435363738394041server.tool(    // Tool ID     "get-mon-balance",    // Description of what the tool does    "Get MON balance for an address on Monad testnet",    // Input schema    {        address: z.string().describe("Monad testnet address to check balance for"),    },    // Tool implementation    async ({ address }) => {        try {            // Check MON balance for the input address            const balance = await publicClient.getBalance({                address: address as `0x${string}`,            });
            // Return a human friendly message indicating the balance.            return {                content: [                    {                        type: "text",                        text: `Balance for ${address}: ${formatUnits(balance, 18)} MON`,                    },                ],            };        } catch (error) {            // If the balance check process fails, return a graceful message back to the MCP client indicating a failure.            return {                content: [                    {                        type: "text",                        text: `Failed to retrieve balance for address: ${address}. Error: ${                        error instanceof Error ? error.message : String(error)                        }`,                    },                ],            };        }    });
Initialize the transport and server from the main function​
index.tssrc1234567async function main() {    // Create a transport layer using standard input/output    const transport = new StdioServerTransport();        // Connect the server to the transport    await server.connect(transport);}
Build the project​
npm run build
The server is now ready to use!
Add the MCP server to Claude Desktop​

Open "Claude Desktop"



Open Settings

Claude > Settings > Developer


Open claude_desktop_config.json



Add details about the MCP server and save the file.

claude_desktop_config.json1234567891011{  "mcpServers": {    ...    "monad-mcp": {      "command": "node",      "args": [        "/<path-to-project>/build/index.js"      ]    }  }}

Restart "Claude Desktop"

Use the MCP server​
You should now be able to see the tools in Claude!

Here's the final result

Further resources​

Model Context Protocol Documentation
Monad Documentation
Viem Documentation

### Code Examples

```prism
git clone https://github.com/monad-developers/monad-mcp-tutorial.git
```

```prism
npm install
```

```prism
// Create a new MCP server instanceconst server = new McpServer({  name: "monad-mcp-tutorial",  version: "0.0.1",  // Array of supported tool names that clients can call  capabilities: ["get-mon-balance"]});
```

```prism
server.tool(    // Tool ID     "get-mon-balance",    // Description of what the tool does    "Get MON balance for an address on Monad testnet",    // Input schema    {        address: z.string().describe("Monad testnet address to check balance for"),    },    // Tool implementation    async ({ address }) => {        // code to check MON balance    });
```

```prism
server.tool(    // Tool ID     "get-mon-balance",    // Description of what the tool does    "Get MON balance for an address on Monad testnet",    // Input schema    {        address: z.string().describe("Monad testnet address to check balance for"),    },    // Tool implementation    async ({ address }) => {        try {            // Check MON balance for the input address            const balance = await publicClient.getBalance({                address: address as `0x${string}`,            });
            // Return a human friendly message indicating the balance.            return {                content: [                    {                        type: "text",                        text: `Balance for ${address}: ${formatUnits(balance, 18)} MON`,                    },                ],            };        } catch (error) {            // If the balance check process fails, return a graceful message back to the MCP client indicating a failure.            return {                content: [                    {                        type: "text",                        text: `Failed to retrieve balance for address: ${address}. Error: ${                        error instanceof Error ? error.message : String(error)                        }`,                    },                ],            };        }    });
```

```prism
async function main() {    // Create a transport layer using standard input/output    const transport = new StdioServerTransport();        // Connect the server to the transport    await server.connect(transport);}
```

```prism
npm run build
```

```prism
{  "mcpServers": {    ...    "monad-mcp": {      "command": "node",      "args": [        "/<path-to-project>/build/index.js"      ]    }  }}
```

---

## How to build custom deep links in an Expo-based mobile app

> Source: https://docs.monad.xyz/guides/deeplinks-using-expo

On this page

Deep links are URLs that take users directly to specific content within a mobile app or website, rather than just launching the app's home screen. They work like shortcuts, enabling smoother navigation and improving user experience.
In this guide, you will learn the basics of adding deep links into your Expo-based mobile app.
What are deep links?​
Deep link is constructed by three parts:

Scheme: The URL scheme that identifies the app that should open the URL (example: myapp://). It can also be https or http for non-standard deep links.
Host: The domain name of the app that should open the URL (example: web-app.com).
Path: The path to the screen that should be opened (example: /product). If the path isn't specified, the user is taken to the home screen of the app.

Deep links can also have params just like web links!
Example:
rnwalletapp://swap?from={token}&to={token}&amount={amount}
Building a deep link​
noteIf you'd like to try a deep link demo you can do by cloning this repo and switching to the branch/deeplink branch:git clone https://github.com/monad-developers/expo-swap-template.gitgit checkout branch/deeplink
Defining the scheme​
The first step is to define a scheme; you can do so by editing the app.json file in the Expo project.
app.json{  "expo": {    "scheme": "myapp" // or your preferred scheme  }}
warningCustom schemes like myapp:// are not unique across Android or iOS.
If two apps register the same scheme, the system won’t know which one to launch, or it might launch the wrong one.
Use something app-specific and hard to accidentally duplicate.
Listening for deep link events​
In your app entrypoint (e.g., _layout.tsx or a provider), add logic to:

Handle initial deep link
Listen for deep link changes

A good practice is to create a DeepLinkHandler and wrap the entire app with it.
Example (in an Expo project using File-based routing):
_layout.tsxapp12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061...
// Function to parse the deep link and get the hostname and queryParamsfunction parseSwapDeeplink(url: string): SwapDeeplinkParams | null {  try {    const { hostname, queryParams } = Linking.parse(url);        if (hostname !== 'swap' || !queryParams) {      return null;    }
    return {      from: queryParams.from as string | undefined,      to: queryParams.to as string | undefined,      amount: queryParams.amount as string | undefined,    };  } catch (error) {    console.error('Error parsing deeplink:', error);    return null;  }}
function DeeplinkHandler({ children }: { children: React.ReactNode }) {  const router = useRouter();    useEffect(() => {        const handleDeeplink = (url: string) => {      // Parse the deep link and get the params (host, path, params etc...)      const params = parseSwapDeeplink(url);      if (params) {        // The example here makes the params globally accessible in the app, however you can use React Context or similar to make the params accessible from anywhere in the app.        (global as any).swapDeeplinkParams = params;        // Based on the path or host you can redirect the user to the respective screen in the app         router.replace('/');      }    };
    // Handle initial URL    Linking.getInitialURL().then(url => url && handleDeeplink(url));
    // Create an event listener and handle URL changes while app is open    const subscription = Linking.addEventListener('url', event => handleDeeplink(event.url));
    // Removes the event listener when the component is destroyed (avoids memory leaks)    return () => subscription.remove();  }, [router]);
  return <>{children}</>;}

export default function Layout() {    ...
    return (        <DeeplinkHandler>            <App />        </DeeplinkHandler>    ); }
That's it, your app is ready to handle deep links based on the hostname and queryParams you can redirect the user to the respective screens.
Additionally if you make the queryParams accessible globally (via context or some other way) you can prefill input values too!
Example: Prefilling token swap amounts!
Testing the deep link​
Here's a demo of how deep links work in a mobile app:

Testing on iOS simulator​
xcrun simctl openurl booted [deeplink]
Example:
xcrun simctl openurl booted "rnwalletapp://swap?from=MON&to=USDC&amount=100"
Testing on Android emulator​
adb shell am start -W -a android.intent.action.VIEW -d [deeplink]
Example:
# Important: Use single quotes to wrap the entire command to prevent shell from parsing & symbolsadb shell 'am start -W -a android.intent.action.VIEW -d "rnwalletapp://swap?from=MON&to=USDC&amount=100"'
warningIf you don't use single quotes, the shell will interpret & as a command separator, and only the first parameter will be passed to the app.
Testing on a physical device​
You can create a simple HTML page with links.
Example:
<a href="rnwalletapp://swap?from=MON&to=USDC&amount=100">Swap MON to USDC</a>
Try out the demo​
If you'd like to try a deep link demo you can do by setting up this repo and switch to the branch/deeplink branch.
git clone https://github.com/monad-developers/expo-swap-template.git
git checkout branch/deeplink
Here are some deep links you can try:

Swap MON to USDC

rnwalletapp://swap?from=MON&to=USDC

Swap 100 MON to USDC

rnwalletapp://swap?from=MON&to=USDC&amount=100

Swap USDC to WMON

rnwalletapp://swap?from=USDC&to=WMON&amount=1000

### Code Examples

```prism
rnwalletapp://swap?from={token}&to={token}&amount={amount}
```

```prism
git clone https://github.com/monad-developers/expo-swap-template.git
```

```prism
git checkout branch/deeplink
```

```prism
{  "expo": {    "scheme": "myapp" // or your preferred scheme  }}
```

```prism
...
// Function to parse the deep link and get the hostname and queryParamsfunction parseSwapDeeplink(url: string): SwapDeeplinkParams | null {  try {    const { hostname, queryParams } = Linking.parse(url);        if (hostname !== 'swap' || !queryParams) {      return null;    }
    return {      from: queryParams.from as string | undefined,      to: queryParams.to as string | undefined,      amount: queryParams.amount as string | undefined,    };  } catch (error) {    console.error('Error parsing deeplink:', error);    return null;  }}
function DeeplinkHandler({ children }: { children: React.ReactNode }) {  const router = useRouter();    useEffect(() => {        const handleDeeplink = (url: string) => {      // Parse the deep link and get the params (host, path, params etc...)      const params = parseSwapDeeplink(url);      if (params) {        // The example here makes the params globally accessible in the app, however you can use React Context or similar to make the params accessible from anywhere in the app.        (global as any).swapDeeplinkParams = params;        // Based on the path or host you can redirect the user to the respective screen in the app         router.replace('/');      }    };
    // Handle initial URL    Linking.getInitialURL().then(url => url && handleDeeplink(url));
    // Create an event listener and handle URL changes while app is open    const subscription = Linking.addEventListener('url', event => handleDeeplink(event.url));
    // Removes the event listener when the component is destroyed (avoids memory leaks)    return () => subscription.remove();  }, [router]);
  return <>{children}</>;}

export default function Layout() {    ...
    return (        <DeeplinkHandler>            <App />        </DeeplinkHandler>    ); }
```

```prism
xcrun simctl openurl booted [deeplink]
```

```prism
xcrun simctl openurl booted "rnwalletapp://swap?from=MON&to=USDC&amount=100"
```

```prism
adb shell am start -W -a android.intent.action.VIEW -d [deeplink]
```

```prism
# Important: Use single quotes to wrap the entire command to prevent shell from parsing & symbolsadb shell 'am start -W -a android.intent.action.VIEW -d "rnwalletapp://swap?from=MON&to=USDC&amount=100"'
```

```prism
<a href="rnwalletapp://swap?from=MON&to=USDC&amount=100">Swap MON to USDC</a>
```

```prism
git clone https://github.com/monad-developers/expo-swap-template.git
```

```prism
git checkout branch/deeplink
```

```prism
rnwalletapp://swap?from=MON&to=USDC
```

```prism
rnwalletapp://swap?from=MON&to=USDC&amount=100
```

```prism
rnwalletapp://swap?from=USDC&to=WMON&amount=1000
```

---

## How to index every WMON transfer using QuickNode Streams

> Source: https://docs.monad.xyz/guides/indexers/quicknode-streams

On this page

In this guide, you will learn how to use QuickNode Streams to index every WMON transfer, including internal transactions, on Monad Testnet.
What is QuickNode Streams?​
QuickNode Streams is a web3 data streaming solution supporting real-time and historical Monad data that offers:

Reliable Data Delivery - Exactly-once, guaranteed delivery, seamlessly integrating with your data lake. Streams ensures every block, receipt, or trace is delivered exactly-once in the order of dataset finality, preventing issues like corrupt or missing data
Real-Time Data Consistency - Consistent, live data streaming
Efficient Historical Data Handling - Configurable date ranges and destinations for streamlined historical data management
Easy Integration - Simple setup through a user-friendly interface
Transparent User Experience - Clear logging, metrics, and usage tracking

Setup Guide​
1. Initial setup​


Sign up for QuickNode and log into your dashboard.


Click on "Streams" in the left sidebar.




Click on "Create Stream".


2. Configure Stream range​


Give your stream a name. In this example we will name it monad-quicknode-stream.


In the "Network" section, select Monad from the dropdown.


In the "Stream Start" section you can choose to start the stream from the latest block or from a specific block number.





In the "Stream End" section you can choose to end the stream until manually paused or at a specific block number.


In the "Latest block delay" section, you can set a block number as a delay in receiving data. For this guide we will receive data as soon as it is available.For example: If the block delay is 3, you will receive data only when there is new data available for 3 blocks including latest block, this helps in case there is a reorg.


In the "Restream on reorg" section you can decide if you would like to get updated data restreamed in case of a reorg. For this guide we will keep this off.


Once done click "Next".



3. Set up dataset​

In the "Dataset" dropdown you can select the dataset of your choice according to the use case. For this guide we will select Block with Receipts since we want to filter logs with events emitted by WMON contract.


Optional: Enable "Batch messages" to receive multiple blocks in a single message. This can be useful when the stream is not starting from the latest block.



Feel free to test it out by entering a block number and clicking "Fetch payload".


4. Create WMON Transfer filter​

In the "Modify the stream payload" section, you can define filters by clicking "Customize your payload". For this guide, we will filter to only retrieve receipts involving WMON transfers.



QuickNode has a set of filter templates. Select the Decoded ERC20 transfers template:



The editor will appear:


The current filter allows all ERC20 transfers through. Replace the filter code with:
12345678910111213141516171819202122232425262728293031323334function main(stream) {    const erc20Abi = `[{    "anonymous": false,    "inputs": [      {"indexed": true, "type": "address", "name": "from"},      {"indexed": true, "type": "address", "name": "to"},      {"indexed": false, "type": "uint256", "name": "value"}    ],    "name": "Transfer",    "type": "event"  }]`;    const data = stream.data ? stream.data : stream;    // Decodes logs from the receipts that match the Transfer event ABI  var result = decodeEVMReceipts(data[0].receipts, [erc20Abi]);    // Filter for receipts with decoded logs  result = result.filter(receipt => {        // Check if there are any ERC20 transfers        if(receipt.decodedLogs) {            // Check if there are any WMON transfers            receipt.decodedLogs = receipt.decodedLogs.filter(log => log.address == "0x760AfE86e5de5fa0Ee542fc7B7B713e1c5425701");                        // Return receipt if there logs which indicate a WMON transfer.            return receipt.decodedLogs.length > 0;        }
        // Return nothing if there are no ERC20 transfers.        return false;    });    return { result };}

Test the filter with "Run test"



"Save & close" to save the filter.



Click "Next"

5. Set up Stream destination​
For this guide we will keep the stream destination simple and use Webhook as the "Destination Type".

Let's use a site like Svix Play to quickly get a webhook and test the stream.



Copy the webhook url from Svix Play:



In QuickNode:


Select Webhook as destination type
Paste your webhook URL
We can keep the rest of the settings as default



Click on "Check Connection" to test the webhook url. Check if you received the "PING" message in the Svix Play dashboard.




Click "Send Payload" to send a test payload to the webhook.




Finally click "Create a Stream" to create the stream.


6. Launch and Monitor​
You should now be able to see the stream delivering the messages to the webhook!


You can pause the stream by clicking the switch in the top right corner.

Next Steps​

Monitor your stream's performance in the QuickNode dashboard
Adjust filter parameters as needed
Connect to your production webhook endpoint when ready

Your stream will now track all WMON transfers until manually paused or until reaching your specified end block.

### Code Examples

```prism
function main(stream) {    const erc20Abi = `[{    "anonymous": false,    "inputs": [      {"indexed": true, "type": "address", "name": "from"},      {"indexed": true, "type": "address", "name": "to"},      {"indexed": false, "type": "uint256", "name": "value"}    ],    "name": "Transfer",    "type": "event"  }]`;    const data = stream.data ? stream.data : stream;    // Decodes logs from the receipts that match the Transfer event ABI  var result = decodeEVMReceipts(data[0].receipts, [erc20Abi]);    // Filter for receipts with decoded logs  result = result.filter(receipt => {        // Check if there are any ERC20 transfers        if(receipt.decodedLogs) {            // Check if there are any WMON transfers            receipt.decodedLogs = receipt.decodedLogs.filter(log => log.address == "0x760AfE86e5de5fa0Ee542fc7B7B713e1c5425701");                        // Return receipt if there logs which indicate a WMON transfer.            return receipt.decodedLogs.length > 0;        }
        // Return nothing if there are no ERC20 transfers.        return false;    });    return { result };}
```

---

## How to index token transfers with GhostGraph

> Source: https://docs.monad.xyz/guides/indexers/ghost

On this page

Introduction​
In this guide, you will create an ERC20 token on Monad Testnet and index its transfers with GhostGraph. You'll learn how to:

Deploy a basic ERC20 token contract
Test the contract locally
Deploy to Monad Testnet
Set up event tracking with GhostGraph

Prerequisites​
Before starting, ensure you have:

Node.js installed (v16 or later)
Git installed
Foundry installed
Some MONAD testnet tokens (for gas fees)
Basic knowledge of Solidity and ERC20 tokens

Project Setup​
First, clone the starter repository:
git clone https://github.com/chrischang/cat-token-tutorial.gitcd cat-token-tutorial
CatToken Contract Implementation​
The src/CatToken.sol contract implements a basic ERC20 token with a fixed supply. Here's the code:
CatToken.solsrc12345678910111213141516// SPDX-License-Identifier: MITpragma solidity ^0.8.19;
import "@openzeppelin/contracts/token/ERC20/ERC20.sol";
contract CatToken is ERC20 {    /**     * @dev Constructor that gives msg.sender all existing tokens.     * Initial supply is 1 billion tokens.     */    constructor() ERC20("CatToken", "CAT") {        // Mint initial supply of 1 billion tokens to deployer        // This will emit a Transfer event that GhostGraph   can index        _mint(msg.sender, 1_000_000_000 * 10 ** decimals());    }}
This implementation:

Creates a token with name "CatToken" and symbol "CAT"
Mints 1 billion tokens to the deployer's address
Uses OpenZeppelin's battle-tested ERC20 implementation

Testing the Contract​
Navigate to the test file test/CatToken.t.sol:
CatToken.t.soltest123456789101112131415161718192021222324252627282930// SPDX-License-Identifier: MITpragma solidity ^0.8.19;
import "forge-std/Test.sol";import "../src/CatToken.sol";
contract CatTokenTest is Test {    CatToken public token;    address public owner;    address public user;
    function setUp() public {        owner = address(this);        user = address(0x1);
        token = new CatToken();    }
    function testInitialSupply() public view {        assertEq(token.totalSupply(), 1_000_000_000 * 10**18);        assertEq(token.balanceOf(owner), 1_000_000_000 * 10**18);    }
    function testTransfer() public {        uint256 amount = 1_000_000 * 10**18;        token.transfer(user, amount);        assertEq(token.balanceOf(user), amount);        assertEq(token.balanceOf(owner), 999_000_000 * 10**18);    }}
Run the tests:
forge test -vv
Deployment Setup​
1. Create a .env file:​
cp .env.example .env
2. Add your credentials to .env file:​
PRIVATE_KEY=your_private_key_hereMONAD_TESTNET_RPC=https://testnet-rpc.monad.xyz
3. Create deployment script script/DeployCatToken.s.sol:​
DeployCatToken.s.solscript12345678910111213141516171819// SPDX-License-Identifier: MITpragma solidity ^0.8.19;
import "forge-std/Script.sol";import "../src/CatToken.sol";
contract DeployCatToken is Script {    function run() external {        // Retrieve private key from environment        uint256 deployerPrivateKey = vm.envUint("PRIVATE_KEY");
        vm.startBroadcast(deployerPrivateKey);        CatToken token = new CatToken();        vm.stopBroadcast();
        // Log the token address - this will be needed for GhostGraph indexing and submit transactions        console.log("CatToken deployed to:", address(token));    }}
Deploying CatToken on Monad Testnet​
1. Load environment variables:​
source .env
2. Deploy the contract:​
forge script script/DeployCatToken.s.sol \--rpc-url $MONAD_TESTNET_RPC \--broadcast
Save the deployed contract address for the next steps.
Remember to add TOKEN_ADDRESS into your .env file
You should now have
PRIVATE_KEY=your_private_key_hereMONAD_TESTNET_RPC=https://testnet-rpc.monad.xyzTOKEN_ADDRESS=0x...
Verify Smart Contract​
1. Load environment variables:​
source .env
2. Verify the contract:​
forge verify-contract \  --rpc-url $MONAD_TESTNET_RPC \  --verifier sourcify \  --verifier-url 'https://sourcify-api-monad.blockvision.org' \  $TOKEN_ADDRESS \  src/CatToken.sol:CatToken
After verification, you should see the contract verified on the MonadVision. You should see a checkmark and the banner stating the contract source code verified.

Script for Token Transfers Transactions Onchain​
We perform some token transfer transactions onchain to trigger the Transfer event that GhostGraph will index.
View the transfer script script/TransferCatTokens.s.sol:
TransferCatTokens.s.solscript123456789101112131415161718192021// SPDX-License-Identifier: MITpragma solidity ^0.8.19;
import "forge-std/Script.sol";import "../src/CatToken.sol";
contract TransferCatTokens is Script {    function run() external {        uint256 deployerPrivateKey = vm.envUint("PRIVATE_KEY");        address token = vm.envAddress("TOKEN_ADDRESS");
        vm.startBroadcast(deployerPrivateKey);
        // Send tokens to test addresses        CatToken(token).transfer(address(0x1), 1000 * 10**18);        CatToken(token).transfer(address(0x2), 2000 * 10**18);        CatToken(token).transfer(address(0x3), 3000 * 10**18);
        vm.stopBroadcast();    }}
Run the below command to execute transfers:
forge script script/TransferCatTokens.s.sol \--rpc-url $MONAD_TESTNET_RPC \--broadcast
You have now deployed your ERC-20 contract and submitted transactions on the Monad testnet. Let’s track these onchain events with GhostGraph.
Setting Up GhostGraph Indexing​


Visit GhostGraph and click sign up for an account


Create a new GhostGraph




Copy and paste this into events.sol file. We are interested in tracking token flow. Let’s insert this event here. To learn more about events: https://docs.tryghost.xyz/ghostgraph/getting-started/define-events

events.sol123interface Events {    event Transfer(address indexed from, address indexed to, uint256 value);}

Copy and paste this into schema.sol file. In this case, we are creating a few struct which we will use to save entity into the Ghost database. To learn more about schema: https://docs.tryghost.xyz/ghostgraph/getting-started/define-schema

schema.sol1234567891011121314151617181920212223struct Global {    string id;    uint256 totalHolders;}
struct User {    address id;    uint256 balance;}
struct Transfer {    string id;    address from;    address to;    uint256 amount;
    uint64 block;    address emitter;    uint32 logIndex;    bytes32 transactionHash;    uint32 txIndex;    uint32 timestamp;}


Click on generate code button to generate indexer.sol file along with some other readonly files. This file will be where the logic and transformations resides.


Copy and paste this into indexer.sol be sure to insert your token address to the CAT_TESTNET_TOKEN_CONTRACT_ADDRESS variable.


indexer.sol12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364// SPDX-License-Identifier: MITpragma solidity 0.8.19;
import "./gen_schema.sol";import "./gen_events.sol";import "./gen_base.sol";import "./gen_helpers.sol";
contract MyIndex is GhostGraph {    using StringHelpers for EventDetails;    using StringHelpers for uint256;    using StringHelpers for address;
    address constant CAT_TESTNET_TOKEN_CONTRACT_ADDRESS = <INSERT YOUR TOKEN ADDRESS>;
    function registerHandles() external {        graph.registerHandle(CAT_TESTNET_TOKEN_CONTRACT_ADDRESS);    }
    function onTransfer(EventDetails memory details, TransferEvent memory ev) external {        // Get global state to track holder count        Global memory global = graph.getGlobal("1");
        // Handle sender balance        if (ev.from != address(0)) {            // Skip if minting            User memory sender = graph.getUser(ev.from);            if (sender.balance == ev.value) {                // User is transferring their entire balance                global.totalHolders -= 1; // Decrease holder count            }            sender.balance -= ev.value;            graph.saveUser(sender);        }
        // Handle receiver balance        User memory receiver = graph.getUser(ev.to);        if (receiver.balance == 0 && ev.value > 0) {            // New holder            global.totalHolders += 1; // Increase holder count        }        receiver.balance += ev.value;        graph.saveUser(receiver);
        // Save global state        graph.saveGlobal(global);
        // Create and save transfer record        Transfer memory transfer = graph.getTransfer(details.uniqueId());        transfer.from = ev.from;        transfer.to = ev.to;        transfer.amount = ev.value;                // Store transaction metadata        transfer.block = details.block;        transfer.emitter = details.emitter;        transfer.logIndex = details.logIndex;        transfer.transactionHash = details.transactionHash;        transfer.txIndex = details.txIndex;        transfer.timestamp = details.timestamp;                graph.saveTransfer(transfer);    }}

Compile and deploy your GhostGraph. After a few seconds, you should see GhostGraph has successfully indexed your contract.



Clicking on the playground will take you to the GraphQL playground, where you can ensure the data is indexed correctly. Let’s copy and paste this into our playground and click the play button to fetch the data from GhostGraph.

GraphQL Playground1234567891011121314151617181920query FetchRecentTransfers {  transfers(    orderBy: "block",     orderDirection: "desc"    limit: 50  ) {    items {      amount      block      emitter      from      id      logIndex      timestamp      to      transactionHash      txIndex    }  }}

tipTry submitting additional transactions by running the transfer script again. You should see that GhostGraph automatically indexes the new transactions.
Conclusion​
You have now successfully created a GhostGraph to track onchain data for your contract. The next step is to connect it to your frontend.
The Ghost team has created end-to-end tutorials on how to do just that here

### Code Examples

```prism
git clone https://github.com/chrischang/cat-token-tutorial.gitcd cat-token-tutorial
```

```prism
// SPDX-License-Identifier: MITpragma solidity ^0.8.19;
import "@openzeppelin/contracts/token/ERC20/ERC20.sol";
contract CatToken is ERC20 {    /**     * @dev Constructor that gives msg.sender all existing tokens.     * Initial supply is 1 billion tokens.     */    constructor() ERC20("CatToken", "CAT") {        // Mint initial supply of 1 billion tokens to deployer        // This will emit a Transfer event that GhostGraph   can index        _mint(msg.sender, 1_000_000_000 * 10 ** decimals());    }}
```

```prism
// SPDX-License-Identifier: MITpragma solidity ^0.8.19;
import "forge-std/Test.sol";import "../src/CatToken.sol";
contract CatTokenTest is Test {    CatToken public token;    address public owner;    address public user;
    function setUp() public {        owner = address(this);        user = address(0x1);
        token = new CatToken();    }
    function testInitialSupply() public view {        assertEq(token.totalSupply(), 1_000_000_000 * 10**18);        assertEq(token.balanceOf(owner), 1_000_000_000 * 10**18);    }
    function testTransfer() public {        uint256 amount = 1_000_000 * 10**18;        token.transfer(user, amount);        assertEq(token.balanceOf(user), amount);        assertEq(token.balanceOf(owner), 999_000_000 * 10**18);    }}
```

```prism
forge test -vv
```

```prism
cp .env.example .env
```

```prism
PRIVATE_KEY=your_private_key_hereMONAD_TESTNET_RPC=https://testnet-rpc.monad.xyz
```

```prism
// SPDX-License-Identifier: MITpragma solidity ^0.8.19;
import "forge-std/Script.sol";import "../src/CatToken.sol";
contract DeployCatToken is Script {    function run() external {        // Retrieve private key from environment        uint256 deployerPrivateKey = vm.envUint("PRIVATE_KEY");
        vm.startBroadcast(deployerPrivateKey);        CatToken token = new CatToken();        vm.stopBroadcast();
        // Log the token address - this will be needed for GhostGraph indexing and submit transactions        console.log("CatToken deployed to:", address(token));    }}
```

```prism
source .env
```

```prism
forge script script/DeployCatToken.s.sol \--rpc-url $MONAD_TESTNET_RPC \--broadcast
```

```prism
PRIVATE_KEY=your_private_key_hereMONAD_TESTNET_RPC=https://testnet-rpc.monad.xyzTOKEN_ADDRESS=0x...
```

```prism
source .env
```

```prism
forge verify-contract \  --rpc-url $MONAD_TESTNET_RPC \  --verifier sourcify \  --verifier-url 'https://sourcify-api-monad.blockvision.org' \  $TOKEN_ADDRESS \  src/CatToken.sol:CatToken
```

```prism
// SPDX-License-Identifier: MITpragma solidity ^0.8.19;
import "forge-std/Script.sol";import "../src/CatToken.sol";
contract TransferCatTokens is Script {    function run() external {        uint256 deployerPrivateKey = vm.envUint("PRIVATE_KEY");        address token = vm.envAddress("TOKEN_ADDRESS");
        vm.startBroadcast(deployerPrivateKey);
        // Send tokens to test addresses        CatToken(token).transfer(address(0x1), 1000 * 10**18);        CatToken(token).transfer(address(0x2), 2000 * 10**18);        CatToken(token).transfer(address(0x3), 3000 * 10**18);
        vm.stopBroadcast();    }}
```

```prism
forge script script/TransferCatTokens.s.sol \--rpc-url $MONAD_TESTNET_RPC \--broadcast
```

```prism
interface Events {    event Transfer(address indexed from, address indexed to, uint256 value);}
```

```prism
struct Global {    string id;    uint256 totalHolders;}
struct User {    address id;    uint256 balance;}
struct Transfer {    string id;    address from;    address to;    uint256 amount;
    uint64 block;    address emitter;    uint32 logIndex;    bytes32 transactionHash;    uint32 txIndex;    uint32 timestamp;}
```

```prism
// SPDX-License-Identifier: MITpragma solidity 0.8.19;
import "./gen_schema.sol";import "./gen_events.sol";import "./gen_base.sol";import "./gen_helpers.sol";
contract MyIndex is GhostGraph {    using StringHelpers for EventDetails;    using StringHelpers for uint256;    using StringHelpers for address;
    address constant CAT_TESTNET_TOKEN_CONTRACT_ADDRESS = <INSERT YOUR TOKEN ADDRESS>;
    function registerHandles() external {        graph.registerHandle(CAT_TESTNET_TOKEN_CONTRACT_ADDRESS);    }
    function onTransfer(EventDetails memory details, TransferEvent memory ev) external {        // Get global state to track holder count        Global memory global = graph.getGlobal("1");
        // Handle sender balance        if (ev.from != address(0)) {            // Skip if minting            User memory sender = graph.getUser(ev.from);            if (sender.balance == ev.value) {                // User is transferring their entire balance                global.totalHolders -= 1; // Decrease holder count            }            sender.balance -= ev.value;            graph.saveUser(sender);        }
        // Handle receiver balance        User memory receiver = graph.getUser(ev.to);        if (receiver.balance == 0 && ev.value > 0) {            // New holder            global.totalHolders += 1; // Increase holder count        }        receiver.balance += ev.value;        graph.saveUser(receiver);
        // Save global state        graph.saveGlobal(global);
        // Create and save transfer record        Transfer memory transfer = graph.getTransfer(details.uniqueId());        transfer.from = ev.from;        transfer.to = ev.to;        transfer.amount = ev.value;                // Store transaction metadata        transfer.block = details.block;        transfer.emitter = details.emitter;        transfer.logIndex = details.logIndex;        transfer.transactionHash = details.transactionHash;        transfer.txIndex = details.txIndex;        transfer.timestamp = details.timestamp;                graph.saveTransfer(transfer);    }}
```

```prism
query FetchRecentTransfers {  transfers(    orderBy: "block",     orderDirection: "desc"    limit: 50  ) {    items {      amount      block      emitter      from      id      logIndex      timestamp      to      transactionHash      txIndex    }  }}
```

---

## Huff

> Source: https://docs.monad.xyz/guides/evm-resources/other-languages/huff

Huff is most closely described as EVM assembly. Unlike Yul, Huff does not provide control flow constructs or abstract away the inner working of the program stack. Only the most upmost performance sensitive applications take advantage of Huff, however it is a great educational tool to learn how the EVM interprets instructions its lowest level.

Huff resources provides additional resources

---

## Other Languages

> Source: https://docs.monad.xyz/guides/evm-resources/other-languages

📄️ VyperVyper is a popular programming language for the EVM that is logically similar to Solidity and syntactically similar with Python.📄️ YulYul is a intermediate language for Solidity that can generally be thought of as inline assembly for the EVM. It is not quite pure assembly, providing control flow constructs and abstracting away the inner working of the stack while still exposing the raw memory backend to developers. Yul is targeted at developers needing exposure to the EVM's raw memory backend to build high performance gas optimized EVM code.📄️ HuffHuff is most closely described as EVM assembly. Unlike Yul, Huff does not provide control flow constructs or abstract away the inner working of the program stack. Only the most upmost performance sensitive applications take advantage of Huff, however it is a great educational tool to learn how the EVM interprets instructions its lowest level.

📄️ VyperVyper is a popular programming language for the EVM that is logically similar to Solidity and syntactically similar with Python.

📄️ YulYul is a intermediate language for Solidity that can generally be thought of as inline assembly for the EVM. It is not quite pure assembly, providing control flow constructs and abstracting away the inner working of the stack while still exposing the raw memory backend to developers. Yul is targeted at developers needing exposure to the EVM's raw memory backend to build high performance gas optimized EVM code.

📄️ HuffHuff is most closely described as EVM assembly. Unlike Yul, Huff does not provide control flow constructs or abstract away the inner working of the program stack. Only the most upmost performance sensitive applications take advantage of Huff, however it is a great educational tool to learn how the EVM interprets instructions its lowest level.

---

## Other Languages

> Source: https://docs.monad.xyz/guides/evm-resources/other-languages/

📄️ VyperVyper is a popular programming language for the EVM that is logically similar to Solidity and syntactically similar with Python.📄️ YulYul is a intermediate language for Solidity that can generally be thought of as inline assembly for the EVM. It is not quite pure assembly, providing control flow constructs and abstracting away the inner working of the stack while still exposing the raw memory backend to developers. Yul is targeted at developers needing exposure to the EVM's raw memory backend to build high performance gas optimized EVM code.📄️ HuffHuff is most closely described as EVM assembly. Unlike Yul, Huff does not provide control flow constructs or abstract away the inner working of the program stack. Only the most upmost performance sensitive applications take advantage of Huff, however it is a great educational tool to learn how the EVM interprets instructions its lowest level.

📄️ VyperVyper is a popular programming language for the EVM that is logically similar to Solidity and syntactically similar with Python.

📄️ YulYul is a intermediate language for Solidity that can generally be thought of as inline assembly for the EVM. It is not quite pure assembly, providing control flow constructs and abstracting away the inner working of the stack while still exposing the raw memory backend to developers. Yul is targeted at developers needing exposure to the EVM's raw memory backend to build high performance gas optimized EVM code.

📄️ HuffHuff is most closely described as EVM assembly. Unlike Yul, Huff does not provide control flow constructs or abstract away the inner working of the program stack. Only the most upmost performance sensitive applications take advantage of Huff, however it is a great educational tool to learn how the EVM interprets instructions its lowest level.

---

## Solidity Resources

> Source: https://docs.monad.xyz/guides/evm-resources/solidity-resources

On this page

Monad is fully EVM bytecode-compatible, with all supported opcodes and precompiles as of the Cancun fork. Monad also preserves the standard Ethereum JSON-RPC interfaces.
As such, most development resources for Ethereum Mainnet apply to development on Monad.
This page suggests a minimal set of resources for getting started with building a decentralized app for Ethereum. Child pages provide additional detail or options. 
As Solidity is the most popular language for Ethereum smart contracts, the resources on this page focus on Solidity; alternatively see resources on Vyper or Huff. Note that since smart contracts are composable, contracts originally written in one language can still make calls to contracts in another language.
IDEs​

Remix is an interactive Solidity IDE. It is the easiest and fastest way to get started coding and compiling Solidity smart contracts without the need for additional tool installations.
VSCode + Solidity extension

Basic Solidity​

CryptoZombies is a great end-to-end introduction to building dApps on the EVM. It provides resources and lessons for anyone from someone who has never coded before, to experienced developers in other disciplines looking to explore blockchain development.
Solidity by Example introduces concepts progressively through simple examples; best for developers who already have basic experience with other languages.
Blockchain Basics course by Cyfrin Updraft teaches the fundamentals of blockchain, DeFi, and smart contracts.
Solidity Smart Contract Development by Cyfrin Updraft will teach you how to become a smart contract developer. Learn to build with projects and get hands-on experience.
Ethereum Developer Degree by LearnWeb3 is the a good course to go from no background knowledge in web3 to being able to build multiple applications and understanding several key protocols, frameworks, and concepts in the web3 space.

Intermediate Solidity​

The Solidity Language official documentation is an end-to-end description of Smart Contracts and blockchain basics centered on EVM environments. In addition to Solidity Language documentation, it covers the basics of compiling your code for deployment on an EVM as well as the basic components relevant to deploying a Smart Contract on an EVM.
Solidity Patterns repository provides a library of code templates and explanation of their usage. 
The Uniswap V2 contract is a professional yet easy to digest smart contract that provides a great overview of an in-production Solidity dApp. A guided walkthrough of the contract can be found here.
Cookbook.dev provides a set of interactive example template contracts with live editing, one-click deploy, and an AI chat integration to help with code questions. 
OpenZeppelin provides customizable template contract library for common Ethereum token deployments such as ERC20, ERC712, and ERC1155. Note, they are not gas optimized.
Rareskills Blog has some great in-depth articles on various concepts in Solidity.
Foundry Fundamentals course by Cyfrin Updraft is a comprehensive web3 development course designed to teach you about Foundry the industry-standard framework to build, deploy, and test your smart contracts.
Smart Contract Programmer YT channel has a plenty of in-depth videos about various Solidity concepts like ABI encoding, EVM memory, and many more.

Advanced Solidity​

The Solmate repository and Solady repository provide gas-optimized contracts utilizing Solidity or Yul.
Yul is a intermediate language for Solidity that can generally be thought of as inline assembly for the EVM. It is not quite pure assembly, providing control flow constructs and abstracting away the inner working of the stack while still exposing the raw memory backend to developers. Yul is targeted at developers needing exposure to the EVM's raw memory backend to build high performance gas optimized EVM code. 
Huff is most closely described as EVM assembly. Unlike Yul, Huff does not provide control flow constructs or abstract away the inner working of the program stack. Only the most upmost performance sensitive applications take advantage of Huff, however it is a great educational tool to learn how the EVM interprets instructions its lowest level.
Advanced Foundry course by Cyfrin Updraft teaches you about Foundry, how to develop a DeFi protocol and a stablecoin, how to develop a DAO, advanced smart contract development, advanced smart contracts testing and fuzzing and manual verification.
Smart Contract Security course by Cyfrin Updraft will teach you everything you need to know to get started auditing and writing secure protocols.
Assembly and Formal Verification course by Cyfrin Updraft teaches you about Assembly, writing smart contracts using Huff and Yul, Ethereum Virtual Machine OPCodes, Formal verification testing, Smart contract invariant testing and tools like Halmos, Certora, Kontrol.
Smart Contract DevOps course by Cyfrin Updraft teaches about access control best practices when working with wallets, post-deployment security, smart contract and web3 devOps and live protocols maintenance and monitoring.
Secureum YT Channel has plenty videos about Solidity from Solidity Basics to all the way to advanced concepts like Fuzzing and Solidity auditing.

Tutorials​

Ethernaut: learn by solving puzzles
Damn Vulnerable DeFi: DVD is a series of smart contract challenges which consists of vulnerable contracts and you are supposed to be able to hack it. These challenges are a good way to practice and apply the Solidity skills you have acquired.

Best practices/patterns​

DeFi developer roadmap
RareSkills Book of Gas Optimization

Testing​

Echidna: fuzz testing
Slither: static analysis for vulnerability detection
solidity-coverage: code coverage for Solidity testing

Smart contract archives​

Smart contract sanctuary - contracts verified on Etherscan
EVM function signature database

---

## Use an Indexer

> Source: https://docs.monad.xyz/guides/indexers/

GhostGraphIndex transfers with GhostGraphEnvioIndex transfers for a telegram bot using EnvioQuickNode StreamsIndex transfers using QuickNode Streams

---

## Verify a Contract

> Source: https://docs.monad.xyz/guides/verify-smart-contract/

FoundryVerify a smart contract on Monad using FoundryHardhatVerify a smart contract on Monad using Hardhat

---

## Verify a smart contract on Monad using Foundry

> Source: https://docs.monad.xyz/guides/verify-smart-contract/foundry

On this page

Once your contract is deployed to a live network, the next step is to verify its source code on the block explorer.
Verifying a contract means uploading its source code, along with the settings used to compile the code, to a
repository (typically maintained by a block explorer). This allows anyone to compile it and compare the generated
bytecode with what is deployed on chain. Doing this is extremely important in an open platform like Monad.
In this guide we'll explain how to do this using Foundry.
MainnetTestnetFoundry Monad template (Recommended)Default Foundry ProjectnoteThe foundry-monad template is configured for testnet by default. To use mainnet, update your foundry.toml file:
Change eth-rpc-url="https://testnet-rpc.monad.xyz" to your mainnet RPC URL
Change chain_id = 10143 to 143
If you are using foundry-monad template, you can use the commands below based on your preferred block explorer:MonadVisionMonadscanSocialscanforge verify-contract \    <contract_address> \    <contract_name> \    --chain 143 \    --verifier sourcify \    --verifier-url https://sourcify-api-monad.blockvision.orgExample:forge verify-contract \    0x8fEc29BdEd7A618ab6E3CD945456A79163995769 \    Counter \    --chain 143 \    --verifier sourcify \    --verifier-url https://sourcify-api-monad.blockvision.orgOn successful verification of smart contract, you should get a similar output in your terminal:Start verifying contract `0x8fEc29BdEd7A618ab6E3CD945456A79163995769` deployed on monad-mainnetAttempting to verify on Sourcify. Pass the --etherscan-api-key <API_KEY> to verify on Etherscan, or use the --verifier flag to verify on another provider.
Submitting verification for [Counter] "0x8fEc29BdEd7A618ab6E3CD945456A79163995769".Contract successfully verifiedNow check the contract on MonadVision.forge verify-contract \    <contract_address> \    <contract_name> \    --chain 143 \    --verifier etherscan \    --etherscan-api-key YourApiKeyToken \    --watchExample:forge verify-contract \    0x8fEc29BdEd7A618ab6E3CD945456A79163995769 \    Counter \    --chain 143 \    --verifier etherscan \    --etherscan-api-key YourApiKeyToken \    --watchOn successful verification of smart contract, you should get a similar output in your terminal:Start verifying contract `0x8fEc29BdEd7A618ab6E3CD945456A79163995769` deployed on monad-mainnet
Submitting verification for [src/Counter.sol:Counter] 0x8fEc29BdEd7A618ab6E3CD945456A79163995769.Submitted contract for verification:        Response: `OK`        GUID: `fhxxx4wsub68jce24ejvhe68fqabgtpmpzheqpdqvencgph1za`        URL: https://monadscan.com/address/0x8fec29bded7a618ab6e3cd945456a79163995769Contract verification status:Response: `NOTOK`Details: `Pending in queue`Warning: Verification is still pending...; waiting 15 seconds before trying again (7 tries remaining)Contract verification status:Response: `OK`Details: `Pass - Verified`Contract successfully verifiedNow check the contract on Monadscan.forge verify-contract \    <contract_address> \    <contract_name> \    --chain 143 \    --watch \    --etherscan-api-key <your_api_key> \    --verifier-url https://api.socialscan.io/monad-mainnet/v1/explorer/command_api/contract \    --verifier etherscanExample:forge verify-contract \    0x8fEc29BdEd7A618ab6E3CD945456A79163995769 \    Counter \    --chain 143 \    --watch \    --etherscan-api-key test \    --verifier-url https://api.socialscan.io/monad-mainnet/v1/explorer/command_api/contract \    --verifier etherscanOn successful verification of smart contract, you should get a similar output in your terminal:Start verifying contract `0x8fEc29BdEd7A618ab6E3CD945456A79163995769` deployed on monad-mainnet
Submitting verification for [src/Counter.sol:Counter] 0x8fEc29BdEd7A618ab6E3CD945456A79163995769.Submitted contract for verification:        Response: `Contract successfully verified`        GUID: `33588004868f0677a3c23734da00fc42895a63542f61b1ed0dbfd2eb6893d7f4`        URL: https://monad.socialscan.io/address/0x8fec29bded7a618ab6e3cd945456a79163995769Contract verification status:Response: `OK`Details: `Pass - Verified`Contract successfully verifiedNow check the contract on Socialscan.1. Update foundry.toml with Monad Configuration​foundry.toml1234567891011[profile.default]src = "src"out = "out"libs = ["lib"]metadata = truemetadata_hash = "none"  # disable ipfsuse_literal_content = true # use source code
# Monad Configurationeth-rpc-url="https://rpc.monad.xyz"chain_id = 1432. Verify the contract using one of the following block explorers:​MonadVisionMonadscanSocialscannoteIf you are using MonadVision, you can use
this guide.
In particular, the Verify Contract
page provides a convenient way to verify your contract.forge verify-contract \    <contract_address> \    <contract_name> \    --chain 143 \    --verifier sourcify \    --verifier-url https://sourcify-api-monad.blockvision.orgExample:forge verify-contract \    0x8fEc29BdEd7A618ab6E3CD945456A79163995769 \    Counter \    --chain 143 \    --verifier sourcify \    --verifier-url https://sourcify-api-monad.blockvision.orgOn successful verification of smart contract, you should get a similar output in your terminal:Start verifying contract `0x8fEc29BdEd7A618ab6E3CD945456A79163995769` deployed on monad-mainnetAttempting to verify on Sourcify. Pass the --etherscan-api-key <API_KEY> to verify on Etherscan, or use the --verifier flag to verify on another provider.
Submitting verification for [Counter] "0x8fEc29BdEd7A618ab6E3CD945456A79163995769".Contract successfully verifiedNow check the contract on MonadVision.forge verify-contract \    <contract_address> \    <contract_name> \    --chain 143 \    --verifier etherscan \    --etherscan-api-key YourApiKeyToken \    --watchExample:forge verify-contract \    0x8fEc29BdEd7A618ab6E3CD945456A79163995769 \    Counter \    --chain 143 \    --verifier etherscan \    --etherscan-api-key YourApiKeyToken \    --watchOn successful verification of smart contract, you should get a similar output in your terminal:Start verifying contract `0x8fEc29BdEd7A618ab6E3CD945456A79163995769` deployed on monad-mainnet
Submitting verification for [src/Counter.sol:Counter] 0x8fEc29BdEd7A618ab6E3CD945456A79163995769.Submitted contract for verification:        Response: `OK`        GUID: `fhxxx4wsub68jce24ejvhe68fqabgtpmpzheqpdqvencgph1za`        URL: https://monadscan.com/address/0x8fec29bded7a618ab6e3cd945456a79163995769Contract verification status:Response: `NOTOK`Details: `Pending in queue`Warning: Verification is still pending...; waiting 15 seconds before trying again (7 tries remaining)Contract verification status:Response: `OK`Details: `Pass - Verified`Contract successfully verifiedNow check the contract on Monadscan.forge verify-contract \    <contract_address> \    <contract_name> \    --chain 143 \    --watch \    --etherscan-api-key <your_api_key> \    --verifier-url https://api.socialscan.io/monad-mainnet/v1/explorer/command_api/contract \    --verifier etherscanExample:forge verify-contract \    0x8fEc29BdEd7A618ab6E3CD945456A79163995769 \    Counter \    --chain 143 \    --watch \    --etherscan-api-key test \    --verifier-url https://api.socialscan.io/monad-mainnet/v1/explorer/command_api/contract \    --verifier etherscanOn successful verification of smart contract, you should get a similar output in your terminal:Start verifying contract `0x8fEc29BdEd7A618ab6E3CD945456A79163995769` deployed on monad-mainnet
Submitting verification for [src/Counter.sol:Counter] 0x8fEc29BdEd7A618ab6E3CD945456A79163995769.Submitted contract for verification:        Response: `Contract successfully verified`        GUID: `33588004868f0677a3c23734da00fc42895a63542f61b1ed0dbfd2eb6893d7f4`        URL: https://monad.socialscan.io/address/0x8fec29bded7a618ab6e3cd945456a79163995769Contract verification status:Response: `OK`Details: `Pass - Verified`Contract successfully verifiedNow check the contract on Socialscan.Foundry Monad template (Recommended)Default Foundry ProjectIf you are using foundry-monad template, you can use the commands below based on your preferred block explorer:MonadVisionMonadscanSocialscanforge verify-contract \    <contract_address> \    <contract_name> \    --chain 10143 \    --verifier sourcify \    --verifier-url https://sourcify-api-monad.blockvision.orgExample:forge verify-contract \    0x8fEc29BdEd7A618ab6E3CD945456A79163995769 \    Counter \    --chain 10143 \    --verifier sourcify \    --verifier-url https://sourcify-api-monad.blockvision.orgOn successful verification of smart contract, you should get a similar output in your terminal:Start verifying contract `0x8fEc29BdEd7A618ab6E3CD945456A79163995769` deployed on monad-testnetAttempting to verify on Sourcify. Pass the --etherscan-api-key <API_KEY> to verify on Etherscan, or use the --verifier flag to verify on another provider.
Submitting verification for [Counter] "0x8fEc29BdEd7A618ab6E3CD945456A79163995769".Contract successfully verifiedNow check the contract on MonadVision.forge verify-contract \    <contract_address> \    <contract_name> \    --chain 10143 \    --verifier etherscan \    --etherscan-api-key YourApiKeyToken \    --watchExample:forge verify-contract \    0x8fEc29BdEd7A618ab6E3CD945456A79163995769 \    Counter \    --chain 10143 \    --verifier etherscan \    --etherscan-api-key YourApiKeyToken \    --watchOn successful verification of smart contract, you should get a similar output in your terminal:Start verifying contract `0x8fEc29BdEd7A618ab6E3CD945456A79163995769` deployed on monad-testnet
Submitting verification for [src/Counter.sol:Counter] 0x8fEc29BdEd7A618ab6E3CD945456A79163995769.Submitted contract for verification:        Response: `OK`        GUID: `fhxxx4wsub68jce24ejvhe68fqabgtpmpzheqpdqvencgph1za`        URL: https://testnet.monadscan.com/address/0x8fec29bded7a618ab6e3cd945456a79163995769Contract verification status:Response: `NOTOK`Details: `Pending in queue`Warning: Verification is still pending...; waiting 15 seconds before trying again (7 tries remaining)Contract verification status:Response: `OK`Details: `Pass - Verified`Contract successfully verifiedNow check the contract on Monadscan.forge verify-contract \    <contract_address> \    <contract_name> \    --chain 10143 \    --watch \    --etherscan-api-key <your_api_key> \    --verifier-url https://api.socialscan.io/monad-testnet/v1/explorer/command_api/contract \    --verifier etherscanExample:forge verify-contract \    0x8fEc29BdEd7A618ab6E3CD945456A79163995769 \    Counter \    --chain 10143 \    --watch \    --etherscan-api-key test \    --verifier-url https://api.socialscan.io/monad-testnet/v1/explorer/command_api/contract \    --verifier etherscanOn successful verification of smart contract, you should get a similar output in your terminal:Start verifying contract `0x8fEc29BdEd7A618ab6E3CD945456A79163995769` deployed on monad-testnet
Submitting verification for [src/Counter.sol:Counter] 0x8fEc29BdEd7A618ab6E3CD945456A79163995769.Submitted contract for verification:        Response: `Contract successfully verified`        GUID: `33588004868f0677a3c23734da00fc42895a63542f61b1ed0dbfd2eb6893d7f4`        URL: https://api.socialscan.io/monad-testnet/v1/explorer/command_api/address/0x8fec29bded7a618ab6e3cd945456a79163995769Contract verification status:Response: `OK`Details: `Pass - Verified`Contract successfully verifiedNow check the contract on Socialscan.tipIf you use foundry-monad you can skip the configuration step1. Update foundry.toml with Monad Configuration​foundry.toml1234567891011[profile.default]src = "src"out = "out"libs = ["lib"]  metadata = truemetadata_hash = "none"  # disable ipfsuse_literal_content = true # use source code
# Monad Configurationeth-rpc-url="https://testnet-rpc.monad.xyz"chain_id = 101432. Verify the contract using one of the following block explorers:​MonadVisionMonadscanSocialscanforge verify-contract \    <contract_address> \    <contract_name> \    --chain 10143 \    --verifier sourcify \    --verifier-url https://sourcify-api-monad.blockvision.orgExample:forge verify-contract \    0x8fEc29BdEd7A618ab6E3CD945456A79163995769 \    Counter \    --chain 10143 \    --verifier sourcify \    --verifier-url https://sourcify-api-monad.blockvision.orgOn successful verification of smart contract, you should get a similar output in your terminal:Start verifying contract `0x8fEc29BdEd7A618ab6E3CD945456A79163995769` deployed on monad-testnetAttempting to verify on Sourcify. Pass the --etherscan-api-key <API_KEY> to verify on Etherscan, or use the --verifier flag to verify on another provider.
Submitting verification for [Counter] "0x8fEc29BdEd7A618ab6E3CD945456A79163995769".Contract successfully verifiedNow check the contract on MonadVision.forge verify-contract \    <contract_address> \    <contract_name> \    --chain 10143 \    --verifier etherscan \    --etherscan-api-key YourApiKeyToken \    --watchExample:forge verify-contract \    0x8fEc29BdEd7A618ab6E3CD945456A79163995769 \    Counter \    --chain 10143 \    --verifier etherscan \    --etherscan-api-key YourApiKeyToken \    --watchOn successful verification of smart contract, you should get a similar output in your terminal:Start verifying contract `0x8fEc29BdEd7A618ab6E3CD945456A79163995769` deployed on monad-testnet
Submitting verification for [src/Counter.sol:Counter] 0x8fEc29BdEd7A618ab6E3CD945456A79163995769.Submitted contract for verification:        Response: `OK`        GUID: `fhxxx4wsub68jce24ejvhe68fqabgtpmpzheqpdqvencgph1za`        URL: https://testnet.monadvision.com/address/0x8fec29bded7a618ab6e3cd945456a79163995769Contract verification status:Response: `NOTOK`Details: `Pending in queue`Warning: Verification is still pending...; waiting 15 seconds before trying again (7 tries remaining)Contract verification status:Response: `OK`Details: `Pass - Verified`Contract successfully verifiedNow check the contract on Monadscan.forge verify-contract \    <contract_address> \    <contract_name> \    --chain 10143 \    --watch \    --etherscan-api-key <your_api_key> \    --verifier-url https://api.socialscan.io/monad-testnet/v1/explorer/command_api/contract \    --verifier etherscanExample:forge verify-contract \    0x8fEc29BdEd7A618ab6E3CD945456A79163995769 \    Counter \    --chain 10143 \    --watch \    --etherscan-api-key test \    --verifier-url https://api.socialscan.io/monad-testnet/v1/explorer/command_api/contract \    --verifier etherscanOn successful verification of smart contract, you should get a similar output in your terminal:Start verifying contract `0x8fEc29BdEd7A618ab6E3CD945456A79163995769` deployed on monad-testnet
Submitting verification for [src/Counter.sol:Counter] 0x8fEc29BdEd7A618ab6E3CD945456A79163995769.Submitted contract for verification:        Response: `Contract successfully verified`        GUID: `33588004868f0677a3c23734da00fc42895a63542f61b1ed0dbfd2eb6893d7f4`        URL: https://testnet.monadvision.com/address/0x8fec29bded7a618ab6e3cd945456a79163995769Contract verification status:Response: `OK`Details: `Pass - Verified`Contract successfully verifiedNow check the contract on Socialscan.

### Code Examples

```prism
forge verify-contract \    <contract_address> \    <contract_name> \    --chain 143 \    --verifier sourcify \    --verifier-url https://sourcify-api-monad.blockvision.org
```

```prism
forge verify-contract \    0x8fEc29BdEd7A618ab6E3CD945456A79163995769 \    Counter \    --chain 143 \    --verifier sourcify \    --verifier-url https://sourcify-api-monad.blockvision.org
```

```prism
Start verifying contract `0x8fEc29BdEd7A618ab6E3CD945456A79163995769` deployed on monad-mainnetAttempting to verify on Sourcify. Pass the --etherscan-api-key <API_KEY> to verify on Etherscan, or use the --verifier flag to verify on another provider.
Submitting verification for [Counter] "0x8fEc29BdEd7A618ab6E3CD945456A79163995769".Contract successfully verified
```

```prism
forge verify-contract \    <contract_address> \    <contract_name> \    --chain 143 \    --verifier etherscan \    --etherscan-api-key YourApiKeyToken \    --watch
```

```prism
forge verify-contract \    0x8fEc29BdEd7A618ab6E3CD945456A79163995769 \    Counter \    --chain 143 \    --verifier etherscan \    --etherscan-api-key YourApiKeyToken \    --watch
```

```prism
Start verifying contract `0x8fEc29BdEd7A618ab6E3CD945456A79163995769` deployed on monad-mainnet
Submitting verification for [src/Counter.sol:Counter] 0x8fEc29BdEd7A618ab6E3CD945456A79163995769.Submitted contract for verification:        Response: `OK`        GUID: `fhxxx4wsub68jce24ejvhe68fqabgtpmpzheqpdqvencgph1za`        URL: https://monadscan.com/address/0x8fec29bded7a618ab6e3cd945456a79163995769Contract verification status:Response: `NOTOK`Details: `Pending in queue`Warning: Verification is still pending...; waiting 15 seconds before trying again (7 tries remaining)Contract verification status:Response: `OK`Details: `Pass - Verified`Contract successfully verified
```

```prism
forge verify-contract \    <contract_address> \    <contract_name> \    --chain 143 \    --watch \    --etherscan-api-key <your_api_key> \    --verifier-url https://api.socialscan.io/monad-mainnet/v1/explorer/command_api/contract \    --verifier etherscan
```

```prism
forge verify-contract \    0x8fEc29BdEd7A618ab6E3CD945456A79163995769 \    Counter \    --chain 143 \    --watch \    --etherscan-api-key test \    --verifier-url https://api.socialscan.io/monad-mainnet/v1/explorer/command_api/contract \    --verifier etherscan
```

```prism
Start verifying contract `0x8fEc29BdEd7A618ab6E3CD945456A79163995769` deployed on monad-mainnet
Submitting verification for [src/Counter.sol:Counter] 0x8fEc29BdEd7A618ab6E3CD945456A79163995769.Submitted contract for verification:        Response: `Contract successfully verified`        GUID: `33588004868f0677a3c23734da00fc42895a63542f61b1ed0dbfd2eb6893d7f4`        URL: https://monad.socialscan.io/address/0x8fec29bded7a618ab6e3cd945456a79163995769Contract verification status:Response: `OK`Details: `Pass - Verified`Contract successfully verified
```

```prism
[profile.default]src = "src"out = "out"libs = ["lib"]metadata = truemetadata_hash = "none"  # disable ipfsuse_literal_content = true # use source code
# Monad Configurationeth-rpc-url="https://rpc.monad.xyz"chain_id = 143
```

```prism
forge verify-contract \    <contract_address> \    <contract_name> \    --chain 143 \    --verifier sourcify \    --verifier-url https://sourcify-api-monad.blockvision.org
```

```prism
forge verify-contract \    0x8fEc29BdEd7A618ab6E3CD945456A79163995769 \    Counter \    --chain 143 \    --verifier sourcify \    --verifier-url https://sourcify-api-monad.blockvision.org
```

```prism
Start verifying contract `0x8fEc29BdEd7A618ab6E3CD945456A79163995769` deployed on monad-mainnetAttempting to verify on Sourcify. Pass the --etherscan-api-key <API_KEY> to verify on Etherscan, or use the --verifier flag to verify on another provider.
Submitting verification for [Counter] "0x8fEc29BdEd7A618ab6E3CD945456A79163995769".Contract successfully verified
```

```prism
forge verify-contract \    <contract_address> \    <contract_name> \    --chain 143 \    --verifier etherscan \    --etherscan-api-key YourApiKeyToken \    --watch
```

```prism
forge verify-contract \    0x8fEc29BdEd7A618ab6E3CD945456A79163995769 \    Counter \    --chain 143 \    --verifier etherscan \    --etherscan-api-key YourApiKeyToken \    --watch
```

```prism
Start verifying contract `0x8fEc29BdEd7A618ab6E3CD945456A79163995769` deployed on monad-mainnet
Submitting verification for [src/Counter.sol:Counter] 0x8fEc29BdEd7A618ab6E3CD945456A79163995769.Submitted contract for verification:        Response: `OK`        GUID: `fhxxx4wsub68jce24ejvhe68fqabgtpmpzheqpdqvencgph1za`        URL: https://monadscan.com/address/0x8fec29bded7a618ab6e3cd945456a79163995769Contract verification status:Response: `NOTOK`Details: `Pending in queue`Warning: Verification is still pending...; waiting 15 seconds before trying again (7 tries remaining)Contract verification status:Response: `OK`Details: `Pass - Verified`Contract successfully verified
```

```prism
forge verify-contract \    <contract_address> \    <contract_name> \    --chain 143 \    --watch \    --etherscan-api-key <your_api_key> \    --verifier-url https://api.socialscan.io/monad-mainnet/v1/explorer/command_api/contract \    --verifier etherscan
```

```prism
forge verify-contract \    0x8fEc29BdEd7A618ab6E3CD945456A79163995769 \    Counter \    --chain 143 \    --watch \    --etherscan-api-key test \    --verifier-url https://api.socialscan.io/monad-mainnet/v1/explorer/command_api/contract \    --verifier etherscan
```

```prism
Start verifying contract `0x8fEc29BdEd7A618ab6E3CD945456A79163995769` deployed on monad-mainnet
Submitting verification for [src/Counter.sol:Counter] 0x8fEc29BdEd7A618ab6E3CD945456A79163995769.Submitted contract for verification:        Response: `Contract successfully verified`        GUID: `33588004868f0677a3c23734da00fc42895a63542f61b1ed0dbfd2eb6893d7f4`        URL: https://monad.socialscan.io/address/0x8fec29bded7a618ab6e3cd945456a79163995769Contract verification status:Response: `OK`Details: `Pass - Verified`Contract successfully verified
```

```prism
forge verify-contract \    <contract_address> \    <contract_name> \    --chain 10143 \    --verifier sourcify \    --verifier-url https://sourcify-api-monad.blockvision.org
```

```prism
forge verify-contract \    0x8fEc29BdEd7A618ab6E3CD945456A79163995769 \    Counter \    --chain 10143 \    --verifier sourcify \    --verifier-url https://sourcify-api-monad.blockvision.org
```

```prism
Start verifying contract `0x8fEc29BdEd7A618ab6E3CD945456A79163995769` deployed on monad-testnetAttempting to verify on Sourcify. Pass the --etherscan-api-key <API_KEY> to verify on Etherscan, or use the --verifier flag to verify on another provider.
Submitting verification for [Counter] "0x8fEc29BdEd7A618ab6E3CD945456A79163995769".Contract successfully verified
```

```prism
forge verify-contract \    <contract_address> \    <contract_name> \    --chain 10143 \    --verifier etherscan \    --etherscan-api-key YourApiKeyToken \    --watch
```

```prism
forge verify-contract \    0x8fEc29BdEd7A618ab6E3CD945456A79163995769 \    Counter \    --chain 10143 \    --verifier etherscan \    --etherscan-api-key YourApiKeyToken \    --watch
```

```prism
Start verifying contract `0x8fEc29BdEd7A618ab6E3CD945456A79163995769` deployed on monad-testnet
Submitting verification for [src/Counter.sol:Counter] 0x8fEc29BdEd7A618ab6E3CD945456A79163995769.Submitted contract for verification:        Response: `OK`        GUID: `fhxxx4wsub68jce24ejvhe68fqabgtpmpzheqpdqvencgph1za`        URL: https://testnet.monadscan.com/address/0x8fec29bded7a618ab6e3cd945456a79163995769Contract verification status:Response: `NOTOK`Details: `Pending in queue`Warning: Verification is still pending...; waiting 15 seconds before trying again (7 tries remaining)Contract verification status:Response: `OK`Details: `Pass - Verified`Contract successfully verified
```

```prism
forge verify-contract \    <contract_address> \    <contract_name> \    --chain 10143 \    --watch \    --etherscan-api-key <your_api_key> \    --verifier-url https://api.socialscan.io/monad-testnet/v1/explorer/command_api/contract \    --verifier etherscan
```

```prism
forge verify-contract \    0x8fEc29BdEd7A618ab6E3CD945456A79163995769 \    Counter \    --chain 10143 \    --watch \    --etherscan-api-key test \    --verifier-url https://api.socialscan.io/monad-testnet/v1/explorer/command_api/contract \    --verifier etherscan
```

```prism
Start verifying contract `0x8fEc29BdEd7A618ab6E3CD945456A79163995769` deployed on monad-testnet
Submitting verification for [src/Counter.sol:Counter] 0x8fEc29BdEd7A618ab6E3CD945456A79163995769.Submitted contract for verification:        Response: `Contract successfully verified`        GUID: `33588004868f0677a3c23734da00fc42895a63542f61b1ed0dbfd2eb6893d7f4`        URL: https://api.socialscan.io/monad-testnet/v1/explorer/command_api/address/0x8fec29bded7a618ab6e3cd945456a79163995769Contract verification status:Response: `OK`Details: `Pass - Verified`Contract successfully verified
```

```prism
[profile.default]src = "src"out = "out"libs = ["lib"]  metadata = truemetadata_hash = "none"  # disable ipfsuse_literal_content = true # use source code
# Monad Configurationeth-rpc-url="https://testnet-rpc.monad.xyz"chain_id = 10143
```

```prism
forge verify-contract \    <contract_address> \    <contract_name> \    --chain 10143 \    --verifier sourcify \    --verifier-url https://sourcify-api-monad.blockvision.org
```

```prism
forge verify-contract \    0x8fEc29BdEd7A618ab6E3CD945456A79163995769 \    Counter \    --chain 10143 \    --verifier sourcify \    --verifier-url https://sourcify-api-monad.blockvision.org
```

```prism
Start verifying contract `0x8fEc29BdEd7A618ab6E3CD945456A79163995769` deployed on monad-testnetAttempting to verify on Sourcify. Pass the --etherscan-api-key <API_KEY> to verify on Etherscan, or use the --verifier flag to verify on another provider.
Submitting verification for [Counter] "0x8fEc29BdEd7A618ab6E3CD945456A79163995769".Contract successfully verified
```

```prism
forge verify-contract \    <contract_address> \    <contract_name> \    --chain 10143 \    --verifier etherscan \    --etherscan-api-key YourApiKeyToken \    --watch
```

```prism
forge verify-contract \    0x8fEc29BdEd7A618ab6E3CD945456A79163995769 \    Counter \    --chain 10143 \    --verifier etherscan \    --etherscan-api-key YourApiKeyToken \    --watch
```

```prism
Start verifying contract `0x8fEc29BdEd7A618ab6E3CD945456A79163995769` deployed on monad-testnet
Submitting verification for [src/Counter.sol:Counter] 0x8fEc29BdEd7A618ab6E3CD945456A79163995769.Submitted contract for verification:        Response: `OK`        GUID: `fhxxx4wsub68jce24ejvhe68fqabgtpmpzheqpdqvencgph1za`        URL: https://testnet.monadvision.com/address/0x8fec29bded7a618ab6e3cd945456a79163995769Contract verification status:Response: `NOTOK`Details: `Pending in queue`Warning: Verification is still pending...; waiting 15 seconds before trying again (7 tries remaining)Contract verification status:Response: `OK`Details: `Pass - Verified`Contract successfully verified
```

```prism
forge verify-contract \    <contract_address> \    <contract_name> \    --chain 10143 \    --watch \    --etherscan-api-key <your_api_key> \    --verifier-url https://api.socialscan.io/monad-testnet/v1/explorer/command_api/contract \    --verifier etherscan
```

```prism
forge verify-contract \    0x8fEc29BdEd7A618ab6E3CD945456A79163995769 \    Counter \    --chain 10143 \    --watch \    --etherscan-api-key test \    --verifier-url https://api.socialscan.io/monad-testnet/v1/explorer/command_api/contract \    --verifier etherscan
```

```prism
Start verifying contract `0x8fEc29BdEd7A618ab6E3CD945456A79163995769` deployed on monad-testnet
Submitting verification for [src/Counter.sol:Counter] 0x8fEc29BdEd7A618ab6E3CD945456A79163995769.Submitted contract for verification:        Response: `Contract successfully verified`        GUID: `33588004868f0677a3c23734da00fc42895a63542f61b1ed0dbfd2eb6893d7f4`        URL: https://testnet.monadvision.com/address/0x8fec29bded7a618ab6e3cd945456a79163995769Contract verification status:Response: `OK`Details: `Pass - Verified`Contract successfully verified
```

---

## Verify a smart contract on Monad using Hardhat

> Source: https://docs.monad.xyz/guides/verify-smart-contract/hardhat

On this page

Once your contract is deployed to a live network, the next step is to verify its source code on the block explorer.
Verifying a contract means uploading its source code, along with the settings used to compile the code, to a
repository (typically maintained by a block explorer). This allows anyone to compile it and compare the generated
bytecode with what is deployed on chain. Doing this is extremely important in an open platform like Monad.
In this guide we'll explain how to do this using Hardhat.
tipThe verification command may show an error message, but this is often misleading - the contract is usually verified successfully on both Sourcify and MonadScan. Check the explorer links to confirm verification.
Hardhat 2Hardhat 3Hardhat 2 Verification​The hardhat-monad template is pre-configured to verify contracts on both MonadVision (Sourcify) and Monadscan (Etherscan) simultaneously.If you're using the template, your hardhat.config.ts should already have:import type { HardhatUserConfig } from "hardhat/config";import "@nomicfoundation/hardhat-toolbox-viem";import "@nomicfoundation/hardhat-ignition-viem";import "dotenv/config";
const PRIVATE_KEY = process.env.PRIVATE_KEY || "";const ETHERSCAN_API_KEY = process.env.ETHERSCAN_API_KEY || "";
const config: HardhatUserConfig = {  solidity: {    version: "0.8.28",    settings: {      metadata: {        bytecodeHash: "ipfs", // Required for Sourcify verification      },    },  },  networks: {    monadTestnet: {      url: "https://testnet-rpc.monad.xyz",      accounts: [PRIVATE_KEY],      chainId: 10143,    },    monadMainnet: {      url: "https://rpc.monad.xyz",      accounts: [PRIVATE_KEY],      chainId: 143,    },  },  sourcify: {    enabled: true,    apiUrl: "https://sourcify-api-monad.blockvision.org",    browserUrl: "https://monadvision.com",  },  etherscan: {    enabled: true,    apiKey: {      monadMainnet: ETHERSCAN_API_KEY,      monadTestnet: ETHERSCAN_API_KEY,    },    customChains: [      {        network: "monadMainnet",        chainId: 143,        urls: {          apiURL: "https://api.etherscan.io/v2/api?chainid=143",          browserURL: "https://monadscan.com",        },      },      {        network: "monadTestnet",        chainId: 10143,        urls: {          apiURL: "https://api.etherscan.io/v2/api?chainid=10143",          browserURL: "https://testnet.monadscan.com",        },      },    ],  },};
export default config;Verify on Mainnet:npx hardhat verify <contract_address> --network monadMainnetVerify on Testnet:npx hardhat verify <contract_address> --network monadTestnetThis will verify your contract on both MonadVision and Monadscan. Once verified, you can view your contract on the respective explorers.Hardhat 3 Verification​tipThe verification command may show an error message, but this is often misleading - the contract is usually verified successfully on both Sourcify and MonadScan. Check the explorer links to confirm verification.The hardhat3-monad template is pre-configured to verify contracts on both MonadVision (Sourcify) and Monadscan (Etherscan). Hardhat 3 uses a different configuration structure with the verify key and chainDescriptors.If you're using the template, your hardhat.config.ts should already have:import hardhatToolboxViemPlugin from "@nomicfoundation/hardhat-toolbox-viem";import { defineConfig } from "hardhat/config";import "dotenv/config";
const PRIVATE_KEY = process.env.PRIVATE_KEY || "";const ETHERSCAN_API_KEY = process.env.ETHERSCAN_API_KEY || "";
export default defineConfig({  plugins: [hardhatToolboxViemPlugin],  solidity: {    version: "0.8.28",    settings: {      optimizer: {        enabled: true,        runs: 200,      },    },  },  networks: {    hardhat: {      type: "edr-simulated",    },    monadTestnet: {      type: "http",      url: "https://testnet-rpc.monad.xyz",      accounts: [PRIVATE_KEY],      chainId: 10143,    },    monadMainnet: {      type: "http",      url: "https://rpc.monad.xyz",      accounts: [PRIVATE_KEY],      chainId: 143,    },  },  verify: {    blockscout: {      enabled: false,    },    etherscan: {      enabled: true,      apiKey: ETHERSCAN_API_KEY,    },    sourcify: {      enabled: true,      apiUrl: "https://sourcify-api-monad.blockvision.org",    },  },  chainDescriptors: {    143: {      name: "MonadMainnet",      blockExplorers: {        etherscan: {          name: "Monadscan",          url: "https://monadscan.com",          apiUrl: "https://api.etherscan.io/v2/api",        },      },    },  },});Verify on Mainnet:npx hardhat verify <contract_address> --network monadMainnetVerify on Testnet:npx hardhat verify <contract_address> --network monadTestnetThis will verify your contract on both MonadVision and Monadscan. Once verified, you can view your contract on the respective explorers.

### Code Examples

```prism
import type { HardhatUserConfig } from "hardhat/config";import "@nomicfoundation/hardhat-toolbox-viem";import "@nomicfoundation/hardhat-ignition-viem";import "dotenv/config";
const PRIVATE_KEY = process.env.PRIVATE_KEY || "";const ETHERSCAN_API_KEY = process.env.ETHERSCAN_API_KEY || "";
const config: HardhatUserConfig = {  solidity: {    version: "0.8.28",    settings: {      metadata: {        bytecodeHash: "ipfs", // Required for Sourcify verification      },    },  },  networks: {    monadTestnet: {      url: "https://testnet-rpc.monad.xyz",      accounts: [PRIVATE_KEY],      chainId: 10143,    },    monadMainnet: {      url: "https://rpc.monad.xyz",      accounts: [PRIVATE_KEY],      chainId: 143,    },  },  sourcify: {    enabled: true,    apiUrl: "https://sourcify-api-monad.blockvision.org",    browserUrl: "https://monadvision.com",  },  etherscan: {    enabled: true,    apiKey: {      monadMainnet: ETHERSCAN_API_KEY,      monadTestnet: ETHERSCAN_API_KEY,    },    customChains: [      {        network: "monadMainnet",        chainId: 143,        urls: {          apiURL: "https://api.etherscan.io/v2/api?chainid=143",          browserURL: "https://monadscan.com",        },      },      {        network: "monadTestnet",        chainId: 10143,        urls: {          apiURL: "https://api.etherscan.io/v2/api?chainid=10143",          browserURL: "https://testnet.monadscan.com",        },      },    ],  },};
export default config;
```

```prism
npx hardhat verify <contract_address> --network monadMainnet
```

```prism
npx hardhat verify <contract_address> --network monadTestnet
```

```prism
import hardhatToolboxViemPlugin from "@nomicfoundation/hardhat-toolbox-viem";import { defineConfig } from "hardhat/config";import "dotenv/config";
const PRIVATE_KEY = process.env.PRIVATE_KEY || "";const ETHERSCAN_API_KEY = process.env.ETHERSCAN_API_KEY || "";
export default defineConfig({  plugins: [hardhatToolboxViemPlugin],  solidity: {    version: "0.8.28",    settings: {      optimizer: {        enabled: true,        runs: 200,      },    },  },  networks: {    hardhat: {      type: "edr-simulated",    },    monadTestnet: {      type: "http",      url: "https://testnet-rpc.monad.xyz",      accounts: [PRIVATE_KEY],      chainId: 10143,    },    monadMainnet: {      type: "http",      url: "https://rpc.monad.xyz",      accounts: [PRIVATE_KEY],      chainId: 143,    },  },  verify: {    blockscout: {      enabled: false,    },    etherscan: {      enabled: true,      apiKey: ETHERSCAN_API_KEY,    },    sourcify: {      enabled: true,      apiUrl: "https://sourcify-api-monad.blockvision.org",    },  },  chainDescriptors: {    143: {      name: "MonadMainnet",      blockExplorers: {        etherscan: {          name: "Monadscan",          url: "https://monadscan.com",          apiUrl: "https://api.etherscan.io/v2/api",        },      },    },  },});
```

```prism
npx hardhat verify <contract_address> --network monadMainnet
```

```prism
npx hardhat verify <contract_address> --network monadTestnet
```

---

## Vyper

> Source: https://docs.monad.xyz/guides/evm-resources/other-languages/vyper

On this page

Vyper is a popular programming language for the EVM that is logically similar to Solidity and syntactically similar with Python.
The Vyper documentation covers installing the Vyper language, language syntax, coding examples, compilation.
A typical EVM developer looking for a Python-like experience is encouraged to use Vyper as the programming language and ApeWorx, which leverages the Python language, as the testing and deployment framework. ApeWorx also allows for the use of typical Python libraries in analysis of testing results such as Pandas.
Vyper and ApeWorx can be used with Jupyter, which offers an interactive environment using a web browser.  A quick setup guide for working with Vyper and Jupyter for smart contract development for the EVM can be found here.
Resources​

Vyper by Example
Snekmate: a Vyper library of gas-optimized smart contract building blocks
Curve contracts: the most prominent example usage of Vyper

---

## Yul

> Source: https://docs.monad.xyz/guides/evm-resources/other-languages/yul

Yul is a intermediate language for Solidity that can generally be thought of as inline assembly for the EVM. It is not quite pure assembly, providing control flow constructs and abstracting away the inner working of the stack while still exposing the raw memory backend to developers. Yul is targeted at developers needing exposure to the EVM's raw memory backend to build high performance gas optimized EVM code.

---



# Section: introduction

---

## Monad for Developers

> Source: https://docs.monad.xyz/introduction/monad-for-developers

On this page

noteThis page summarizes "Why Monad" for developers. For a summary of what you need to know in order
to develop or redeploy on Monad, see
Deployment Summary for Developers.
Monad is an Ethereum-compatible Layer-1 blockchain with 10,000 tps of throughput, 400ms block frequency, and 800ms finality.
Monad's implementation of the Ethereum Virtual Machine complies with the Pectra fork.
The Monad client has been simulated with historical Ethereum transactions and produces
identical merkle roots.
Monad also offers full Ethereum RPC compatibility so that users can interact with Monad using
familiar tools like Etherscan, Phantom, or MetaMask.
Monad accomplishes these performance improvements, while preserving backward compatibility, through
the introduction of several major innovations:

MonadBFT, a frontier BFT consensus mechanism solving the
tail-forking problem
RaptorCast for efficient block transmission
Asynchronous Execution for pipelining
consensus and execution to raise the time budget for execution
Parallel Execution and JIT Compilation for efficient transaction
execution
MonadDb for efficient storage of Ethereum state

Although Monad features parallel execution and pipelining, it's important to note that blocks in Monad are linear, and transactions are linearly ordered within each block.
The first Monad client is built by
Category Labs and is written from scratch in C++ and Rust. The code
is open-source under GPL-3.0 here:

monad-bft
monad

Transactions​
Address spaceSame address space as Ethereum (20-byte addresses using ECDSA)Transaction format/typesSame as Ethereum. Monad transactions use the same typed transaction envelope introduced in EIP-2718, encoded with RLP.Transaction type 0 ("legacy"), 1 ("EIP-2930"), 2 ("EIP-1559"; now the default in Ethereum), and 4 ("EIP-7702") are supported. See transaction type reference.See Transactions for more details.EIP-7702Supported. See EIP-7702 on MonadEIP-155 replay protectionNote that pre EIP-155 transactions are allowed on the protocol level on Monad, therefore it's discouraged to use an Ethereum account that had previously made pre EIP-155 transactions. DiscussionWallet compatibilityMonad is compatible with standard Ethereum wallets such as Phantom or MetaMask. The only change required is to alter the RPC URL and chain id.Gas pricingMonad is EIP-1559-compatible; base fee and priority fee work as in Ethereum.
Base fee follows a dynamic controller, similar to the EIP-1559 controller but with slower increases and faster decreases. Details
Transactions are charged based on gas limit rather than gas usage, i.e. total tokens deducted from the sender's balance is value + gas_price * gas_limit. This is a DOS-prevention measure for asynchronous execution.
See Gas in Monad for more details.
Smart contracts​
OpcodesMonad is bytecode-compatible with Ethereum (Pectra fork).
All opcodes as of the Pectra fork are supported.Opcode pricingOpcode pricing is the same as Ethereum, except for a few repricings needed to reweight relative scarcities of resources due to optimizations. DetailsPrecompilesAll Ethereum precompiles as of the Pectra fork (0x01 to 0x11), plus precompile 0x0100 (RIP-7212) are supported. See PrecompilesMax contract size128 kb (up from 24.5 kb in Ethereum)
Consensus​
Sybil resistance mechanismProof-of-Stake (PoS)DelegationAllowed (in-protocol)Consensus mechanismMonad's consensus mechanism, MonadBFT,
represents a major leap in Byzantine Fault-Tolerant (BFT) consensus. It is the first
BFT consensus mechanism to address the critical problem of
tail forking
in pipelined HotStuff-style consensus.
Accomplishing this allows MonadBFT to achieve high throughput (10,000+ tps), frequent
block times (400 ms), fast finality (800 ms), linear messaging complexity, and large
validator sets (200+) without being susceptible to tail forking, a critical weakness
in prior protocols where a leader can fork away its predecessor's block.Block propagation mechanismRaptorCastBlock frequency400 msFinalitySpeculative finality at 400 ms; full finality at 800 msMempoolLeaders maintain a local mempool. When an RPC receives a transaction, it forwards it to the next 3 leaders who keep it in their local mempool. If the RPC node doesn't observe the transaction getting included, it repeats this process of forwarding to the next 3 leaders 2 more times. Additional forwarding may be added at a later time.Consensus participantsDirect consensus participants vote on block proposals and serve as leaders. To serve as a direct participant, a node must have at least MinStake staked and be in the top MaxConsensusNodes participants by stake weight. These parameters are set in code.Asynchronous executionIn Monad, consensus and execution occur in a pipelined fashion.  Nodes come to consensus on the official transaction order prior to executing that ordering (Asynchronous Execution); the outcome of execution is not a prerequisite to consensus.In blockchains where execution is a prerequisite to consensus, the time budget for execution is a small fraction of the block time.  Pipelining consensus and execution allows Monad to expend the full block time on both consensus and execution.Block proposals consist of an ordered list of transactions and a delayed state merkle root from k=3 blocks ago.Monad introduces the Reserve Balance system to ensure that nodes at consensus time only include (or vote to include) transactions whose senders have sufficient balance to fund their execution.State determinism Finality occurs at consensus time; the official ordering of transactions is enshrined at this point, and the outcome is fully deterministic for any full node, who will generally execute the transactions for that new block in under 800 ms.The D-block delay for state merkle roots is only for state root verification, for example for allowing a node to ensure that it didn't make a computation error.
Execution​
The execution phase for each block begins after consensus is reached on that block, allowing the node to proceed with consensus on subsequent blocks.
Parallel Execution​
Transactions are linearly ordered; the job of execution is to arrive at the state that results from executing that list of transactions serially. The naive approach is just to execute the transactions one after another. Can we do better? Yes we can!
Monad implements parallel execution:

An executor is a virtual machine for executing transactions. Monad runs many executors in parallel.
An executor takes a transaction and produces a result. A result is a list of inputs to and outputs of the transactions, where inputs are (ContractAddress, Slot, Value) tuples that were SLOADed in the course of execution, and outputs are (ContractAddress, Slot, Value) tuples that were SSTOREd as a result of the transaction.
Results are initially produced in a pending state; they are then committed in the original order of the transactions. When a result is committed, its outputs update the current state. When it is a result’s turn to be committed, Monad checks that its inputs still match the current state; if they don’t, Monad reschedules the transaction. As a result of this concurrency control, Monad’s execution is guaranteed to produce the same result as if transactions were run serially.
When transactions are rescheduled, many or all of the required inputs are cached, so re-execution is generally relatively inexpensive. Note that upon re-execution, a transaction may produce a different set of Inputs than the previous execution did;

MonadDb: high-performance state backend​
All active state is stored in MonadDb, a storage backend for solid-state drives (SSDs) that is optimized for storing merkle trie data. Updates are batched so that the merkle root can be updated efficiently.
MonadDb implements in-memory caching and uses asio for efficient asynchronous reads and writes. Nodes should have 32 GB of RAM for optimal performance.
Comparison to Ethereum: User's Perspective​
AttributeEthereumMonadTransactions/second (smart contract calls and transfers)~10~10,000Block Frequency12 seconds400 msFinality2 epochs (12-18 min)800 msBytecode standardEVM (Pectra fork)EVM (Pectra fork)Precompiles0x01 to 0x11 (Pectra fork)0x01 to 0x11 (Pectra fork) plus 0x0100 (RIP-7212).See PrecompilesMax contract size24.5 kb128 kbRPC APIEthereum RPC APIMonad RPC API (generally identical to Ethereum RPC API, see differences)CryptographyECDSAECDSAAccountsLast 20 bytes of keccak-256 of public key under ECDSALast 20 bytes of keccak-256 of public key under ECDSAConsensus mechanismGasper (Casper-FFG finality gadget + LMD-GHOST fork-choice rule)MonadBFT (tail-fork-resistant pipelined consensus with linear messaging complexity in the common case)MempoolGlobalLocalTransaction orderingLeader's discretion (in practice, PBS)Leader's discretion (default behavior: priority gas auction)Sybil-resistance mechanismPoSPoSDelegation allowedNo; pseudo-delegation through LSTsYes; see StakingHardware Requirements (full node)4-core CPU32 GB RAM4 TB SSD NVMe25 Mbit/s bandwidth(reference)16-core CPU32 GB RAM2 x 2 TB SSD NVMe100 Mbit/s bandwidth(more info)
Tooling and Infrastructure​
Many leading Ethereum developer tools support Monad testnet. See
Tooling and Infrastructure
for a list of supported providers by category.
Next Steps​
Monad's public testnet is live. Head to Network Information to get started.
Now that you are familiar with Monad's architecture and features, head to
Deployment Summary for Developers
for everything you need to know to deploy.

---

## Monad for Users

> Source: https://docs.monad.xyz/introduction/monad-for-users

On this page

Monad is a high-performance Ethereum-compatible L1, offering users the best of both worlds:
portability and performance.
From a portability perspective, Monad offers full bytecode compatibility for the Ethereum Virtual
Machine (EVM), so that applications built for Ethereum can be ported to Monad without code changes,
and full Ethereum RPC compatibility, so that infrastructure like Etherscan or The Graph can be
used seamlessly.
From a performance perspective, Monad offers 10,000 tps of throughput, i.e. 1 billion
transactions per day, while offering 400ms block frequency and 800ms finality. This allows
Monad to support many more users and far more interactive experiences than existing blockchains,
while offering far cheaper per-transaction costs.
What's familiar about Monad?​
From a user perspective, Monad behaves very similarly to Ethereum. You can use the same wallets
(e.g. Phantom, MetaMask) or block explorers (e.g. Etherscan) to sign or view transactions. The same
apps built for Ethereum can be ported to Monad without code changes, so it is expected that you'll
be able to use many of your favorite apps from Ethereum on Monad. The address space in Monad is the
same as in Ethereum, so you can reuse your existing keys.
Like Ethereum, Monad features linear blocks, and linear ordering of transactions within a block.
Like Ethereum, Monad is a proof-of-stake network maintained by a decentralized set of validators.
Anyone can run a node to independently verify transaction execution, and significant care has been
taken to keep hardware requirements minimal.
What's different about Monad?​
Monad makes exceptional performance possible by introducing parallel execution and superscalar
pipelining to the Ethereum Virtual Machine.
Parallel execution is the practice of utilizing multiple cores and threads to strategically
execute work in parallel while still committing the results in the original order. Although
transactions are executed in parallel "under the hood", from the user and developer perspective they
are executed serially; the result of a series of transactions is always the same as if the
transactions had been executed one after another.
Superscalar pipelining is the practice of creating stages of work and executing the stages in
parallel. A simple diagram tells the story:
Pipelining laundry day. Top: Naive; Bottom: Pipelined. Credit:
Prof. Lois Hawkes, FSU
When doing four loads of laundry, the naive strategy is to wash, dry, fold, and store the first load
of laundry before starting on the second one. The pipelined strategy is to start washing load 2 when
load 1 goes into the dryer. Pipelining gets work done more efficiently by utilizing multiple
resources simultaneously.
Monad introduces pipelining to address existing bottlenecks in state storage, transaction
processing, and distributed consensus. In particular, Monad introduces pipelining and other
optimizations in five major areas:

MonadBFT for performant, tail-fork-resistant BFT consensus
RaptorCast for efficient block transmission
Asynchronous Execution for pipelining
consensus and execution to raise the time budget for execution
Parallel Execution and
JIT Compilation for efficient transaction
execution
MonadDb for efficient state access

Monad's client, which was written from scratch in C++ and Rust, reflect these architectural
improvements and result in a platform for decentralized apps that can truly scale to world adoption.
Why should I care?​
Decentralized apps are replacements for centralized services with several significant advantages:

Open APIs / composability: decentralized apps can be called atomically by other decentralized
apps, allowing developers to build more complex functionality by stacking existing components.
Transparency: app logic is expressed purely through code, so anyone can review the logic for
side effects. State is transparent and auditable; proof of reserves in DeFi is the default.
Censorship-resistance and credible neutrality: anyone can submit transactions or upload
applications to a permissionless network.
Global reach: anyone with access to the internet can access crucial financial services,
including unbanked/underbanked users.

However, decentralized apps need cheap, performant infrastructure to reach their intended level of
impact. A single app with 1 million daily active users (DAUs) and 10 transactions per user per day
would require 10 million transactions per day, or 100 tps. A quick glance at
L2Beat - a useful website summarizing the throughput and
decentralization of existing EVM-compatible L1s and L2s - shows that no EVM blockchain supports even
close to that level of throughput right now.
Monad materially improves on the performance of an EVM-compatible blockchain network, pioneering
several innovations that will hopefully become standard in Ethereum in the years to come.
With Monad, developers, users, and researchers can reuse the wealth of existing applications,
libraries, and applied cryptography research that have all been built for the EVM.
Testnet​
Monad's public testnet is live. Head to
Network Information to get started.

---

## Why Blockchain?

> Source: https://docs.monad.xyz/introduction/why-blockchain

On this page

A blockchain is decentralized agreement among a diverse set of participants about two things:

An official ordering (ledger) of transactions
An official state of the world, including balances of accounts and the state of various programs.

In modern blockchains such as Ethereum, transactions consist of balance transfers, creation of new programs, and function calls against existing programs. The aggregate result of all transactions up to now produces the current state, which is why agreement about (1) above implies agreement about (2).
A blockchain system has a set of protocol rules, also known as a consensus mechanism, which describe how a distributed set of nodes which are currently in sync will communicate with each other to agree upon additional transactions to add to the ledger. (MonadBFT is an example of a consensus mechanism.)
Induction keeps the nodes in sync: they start with the same state and apply the same transactions, so at the end of applying a new list of transactions, they still have consistent state.
Shared global state enables the development of decentralized apps - apps that live "on the blockchain", i.e. on each of the nodes in the blockchain system. A decentralized app is a chunk of code (as well as persistent, app-specific state) that can get invoked by any user, who does so by submitting a transaction pointing to a function on that app. Each of the nodes in the blockchain is responsible for correctly executing the bytecode being called; duplication keeps each node honest.
An example app​
Decentralized apps can implement functionality that we might otherwise expect to be implemented in a centralized fashion. For example, a very simple example of a decentralized app is a Virtual Bank (typically referred to in crypto as a Lending Protocol).
In the physical world, a bank is a business that takes deposits and loans them out at a higher rate. The bank makes the spread between the high rate and the low rate; the borrower gets a loan to do something economically productive; and you earn interest on your deposits. Everyone wins!
A Virtual Bank is simply an app with four major methods: deposit, withdraw, borrow, and repay. The logic for each of those methods is mostly bookkeeping to ensure that deposits and loans are being tracked correctly:
class VirtualBank:  def deposit(sender, amount):    # transfer amount from sender to myself (the bank)    # do internal bookkeeping to credit the sender
  def withdraw(sender, amount):    # ensure the sender had enough on deposit    # do internal bookkeeping to debit the sender    # transfer amount from myself (the bank) to sender
  def borrow(sender, amount):    # ...
  def repay(sender, amount);    # ...
In Ethereum, or in Monad, someone can write code for this Virtual Bank and upload it; then anyone can utilize it for borrowing and lending, potentially far more easily than when trying to get access to banking services in their home country.
This simple example shows the power of decentralized apps. Here are a few other benefits to call out:

Open APIs / composability: decentralized apps can be called atomically by other decentralized apps, allowing developers to build more complex functionality by stacking existing components.
Transparency: app logic is expressed purely through code, so anyone can review the logic for side effects. State is transparent and auditable; proof of reserves in DeFi is the default.
Censorship-resistance and credible neutrality: anyone can submit transactions or upload applications to a permissionless network.
Global reach: anyone with access to the internet can access crucial financial services, including unbanked/underbanked users.

### Code Examples

```prism
class VirtualBank:  def deposit(sender, amount):    # transfer amount from sender to myself (the bank)    # do internal bookkeeping to credit the sender
  def withdraw(sender, amount):    # ensure the sender had enough on deposit    # do internal bookkeeping to debit the sender    # transfer amount from myself (the bank) to sender
  def borrow(sender, amount):    # ...
  def repay(sender, amount);    # ...
```

---

## Why Monad: Decentralization + Performance

> Source: https://docs.monad.xyz/introduction/why-monad

On this page

Decentralization matters​
A blockchain has several major components:

Consensus mechanism for achieving agreement on transactions to append to the ledger
Execution/storage system for maintaining the active state

In increasing the performance of these components, one could cut corners, for example by requiring all
of the nodes to be physically close to each other (to save on the overhead of consensus), or by
requiring a huge amount of RAM (to keep much or all of the state in memory), but it would be at a
significant cost to decentralization.
And decentralization is the whole point!
As discussed in Why Blockchain?, decentralized shared global state
allows many parties to coordinate while relying on a single, shared, objective source of truth.
Decentralization is key to the matter; a blockchain maintained by a small group of node operators (or
in the extreme case, a single operator!) would not offer benefits such as trustlessness, credible
neutrality, and censorship-resistance.
For any blockchain network, decentralization should be the principal concern. Performance improvements
should not come at the expense of decentralization.
Today's performance bottlenecks​
Ethereum's current execution limits (1.25M gas per second) are set conservatively, but for several
good reasons:

Inefficient storage access patterns
Single-threaded execution
Very limited execution budget, because consensus can't proceed without execution
Concerns about state growth, and the effect of state growth on future state access costs

Monad addresses these limitations through algorithmic improvements and architectural changes,
pioneering several innovations that will hopefully become standard in Ethereum in the years to come.
Maintaining a high degree of decentralization, while making material performance improvements, is the
key consideration.
Addressing these bottlenecks through optimization​
Monad enables pipelining and other optimizations in four major areas to enable exceptional Ethereum
Virtual Machine performance and materially advance the decentralization/scalability tradeoff.
Subsequent pages describe these major areas of improvement:

MonadBFT, a frontier BFT consensus mechanism solving the
tail-forking problem
RaptorCast for efficient block transmission
Asynchronous Execution for pipelining
consensus and execution to raise the time budget for execution
Parallel Execution and JIT Compilation for efficient transaction
execution
MonadDb for efficient storage of Ethereum state

---



# Section: markdown-page

---

## Markdown page example

> Source: https://docs.monad.xyz/markdown-page

You don't need React to write simple standalone pages.

---



# Section: monad-arch

---

## Asynchronous Execution

> Source: https://docs.monad.xyz/monad-arch/consensus/asynchronous-execution

On this page

Summary​
Asynchronous Execution is a technique that allows Monad to substantially increase execution throughput by decoupling consensus from execution.
Decoupling consensus from execution allows Monad to substantially increase the execution budget, since execution goes from occupying a small fraction of the block time to occupying the full block time.
Background: interleaved execution is inefficient​
Consensus is the process where nodes come to agreement about the official ordering of transactions. Execution is the process of actually executing those transactions and updating the state.
In Ethereum and most other blockchains, execution is a prerequisite to consensus. When nodes come to consensus on a block, they are agreeing on both (1) the list of transactions in the block, and (2) the merkle root summarizing all of the state after executing that list of transactions. As a result, the leader must execute all of the transactions in the proposed block before sharing the proposal, and the validating nodes must execute those transactions before responding with a vote.
We refer to this style of blockchain as one that has execution interleaved with consensus. In this paradigm, the time budget for execution is extremely limited, since it has to happen twice and leave enough time for multiple rounds of cross-globe communication for consensus.
Additionally, since execution will block consensus, the per-block gas limit must be chosen extremely conservatively to ensure that the computation completes on all nodes within the budget even in the worst-case scenario.
The result is that the per-block gas limit is a tiny fraction of the block time. In particular, in Ethereum, the gas limit (30M worst-case gas) corresponds to a roughly 100ms time budget, even though the the block time is 12 seconds:
Comparing Ethereum execution budget to block time
That's 1% of the block time! In short, interleaving consensus and execution has a massive time-shrinking effect.
What if it didn't have to be this way?
Asynchronous Execution​
Monad decouples consensus from execution, moving execution out of the hot path of consensus into a separate, slightly-lagged swim lane.
In Monad, nodes come to consensus (i.e. agreement about the official ordering of transactions), without ever executing those transactions.
That is, the leader proposes an ordering without knowing the resultant state root, and the validating nodes vote on block validity without knowing (for example) whether all of the transactions in the block execute without reverting.
When a block is finalized, every node in the network (validators and full nodes) can execute the block's transactions to produce the latest, agreed-upon state.
As a result of this change, execution can be budgeted the full block time. To see why, consider the somewhat stylized diagrams, in which blue rectangles correspond to execution, and orange rectangles correspond to consensus:
Interleaved execution
In interleaved execution, the sum of the execution and consensus budgets equals the block time, and consensus occupies most of the block time.
Interleaved execution
Asynchronous execution
In asynchronous execution, consensus occupies the full block time - and so does execution, because they are occurring in separate swim lanes, at the same time:
Asynchronous execution
Comparison
Comparing the two styles side by side, you can see the benefit of the asynchronous style: the execution budget can be significantly expanded to occupy the full block time:
Top: interleaved; bottom: asynchronous.
Determined ordering implies state determinism​
Although execution lags consensus, the true state of the world is determined as soon as the ordering is determined. Execution is required to unveil the truth, but the truth is already determined.
It's worth noting that in Monad, like in Ethereum, it is fine for transactions in a block to "fail" in the sense that the intuitive outcome did not succeed.(For example, there could be a transaction included in a block in which Bob tries to send 10 tokens to Alice but only has 1 token in his account. The transfer 'fails' but the transaction is still valid.
The outcome of any transaction, including failure, is deterministic.
Example of transaction determinism even when some transactions fail
Finer details​
Delayed Merkle Root​
As mentioned above, Monad block proposals don't include the merkle root of the state trie, since that would require execution to have already completed.
All nodes should stay in sync because they're all doing the same work. But it'd be nice to be sure! As a precaution, proposals also includes a merkle root from D blocks ago, allowing nodes to detect if they're diverging. D is a systemwide parameter (currently set in testnet and mainnet to 3).
Delayed merkle root validity is part of block validity, so if the leader proposes a block but the delayed merkle root is wrong, the block will be rejected.
As a result of this delayed merkle root:

After the network comes to consensus (2/3 majority vote) on block N (typically upon receiving block N+2, which contains a QC-on-QC for block N), it means that the network has agreed that the official consequence of block N-D is a state rooted in merkle root M. Light clients can then query full nodes for merkle proofs of state variable values at block N-D.
Any node with an error in execution at block N-D will fall out of consensus starting at block N. This will trigger a rollback on that node to the end state of block N-D-1, followed by re-execution of the transactions in block N-D (hopefully resulting in the merkle root matching), followed by re-execution of the transactions in block N-D+1, N-D+2, etc.

Ethereum's approach uses consensus to enforce state machine replication in a very strict way: after nodes come to consensus, we know that the supermajority agrees about the official ordering and the state resulting from that ordering. However, this strictness comes at great cost because interleaved execution limits execution throughput. Asynchronous execution achieves state machine replication without this limitation, and the delayed merkle root serves an additional precaution.
Delayed merkle root
Reserve balance​
Because consensus can only be assumed to have up to the k-block delayed view of the global
state, it is necessary to adjust the consensus and execution rules slightly to allow consensus to
safely build blocks that include only transactions whose gas costs can be paid for.
Monad introduces the Reserve Balance rules to
ensure this. The rules place light restrictions on when transactions can be
included at consensus time, and imposes some conditions under which transactions will
revert at execution time.
Speculative execution​
In MonadBFT, nodes receive a proposed block N at slot N, but it is not finalized until slot N+2. During the intervening time, a node can still locally execute the proposed block (without the guarantee that it will become voted or finalized). This allows a few nice properties:

In the likely event that the proposed block is finalized, the validator node has already done the work and can immediately update its merkle root pointer to the result.
Transactions can be simulated (in eth_call or eth_estimateGas) against the speculative state which is likely more up-to-date.

Transactions from newly-funded accounts​
Because consensus runs slightly ahead of execution, newly-funded accounts which previously had zero balance cannot send transactions until the transfer that credits them with tokens has proceeded to the Verified state.
In practice, this means that if you send tokens from account A into an account B (which has 0 balance), then you should wait until seeing the transaction receipt (indicative that that block has reached Finalized state), and then wait another 1.2 seconds.
Alternatively, depending on the nature of intended transaction from B, it may be possible to write a smart contract callable by A which combines the funding operation and whatever B was intending to do, requiring no delay between funding and spending.
Block states​
See block states for a summary of the states through which each block progresses.

---

## Asynchronous I/O

> Source: https://docs.monad.xyz/monad-arch/concepts/asynchronous-io

Asynchronous I/O is a form of input/output processing that allows the CPU to continue executing concurrently while communication is in progress.
Disk and network are orders of magnitude slower than the CPU.  Rather than initiating an I/O operation and waiting for the result, the CPU can initiate the I/O operation as soon as it's known that the data will be needed, and continue executing other instructions which do not depend on the result of the I/O operation.
Some rough comparisons for illustration purposes:
DeviceLatencyBandwidthCPU L3 Cache10 ns>400 GB/sMemory100 ns100 GB/sDisk (NVMe SSD)400 us380 MB/sNetwork50 - 200 ms1 Gb/s (125 MB/s)
(actual disk stats as reported by fio for random reads of size 2KB - ~190k IOPS)
Fortunately, SSD drives can perform operations concurrently, so the CPU can initiate several requests at the same time, continue executing, and then receive the results of multiple operations around the same time.
Some databases (such as lmdb / mdbx) use memory-mapped storage to read and write to disk. Unfortunately, memory-mapped storage is implemented by the kernel (mmap) and is not asynchronous, so execution is blocked while waiting for the operation to complete.
More about asynchronous I/O can be read here.

---

## Block States

> Source: https://docs.monad.xyz/monad-arch/consensus/block-states

On this page

In MonadBFT, a block progresses through three states.
Additionally, due to asynchronous execution, block finalization is a
separate (earlier) matter from state root verification. As a result of this architecture, each
Monad block can be considered to be in one of four states.
Note that a block's state is from the perspective of a particular observer (any other validator or
full node). As new messages arrive, they allow that observer to progress the block's state locally.
Although the states are defined locally, they correspond to assurance that the rest of the network
will ultimately converge on an outcome consistent with that state.
For example, if a node marks a block as Finalized, it is because that node has received a message
carrying sufficient proof that the rest of the network will ultimately converge on enshrining that
block at that block height.
States​
A Monad block is in one of the four states:

Proposed
Voted
Finalized
Verified

Classification of historical blocks based on the latest proposed block N.
Proposed​
The block has been proposed by a leader but has not been voted upon.
Note: if execution is not lagging behind consensus, a node may
speculatively execute the proposed block.
Voted​
We have a Quorum Certificate (QC) in hand for the block,
indicating that it has been voted affirmatively for by a supermajority of validators. (Typically,
this is due to receiving a child block for this block.)
In MonadBFT, Voted means the block can be
speculatively finalized.
Finalized​
We have a QC-squared in hand for the block (that is, we have a
QC for a block that contains a QC on the original block).
This serves as proof that a supermajority of validators have ratified the existence and validity
of a QC on the original block.
Due to the consensus rules of MonadBFT, this means that the block is finalized.
Verified​
A block containing the delayed merkle root
has been finalized, meaning that the execution outputs of the block has been agreed upon by a
supermajority of validator nodes.
Concretely, the latest verified block will be the
latest_finalized_block - execution_delay.
Mapping to JSON-RPC commitment levels​
Monad uses a different consensus algorithm than Ethereum, but is API compatible with the
JSON-RPC programming interface defined by the
Geth client.
Geth communicates consensus information about blocks publicly over JSON-RPC using the tags
"latest", "safe", and "finalized". Here is how they map to Monad's block states:
Geth RPC state...corresponds to Monad block stateWhy?"latest"Voted(As of v0.10.2. This will be changed to Proposed shortly)Both states refer to the most recently observed block, prior to any action by the consensus algorithm 1"safe"VotedIn Ethereum's LMD-GHOST algorithm, "safe" means something like "extremely unlikely to be reverted, but still theoretically possible"; Monad's voted has a similar meaning"finalized"FinalizedThis has the same meaning on both chains: not revertible without a hard fork
noteGeth recognizes two other block tags, "earliest" and "pending". These are not consensus
states. The former is a synonym for the genesis block, and the latter does not make sense given
how Monad's transaction propagation mechanism is
different.
Real-time data and block states​
Monad offers several sources of real-time blockchain data.
To provide the fastest service possible, some data feeds report blockchain data for the latest
block your node knows about, as soon as it learns about it.
As you can see above, the latest block your node is aware of -- the most recent block in the
Proposed state -- may be speculatively executed. Thus, you may see data about blocks that do
not ultimately become part of the Monad blockchain, although this is very rare.
This page gives an in-depth overview of how the
block state progression works, in case you want to consume real-time data and wish to understand
how speculative execution and real-time data reporting fit together.
To see an explicit example of how this relates to a real data feed, see the
WebSocket Guide section about
monadNewHeads, an extension to the
Geth newHeads data feed that
reports speculatively-executed blocks (those still in the Proposed state).

Footnotes​


Currently "latest" is actually mapped to Voted, but given the intended meaning of
"latest" in Geth, it will be changed shortly to Proposed. ↩

---

## Blocksync

> Source: https://docs.monad.xyz/monad-arch/consensus/blocksync

On this page

Summary​
Blocksync is a mechanism that nodes can use to acquire missing blocks. A block is considered missing when a Quorum Certificate is observed that references an unknown block.
Blocks can be missing from a node in one of two scenarios:

After the node completes statesync and its local block height is close enough to the network tip.
During ordinary consensus operations, the node does not receive enough RaptorCast chunks to decode the block. This can be due to packet loss or a network partition.

Blocksync procedure​

A single header request is made for a range of num_blocks blocks, starting with last_block_id.
A chain of num_blocks headers are received, forming a cryptographically verifiable chain back to last_block_.
For each of the num_blocks headers received, concurrent (up to a max concurrency factor) body requests are made containing the body_id included in the header.
Each body response is cryptographically verifiable by comparing against the corresponding header body_id.

---

## Concepts

> Source: https://docs.monad.xyz/monad-arch/concepts

📄️ Asynchronous I/OAsynchronous I/O is a form of input/output processing that allows the CPU to continue executing concurrently while communication is in progress.📄️ PipeliningPipelining is a technique for implementing parallelism by dividing tasks into a series of smaller tasks which can be processed in parallel.

📄️ Asynchronous I/OAsynchronous I/O is a form of input/output processing that allows the CPU to continue executing concurrently while communication is in progress.

📄️ PipeliningPipelining is a technique for implementing parallelism by dividing tasks into a series of smaller tasks which can be processed in parallel.

---

## Concepts

> Source: https://docs.monad.xyz/monad-arch/concepts/

📄️ Asynchronous I/OAsynchronous I/O is a form of input/output processing that allows the CPU to continue executing concurrently while communication is in progress.📄️ PipeliningPipelining is a technique for implementing parallelism by dividing tasks into a series of smaller tasks which can be processed in parallel.

📄️ Asynchronous I/OAsynchronous I/O is a form of input/output processing that allows the CPU to continue executing concurrently while communication is in progress.

📄️ PipeliningPipelining is a technique for implementing parallelism by dividing tasks into a series of smaller tasks which can be processed in parallel.

---

## Consensus

> Source: https://docs.monad.xyz/monad-arch/consensus/

MonadBFTTail-fork-resistant pipelined consensusRaptorCastEfficient block propagation of large blocks, utilized by leaders in MonadBFTAsynchronous ExecutionMoving execution out of the hot path of consensus so it can use the full block timeBlock StatesSummarizing the progression of Monad blocks from proposal to verificationLocal MempoolPolicies for sharing pending transactions to leaders while minimizing bandwidthStatesyncAlgorithms for bootstrapping a node from peersBlocksyncAlgorithms for catching up on missed trafficPeer DiscoveryHow nodes know where to find each otherMessage AuthenticationSignature schemes used in MonadTransport Protocol UsageTCP and UDP usage for node communication

---

## Execution

> Source: https://docs.monad.xyz/monad-arch/execution/

Parallel ExecutionOptimistic parallel executionMonadDbCustom database for storing the Ethereum Merkle Patricia Trie natively on SSDJIT CompilationHigh-performance execution of EVM bytecode by compiling to machine code

---

## JIT Compilation

> Source: https://docs.monad.xyz/monad-arch/execution/native-compilation

On this page

Summary​
Executing each EVM contract call to completion as quickly as possible is a key part of Monad’s overall performance. To do this, Monad uses both a highly optimized interpreter and a bespoke native-code compiler. The compiler analyzes frequently used contracts once and caches native code so subsequent calls execute more efficiently while preserving exact EVM semantics (including gas and error behavior).
Interpreting vs. Compiling​
Most Ethereum clients execute smart contract code one instruction at a time, checking stack bounds and available gas before applying the instruction’s semantics. This is an interpreter. Interpreters are straightforward to build and maintain, have low startup latency, and can perform very well when implemented with modern techniques.
An alternative is to compile programs. Before execution begins, code is analyzed and transformed into a representation that executes more efficiently. Compilation adds upfront latency and complexity, but it happens once per contract version. If repeated executions are faster, overall system performance improves.
For simplicity and portability, many compilers target a higher-level intermediate representation (e.g., LLVM IR or Cranelift). Because the Monad client targets a specific hardware configuration, the compiler emits native x86-64 directly to maximize control and performance while still matching EVM behavior exactly.
Eliminating Redundant Work​
Compilation lets us precompute behavior ahead of time. Consider this straight-line fragment:
JUMPDESTPUSH1 0x1ADDPUSH0JUMP
Once execution reaches the JUMPDEST, it must proceed through PUSH1, ADD, PUSH0 and JUMP. A pure interpreter would charge gas and perform checks for each instruction as it executes. A compiler can recognize the straight-line block and perform a single upfront gas check for the combined cost of the block (subject to EVM rules), then emit code that runs the block without per-instruction bookkeeping. The result is fewer CPU instructions while preserving identical gas accounting and out-of-gas semantics.
Constant folding is another example. Given:
PUSH1 0x2PUSH1 0x3ADD
the compiler can determine the stack state at ADD and fold it to:
PUSH1 0x5
internally, while still charging the same total gas as the original sequence and maintaining 256-bit modular arithmetic semantics.
Optimizing Code​
Beyond removing redundant work, the compiler chooses efficient implementations based on where operands reside. It maintains a simulated EVM stack that maps each 256-bit stack word to a location on the machine: main memory, a set of general-purpose integer registers, or a single AVX vector register. This approach is a combination of register allocation in a traditional optimizing compiler and stack caching techniques for compiling stack-based languages.
Each EVM instruction is then specialized to the operand locations it sees. For example, AND can be implemented with a single x86 vpand when both arguments are already in AVX registers. Much of the compiler’s effectiveness comes from emitting specialized sequences for common operand-location combinations.
Compilation Performance​
Compiling every contract ahead of time is impractical. Instead, the compiler tracks contracts by cumulative gas consumed over all executions and caches native code for the “hottest” ones. As blocks execute, newly hot contracts enter a compile queue. Compilation runs asynchronously, and contracts that are not yet compiled (or never become hot) continue to run on the highly optimized interpreter. The cache ensures repeated calls to popular contracts benefit from compilation without blocking execution on compile latency.

### Code Examples

```prism
JUMPDESTPUSH1 0x1ADDPUSH0JUMP
```

```prism
PUSH1 0x2PUSH1 0x3ADD
```

```prism
PUSH1 0x5
```

---

## Local Mempool

> Source: https://docs.monad.xyz/monad-arch/consensus/local-mempool

On this page

Summary​
Most blockchains use a global mempool with peer-to-peer gossipping for transaction propagation. This approach is not suitable for high-performance distributed consensus for a few reasons:

It is slow because it may involve many hops for a transaction to reach a leader, increasing time to inclusion.
It is wasteful on bandwidth because the gossip protocol involves many retransmissions.
It ignores the leader schedule which is typically known well in advance.

In Monad, there is no global mempool; instead, each validator maintains a local mempool, and RPC nodes forward transactions to the next few leaders for inclusion in their local mempool. This is much more efficient on bandwidth usage and allows transactions to be included more quickly.
Background​
A mempool is a collection of pending transactions. Many blockchain networks use a global mempool design, using peer-to-peer gossip protocols to keep roughly the same mempool state across all nodes in the network. A primary motivation of a global mempool design is that no matter who is leader, they will have access to the same set of pending transactions to include in the next block.
A global mempool is effective for low-throughput networks, where network bandwidth is typically not a bottleneck. However, at thousands of transactions per second, the gossip protocols (and especially the required retransmission at each node) can easily consume the entire network bandwidth budget. Moreover, a global mempool is wasteful since the leader schedule is typically known well in advance.
Transaction Lifecycle in Monad​
There is no global mempool in Monad. Validators maintain local mempools; RPC nodes forward transactions to upcoming leaders to ensure that those transactions are available for inclusion.
More precisely, transaction flow is as follows:

A transaction is submitted to the RPC process of a node (typically a full non-validator node). We'll call this node the "owner node" of the transaction, since it assumes responsibility for communicating the status with the user.
The RPC process performs some static checks on the transaction.
The RPC process passes the transaction to the consensus process.
The consensus process performs static checks and dynamic checks against local state in MonadDb, such as checking the sender's account balance and nonce.
If the transaction is valid, the consensus process forwards the transaction to N upcoming leader validator nodes. Currently, N is set to 3 in Monad testnet and mainnet.
Each of those N validators performs the same checks before inserting valid transactions into their local mempools.
When it is a leader's turn to create a proposal, it selects transactions from its local mempool.
The owner node of the transaction monitors for that transaction in subsequent blocks. If it doesn't see the transaction in the next N blocks, it will re-send to the next N leaders. It repeats this behavior for a total of K times. Currently, K is set to 3 in Monad testnet and mainnet.

The behavior of this transaction flow is chosen to reduce time-to-inclusion while minimizing the number of messages.
Transaction path from RPC to leader (through the local mempool).
Local mempool eviction​
Transactions are evicted from a validator's local mempool for the following reasons:

Whenever a validator finalizes a block, any replicas of transactions in that block are pruned from the local mempool.
Validators periodically check the validity of each transaction in the mempool and evict invalid transactions (e.g. nonces are too low, account balances are insufficient).
If the local mempool's size reaches a soft limit, older transactions will be evicted.

---

## Monad Architecture

> Source: https://docs.monad.xyz/monad-arch/

ConceptsExplaining high level themes (async io and pipelining) that recur in MonadConsensusAlgorithms for maintaining a globally distributed, decentralized validator setExecutionAlgorithms for executing EVM transactions efficientlyReal-time DataConsuming recent blockchain data as quickly as possibleTransaction LifecycleMapping the path of a transaction in Monad

---

## MonadBFT

> Source: https://docs.monad.xyz/monad-arch/consensus/monad-bft

On this page

Summary​
MonadBFT represents a major leap in Byzantine Fault Tolerant (BFT) consensus. It is responsible
for ensuring that the Monad network aligns on valid proposed blocks efficiently and securely,
while supporting 10,000+ tx/s and sub-second time-to-finality, while also supporting a large
consensus node set.
MonadBFT combines all of these properties while also being resilient to tail-forking, a
critical weakness of pipelined leader-based BFT protocols where a leader can fork away its
predecessor's block.
For a full description and deep technical dive into MonadBFT, please refer to the
full research paper, the
latest blog post from Category Labs and the
original blog post
introducing MonadBFT.
MonadBFT achieves:

Speculative finality in a single consensus round, and full finality in two rounds.
Linear message and authenticator complexity on the happy path (meaning under normal operations, when no failures occur). This allows the consensus
validator set to scale to a large number of nodes.
Optimistic responsiveness: round progression without
waiting for the worst-case network delay, both in the common case and while recovering
from failed rounds.
Leader fault isolation A single failed leader only incurs one timeout delay. All other
rounds are able to proceed as quickly as the network allows. This is in contrast to existing
pipelined BFT protocols, which have a two timeouts for a failed leader.
Tail-forking resistance: built-in protection against tail-forking, a
class of Maximal Extractable Value (MEV) attacks where a malicious leader could otherwise
fork away its predecessor's block. This resolves a critical issue in prior pipelined
leader-based BFT consensus mechanisms.

No other pipelined leader-based BFT protocol combines all these features.
noteCategory Labs has made several recent improvements to MonadBFT. This page and the research paper
have now been updated with full details. Find out what's new in the
Fast Recovery section or by reading this blog post.
Configuration in Monad​
Sybil resistance mechanismProof-of-Stake (PoS)Min block time400 msFinality2 slots (800 ms)Speculative finality (can only revert in rare circumstances requiring equivocation by the original leader)1 slot (400 ms)Delegation allowedYes
Demo​
See this
blog post from Category Labs for a live demo of MonadBFT!
The demo runs the exact implementation of monad-bft
that powers the live Monad blockchain, compiled to Wasm and run in your browser against a
simulation framework
(mock-swarm).
Common Concepts​
To explain MonadBFT, it helps to define a few concepts first. We will start with some
concepts common to many BFT mechanisms:
Byzantine threshold​
As is customary, let there be n = 3f+1 nodes, where f is the max number of Byzantine
(faulty) nodes. That is, 2f+1 (2/3) of the nodes are non-Byzantine. In the discussion
below, we treat all nodes as having equal stake weight; in practice all thresholds can be
expressed in terms of stake weight rather than in node count.
Supermajority​
>2/3 of the stake weight.
Round​
The protocol proceeds in rounds, also referred to as views. The round number increases by 1
with each step of the protocol regardless of whether a block proposal is successfully made.
Leader​
Each round has one leader who has the authority to make a block proposal. The leader rotates each
round according to a schedule determined previously using the stake weights.
Block​
A block consist of a round number, a payload (an ordered list of transactions), and a
QC. A block builds on a parent block, and includes a QC certifying
that parent block. Blocks are chained together via the parent relationship, which is why we called
it a blockchain.
Quorum Certificate (QC)​
Validators evaluate the validity of each block proposal and send their votes to the next leader. If
the next leader receives a supermajority of YES votes, they aggregate those votes into a
Quorum Certificate (QC) on that block proposal. A QC is proof that 2/3 of the network received and
voted YES on a block proposal.
Although this is more of an implementation detail, it is worth noting that in Monad's
implementation of MonadBFT, validators sign with BLS signatures
because those signatures can be efficiently aggregated, making signature verification on the
QC relatively inexpensive.
Linear communication​
Each round follows a fan-out fan-in pattern. The leader sends their block proposal to each validator
(using RaptorCast for efficient broadcast). Validators evaluate the block proposal
and send a signed vote directly to the next leader. This linear communication mechanism
contrasts with other protocols which rely on all-to-all (quadratic) communication; it allows
the consensus set to scale.
Concepts relatively unique to MonadBFT​
The following are concepts that are relatively unique to MonadBFT. We are splitting them out
to aid in comprehension.
For simplicity, we focus on the standard recovery in MonadBFT. The fast recovery optimizations
are explained in the Fast Recovery section.
Proposal​
A block proposal (often just called proposal) consists of the current round number, a block, an optional TC
or NEC, and a signature
(from the leader making the proposal) over the previous elements. In the simple case, optional
fields are blank and the round number is the same as the block's round number, such that the proposal
is basically a signed block. Sometimes, a block that failed to get traction gets reproposed; in
that case, the block will still have the round number from when it was first proposed, but the
proposal will have the round number of when it is reproposed.
Fresh Proposal​
A fresh proposal is a proposal containing a new block, i.e. one that is not
influenced by prior failed proposals.
A fresh proposal will either:

have a round number that is equal to its QC's round number plus 1.
This is the common case, when leaders are honest and online, and the network does not have
any abnormal delays.
have a TC identifying a high QC. This happens when a leader
recovers from a failed round (fast recovery).
have a NEC. This happens very rarely,
when a leader recovers from a more complex failure (standard recovery).

Reproposal​
A reproposal is a proposal containing a block from a previous fresh proposal that
the current leader is trying to revive or finalize. A reproposal will have a round number
greater than its QC's round number plus 1.
Whether a leader recovering from a failure has to repropose a previous block or not is determined
by the TC. If the TC contains a high tip (instead of a high QC), then
the block corresponding to the high tip must be reproposed. Reproposals are part of the standard
recovery. In practice, reproposals can often be skipped with fast recovery.
Tip​
A tip is a proposal minus the block's payload. You can think of it as the block header of the
proposal plus a bit of extra metadata, including the round number that that proposal was
received.
In MonadBFT, every validator keeps track of its latest tip, which is updated whenever the validator
votes for a proposal. If the validator votes for a reproposal, the tip is set to the original
proposal, not its reproposal.
High Tip​
Given a set of tips, high tip is just the tip with the highest round number. If there are multiple
such tips, then the tip that builds on the highest QC embedded in it is chosen.
Timeout Message​
A timeout message is a signed attestation that a validator produces when it hasn't received a
valid block from the scheduled leader in the expected time. The timeout message attests to the
lack of a valid block.
Each validator sends the timeout message to all other validators, utilizing all-to-all
communication.
Timeout messages are utilized in other BFT protocols. In MonadBFT, timeout messages include
the sender's tip - additional information about their view of the world which will be
utilized in MonadBFT to recover gracefully from the timeout.
For fast recovery, the timeout message contains the validator's highest QC, if it is of equal
or higher view than the view of the local tip.
Timeout Certificate (TC)​
When a timeout occurs, validators start sending and receiving timeout messages.
Each validator accumulates the timeout messages that it receives; if it gets to a supermajority
of such messages, it builds a Timeout Certificate (TC).
The TC includes information on all of the tips from all of the validators contributing timeout
messages. The high tip (for standard recovery) is also computed. In most cases, fast
recovery is possible, and the TC contains a high QC instead of a high tip.
No-Endorsement Message and No-Endorsement Certificate​
Under certain conditions, a leader will ask the other validators for the full proposal (block)
corresponding to a tip. If the validator doesn't have it, they will respond with a signed
No-Endorsement Message attesting to this.
If the leader gets a supermajority of No-Endorsement Messages when trying to recover the
proposal of a tip, they can produce a No-Endorsement Certificate - proof that a supermajority
of the network didn't have that proposal.
Block states due to MonadBFT​
Blocks can be in one of three states due to MonadBFT:

Proposed
Voted
Finalized

These are three of the four states that blocks can be in overall within Monad, as mentioned in
Block States. (The fourth state, Verified, is achieved outside of MonadBFT
as a part of Asynchronous Execution.)
Below, we describe how blocks progress through these states.
Happy Path​
The happy path describes the ordinary case of how a block goes from being proposed to being
finalized without any timeouts or failed rounds.
Scenario​
To describe the flow of the happy path, we'll follow the scenario shown in the diagram below.
It is currently round K and the scheduled leader is Alice. Bob and Charlie
are the next two leaders in the schedule. Alice has last seen block N-1, so she is
going to propose block N.


MonadBFT proceeds as follows.
Round K: Alice's proposal​


Proposal: Alice, the designated leader for round K, chooses a payload, i.e. a
list of transactions chosen from her mempool. She builds block N, consisting of the
payload and a QC from the previous proposal (don't worry about this part). Alice sends the
proposal consisting of that block directly to all other validators.


Voting: Each validator checks Alice's proposal for validity. If the proposal is valid,
the validator sends signed votes directly to Bob, the designated leader for round K+1, and
marks block N as Proposed.


QC Formation: Upon getting a supermajority of votes about Alice's proposal, Bob aggregates
the votes into a QC about Alice's proposal.


Round K+1: Bob's proposal​


Proposal: Bob chooses a payload. Bob combines the payload with the
QC from Alice's proposal to produce a new block, which he sends
to all other validators.


Voting: Each validator checks Bob's proposal for validity. If the proposal is valid,
the validator sends votes directly to Charlie, the designated leader for round K+2, and
marks block N as Voted (and block N+1 as
Proposed.)
This also means that the block can be speculatively finalized. This speculative finality
will only revert under very specific rare conditions, which also come with accountability.
More on this later.


QC Formation: Upon getting a supermajority of votes about Bob's proposal, Charlie
aggregates the votes into a QC about Bob's proposal. This QC can
also be thought of a QC-squared on Alice's proposal, since it is a QC attesting to the fact
that a supermajority received the QC about Alice's proposal.


Round K+2: Charlie's proposal​


Charlie's proposal: As before, Charlie builds a block, consisting of a new payload and
the QC on Bob's proposal. Charlie sends the proposal to everyone.


Voting: Each validator checks Charlie's proposal for validity. If the proposal is valid,
the validator sends votes directly to David, the designated leader for round K+3, and marks
block N as Finalized (and block N+1 as
Voted and block N+2 as
Proposed.)


Although we will stop describing the sequence at this point, the consensus mechanism continues
repetitively. As soon as each validator receives David's proposal (which contains a QC about
Charlie's proposal aka a QC-squared about Bob's proposal), they can mark Bob's proposal as
Finalized (and Charlie's as Voted). And so on.
This underscores the pipelining aspect of MonadBFT. Every round, a new payload and a new QC
about the previous proposal gets shared, allowing the parent proposal to be speculatively
finalized and the grandparent proposal to be fully finalized. You can see this here:
Illustrating the pipelined (staggered) nature of MonadBFT. Same diagram as the previous, but
zoomed out to include one more round.
Unhappy Path (Fault Handling)​
The unhappy path describes the abnormal case where either the leader fails to send out a valid proposal or
the QC builder (next leader) fails to build a QC.
Understanding the unhappy path is crucial to understanding how the happy path works as well!
The thing that ultimately allows a validator to speculatively finalize a proposal after
receiving the child proposal, or finalize a proposal after receiving the grandchild proposal,
is knowing that the fallback mechanism will still preserve the original proposal.
Here, we will focus on the standard recovery, which is actually the fallback of the fallback
mechanism. In most cases in practice, we can use fast recovery, which substantially
speeds up the time for the protocol to go back to the happy path after a failure occurs.
However, for the protocol as a whole to achieve the tail forking resistance, even in the worst
case of Byzantine failures, we rely on the standard recovery, which we now present.
Scenario​
As before, to describe the flow of the unhappy path, we'll follow a scenario shown in a diagram.
Again, suppose that it is currently round K and Alice is the scheduled leader. Bob and
Charlie are the next two leaders in the schedule. Alice has last seen block N-1, so she is
going to propose block N.
In our example, Alice sends block N at round K, but Bob fails to send a block at round K+1.
This could be because he was offline, or it could be that Alice either sent an invalid block,
or not enough people voted for it.

Round K: Alice's proposal​


Proposal: Alice, the designated leader for round K, chooses a payload and
builds block N, consisting of the payload and a QC from the
previous proposal (again, don't worry about this part).
Alice sends the proposal directly to all other validators.


Voting: Each validator checks the proposal for validity and, if valid, sends signed
votes directly to Bob, the designated leader for round K+1. Each validator marks Alice's
proposal locally as Proposed.


When round K+1 was expected: Bob's missed slot​


Bob fails to propose block N+1, so all votes are blackholed and no QC for Alice's
block is produced.


Everyone sends timeout messages: After a timeout window, each validator "realizes" that
round K has failed since no QC is formed for Alice's block. Therefore, everyone sends a
timeout message about block K to every other validator. (Note that this
communication is all-to-all.)


TC assembly: Upon getting a supermajority of timeout messages, every validator including
Bob assembles a TC, proving that round K (Alice proposer, Bob
QC builder) failed. Upon building a TC for K, validators advance their round to K+1.


Round K+1, as progressed by TC​
The TC contains a computed value called high_tip, which (roughly speaking)
is the block header of the latest valid block that any of the validators contributing to
the timeout message have seen. You can think of high_tip as the max block observed over
the 2/3 of the stake weight required to sign the TC.
In this specific example, high_tip will be the block header of Alice's block.
Under the rules of MonadBFT, the next leader is obligated to either re-propose the block
referenced in high_tip of the TC (i.e. Alice's block), or to prove that that block is
unsupported. (We'll discuss this in more detail below.)
Since we are now in Round K+1, the next leader is Bob. (You might find this ironic, but it
is a necessary consequence of the fact that the protocol cannot distinguish between the
possibility that Bob was offline, and the possibility that either Alice sent an invalid block
or not enough people voted on Alice's block. In either of the latter cases, it would be
unfair to skip Bob.)

(Optional) Requesting Alice's block from other validators: Bob needs to re-propose Alice's
block. However, the high_tip is only a block header - not the full block body - so if Bob
doesn't have Alice's block, he can request the full version from the other validators (via
blocksync).

Reproposal case (Bob re-proposes Alice's block)​


Reproposal: If Bob has Alice's block (either due to already receiving it when he
originally proposed it, or via blocksync) then he proposes it along with the TC justifying
the re-proposal.


Voting: Each validator votes on the validity of Bob's reproposal. If the reproposal
is valid, validators send their votes to the next leader, Charlie.


QC Formation: Charlie assembles a QC from the votes.


Charlie's proposal: Charlie builds a block at round K+2, consisting of a new payload and
the QC on reproposal from round K+1, and sends the block to everyone. At this point Alice's
block becomes Voted to anyone who receives Charlie's block.
Everyone advances their rounds to K+2 and the protocol returns to the happy path.


Fresh proposal case (Bob proves Alice's block is unsupported)​


No-Endorsement of Bob's block: Recall that in step 6, Bob was allowed to poll
the other validators for Alice's block. When a validator is polled, if they also don't
have it, they can send Bob a signed
No-Endorsement Message attesting
to not having seen Alice's block. If a supermajority of the validators sign
No-Endorsement Messages, then Bob may assemble a
No-Endorsement Certificate (NEC).


Bob's fresh proposal: Under the rules of MonadBFT, Bob may skip re-proposing
Alice's block, and instead make a fresh proposal of a new block (at the
same block height N) if he can also supply a NEC.
It's important to emphasize that Bob is only allowed to skip reproposing Alice's
block if a supermajority of validators sign the NEC. Otherwise, he is obligated to re-propose.
This rule helps ensure that Alice's block finalizes even though Bob failed to build a QC for
Alice's block.
From this point, consensus proceeds normally, returning to the happy path.


No proposal case​
There is a third possibility, which is that Bob fails to propose anything at all in round K+1.
(This is fairly likely, because he failed to send a block the first time that round K+1 was
expected.) In this case, a timeout occurs again, this time of round K+1, allowing consensus
to move to round K+2, Charlie's turn. Charlie then inherits the situation Bob was in in round
K+1, i.e. he must either re-propose Alice's block, or prove that Alice's block is unsupported.
More generally, if Charlie (and maybe a few subsequent leaders) also fail to propose anything,
the situation will persist until someone either re-proposes Alice's proposal or proves that it is
unsupported. That's the MonadBFT rule about the high_tip, and it ensures that Alice's block
will eventually finalize unless it never should have been supported.
Discussion​
No-Tail-Forking​
In prior implementations of pipelined HotStuff-family consensus protocols, the case where Bob misses his slot results
in Alice's proposal also being rolled back (tail forked). The intuition behind this is: Bob is
the only person responsible for receiving everyone's votes on Alice's proposal, so when he goes
offline, all of those votes are blackholed, making it hard to distinguish between the case
where most validators voted YES for Alice's proposal and the case where most validators
rejected her proposal.
For instance, in Fast-HotStuff, TCs carry enough information to prove that Bob missed his slot, allowing
Bob  to justifiably propose a block that skips Alice's block, making Alice's
block a casualty. Bob simply re-proposes the same block height as Alice did,
replacing Alice's block in the final blockchain. This is the reason why pipelined HotStuff
consensus mechanisms prior to MonadBFT frequently see pairs of missed slots.
Tail forking is a serious weakness. When Alice’s block is proposed, if Bob sees valuable MEV opportunities in it, Bob—as QC builder (next leader)—may refuse to build the QC for Alice’s block and to propose his own block carrying Alice’s QC. In this case, validators cannot detect whether Alice failed to propagate her proposal or Bob refused to build a QC; therefore Bob is given an opportunity in round K+1 to propose a block. Bob can then extract high-value MEV by selecting only preferred transactions, and by reordering or replacing them at will. In other blockchains, unintentionally allowing blocks to be re-mined has resulted in massive impact.
The key to MonadBFT's No-Tail-Forking property lies in the handling of the missed slot
situation. Intuitively speaking, in MonadBFT, TCs carry enough
information to propagate the knowledge of the existence of Alice's block forward even when Bob
blackholes all of the votes about it.
When it becomes Bob's turn to propose, he is obliged to re-propose Alice's block (based on the TC,
which includes high_tip, aka a valid block header for Alice's block) unless he can get a
supermajority (2f+1) to attest to not seeing Alice's block. The fact that a supermajority
sign the NEC
is key: even if f nodes are Byzantine, that still leaves f+1 non-Byzantine nodes attesting
to not seeing Alice's block, which guarantees that Alice's block should not have achieved
quorum since quorum requires 2f+1 votes and there were at least f+1 non-Byzantine NO votes.
The MonadBFT paper provides a far more robust definition
of the protocol, and a formal proof that tail-forking cannot occur.
Speculative Finality​
The other extremely nice property of MonadBFT is one-slot speculative finality.
To explain this, it is first helpful to issue a reminder that a block's state is always from
the perspective of a particular observer. For example, if you receive a QC for a block, then
you can move that block to the Voted state, but if your friend didn't
receive that QC yet, then she would still consider that block to be in the
Proposed state.
The challenge of building a distributed consensus mechanism lies in defining rules that allow
nodes to individually update their state machines in response to messages even while assuming
the worst, i.e. even while assuming that they might be the only one that received that message.
After receiving Alice's Proposal​
Say that you are Valerie, one of the validators in the network. You receive Alice's proposal;
you run the validity checks on it and they pass, so you mark Alice's proposal as
Proposed.
Note that you don't know if anyone else has received this proposal, Alice could be being tricky
and have only sent the proposal to you (or to a very small number of nodes) in an attempt to
get you to diverge from everyone else.
After receiving Bob's Proposal​
Now say you receive Bob's proposal, which carries a QC for Alice's proposal. You run validity
checks on Bob's proposal and they pass, so you mark Alice's proposal as
Voted.
Again, although you now possess proof that a supermajority voted for Alice's proposal, you
should be worried that Bob might be trying to trick you by only sending this to you. You
should be worried that Bob's proposal doesn't reach quorum.
The superpower of MonadBFT is that, due to the complicated set of rules for handling a timeout
described earlier, when you are in Valerie's position of having received Bob's proposal, you
can mostly overpower that fear, at least as it pertains to the status of Alice's proposal. You
may speculatively finalize Alice's proposal upon moving it to the Voted stage. That is,
you can be confident that Alice's proposal will almost certainly end up being finalized, unless
a very specific set of rare circumstances arises.
Intuitively, this makes sense given what we said above. You, Valerie, possess a QC for Alice's
block, assembled by Bob. That actually means that, from your point of view, Bob was not offline.
And even if Bob were effectively offline to most people (e.g. he only sent the next
proposal and QC-on-Alice's-block to you), you know that the procedure will be to assemble a
TC; that the high_tip in that TC will probably point to Alice's block. Why? Because:

the QC in your hands proves that a supermajority (2f+1) has seen Alice's block,
the TC will also require a supermajority (2f+1)
So at least f+1 voters will be common to both the QC and TC, and at most f are
Byzantine, so at least 1 will reference Alice's block.

And if Alice's block makes it into high_tip, then Charlie will be forced to re-propose it
(unless he could get a NEC on it, which he can't because that would require
No-Endorsement Messages from a supermajority, when a supermajority already signed a QC on
Alice's block).
So at first glance it seems like we, Valerie, might be able to finalize Alice's block as soon
as we receive a QC on it.
The only loophole​
It turns out that there is one loophole which prevents us from being so confident. The loophole
arises if Alice equivocated -- signed a second block b' at the same height as the first
block b (which we have a QC for), and sent b' to a few nodes.
Under those circumstances, in the event where Bob sent his proposal only to us before going
offline, then it is possible that high_tip in the resultant TC will resolve to b' instead
of b. If that were to happen, then Charlie could end up either re-proposing b', or
collecting an NEC on b' and using that to justify proposing a new block at Alice's block
height.
In practice, this loophole is extremely rare for several reasons:


Equivocation is an easily provable fault - all you need as evidence is both blocks at the
same height both signed by Alice. Equivocation is a huge deal in blockchains, and can be
severely punished.


When Alice equivocates, she is only potentially disrupting herself (while also exposing
herself to punishment for equivocation).


The MonadBFT paper provides a much more rigorous version
of this argument. But in summary, locally observing a QC (moving a proposal to Voted) is a
very strong indicator that the proposal will finalize, since the only way it won't is if Alice
equivocated, Bob missed his slot, almost 1/3 of the network was Byzantine, and we still got
quite unlucky with respect to which nodes ended up populating the TC.
Fast Recovery​
Since releasing the original MonadBFT paper in early 2025,
Category Labs has analyzed the protocol’s behavior and designed, evaluated, and implemented
several improvements.
The protocol changes allow for fast recovery in the most common failure scenarios.
This blog post gives a great introduction to how fast recovery
works. In summary:

Validators now send their votes not only to the leader of the next view, but also to the leader of
the current view. This gives each leader a chance to collect votes for its own proposal to
form a QC, rather than relying solely on the next leader (who may be Byzantine). The leader
broadcasts this QC.
Validators can include the highest QC that they have observed in their timeout message, instead
of the tip. They do so if the QC is fresher (more recent) than the locally highest tip or produced in the same
round as the tip.
If a validator sends a tip (instead of a high QC) in a timeout message, the validator also
includes a tip vote, i.e., a vote for that tip with the current view number. 2f+1 votes
for the same proposal in the same view, obtained via regular votes or timeout messages can be
combined to form a new QC that can directly be extended by the next leader.
The timeout certificate includes the highest QC of the received timeout messages if it is at least
as high as the highest tip. It also contains proof that the correct high tip or high QC was chosen.
If the TC contains the high QC, then the leader can directly propose a fresh block extending that high QC.

These mechanisms enable faster recovery in the most common failure scenarios. For example, consider a
situation where the leader in view v is offline. In the original MonadBFT protocol, this would cause
views v-1 and v to time out (since the votes cast in v-1 are lost, and no block is proposed in
view v). Additionally, the block proposed in view v-1 would have to be reproposed in view v+1,
resulting in two consecutive views without a fresh block proposal.
With the updated protocol, several mechanisms enable faster recovery. For instance, in the timeout
message of view v, each validator includes a tip vote for the block proposed in view v-1. This
allows the leader of view v+1 to construct a QC in view v. Since no two conflicting QCs can be
formed in the same view, the leader of v+1 can directly propose a fresh block extending this QC.
As a result, a single crashed leader only causes the leader's view to time out; all other views
succeed, and in each of them, a fresh block is proposed.
The other mechanisms similarly provide fast recovery options. We still retain the reproposal and
NEC
mechanisms from the original MonadBFT paper to address more complex Byzantine failures. However,
with these improvements, we believe most failures can now be handled smoothly via the new fast
recovery paths.

References​

Mohammad Mussadiq Jalalzai, Kushal Babel.
MonadBFT: Fast, Responsive, Fork-Resistant Streamlined Consensus, 2025.
Maofan Yin, Dahlia Malkhi, Michael K. Reiter, Guy Golan Gueta, and Ittai Abraham.
HotStuff: BFT Consensus in the Lens of Blockchain, 2018.
Mohammad M. Jalalzai, Jianyu Niu, Chen Feng, Fangyu Gai.
Fast-HotStuff: A Fast and Resilient HotStuff Protocol, 2020.
Rati Gelashvili, Lefteris Kokoris-Kogias, Alberto Sonnino, Alexander Spiegelman, and Zhuolun Xiang.
Jolteon and ditto: Network-adaptive efficient consensus with asynchronous fallback.
arXiv preprint arXiv:2106.10362, 2021.
The Diem Team.
DiemBFT v4: State Machine Replication in the Diem Blockchain, 2021.

---

## MonadDb

> Source: https://docs.monad.xyz/monad-arch/execution/monaddb

On this page

Summary​
MonadDb is a critical component in Monad for maintaining full Ethereum compatibility while delivering high performance. It is a custom-built key-value database designed for storing authenticated blockchain data. MonadDb, specifically, is optimized for efficiently storing Merkle Patricia Trie nodes on disk.
Merkle Patricia Trie Structured Database​
Most Ethereum clients use generic key-value databases that are implemented as either B-Tree (e.g. LMDB) or LSM-Tree (e.g. LevelDB, RocksDB) data structures. However Ethereum uses the Merkle Patricia Trie (MPT) data structure for storing state and other authenticated fields like receipts and transactions. This results in a suboptimal solution where one data structure is embedded into another data structure. MonadDb implements a Patricia Trie (a specific variant of radix tree) data structure natively, both on-disk and in-memory. Despite the opinionated design, MonadDb is a flexible key-value store capable of storing any type of data. For instance, MonadDb is also used to store block headers and payloads for Monad.
Asynchronous IO​
Monad executes multiple transactions in parallel. In order to enable this, reads should not block continued operation, and this goal motivates asynchronous I/O (async I/O) for the database. The above-mentioned key-value databases lack proper async I/O support (although there are some efforts to improve in this area). MonadDb fully utilizes the latest kernel support for async I/O (on Linux this is io_uring). This avoids spawning a large number of kernel threads to handle pending I/O requests in an attempt to perform work asynchronously.
Filesystem bypass​
Modern filesystems provide a convenient abstraction for applications, but introduce overhead when building high-throughput I/O software. These often hidden costs include block allocation, fragmentation, read/write amplification, and metadata management. The abstraction of files and a set of system calls allows applications to interact with the file data as if it were stored contiguously. The complexity of managing exact physical disk locations is abstracted away from the applications (and their developers). However, the actual content on disk might be fragmented into multiple non-contiguous pieces.  Accessing or writing to such a file usually involves more than one simple I/O operation.
To minimize overhead, MonadDb provides operators the option to bypass the filesystem. MonadDb implements its own indexing system based on the Patricia trie data structure, eliminating filesystem dependencies. Users have the flexibility to operate MonadDb on either regular files or block devices. For optimal performance, it is recommended to run MonadDb directly on block devices. This approach avoids all filesystem-related overhead, allowing MonadDb to fully unlock SSD performance.
Concurrency Control​
The Monad blockchain consists of multiple clients, each interacting with the database as either reader or writer. To support this functionality, MonadDb must efficiently synchronize between a single writer (execution) and multiple readers (consensus and RPC).
MonadDb implements a persistent (or immutable) Patricia trie. When a branch in the trie is updated, new versions of the nodes on that branch are created, and the previous version of the trie is preserved. This approach facilitates versioning within the database and significantly simplifies synchronization between readers and the writer. It ensures that all reads are accurate and consistent while guaranteeing that writes are both complete and atomic from the perspective of the readers.
Write Performance on Modern SSD​
The usage of a persistent data structure also allows us to perform sequential writes, which offers better performance than random writes on modern SSDs. Modern SSD garbage collection occurs at the block level. On sequential writes, an entire block gets filled before the next one, which dramatically simplifies garbage collection. Garbage collection is much more expensive for random writes. Sequential writes also distribute data more efficiently, thereby reducing write amplification and increasing SSD longevity.
Compaction​
As historical versions accumulate, the amount of data written to disk will grow. Given the limited disk capacity it operates on, it is impossible to retain complete historical records. MonadDb stores recent versions of blockchain data and state and dynamically adjusts the history length based on available disk space. As newer versions are stored and older versions are pruned, the underlying storage space becomes fragmented. To address this, MonadDb performs compaction inline with updates, consolidating active data and releasing unused storage for recycling. This reduces fragmentation while maintaining performance and data integrity.

---

## Parallel Execution

> Source: https://docs.monad.xyz/monad-arch/execution/parallel-execution

On this page

Summary​
Monad executes transactions in parallel.  While at first it might seem like this implies different execution semantics than exist in Ethereum, it actually does not.  Monad blocks are the same as Ethereum blocks - a linearly ordered set of transactions.  The result of executing the transactions in a block is identical between Monad and Ethereum.
Optimistic Execution​
At a base level, Monad uses optimistic execution. This means that Monad will start executing transactions before earlier transactions in the block have completed.  Sometimes (but not always) this results in incorrect execution.
Consider two transactions (in this order in the block):

Transaction 1 reads and updates the balance of account A (for example, it receives a transfer from account B).
Transaction 2 also reads and updates the balance of account A (for example, it makes a transfer to account C).

If these transactions are run in parallel and transaction 2 starts running before transaction 1 has completed, then the balance it reads for account A may be different than if they were run sequentially.  This could result in incorrect execution.
The way optimistic execution solves this is by tracking the inputs used while executing transaction 2 and comparing them to the outputs of transaction 1.  If they differ, we have detected that transaction 2 used incorrect data while executing and it needs to be executed again with the correct data.
While Monad executes transactions in parallel, the updated state for each transaction is "merged" sequentially in order to check the condition mentioned above.
Related computer science topics are optimistic concurrency control (OCC) and software transactional memory (STM).
Optimistic Execution Implications​
In a naïve implementation of optimistic execution, one doesn't detect that a transaction needs to be executed again until earlier transactions in the block have completed.  At that time, the state updates for all the earlier transactions have been merged so it's not possible for the transaction to fail due to optimistic execution a second time.
There are steps in executing a transaction that do not depend on state. An example is signature recovery, which is an expensive computation.  This work does not need to be repeated when executing the transaction again.
Furthermore, when executing a transaction again due to failure to merge, often the account(s) and storage accessed will not change.  This state is still be cached in memory, so again this is expensive work that does not need to be repeated.
Further Work​
There are other opportunities to avoid re-executing transactions which are still being explored.

---

## Peer Discovery

> Source: https://docs.monad.xyz/monad-arch/consensus/peer-discovery

On this page

Summary​
Peer discovery enables a new validator or full node to join the network by connecting with
other existing nodes, in order to receive consensus messages necessary to validate and
keep up to the chain tip.
To participate in peer discovery, a node needs to generate a MonadNameRecord, which
contains the socket address of the node, a sequence number, and the signature over the
socket address and sequence number using its secp key. Currently only IPv4 addresses
are supported.
struct MonadNameRecord {  address: std::net::SocketAddrV4,  seq: u64,  signature: SecpSignature,}
The socket address is the network address at which other nodes in the network may
contact it. A sequence number is necessary to ensure newer name records take priority
over older name records. For example, when a node sees a peer's name records with a
higher sequence number, it will update its routing table with the new name record.
A node specifies a few bootstrap nodes and their name records when starting up. Bootstrap
nodes are not specialized nodes; any node in the network can be a bootstrap node. The
node will then advertise its own name record by sending pings to other peers, where the
ping message contains its own name record. The node also sends lookup request to its peers
when it is missing name records of current active validators. Periodically, the node looks
for new nodes or prunes excessive nodes depending on the min and max number of peers
configured.

### Code Examples

```prism
struct MonadNameRecord {  address: std::net::SocketAddrV4,  seq: u64,  signature: SecpSignature,}
```

---

## Pipelining

> Source: https://docs.monad.xyz/monad-arch/concepts/pipelining

Pipelining is a technique for implementing parallelism by dividing tasks into a series of smaller tasks which can be processed in parallel.
Pipelining is used in computer processors to increase the throughput of executing a series of instructions sequentially at the same clock rate. (There are other techniques used in processors to increase throughput as well.)  More about instruction-level parallelism (ILP) can be read here.
A simple example of pipelining:
Pipelining laundry day. Top: Naive; Bottom: Pipelined. Credit: Prof. Lois Hawkes, FSU
When doing four loads of laundry, the naive strategy is to wash, dry, fold, and store the first load of laundry before starting on the second one.  The pipelined strategy is to start washing load 2 when load 1 goes into the dryer.  Pipelining gets work done more efficiently by utilizing multiple resources simultaneously.

---

## RaptorCast

> Source: https://docs.monad.xyz/monad-arch/consensus/raptorcast

On this page

Summary​
RaptorCast is a specialized multicast message delivery protocol used in MonadBFT to send block proposals from leaders to validators. Block proposals are converted into erasure-coded chunks using the Raptor code in RFC 5053. Each chunk is sent to all validators through a two-level broadcast tree, where the first level is a single non-leader node. Each non-leader node is responsible for serving as the first-level node for a different set of chunks; the proportion of chunk assignments is equal to the validator's stake weight.
RaptorCast thus utilizes the full upload bandwidth of the entire network to propagate block proposals to all validators, while preserving Byzantine fault tolerance.
tipCheck out this blog post by Category Labs for a full briefing on RaptorCast's data transmission, erasure coding, and broadcast strategy.
Introduction​
infoThe technical description of RaptorCast below relates to block propagation amongst validator nodes participating in consensus. In particular, block propagation to full nodes is handled differently.
In MonadBFT, leaders need to send block proposals to every validator. Getting block proposals from a leader to the rest of the network is one of the challenging problems in high-performance distributed consensus because block proposals are large and the network is not reliable.
Consider the following two naive approaches to addressing this problem:


Sending messages directly from the leader to each validator. This is the simplest approach, but it would impose very high upload bandwidth requirements for a leader because block proposals are large - for example, 10,000 transactions at 200 bytes per transaction is 2MB.


Sending messages from the leader to a few peers, who each re-broadcast to a few peers. This approach would reduce the upload bandwidth requirements for the leader, but it would increase maximum latency to all of the nodes, and it risks message loss if some of the peers are Byzantine and fail to forward the message.


RaptorCast is the multicast message delivery protocol that solves this problem, offering the best tradeoff between bandwidth requirements, latency, and fault-tolerance. RaptorCast was developed specifically for MonadBFT, and satisfies the following requirements.
In the below discussion, the "message" is the block proposal, and the "message originator" is the leader.
Design requirements​


Reliable message delivery to all participating consensus nodes is guaranteed if a 2/3 supermajority of the stake weight is non-faulty (honest and online).


Upload bandwidth requirements for a validator are linearly proportional to message size and are independent of the total number of participating validators.1




The worst-case message propagation time is twice the worst-case one-way latency between any two nodes. In other words, the propagation of a message to all intended recipients happens within the round-trip time (RTT) between the two most distant nodes in the network.


Messages are transmitted with a configurable amount of redundancy (chosen by the node operator). Increased redundancy mitigates packet loss and reduces message latency (recipient can decode sooner and more quickly).


How RaptorCast works​
Erasure coding​
Messages are erasure-coded by the message originator. Erasure coding means that the message is encoded into a set of chunks, and the message can be decoded from any sufficiently-large subset of the chunks.
The specific code used by RaptorCast is a variant of the Raptor code documented in RFC 5053, with some Monad-specific modifications to

improve the encoding efficiency of small messages
reduce the computational complexity of message encoding (at the cost of a slight increase in decoding complexity)

Message and chunk distribution model​
RaptorCast uses a two-level broadcast tree for each chunk. The message originator is the root of the tree, a single non-originator node lives at level 1, and every other node lives at level 2.
Each chunk of the encoded message potentially corresponds to a different broadcast tree, but the current implementation uses the same broadcast tree for contiguous ranges of the encoded message chunk space.
The following diagram illustrates this chunk distribution model:
Generic view of the two-hop Raptorcast broadcast tree.
Using a two-level broadcast tree minimizes latency for message delivery. Each level of the tree has worst-case latency of the one-way latency between any two nodes in the network (the network’s “latency diameter”), so the worst case delivery time under RaptorCast is the round-trip-time of the network.
Fault tolerance​
infoRaptorCast runs directly over UDP, with a single message chunk per UDP packet.
Note that the broadcast tree is unidirectional. Unlike TCP, RaptorCast does not include a recovery mechanism for downstream nodes in the tree to detect packet loss and request retransmission, since this would violate latency expectations. To compensate, RaptorCast transmits the message in a redundant fashion, with a redundancy factor chosen by the message originator based on the network’s expected packet loss.
For example, under the following assumptions:

20% network packet loss
maximum 33% of the network is faulty or malicious

then the message originator should expect in the worst case that (1 - 0.2) * (1 - 0.33) or ~53.6% of chunks reach the intended destination. To offset that worst case loss, the originator should send 1 / 0.536 - 1 or roughly 87% additional chunks.
The default MTU used is 1480 bytes. After subtracting RaptorCast header overhead for the default Merkle tree depth of 6, this leaves 1220 bytes per packet for an encoded Raptor payload.  A 2.000.000 byte block maps to 2e6 / 1220 = 1640 source chunks. Using the current redundancy factor of 3, 4920 encoded chunk will then be distributed to other validators by proportionate stake weight.
If there are 100 validators, those 4920 encoded chunks will be divided into 99 (the originator is excluded) distinct chunk ranges and the leader will initiate a broadcast tree for each validator corresponding to its unique chunk range (and payload). If the validators had equal stake, each would receive 4920 / 99 = 50 chunks in contiguous ranges.
A 2 MB block is split into chunks, expanded and disseminated.
Note that the two-stage distribution model allows participating consensus nodes to receive a copy of a message even if direct network connectivity with the message originator is intermittently or entirely faulty.
RaptorCast used to send erasure-encoded chunks from a leader to each validator.
The message originator (leader) typically2 distributes generated chunks to the first-hop recipients according to stake weight. For example:

Validator 1 has stake 1
Validator 2 has stake 2
Validator 3 has stake 3
Validator 4 has stake 4

When Validator 1 is the leader, they will send:

2 / (2 + 3 + 4) of generated chunks to validator 2
3 / (2 + 3 + 4) of generated chunks to validator 3
4 / (2 + 3 + 4) of generated chunks to validator 4

The leader currently sends chunks in contiguous ranges but development work is currently being done to enable dissemination at a more granular level. With the new algorithm, individual or much smaller sets of chunks would be sent randomly to first-hop validators without replacement, weighted by stake. This approach produces better utilization of the network as all validators can start processing chunks as they arrive and send for redistribution (start the second-hop).
Chunk transport integrity​
The originator signs every encoded chunk, so intermediate nodes (level one) in the broadcast tree can verify the integrity of an encoded chunk before forwarding it.
Furthermore, the number of source chunks K is encoded in the message. For given K, the recipient currently accepts encoded chunks in the range of 0 to 7 * K - 1. This gives the originator sufficient freedom to specify a high degree of redundancy (up to 7), while also limiting the potential for network spam by a rogue validator.
To amortize the cost of generating and verifying these signatures over many chunks, RaptorCast aggregates contiguous ranges of encoded message chunks in variable-depth Merkle trees, and produces a single signature for every Merkle tree root.
Other uses of RaptorCast​
RaptorCast is not only used for broadcasting a block in chunks from the leader.
Transaction forwarding​
Transaction forwarding, e.g. from a full node to the next three validator hosts, is
performed via RaptorCast, benefiting from its properties of speed and robustness. In this
context, only one hop is required - the receiver should not rebroadcast.
Secondary RaptorCast - full node block propagation​
RaptorCast is also used to disseminate block proposals to full nodes. As described in
full node configurations, each participating
validator creates a secondary RaptorCast network rooted in itself, utilizing full nodes
as the recipients. Full nodes are added to a validator's secondary RaptorCast group
if they are prioritized by the validator, or if they are running in public mode and
are selected by the selection algorithm.
Each validator, after reconstructing the proposal, can disseminate
all received (or produced) chunks to full nodes via dedicated relationship or
secondary RaptorCast.
Secondary RaptorCast mirrors the primary RaptorCast diagram above. Under secondary
RaptorCast, the originator is now any validator, and the group receiving chunks is a collection
of public and prioritized full nodes, rather than the stake-weighted validator set. All
full nodes in secondary RaptorCast receive an equal number of chunks (no stake-weight applicable).
In terms of bandwidth, secondary RaptorCast is much more efficient than dedicated full nodes,
because the upload bandwidth requirement for the validator is constant, rather than scaling
linearly for the number of dedicated full nodes. Similar to primary RaptorCast, by adding a
second hop, the burden of dissemination is borne more evenly by the participants in the group.

Footnotes​


This holds when participating validators are (approximately) equally staked. In situations with (very) unevenly distributed stake weights, we need to deviate from the equal-upload property in order to maintain reliable message delivery for every possible scenario where two-thirds of the stake weight corresponds to non-faulty nodes. ↩


The pure stake-weighted distribution scheme can break down when the number of required chunks is sufficiently small, e.g. 12 chunks distributed to 100 validators. This corner case is actively being addressed. ↩

---

## Real-time Data

> Source: https://docs.monad.xyz/monad-arch/realtime-data/

Real-Time Data SourcesHow Monad reports real-time blockchain dataSpeculative Real-Time DataAn optimization for reporting real-time data with very low latency

---

## Real-Time Data Sources

> Source: https://docs.monad.xyz/monad-arch/realtime-data/data-sources

On this page

For many use cases, developers and users can access current and historical
data for the Monad blockchain via the JSON-RPC interface.
This is not the most efficient way to receive data about the latest blocks,
however. The traditional JSON-RPC access methods use a request/response
model (which requires polling) instead of a notification model, where new
updates are pushed to you as soon as they happen.
warningBecause the Monad blockchain is much faster than other EVM-compatible
L1 blockchains, the traditional JSON-RPC methods may not provide enough
performance if you consume a lot of data, even if they've worked for you on
other EVM ecosystems. The next section explains why in detail.
Why might I need real-time data, even if I didn't before?​
Monad is a fast blockchain capable of thousands of transactions per second:
when the Monad ecosystem runs at peak rates there is much more data per second
than in other L1 EVM-compatible blockchains such as mainnet Ethereum.
The data ecosystem of original Ethereum evolved around a network that ran at
less than 100 TPS, so certain data query patterns that work there might not
perform well enough when the amount of data is almost 100 times larger.
A classic example is an indexer workflow of fetching data about every
transaction and every log in a block, using JSON-RPC methods like
eth_getLogs. A typical Ethereum block will have hundreds of transactions in
it, and there will be one new block every 12 seconds or so. For Monad, there
are 2.5 blocks every second, and each block can contain thousands of
transactions.
The number of eth_getLogs requests would be almost 100 times greater, putting
a strain on the JSON-RPC service provider. Using real-time data services can
help. Such services exist on other EVM blockchains too, but they're essential
in more situations for Monad.
How do I receive real-time data?​
Monad currently offers three sources of real-time data, which offer different
trade-offs in latency vs. complexity.
Source #1: Geth-compatible real-time events​
This is a WebSocket-based protocol
that originated in the Geth Ethereum client but is widely supported by other
EVM-compatible blockchains. Monad implements the eth_subscribe method and
the newHeads and logs subscription types. The syncing and
newPendingTransactions subscription types are not supported.
The newHeads and logs subscriptions wait for block finalization, so they
have one additional feature that the original Geth implementation does not:
you do not need any logic to handle chain reorganizations, because they are
not possible. You will never see the same block number more than once, and
logs will never be removed. For this reason, however, this is the slowest
of the real-time data sources.
This real-time data feed is published by the Monad RPC server component.
Source #2: Monad extensions to Geth real-time events​
The Monad RPC server also offers an extension to the Geth protocol; it
provides eth_subscribe subscriptions called monadNewHeads and monadLogs.
These publish almost the same data as the Geth real-time events protocol,
and the data is published sooner -- by about one second on average -- but on
a speculative basis.
This makes data available as soon as possible, but requires the user to
understand speculative execution and how it affects real-time data. You can
read more about these subscriptions in the WebSocket Guide.
Source #3: Execution events SDK​
This is the fastest way to consume real-time data. It requires you to write
your own real-time data processing software using the Monad client SDK in C,
C++, or Rust -- and then run it alongside your own Monad node.
This is the source of data that powers the other two access methods: it is
what the RPC server itself is listening to, to create the WebSocket feeds.
It has its own documentation.
Comparison of data offerings​
Data offeringHow to consumePublished byAvailablityTransaction-level infoWhen data is publishedGeth real-time eventsWebSocketRPC serverBlock commitLogs only1 second after block proposal (avg.)Geth real-time events (with Monad extensions)WebSocketRPC serverBlock commitLogs onlyAs soon as proposal is receivedExecution event SDKC/C++ or Rust SDKExecution daemonTx commitLogs, call frames, state reads/writesAs soon as proposal is received
The first two offerings are consumed using eth_subscribe method over a
WebSocket. They are available from third-party data providers if you don't
wish to run your own Monad node.
The SDK offering requires you to write your own third-party program using
the C/C++ or Rust SDK. These programs are not plugins that run inside the
node software -- they are free-standing programs written entirely by you. As
events occur inside the EVM (in the execution daemon), they are recorded to
shared memory. Your program also is reading this same shared memory.
Therefore, your program must run on the same host as a Monad node.

---

## Speculative Real-Time Data

> Source: https://docs.monad.xyz/monad-arch/realtime-data/spec-realtime

On this page

The Monad architectural overview explains the asynchronous execution
feature. It is essential to have a basic understanding of how this feature
works before you consume Monad's fastest real-time data feeds, especially
the speculative execution
and block states sections.
Why do I need to understand speculative execution?​
Monad's design has considerably more parallelism than a typical EVM-compatible
blockchain. This includes nodes speculatively executing the transactions in a
newly-received block before being certain that that block will finalize. The
real-time data feeds are created during speculative execution, so if you
consume them, you might see data about transactions and their effects (e.g.,
logs and balance changes), but those transactions may never really happen!
To avoid reacting to blockchain data that is not "real", you need to know how
Monad real-time data feeds express speculative execution, and how they inform
you later whether blocks (and their transactions and state effects) were
ultimately added to the blockchain (or not).
Given this additional complexity, why would you consume these real-time feeds?
The answer is so that your software can get the same performance benefits
from speculative execution that Monad itself gets
(explained below).
The cost you pay for this benefit is that you need to understand more about
how Monad works, so that you can write your data processing code correctly.
Can I consume real-time data without dealing with speculative execution?​
Yes.
Monad currently offers three sources of real-time data.
Speculative execution does not affect the Geth real-time events
compatibility offering. This data feed waits for blocks to be fully committed
to the blockchain before publishing any data, thus filtering out all the
real-time updates from blocks that fail to finalize.
infoBecause the newHeads the logs subscriptions wait for finalization, they
have one additional feature that the original Geth implementation does not:
you do not need any logic to handle chain reorganizations, because they are
not possible. You will never see the same block number more than once, and
logs will never be removed.Geth-style reorganizations don't occur in the monadNewHeads or monadLogs
subscriptions either. Instead, you are explicitly told what the consensus
algorithm is doing with the blocks you have already seen, so you know what
blockchain data gets committed or not. The purpose of this document is to
explain exactly what this information means, so you know how to react to it.
What benefits do I get from speculative execution?​
Realtime data generated by speculative execution is valuable to a consumer
for two reasons:

It allows you to use the same pipelining tricks that Monad itself uses
Sometimes it's valuable to react as soon as possible, even when the
data you're seeing is not a sure thing

Advantage #1: pipelining​
Monad's pipelining tricks are explained here
and here. You may
recall the below illustration of the laundry analogy, which helps explain the
concept in both places:
Pipelining laundry day. Top: Naive; Bottom: Pipelined. Credit: Prof. Lois Hawkes, FSU
Here's a concrete example of how you can use pipelining yourself:
Suppose you are writing a automated trading application. Further suppose that
when a certain contract (e.g., a CLOB contract) emits a particular log event,
your trading algorithm uses data from that log event as a signal to buy or
sell.
Before actually trading, you may need to perform additional actions first.
Some of the things you might do are:


Check your risk limits, to see if increasing the position will
give you too much exposure, or bring you too close to a potential
liquidation


Run a more complex mathematical model, if your strategy needs to perform
complex computations based on the input in the trading signal


Create and cryptographically sign the transaction for your buy/sell order


All these things take time, and you can do them in preparation for your
eventual trade, while you wait to find out if the block containing the market
signal was actually finalized. If the block is finalized, you've already
completed the essential work and can just "pull the trigger" (i.e., send the
presigned trade transaction message). If the block is not finalized, you
just throw the preparatory work away and never do the trade.
Advantage #2: reacting before we know it's "real"​
Consider a UI component which wants to keep users informed about the progress
of their transaction. When the transaction is speculatively executed, it can
be marked as Pending in the UI, so that the user knows it has been seen and
there's a very good chance it will go through. Even if it fails to progress
to a later commit state, seeing a bit of instant feedback tends to be a
superior user experience.
Also, consider again the example of our automated trading application. Timing
is very important in financial markets. When prices are changing rapidly, a
trade right now could be much more valuable than a trade a few seconds
later. It might make sense to initiate a trade immediately off of
speculative data, even knowing that some tiny percentage of the time, the
trade is based on a false premise.
You may lose money sometimes, i.e., when your strategy reacts to "not real"
market data in a block that fails to finalize. But usually this does not
happen, and the gains from being early most of the time could outweigh the
occasional losses when you react to "false" data.
There are also other kinds of applications, e.g., on-chain games, where
being more interactive is better than being perfectly accurate all the time.
Block commit states
Elsewhere in the documentation,
we learned that a block can be in one of four states: Proposed, Voted,
Finalized, and Verified. These are sometimes called "commit states" or
"consensus states" in the documentation.
In speculative real-time data feeds, whenever you are given blockchain data, you
will also be told:

What commit state the associated block is in
If the initial state was not verified, you will be notified at some point
later when the block transitions to a different state

Later in this article, we'll walk through exactly how the process happens in the
current version of the software.
Block numbers and block ids​
Once a block is canonically appended to the blockchain, it becomes uniquely
identified by a (sequentially increasing) block number, also called a "block
height." The inclusion of a block on the blockchain is the goal of the
consensus algorithm, and is called "finalization."
When a block is first constructed, it is constructed assuming it will become
the next block number, N. But prior to finalization, consensus nodes are
still trying to agree whether or not this candidate block will actually become
block N.
In consensus terminology, a leader constructs a block and proposes it to
the Monad network. Consensus nodes vote on the proposal of a particular
candidate block B to become the finalized block with number N. We call
this candidate block a "proposed block." It's not part of the blockchain
yet, but it probably will be soon.
It's possible for the proposal to fail for many reasons. In the most common
case, the proposed block does not reach enough other nodes before the timeout
period expires, due to network issues.
In that case, you would see another candidate to become the same block number
N later on. Because the real-time data feeds are fed by speculative
execution, you might see blockchain data for both of the block N
candidates, and will be told later which one was correct.
The critical thing to understand is that this blockchain data may claim to be
for "block number N", but it's not be the "real" block N yet: it's just
a proposal to become block N.
Consequently, when you see real-time data for a block before it finalizes,
the block number alone is not enough to uniquely identify it. This is only
the block number that the block will have, if it eventually gets
finalized. Instead, consensus uses a "block id" to uniquely identify
proposed blocks. The id can be used to track a specific block through its
commit state lifecycle.
Consider the following situation:
                                   ■                                   ║  ┌─────────────┐   ┌─────────────┐                                   ║  │             │   │             │                         ┌─────────╬──┤  Block 102  ◀───┤  Block 103  │                         │         ║  │  id: 79c25  │   │  id: 13a33  │┌─────────────┐   ┌──────▼──────┐  ║  │             │   │             ││             │   │             │  ║  └─────────────┘   └─────────────┘│  Block 100  ◀───┤  Block 101  │  ║│  id: 5b3a6  │   │  id: 6d585  │  ║│             │   │             │  ║└─────────────┘   └──────▲──────┘  ║  ┌─────────────┐                         │         ║  │             │                         └─────────╬──┤  Block 102  │                                   ║  │  id: 3ed4d  │                                   ║  │             │                                   ║  └─────────────┘                                   ║                                   ║                                 ◀ ║ ▶                  Finalized blocks ║ Proposed blocks                     (committed to ║ (may not become                       blockchain) ║ committed to                                   ║ blockchain)                                   ║                                   ■
In this diagram:

Block 101 is the latest block to be finalized
There are two competing proposed blocks vying to become block 102;
they can be distinguished by their block ids
One of the proposed blocks (13a33) is the parent of another
proposed block
You might see real-time data for all of these blocks; for those
which are not finalized, you can start your pipeline processing right
away, but you may want to wait until they reach a better commitment
state before acting

infoThe above situation is very rare in practice, but you should be aware that
it is possible.
Consensus, execution, and commit states
Monad's real-time data stream is emitted directly by the EVM. In Category
Labs' implementation of a Monad node, execution and consensus are decoupled,
as they are in most Ethereum-compatible blockchain software. That is,
consensus and execution are not just different algorithms, but completely
separate programs that communicate with each other. Consensus is the
algorithm (and the daemon) which decides whether or not a potential block
will become part of the blockchain.
Execution hosts the EVM, and executes blocks on a speculative basis, before
it is told the fate of the block by the consensus algorithm. Meanwhile,
consensus is in the "driver's seat": it is the primary driver in the creation
of new blocks, and execution acts as service that consensus uses. However,
only execution produces real-time data and maintains the state database,
because it is the only thing that sees the details of every log, every call
frame, etc.
The exact way that blocks progress from one state to the next is explained below.
Note that a block's state is from the perspective of a particular observer --
for example if you receive a QC
for a block, then you can move that block to the Voted state, but if your friend didn't
receive that QC yet, then she would still consider that block to be in the Proposed state.
The challenge of building a distributed consensus mechanism lies in defining
rules that allow nodes to individually update their state machines in response
to messages even while assuming the worst, i.e. even while assuming that they
might be the only one that received that message.
First commit state: Proposed​
When a new block is proposed by a leader (a Monad validator node), it is sent
from that leader's consensus node to all other consensus nodes to be voted on.
From the perspective of each of those nodes (as well as any observers), if
the block is valid (i.e., follows all protocol rules), it is in the
Proposed state.
Upon receiving a valid block, each consensus node will send a "yes" vote
to the next leader, while also scheduling it for immediate speculative execution
by its local execution daemon.
Shortly after this happens -- even as the "yes" vote is starting to be
transmitted over the Internet -- the execution daemon begins executing the
proposed block in the EVM. A few milliseconds later, the EVM will begin
publishing real-time data for this block.
In the current implementation of the software, all blockchain data is first
observed in the Proposed state. A Proposed block is a tricky thing. Nearly
100% of proposals that are received do eventually become finalized. In a
statistical sense then, seeing a Proposed block seems quite good.
However, that is because usually the global Monad network is functioning
properly: the vast majority of the time, there are no major telecom outages
on the Internet and there is no attempted malicious activity going on.
You are seeing the block so early, that no one has voted for it except you
(if you are a validator), and the leader that proposed it. The first stage vote
is occurring in parallel, at roughly the same time that you are watching
real-time data from its execution.
This is the paradox of a Proposed block: the transactions within it are almost
certainly going to happen. And yet if you need very high levels of assurance
before acting, it would be foolish to assume they definitely will: the
blockchain's primary defense against errors, outages, and attacks (its consensus
algorithm) has not weighed in yet.
Make sure you understand the implications of a block being in the Proposed
state: it's very early, but has no defense against network problems, software
errors, or malicious behavior. Each later stage reduces the likelihood of
problems occurring, and the kinds of problems that can occur.
Second commit state: Voted​
As mentioned above, the consensus algorithm is conducting a first round vote
on whether or not that block will be appended to the blockchain. The goal of
this referendum is to produce a "quorum (minimum number of required votes
for referendum to pass) of "yes" votes.
The vote is coordinated by the second-round leader, who gathers a quorum of
cryptographically-signed "yes" votes into an aggregate signature called a
"quorum certificate" (QC). The second round leader sends out that QC to all
consensus nodes.
If you have received a QC on a block, that means that you
have proof that the block passed the first round of voting. When this
happens, you may consider the block to be in the
Voted state.
A few things to note about the voted state:
Voted does not mean it's on the blockchain​
A block cannot yet be definitively appended to the blockchain when it reaches
the Voted state. Monad's consensus algorithm uses two rounds of voting.
Possession of a QC (i.e. proof that the first round concluded in most
participants voting yes) removes the most common kinds of risks, but some risk
of being reverted remains.
Possessing a QC removes the risk that a block will be "lost" due to the most
common issues such as network outages and latency issues. Even if it turned
out that you were the only observer with this QC due to a severe network outage,
Monad's consensus algorithm has a fallback mechanism that ensures that the
original block will be reproposed and ultimately finalized under almost all
conditions.
Under what conditions is the existence of a QC not enough? Several things must
have happened, but the most notable is that the original leader must have
equivocated, i.e. proposed two different blocks at the same block height,
sending each to a different set of nodes.
Equivocation is an unlikely thing for a leader to do, since it is an easily
attributable fault (proof is just the pair of conflicting blocks signed by the
same leader), and since the leader only hurts themselves by invalidating their
own proposal. This is why a block that has reached the Voted stage is very
likely to be finalized.
A block might never enter the Voted state​
A proposed block might never receive a QC, if its first consensus vote fails.
The most common reason that a block does not get voted in is network latency
issues. Suppose, for example, that both your node and the leader are in
Australia, and there is significant congestion with the cross-continental
network traffic. In that case, most of the blockchain nodes may not learn
about the proposal before the timeout period expires, and the vote will fail.
Note that you will not be told that the vote fails. The failure of the vote
is implicit, but you can tell it happened because of the next property.
For some block number N, some proposed block will eventually be voted in​
If you do not receive a QC for a particular block with block number N, then
at some other time you will receive a different proposed block to become
block N and that will receive a QC.
A sequence like the following may occur:

You see all of real-time data for some block B1, which is proposed to
become block number N
You see a different block, B2 (and all of its execution events) also
competing to become block N
B2 receives a QC, and this is the only thing that happens. Namely, B1
does not receive an explicit "abandonment" event: it is just never
mentioned again, and is implicitly abandoned by the network endorsing
another block with the same number

Third commit state: Finalized​
Finalized means the block is now part of the canonical blockchain and cannot
be reverted without a hard fork. From this point forward, we no longer need
the block id and can refer to a block solely by its block number.
When a block number N is finalized, it implicitly abandons all other
proposed blocks with the same block number N. Such blocks could be in either
the proposed or the voted state. We say the abandonment is implicit because no
event will be recorded to explicitly announce the abandonment of previously
seen block id.
If you are using pipelining programming techniques when you consume real-time
data, then you are probably keeping track of some state associated with
unfinalized blocks. In our trading example, this would be the pre-prepared
buy or sell order transaction message.
Every time a block is finalized, you read must check for any blocks
(1) with the same block number, but (2) with a different id, and abort your
pipelined processing for those blocks. They will never be appended to the
blockchain and the associated transactions and their effects -- whose
execution events you have already seen -- will never occur.
Why are there two different stages of voting?​
This is because the subject of the vote -- the thing we are trying to
get agreement on -- is different.


In the first vote, the network wants to verify that a block satisfies
all the protocol rules. If a QC is obtained, we know that a majority
of the honest nodes agree that the block should be added. This first
vote is called the "voted" stage since the block itself has been
voted for.


In the second vote, we want to get cryptographically secure agreement
that enough of the network has actually seen the result of the first vote.
This second vote is called the "finalized" stage since, now that everyone
knows the first vote succeeded, they can also agree that it must be the
next block on the blockchain.


The second vote is trying to answer the question posed by the old saying
"If a tree falls in a forest and no one is around to hear it, does it make a
sound?"
Consider how the "fan-in, fan-out"
linear communication pattern
of the BFT protocol works. We talk about nodes "having a QC", but the QC is
computed by the leader of the next round -- this leader is the one actually
"conducting" the vote.
Even if the leader is dishonest, it cannot forge the vote because it cannot
forge other nodes' cryptographic signatures. But it can fail to successfully
tell enough of its peers about the QC, since it must communicate the QC to
everyone. Network problems are common, so communication can always fail.
Thus we need a second round of voting, for validators to reach distributed
agreement about the fact that they've seen the first QC. Now it's safe to
assume that everyone (or at least the honest majority) will have the same
canonical blockchain.
The reason that Voted is a very reliable commit state on Monad is that if
common problems occur during the second stage vote, the
algorithm will continue trying to conduct the second stage vote, failing only
in some narrow corner cases involving equivocation.
Fourth commit state: Verified​
The consensus algorithm produces one last state transition for a block, called
Verified.
The Verified state is a consequence of Monad's asynchronous execution. Recall
that a consensus node votes on a block before its execution is complete.
This implies that consensus must be voting on the block's execution inputs,
but not on the block's execution outputs.
Consensus nodes cannot be voting, for example, on the correct value of the
state root produced by the execution of the block, because they don't know
what it is (remember, it is being computed in parallel with the vote
occurring). This means that the Voted state does not certify the
correctness of any output fields in the Ethereum block header such as
state_root, receipts_root, etc.
This is possible because any well-formed Ethereum block will have completely
deterministic effects on the blockchain state, when executed by a conforming
EVM implementation. Thus, it is safe to append a block onto the blockchain,
knowing that everyone will agree on its behavior, even if we don't know
exactly what the behavior will be.
Clearly though, for the blockchain to be reliable, consensus nodes must
eventually vote on the correctness of the execution outputs. Suppose they did
not, and further suppose that a bug existed in some execution nodes but not
in others (perhaps running a different version of the client software). If
there were no mechanism to feed the execution outputs back into consensus
decisions, the state could become forked without anyone noticing. Consensus
proposals start by assuming that all execution nodes will compute the
correct state, but to prevent bugs and malicious actions from compromising
the network, it must check that this happens eventually.
Here is how Monad solves this issue:
To give execution ample time to finish, execution outputs for block B
are not incorporated into the consensus protocol until three rounds in the
future, alongside the proposal of block B+3. When this proposal is
finalized (ideally two rounds later, during the proposal of block B+5),
then a supermajority of nodes will have voted for the correct values of
the execution outputs.
To roughly summarize the difference:

Finalized means the block's definition (i.e., its transactions) are
definitely part of the blockchain
Verified means that a supermajority stake's worth of other nodes have
verified that your local node's computation of the state changes of these
transactions match the supermajority's

To understand more, read here.
Does this imply that verified state is the gold standard for "100%, can never
fail" transaction reporting? Also no, if you are trusting a data feed produced
by a single node. Who is to say, for example, that the node producing the data
in not suffering from a bug, or has been hacked?
As always in the blockchain universe, critical transactions that demand
total peace of mind can only be verified by widespread agreement, broadly
defined. This includes explicitly checking with other nodes, to ensure no
hosts or network intermediaries have been compromised and the software is
working properly.
In practice, the Voted state is usually good enough for most things: it should
very rarely revert in practice, so it is also used as the "safe" block tag
in Monad's RPC implementation.

### Code Examples

```prism
■                                   ║  ┌─────────────┐   ┌─────────────┐                                   ║  │             │   │             │                         ┌─────────╬──┤  Block 102  ◀───┤  Block 103  │                         │         ║  │  id: 79c25  │   │  id: 13a33  │┌─────────────┐   ┌──────▼──────┐  ║  │             │   │             ││             │   │             │  ║  └─────────────┘   └─────────────┘│  Block 100  ◀───┤  Block 101  │  ║│  id: 5b3a6  │   │  id: 6d585  │  ║│             │   │             │  ║└─────────────┘   └──────▲──────┘  ║  ┌─────────────┐                         │         ║  │             │                         └─────────╬──┤  Block 102  │                                   ║  │  id: 3ed4d  │                                   ║  │             │                                   ║  └─────────────┘                                   ║                                   ║                                 ◀ ║ ▶                  Finalized blocks ║ Proposed blocks                     (committed to ║ (may not become                       blockchain) ║ committed to                                   ║ blockchain)                                   ║                                   ■
```

---

## Statesync

> Source: https://docs.monad.xyz/monad-arch/consensus/statesync

On this page

Summary​
Statesync is the process for synchronizing state to a target block close to the current tip. A synchronizing node ("client") requests data from other up-to-date validators ("servers") to help it progress from its current view to its target view; the servers rely on metadata in MonadDb to efficiently respond to the request.
Since the current tip is a moving target, following completion of statesync, the client makes another statesync request to get closer to the current tip, or replays queued blocks if within striking distance.
Approach​
Statesync is the process of synchronizing state stored in MonadDb to a target block close to the current tip.
The current tip is a moving target, so as statesync is running, the syncing node stores new blocks beyond the target block and, upon completion of statesync, replays these additional blocks through normal execution to catch up to the current tip. The target block may be updated several times during this process.
Statesync follows a client-server model, where the statesync requester is the client and the validator node servicing a statesync request is the server.
Data included in statesync​
MonadDb stores a variety of data relating to the execution of blocks. However, only a subset is required for full participation in the active set and thus included in statesync:

accounts, including balances, code, and storage
the last 256 block headers (to verify correctness)

In an effort to evenly distribute load, each of the aforementioned is spliced into chunks. The client assigns each chunk to a server who remains the peer for that chunk until synchronization is complete.
Servers are randomly selected from the list of available peers. The client maintains a certain number of sessions up to a configured maximum. In the event that servers are unresponsive, the client’s statesync request will timeout and request from a different server.
Versioning and verification​
For efficiency, the client requests state from least- to most-recently updated, converging on the tip near the end of the process. Servers serve diffs relative to the client's latest block.

In the example above, the statesync client makes three consecutive requests to the statesync server assigned to prefix p. For each request, there are five parameters specified:

prefix - the prefix of the Merkle Patricia Trie
i - the start block number
j - the end block number
target - the target block number
last_target - last target block number, this is used to deduce deletions to send

Because there may be multiple rounds of statesync (as statesync occurs, the chain is progressing and the target block may need to adjust), j is buffered by some offset B from the target block to avoid retransmitting most recently used nodes in the MPT.  When i and target block are sufficiently close, as in the last round above, the statesync client will request j = target.
At this point, if target is less than statesync_threshold (600 blocks by default) from the tip of the chain, statesync is concluded and the state root will be validated. Any remaining blocks between target and tip are then synced via blocksync. If target is greater than statesync_threshold blocks from the tip of the chain, a new round of statesync will begin.
During block execution, the server stores the version alongside node contents. As such, upon receipt of a statesync request, the server is able to quickly narrow down the relevant subtrie and submit read requests, which are embarrassingly parallel.
Trust assumptions​
Statesync clients trust that the requested data (including state root and parent hash) from statesync servers is correct. This is currently sampled randomly from the validator set according to stakeweight, but clients can optionally whitelist specific known providers as statesync servers.
The current implementation validates the data transmitted when the whole transfer is complete by comparing the state root. Because the work is split between multiple servers, a single server sending invalid data can cause a state root mismatch, without attribution to the faulty server. The only recourse in this situation is to retry the whole transfer, giving the faulty server an opportunity to fail the operation again.
Changes are currently being implemented to verify the data transmitted on a per-server basis. In the event of a faulty server sending invalid data, the statesync client can discard and retry only the affected prefix. Further, it can identify the faulty server, log the error and potentially blacklist it from subsequent requests.

---

## Transaction Lifecycle in Monad

> Source: https://docs.monad.xyz/monad-arch/transaction-lifecycle

On this page

Transaction Submission​
The lifecycle of a transaction starts with a user preparing a signed transaction and submitting it to an RPC node.
Transactions are typically prepared by an application frontend, then presented to the user's wallet for signing. Most wallets make an eth_estimateGas RPC call to populate the gas limit for this transaction, although the user can also override this in their wallet. The user is also typically asked to choose a gas price for the transaction, which is a number of NativeTokens per unit of gas.
After the user approves the signing in their wallet, the signed transaction is submitted to an RPC node using the eth_sendTransaction or eth_sendRawTransaction API call.
Mempool Propagation​
As described in Local Mempool:
The RPC node performs validity checks:

signature verification
nonce not too low
gas limit below block gas limit

before forwarding the pending transaction to the next N leaders.
Each of those leaders replicate those validity checks before adding the pending transaction to their local mempool.
If the transaction isn't included in any of the blocks proposed by those leaders, the RPC node repeats this process, sending to the next N leaders. The process is repeated up to K times.
Block Inclusion​
Pending transactions are included in a block only if further dynamic checks pass:

account balance is sufficient to pay for gas (see: Balance Validation at Time of Consensus)
nonce is contiguous
there is space in the block and the leader has chosen to include this transaction

Block Propagation​
Blocks are propagated through the network as discussed in MonadBFT, using the RaptorCast messaging protocol for outbound messages from the leader.
Under MonadBFT, a block progresses from the Proposed phase to the Voted phase (after 1 block) and then to the Finalized phase (after 2 blocks).
Once the block is Finalized, the transaction has officially "occurred" in the history of the blockchain. Since its order is determined, its truth value (i.e., whether it succeeds or fails, and what the outcome is immediately after that execution) is determined.
Local Execution​
As soon as a node receives a block, it begins executing the transactions from that block. For efficiency reasons, transactions are executed optimistically in parallel, but it is as if the transactions were executed serially, since results are always committed in the original order.
Querying the Outcome​
The user can query the result of the transaction by calling eth_getTransactionByHash or eth_getTransactionReceipt on any RPC node. The RPC node will return as soon as execution completes locally on the node.

---

## Transport Protocol Usage

> Source: https://docs.monad.xyz/monad-arch/consensus/transport-protocols

Monad nodes use both TCP and UDP protocols for different types of communication.
Traffic TypeProtocolPrimary RaptorCastUDPSecondary RaptorCastUDPPeer DiscoveryUDPTransaction ForwardingUDPBlock Forwarding to Dedicated Full NodesUDPBlocksyncTCPStatesyncTCP

---



# Section: node-ops

---

## Archive Data Setup

> Source: https://docs.monad.xyz/node-ops/archive-data/

The Data WaterfallWhere RPC looks for historical dataRunning an Archive ServerConfiguring RPC to use Archive DataHow to configure RPC to use archive data

---

## Configuring RPC to use archive data

> Source: https://docs.monad.xyz/node-ops/archive-data/configuring-rpc

On this page

This is not for validator nodesIntegration with the archive is designed for full nodes servicing RPC requests, not for validator
nodes.
Enabling call tracesEnabling --trace_calls is recommended for RPC nodes.
This preserves the detailed error information necessary for call traces, e.g. debug_traceTransaction.
To make this override, please run sudo systemctl edit monad-execution and add the --trace_calls CLI param
to the ExecStart definition (may need a line continuation character \):sudo systemctl edit monad-execution[Service]Type=simpleExecStart=ExecStart=/usr/local/bin/monad \    [... existing cli commands, see comment at the bottom of the systemctl editor ...]    --trace_calls
Configuring monad-rpc with Archive Server backup​


Configure an Archive Server that is geographically close to
this full node.


Add the following vars to your /home/monad/.env:
# Replace <db username>, <db pwd> and <db hostname> with your values from Step (1)MONGO_URL="mongodb://<db username>:<db pwd>@<db hostname>:27017"MONGO_DB_NAME="archive-db"DB_HOST=<db hostname>DB_PWD=<db pwd>DB_USERNAME=<db username>


Verify connectivity:
source /home/monad/.env
nc -vz $DB_HOST 27017mongosh "$MONGO_URL" --quiet --eval '    try {    db.adminCommand({ping: 1});    const archiveDb = db.getSiblingDB("archive-db");    const hasCollection = archiveDb.getCollectionNames().includes("block_level");    print(hasCollection ? "OK: Collection exists" : "FAIL: Collection missing");    quit(hasCollection ? 0 : 1);    } catch(e) {    print("FAIL: " + e.message);    quit(1);    }'


Add the following systemd override to monad-rpc:
sudo systemctl edit monad-rpc
[Service]ExecStart=ExecStart=/usr/local/bin/monad-rpc \    [... existing cli commands, see comment at the bottom of the systemctl editor ...]    --mongo-url ${MONGO_URL} \    --mongo-db-name ${MONGO_DB_NAME} \    --use-eth-get-logs-index


Reload and restart:
sudo systemctl daemon-reloadsudo systemctl restart monad-rpc


Check for an early block outside local retention:
curl -X POST -H "Content-Type: application/json" --data '{        "jsonrpc": "2.0",        "method": "eth_getBlockByNumber",        "params": ["0x1", false],        "id": 1    }'  http://localhost:8080


Configuring monad-rpc with AWS backup​


Ensure an AWS identity and credentials are on the box.

Run aws configure to setup your AWS credentials and config on the full node. This should
generate config and credentials files under ~/.aws/. See the
AWS CLI docs.
When running in systemd, AWS permissions need to be created under monad user. See the
general validator or fullnode docs for the broader instructions to run rpc, but ensure the
monad user has aws credentials with access to the bucket.



Create an AWS IAM policy using this user guide and the following sample json:
{    "Version": "2012-10-17",    "Statement": [        {            "Effect": "Allow",            "Action": [                "s3:GetObject",                "s3:ListBucket",                "s3:GetBucketRequestPayment",                "execute-api:Invoke"            ],            "Resource": [                "arn:aws:s3:::*/*",                "arn:aws:s3:::*",                "arn:aws:execute-api:*:*:*"            ],            "Condition": {                "StringEquals": {                    "aws:ResourceOrgID": "o-sq9ayub2wk"                }            }        }    ]}


To obtain a free-tier api-key, send an AWS Signature v4 signed request to https://9df09fanz1.execute-api.us-east-2.amazonaws.com/prod/free-tier-key


ex. using awscurl utility:
awscurl https://9df09fanz1.execute-api.us-east-2.amazonaws.com/prod/free-tier-key --region us-east-2




Add the following vars to your /home/monad/.env:
ARCHIVE_API_KEY=<key from step 3># Replace with appropriate mainnet, localnet or testnet bucket# Below is the public testnet bucket maintained by Category LabsARCHIVE_BUCKET="testnet-ltu-032-0"# Below is the public mainnet bucket maintained by Category LabsARCHIVE_BUCKET="mainnet-deu-010-0"


Add the following systemd override to monad-rpc:
sudo systemctl edit monad-rpc
[Service]ExecStart=ExecStart=/usr/local/bin/monad-rpc \    [... existing cli commands, see comment at the bottom of the systemctl editor ...]    --s3-bucket ${ARCHIVE_BUCKET} \    --region "us-east-2" \    --archive-url "https://9df09fanz1.execute-api.us-east-2.amazonaws.com/prod" \    --archive-api-key ${ARCHIVE_API_KEY}


Reload and restart:
sudo systemctl daemon-reloadsudo systemctl restart monad-rpc


Check for an early block outside local retention:
noteIf you already have MongoDB backend enabled, this will not test anything by default. To test,
temporarily remove the MongoDB backend, run the following and restore the MongoDB config.
curl -X POST -H "Content-Type: application/json" --data '{        "jsonrpc": "2.0",        "method": "eth_getBlockByNumber",        "params": ["0x1", false],        "id": 1    }'  http://localhost:8080

### Code Examples

```prism
sudo systemctl edit monad-execution
```

```prism
[Service]Type=simpleExecStart=ExecStart=/usr/local/bin/monad \    [... existing cli commands, see comment at the bottom of the systemctl editor ...]    --trace_calls
```

```prism
# Replace <db username>, <db pwd> and <db hostname> with your values from Step (1)MONGO_URL="mongodb://<db username>:<db pwd>@<db hostname>:27017"MONGO_DB_NAME="archive-db"DB_HOST=<db hostname>DB_PWD=<db pwd>DB_USERNAME=<db username>
```

```prism
source /home/monad/.env
nc -vz $DB_HOST 27017mongosh "$MONGO_URL" --quiet --eval '    try {    db.adminCommand({ping: 1});    const archiveDb = db.getSiblingDB("archive-db");    const hasCollection = archiveDb.getCollectionNames().includes("block_level");    print(hasCollection ? "OK: Collection exists" : "FAIL: Collection missing");    quit(hasCollection ? 0 : 1);    } catch(e) {    print("FAIL: " + e.message);    quit(1);    }'
```

```prism
sudo systemctl edit monad-rpc
```

```prism
[Service]ExecStart=ExecStart=/usr/local/bin/monad-rpc \    [... existing cli commands, see comment at the bottom of the systemctl editor ...]    --mongo-url ${MONGO_URL} \    --mongo-db-name ${MONGO_DB_NAME} \    --use-eth-get-logs-index
```

```prism
sudo systemctl daemon-reloadsudo systemctl restart monad-rpc
```

```prism
curl -X POST -H "Content-Type: application/json" --data '{        "jsonrpc": "2.0",        "method": "eth_getBlockByNumber",        "params": ["0x1", false],        "id": 1    }'  http://localhost:8080
```

```prism
{    "Version": "2012-10-17",    "Statement": [        {            "Effect": "Allow",            "Action": [                "s3:GetObject",                "s3:ListBucket",                "s3:GetBucketRequestPayment",                "execute-api:Invoke"            ],            "Resource": [                "arn:aws:s3:::*/*",                "arn:aws:s3:::*",                "arn:aws:execute-api:*:*:*"            ],            "Condition": {                "StringEquals": {                    "aws:ResourceOrgID": "o-sq9ayub2wk"                }            }        }    ]}
```

```prism
awscurl https://9df09fanz1.execute-api.us-east-2.amazonaws.com/prod/free-tier-key --region us-east-2
```

```prism
ARCHIVE_API_KEY=<key from step 3># Replace with appropriate mainnet, localnet or testnet bucket# Below is the public testnet bucket maintained by Category LabsARCHIVE_BUCKET="testnet-ltu-032-0"# Below is the public mainnet bucket maintained by Category LabsARCHIVE_BUCKET="mainnet-deu-010-0"
```

```prism
sudo systemctl edit monad-rpc
```

```prism
[Service]ExecStart=ExecStart=/usr/local/bin/monad-rpc \    [... existing cli commands, see comment at the bottom of the systemctl editor ...]    --s3-bucket ${ARCHIVE_BUCKET} \    --region "us-east-2" \    --archive-url "https://9df09fanz1.execute-api.us-east-2.amazonaws.com/prod" \    --archive-api-key ${ARCHIVE_API_KEY}
```

```prism
sudo systemctl daemon-reloadsudo systemctl restart monad-rpc
```

```prism
curl -X POST -H "Content-Type: application/json" --data '{        "jsonrpc": "2.0",        "method": "eth_getBlockByNumber",        "params": ["0x1", false],        "id": 1    }'  http://localhost:8080
```

---

## Execution Events and Websocket Setup

> Source: https://docs.monad.xyz/node-ops/events-and-websockets

On this page

Summary​
The Execution Events and Websocket
features were designed to work together to make Monad even faster for high volume applications.
Execution Events is a low-level system, and WebSocket support is one specific usage of that system.
Execution Events​
Execution Events offers developers the highest performance option
for listening to real-time data from the Monad blockchain.


Execution Events uses a shared memory communication system that requires additional setup,
which is described here. This setup is not part of the default instructions; it's only needed
if you run real-time data consumers that use the Execution Events feature.


The "shared memory" nature of the communication means that consumers
of execution events must run directly on the same host as the Monad node, so
they can observe real-time data in the host's RAM


Monad's RPC server can optionally use execution events for better
performance, and to support certain features, namely, the eth_subscribe
JSON-RPC call


noteHere is an overview of all real-time data offerings
in Monad. Here is a tutorial on writing programs that consume
execution events.
WebSockets​
In Monad's JSON-RPC server, WebSockets have two uses:

Creating a persistent connection to make JSON-RPC requests
The ability to call the eth_subscribe API, which will "push" new real-time
data as it happens, so you do not need to poll for new events

WebSocket support must be explicitly enabled in the RPC server with
command-line flag --ws-enabled. When
--ws-enabled is passed, then the host must be configured to support
execution events, otherwise RPC will exit with an error.
An user guide to WebSockets on Monad is here.
Requirements​

A running Monad full node (setup instructions)
A hugetlbfs filesystem mount

This can be set up using the hugeadm utility; see below for an example


Custom (aka "override") systemd unit files for both RPC and Execution

Examples are both below



Setup a hugetlbfs mount using hugeadm​
General prerequisites​
Install the required package:
sudo apt install libhugetlbfs-bin
Execution events SDK prerequisites​
If you want to consume real-time data in your own software using the execution
events SDK, you must install these additional packages:
sudo apt install libhugetlbfs-dev libhugetlbfs0 libzstd-dev
These are only required for the SDK; if you only need to enable WebSocket
support in the RPC server, you do not need these packages.
CLI one-time setup​
warningThis is for one-time testing and will NOT persist after a reboot
# NOTE: here we use `monad` but if you are running as a custom user, that should be set here$ sudo hugeadm --create-user-mounts monad
Sample systemd unit file​
This makes the mounts persistent after a reboot.
File location:
/etc/systemd/system/events-hugepages-mounts.service
File contents (as viewed when using the override editor):
### Anything between here and the comment below will become the contents of the drop-in file
# NOTE: as mentioned above, you can change the `monad` user to your custom user (if needed)[Unit]Description=Create hugepage mounts for monadAfter=local-fs.target
[Service]Type=oneshotExecStart=/usr/bin/hugeadm --create-user-mounts monadRemainAfterExit=yes
[Install]WantedBy=multi-user.target
### Edits below this comment will be discarded
Configure the systemd overrides​
Important items​
systemd:

As a reminder, if you installed Monad via apt, the systemd unit files live in: /usr/lib/systemd/sytem
This means we need to create a systemd override
systemd overrides for ExecStart (and other additive settings) require two blocks. The first "clears" the original value and the second sets the new value.
You will need to do a systemctl daemon-reload after the changes

events + websockets:

RPC + websockets has a HARD dependency on Execution runnning with events

websockets specific:

You will need to open a port in your firewall
The default is 8081
If you want to use a custom port, the --ws-port <PORT> for RPC allows you to set the port of your choosing

Configure the Execution override for systemd​
This override enables the events sub-component for Execution
warningIf RPC + websockets is started without events being enabled for Execution, RPC will start and then crash
You can launch the override editor via:
sudo systemctl edit monad-execution
Which will make a new file at /etc/systemd/system/monad-execution.service.d/override.conf
File contents (as viewed when using the override editor):
### Anything between here and the comment below will become the contents of the drop-in file
# NOTE: BOTH ExecStarts are REQUIRED
[Service]ExecStart=ExecStart=/usr/local/bin/monad \    --chain "$CHAIN" \    --db /dev/triedb \    --block_db /home/monad/monad-bft/ledger \    --statesync /home/monad/monad-bft/statesync.sock \    --exec-event-ring /var/lib/hugetlbfs/user/monad/pagesize-2MB/event-rings/monad-exec-events \    --sq_thread_cpu 1 \    --log_level INFO
### Edits below this comment will be discarded
Do reload:
sudo systemctl daemon-reload
Restart Execution​
Adding this step here to ensure that Execution is restarted with the events enabled
sudo systemctl restart monad-execution
Configure the RPC override for systemd​
This override enables the websockets sub-component for RPC
You can launch the override editor via:
sudo systemctl edit monad-rpc
Which will make a new file at /etc/systemd/system/monad-rpc.service.d/override.conf
File contents:
# NOTE: BOTH ExecStarts are REQUIRED
[Service]ExecStart=ExecStart=/usr/local/bin/monad-rpc \    --ipc-path /home/monad/monad-bft/mempool.sock \    --triedb-path /dev/triedb \    --otel-endpoint "http://0.0.0.0:4317" \    --allow-unprotected-txs \    --node-config /home/monad/monad-bft/config/node.toml \    --exec-event-path /var/lib/hugetlbfs/user/monad/pagesize-2MB/event-rings/monad-exec-events \    --ws-enabled
Restart RPC​
sudo systemctl restart monad-rpc
Checking the connectivity​
A quick way to check if WebSocket connectivity is working is to use a
general purpose command-line tool that can act as WebSocket client,
such as websocat. This is a
powerful command-line "swiss army knife" tool, like nc or the
original socat. It is not officially packaged for Debian/Ubuntu yet,
but precompiled binaries can be downloaded or installed via
cargo install websocat (it is a Rust program).
Here is an example of running it in verbose mode (-v), with the
WebSocket service hosted on default port 8081:
$ websocat -v ws://localhost:8081[INFO  websocat::lints] Auto-inserting the line mode[INFO  websocat::stdio_threaded_peer] get_stdio_peer (threaded)[INFO  websocat::ws_client_peer] get_ws_client_peer[INFO  websocat::net_peer] Connected to TCP 127.0.0.1:8081[INFO  websocat::ws_client_peer] Connected to ws[INFO  websocat::ws_peer] Received WebSocket ping
To subscribe, type the subscription JSON RPC call for
eth_subscribe into your terminal's stdin and press enter:
{ "id": 1, "jsonrpc": "2.0", "method": "eth_subscribe", "params": ["newHeads"] }
Every half-second or so, you should see updates about new blocks.

### Code Examples

```prism
sudo apt install libhugetlbfs-bin
```

```prism
sudo apt install libhugetlbfs-dev libhugetlbfs0 libzstd-dev
```

```prism
# NOTE: here we use `monad` but if you are running as a custom user, that should be set here$ sudo hugeadm --create-user-mounts monad
```

```prism
/etc/systemd/system/events-hugepages-mounts.service
```

```prism
### Anything between here and the comment below will become the contents of the drop-in file
# NOTE: as mentioned above, you can change the `monad` user to your custom user (if needed)[Unit]Description=Create hugepage mounts for monadAfter=local-fs.target
[Service]Type=oneshotExecStart=/usr/bin/hugeadm --create-user-mounts monadRemainAfterExit=yes
[Install]WantedBy=multi-user.target
### Edits below this comment will be discarded
```

```prism
sudo systemctl edit monad-execution
```

```prism
### Anything between here and the comment below will become the contents of the drop-in file
# NOTE: BOTH ExecStarts are REQUIRED
[Service]ExecStart=ExecStart=/usr/local/bin/monad \    --chain "$CHAIN" \    --db /dev/triedb \    --block_db /home/monad/monad-bft/ledger \    --statesync /home/monad/monad-bft/statesync.sock \    --exec-event-ring /var/lib/hugetlbfs/user/monad/pagesize-2MB/event-rings/monad-exec-events \    --sq_thread_cpu 1 \    --log_level INFO
### Edits below this comment will be discarded
```

```prism
sudo systemctl daemon-reload
```

```prism
sudo systemctl restart monad-execution
```

```prism
sudo systemctl edit monad-rpc
```

```prism
# NOTE: BOTH ExecStarts are REQUIRED
[Service]ExecStart=ExecStart=/usr/local/bin/monad-rpc \    --ipc-path /home/monad/monad-bft/mempool.sock \    --triedb-path /dev/triedb \    --otel-endpoint "http://0.0.0.0:4317" \    --allow-unprotected-txs \    --node-config /home/monad/monad-bft/config/node.toml \    --exec-event-path /var/lib/hugetlbfs/user/monad/pagesize-2MB/event-rings/monad-exec-events \    --ws-enabled
```

```prism
sudo systemctl restart monad-rpc
```

```prism
$ websocat -v ws://localhost:8081[INFO  websocat::lints] Auto-inserting the line mode[INFO  websocat::stdio_threaded_peer] get_stdio_peer (threaded)[INFO  websocat::ws_client_peer] get_ws_client_peer[INFO  websocat::net_peer] Connected to TCP 127.0.0.1:8081[INFO  websocat::ws_client_peer] Connected to ws[INFO  websocat::ws_peer] Received WebSocket ping
```

```prism
{ "id": 1, "jsonrpc": "2.0", "method": "eth_subscribe", "params": ["newHeads"] }
```

---

## Full Node Installation

> Source: https://docs.monad.xyz/node-ops/full-node-installation

On this page

Components​
Monad nodes are running services using systemd:

monad-bft - Consensus client
monad-execution - Execution client
monad-rpc - RPC server
monad-mpt - One-time execution for initializing the TrieDB disk
monad-cruft - Cleanup service running hourly
otelcol - OTEL collector service for metric collection

The systemd services are running using monad service user.
The configuration and data structure is:

/home/monad/.env - contains the environment variables to configure monad services
/home/monad/monad-bft/config/node.toml - contains configurable consensus parameters, most
notably the name of the node, typically "<PROVIDER_NAME>-1" and a list of upstream validators
(denoted by secp pubkey and DNS) who have been configured to republish blocks to your full node.
/home/monad/monad-bft/config/forkpoint/ - contains consensus quorum checkpoints (written every
block) used for bootstrapping state
/home/monad/monad-bft/config/validators/ - contains validator sets generated at the
boundary block. The newly generated
file contains the consensus validator sets for the current epoch and for the upcoming epoch.
The most recent validator set is found at validators.toml.
/home/monad/monad-bft/ledger/ - contains consensus (BFT) block headers and bodies, including the transactions
/dev/triedb - TrieDB database device, contains the state of the blockchain

Prerequisites​
Please refer to the Hardware Requirements before continuing.

Bare-metal server
Ubuntu 24.04+ Operating system
Linux Kernel >= 6.8.0.60 (see warning below)
Disabled HyperThreading (HT) or Simultaneous MultiThreading (SMT) via BIOS settings

these features degrade the node performance



warningThere is a known bug affecting
Linux kernel versions v6.8.0.56-generic - v6.8.0.59-generic (inclusive) that causes Monad
clients to hang in an uninterruptible sleep state, severely impacting node stability.
We recommend v6.8.0.60-generic or higher.
Prepare the Node​
infoThe following instructions assume the commands are executed as root user.
Update the system​
Update the system.
apt updateapt upgrade -y
Reboot the machine if required, for example if the upgrade prints Pending kernel upgrade!.
Install additional dependencies.
apt install -y curl nvme-cli aria2 jq
Install monad package​
Configure the APT repository.
cat <<EOF > /etc/apt/sources.list.d/category-labs.sourcesTypes: debURIs: https://pkg.category.xyz/Suites: nobleComponents: mainSigned-By: /etc/apt/keyrings/category-labs.gpgEOF
curl -fsSL https://pkg.category.xyz/keys/public-key.asc \  | gpg --dearmor --yes -o /etc/apt/keyrings/category-labs.gpg
MainnetTestnetInstall monad package.apt updateapt install -y monad=0.12.2-rpc-hotfix2apt-mark hold monadInstall monad package.apt updateapt install -y monad=0.12.2-rpc-hotfix2apt-mark hold monad
Create monad user​
Create a non-privileged user named monad with a home directory and Bash shell.
useradd -m -s /bin/bash monad
Create config directories structure in /home/monad.
mkdir -p /home/monad/monad-bft/config \         /home/monad/monad-bft/ledger \         /home/monad/monad-bft/config/forkpoint \         /home/monad/monad-bft/config/validators
Configure TrieDB Device​
Create the device​
Set the NVMe drive (e.g. /dev/nvme1n1) to be used for TrieDB device, create a new partition table and a partition that spans the
entire drive. The drive should be on a disk that has no filesystem mounted and no RAID configured.
TRIEDB_DRIVE=/dev/nvme1n1 # CHANGE THIS TO YOUR NVME DRIVE
parted $TRIEDB_DRIVE mklabel gptparted $TRIEDB_DRIVE mkpart triedb 0% 100%
Create a udev rule to set permissions and create a symlink for the partition.
PARTUUID=$(lsblk -o PARTUUID $TRIEDB_DRIVE | tail -n 1)echo "Disk PartUUID: ${PARTUUID}"
echo "ENV{ID_PART_ENTRY_UUID}==\"$PARTUUID\", MODE=\"0666\", SYMLINK+=\"triedb\"" \  | tee /etc/udev/rules.d/99-triedb.rules
Trigger and reload udev rules, and verify TrieDB is pointing to the NVMe device.
udevadm triggerudevadm control --reloadudevadm settlels -l /dev/triedb
Verify the LBA configuration​
Verify LBA Configuration, and enable 512 byte LBA if not enabled.
Check if 512 byte LBA is enabled on TRIEDB_DRIVE:
nvme id-ns -H $TRIEDB_DRIVE | grep 'LBA Format' | grep 'in use'
This command should return the following expected output:
LBA Format  0 : Metadata Size: 0   bytes - Data Size: 512 bytes - Relative Performance: 0 Best (in use)
infoData Size should be set to 512 bytes and marked as (in use). If that is not the case,
then you will need to set the TRIEDB_DRIVE to use 512 byte LBA with the following command.nvme format --lbaf=0 $TRIEDB_DRIVEVerify that the configuration has been corrected.nvme id-ns -H $TRIEDB_DRIVE | grep 'LBA Format' | grep 'in use'
Format the partition​
Format the TrieDB partition by executing the monad-mpt one-time service.
systemctl start monad-mptjournalctl -u monad-mpt -n 14 -o cat
This should return similar output.
MPT database on storages:          Capacity           Used      %  Path           1.75 Tb      256.03 Mb  0.01%  "/dev/nvme1n1p1"MPT database internal lists:     Fast: 1 chunks with capacity 256.00 Mb used 0.00 bytes     Slow: 1 chunks with capacity 256.00 Mb used 0.00 bytes     Free: 7148 chunks with capacity 1.75 Tb used 0.00 bytesMPT database has 1 history, earliest is 18446744073709551615 latest is 18446744073709551615.     It has been configured to retain no more than 33554432.     Latest proposed is (18446744073709551615, 0000000000000000000000000000000000000000000000000000000000000000).     Latest voted is (18446744073709551615, 0000000000000000000000000000000000000000000000000000000000000000).     Latest finalized is 18446744073709551615, latest verified is 18446744073709551615, auto expire version is 0monad-mpt.service: Deactivated successfully.Finished monad-mpt.service - "Service file for Monad MPT".
Configure Firewall rules​
Configure these firewall rules:

block all incoming traffic and enable all outgoing (default)
allow SSH inbound connections (remote access)
allow inbound and outbound to port 8000 for TCP/UDP (Consensus client P2P traffic)

Setup the UFW firewall:
ufw allow sshufw allow 8000ufw enableufw status
Hardware firewallsIf using hardware firewalls, you may need to perform additional steps to open up port 8000 to UDP
and TCP traffic.
Test outbound TCPTo verify outbound connectivity on TCP port 8000, test a connection to remote host:$ nc -vz 64.31.29.190 8000Connection to 64.31.29.190 8000 port [tcp/*] succeeded!See the node.toml file to test with a remote bootstrap peer.
Configure OTEL Collector​
The monad package supports OTEL collector. Through this, you will be able to see all the
relevant Monad-specific metrics, available at http://0.0.0.0:8889/metrics.
OTEL_VERSION="0.139.0"OTEL_PACKAGE="https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v${OTEL_VERSION}/otelcol_${OTEL_VERSION}_linux_amd64.deb"
curl -fsSL "$OTEL_PACKAGE" -o /tmp/otelcol_linux_amd64.debdpkg -i /tmp/otelcol_linux_amd64.deb
cp /opt/monad/scripts/otel-config.yaml /etc/otelcol/config.yamlsystemctl restart otelcol
Configure the Node​
Get configuration files​
MainnetTestnetConfiguration files for full nodes:MF_BUCKET=https://bucket.monadinfra.comcurl -o /home/monad/.env $MF_BUCKET/config/mainnet/latest/.env.examplecurl -o /home/monad/monad-bft/config/node.toml $MF_BUCKET/config/mainnet/latest/full-node-node.tomlConfiguration files for validators:MF_BUCKET=https://bucket.monadinfra.comcurl -o /home/monad/.env $MF_BUCKET/config/mainnet/latest/.env.examplecurl -o /home/monad/monad-bft/config/node.toml $MF_BUCKET/config/mainnet/latest/node.tomlConfiguration files for full nodes:MF_BUCKET=https://bucket.monadinfra.comcurl -o /home/monad/.env $MF_BUCKET/config/testnet/latest/.env.examplecurl -o /home/monad/monad-bft/config/node.toml $MF_BUCKET/config/testnet/latest/full-node-node.tomlConfiguration files for validators:MF_BUCKET=https://bucket.monadinfra.comcurl -o /home/monad/.env $MF_BUCKET/config/testnet/latest/.env.examplecurl -o /home/monad/monad-bft/config/node.toml $MF_BUCKET/config/testnet/latest/node.toml
Define Keystore password​
Set your own unique and strong password for KEYSTORE_PASSWORD.
This password is used to encrypt and decrypt your keystores.
It must be wrapped in single quotes (e.g. 'password').
Assuming KEYSTORE_PASSWORD in /home/monad/.env file is not already set, generate a secure random password.
sed -i "s|^KEYSTORE_PASSWORD=$|KEYSTORE_PASSWORD='$(openssl rand -base64 32)'|" /home/monad/.envsource /home/monad/.env
mkdir -p /opt/monad/backup/echo "Keystore password: ${KEYSTORE_PASSWORD}" > /opt/monad/backup/keystore-password-backup
Generate Keystores​
Generate encrypted BLS and SECP keys using monad-keystore binary.
bash <<'EOF'set -e
source /home/monad/.env
if [[ -z "$KEYSTORE_PASSWORD" || \      -f /home/monad/monad-bft/config/id-secp || \      -f /home/monad/monad-bft/config/id-bls ]]; then  echo "Skipping: missing KEYSTORE_PASSWORD or keys already exist."  exit 1fi
monad-keystore create \  --key-type secp \  --keystore-path /home/monad/monad-bft/config/id-secp \  --password "${KEYSTORE_PASSWORD}" > /opt/monad/backup/secp-backup
monad-keystore create \  --key-type bls \  --keystore-path /home/monad/monad-bft/config/id-bls \  --password "${KEYSTORE_PASSWORD}" > /opt/monad/backup/bls-backup
grep "public key" /opt/monad/backup/secp-backup /opt/monad/backup/bls-backup \  | tee /home/monad/pubkey-secp-bls
echo "Success: New keystores generated"
EOF
Public keys are exported to /home/monad/pubkey-secp-bls for convenience.
External BackupPlease ensure that these backup files are properly stored in an external location, outside of the node. They are required to restore your full node or validator identity in the event of hardware failure or system loss:
/opt/monad/backup/secp-backup
/opt/monad/backup/bls-backup

Update node.toml​
Public Full node configurationFull nodes can receive block proposals either directly from a validator that whitelists it,
or via a raptorcast group. These different configurations are described
here.The bellow instructions are intended for the public full node configuration,
where a full node joins the network by connecting to available upstream validators participating
in secondary raptorcast. Joining in this configuration is permissionless.
Update the configuration that was downloaded previously (for reference, you can check the testnet config and the mainnet config):


Edit /home/monad/monad-bft/config/node.toml.


The beneficiary field to include the address that should receive block rewards.
For full nodes, this field can be set to the burn address.
beneficiary = "0x0000000000000000000000000000000000000000"
For validator, use the beneficiary wallet address. This address should be prefixed by 0x.
beneficiary = "0x<VALIDATOR_REWARDS_ADDRESS>"


Update the node_name field to include your provider name.
Note that if you are operating multiple nodes, the node name should be unique.
node_name = "full_<PROVIDER>-<OPTIONAL_SUFFIX>"


Ensure enable_client = true under [fullnode_raptorcast].


Ensure expand_to_group = true under [statesync].


[blocksync_override] peers should remain empty for public full nodes.


Node signature record​
The node Name record is a cryptographically signed record that contains a node's network address information and is used for peer discovery and network topology management in the monad-bft system.
Using the keypairs are created, a fullnode will need to sign its name record using the SECP key in order to participate in peer discovery.
The sequence number (seq) in the record allows nodes to determine which version of a peer's address information is most recent, supporting scenarios where nodes change their network location.
source /home/monad/.envmonad-sign-name-record \  --address $(curl -s4 ifconfig.me):8000 \  --keystore-path /home/monad/monad-bft/config/id-secp \  --password "${KEYSTORE_PASSWORD}" \  --self-record-seq-num 0
Update the peer_discovery section in node.toml with the IP addresses, sequence number and name record signature generated from the previous command, for example:
self_address = "12.34.56.78:8000"self_record_seq_num = 0self_name_record_sig = "5995f8dc5af4ca70e3b49ce793e7fe353d72b261c14037272958a9f0cc105fdd4890e56cb99765750ca48bab113cccbb378fc61dff8b23da4a03c07bba60034300"
Remote Configuration Fetching (v0.12.1+)​
Nodes can automatically fetch forkpoint.toml and validators.toml from remote locations on startup.
This feature is configured using the following environment variables in /home/monad/.env:
MainnetTestnetREMOTE_VALIDATORS_URL='https://bucket.monadinfra.com/validators/mainnet/validators.toml'REMOTE_FORKPOINT_URL='https://bucket.monadinfra.com/forkpoint/mainnet/forkpoint.toml'REMOTE_VALIDATORS_URL='https://bucket.monadinfra.com/validators/testnet/validators.toml'REMOTE_FORKPOINT_URL='https://bucket.monadinfra.com/forkpoint/testnet/forkpoint.toml'
These URLs point to the latest configuration files.
When defined, the node will automatically attempt to download fresh configuration files on startup, simplifying node operations and reducing manual intervention during network updates.
Monad Foundation is not the exclusive provider of these configuration files. Feel free to replace the above remote links with those from other providers.
Call traces (optional)​
For full nodes intended for archiving or RPC workflows, enabling --trace_calls is recommended.
This preserves the detailed error information necessary for call traces, e.g. debug_traceTransaction.
To make this override, please run systemctl edit monad-execution and add the --trace_calls CLI param
to the ExecStart definition (may need a line continuation character \):
systemctl edit monad-execution
[Service]Type=simpleExecStart=ExecStart=/usr/local/bin/monad \    ...    --trace_calls    ...
Monad Cruft service​
Installation of the monad Debian package enables the monad-cruft timer, which runs hourly to
clear old artifacts (/opt/monad/scripts/clear-old-artifacts.sh). This is necessary to prevent
inode exhaustion as artifacts like forkpoint.toml and ledger files accumulate.
Starting with v0.12.2, you can configure artifact retention times by setting environment variables in /home/monad/.env. The following variables control how long artifacts are retained before deletion (all values in minutes):

RETENTION_LEDGER - Ledger files (headers and bodies, default: 600 = 10 hours)
RETENTION_WAL - WAL files (default: 300 = 5 hours)
RETENTION_FORKPOINT - Forkpoint files (default: 300 = 5 hours)
RETENTION_VALIDATORS - Validators files (default: 43200 = 30 days)

# Example: Add retention configuration to /home/monad/.envRETENTION_LEDGER=600RETENTION_WAL=300RETENTION_FORKPOINT=300RETENTION_VALIDATORS=43200
To customize retention, add or modify these variables in /home/monad/.env. For example, to retain ledger files for 20 hours:
echo "RETENTION_LEDGER=1200" >> /home/monad/.env
These settings will be automatically picked up by the monad-cruft timer on its next hourly run.
Start the Node​
Set filesystem permissions:
chown -R monad:monad /home/monad/
Enable the monad services to allow them to automatically start whenever the server is rebooted:
systemctl enable monad-bft monad-execution monad-rpc
Next, run the Hard Reset Instructions to import a recent database snapshot into the node.
Start the monad services:
systemctl start monad-bft monad-execution monad-rpc
This completes the process of starting up a full node!
Refer to the General Operations to monitor the state of the node.

### Code Examples

```prism
apt updateapt upgrade -y
```

```prism
apt install -y curl nvme-cli aria2 jq
```

```prism
cat <<EOF > /etc/apt/sources.list.d/category-labs.sourcesTypes: debURIs: https://pkg.category.xyz/Suites: nobleComponents: mainSigned-By: /etc/apt/keyrings/category-labs.gpgEOF
curl -fsSL https://pkg.category.xyz/keys/public-key.asc \  | gpg --dearmor --yes -o /etc/apt/keyrings/category-labs.gpg
```

```prism
apt updateapt install -y monad=0.12.2-rpc-hotfix2apt-mark hold monad
```

```prism
apt updateapt install -y monad=0.12.2-rpc-hotfix2apt-mark hold monad
```

```prism
useradd -m -s /bin/bash monad
```

```prism
mkdir -p /home/monad/monad-bft/config \         /home/monad/monad-bft/ledger \         /home/monad/monad-bft/config/forkpoint \         /home/monad/monad-bft/config/validators
```

```prism
TRIEDB_DRIVE=/dev/nvme1n1 # CHANGE THIS TO YOUR NVME DRIVE
parted $TRIEDB_DRIVE mklabel gptparted $TRIEDB_DRIVE mkpart triedb 0% 100%
```

```prism
PARTUUID=$(lsblk -o PARTUUID $TRIEDB_DRIVE | tail -n 1)echo "Disk PartUUID: ${PARTUUID}"
echo "ENV{ID_PART_ENTRY_UUID}==\"$PARTUUID\", MODE=\"0666\", SYMLINK+=\"triedb\"" \  | tee /etc/udev/rules.d/99-triedb.rules
```

```prism
udevadm triggerudevadm control --reloadudevadm settlels -l /dev/triedb
```

```prism
nvme id-ns -H $TRIEDB_DRIVE | grep 'LBA Format' | grep 'in use'
```

```prism
LBA Format  0 : Metadata Size: 0   bytes - Data Size: 512 bytes - Relative Performance: 0 Best (in use)
```

```prism
nvme format --lbaf=0 $TRIEDB_DRIVE
```

```prism
nvme id-ns -H $TRIEDB_DRIVE | grep 'LBA Format' | grep 'in use'
```

```prism
systemctl start monad-mptjournalctl -u monad-mpt -n 14 -o cat
```

```prism
MPT database on storages:          Capacity           Used      %  Path           1.75 Tb      256.03 Mb  0.01%  "/dev/nvme1n1p1"MPT database internal lists:     Fast: 1 chunks with capacity 256.00 Mb used 0.00 bytes     Slow: 1 chunks with capacity 256.00 Mb used 0.00 bytes     Free: 7148 chunks with capacity 1.75 Tb used 0.00 bytesMPT database has 1 history, earliest is 18446744073709551615 latest is 18446744073709551615.     It has been configured to retain no more than 33554432.     Latest proposed is (18446744073709551615, 0000000000000000000000000000000000000000000000000000000000000000).     Latest voted is (18446744073709551615, 0000000000000000000000000000000000000000000000000000000000000000).     Latest finalized is 18446744073709551615, latest verified is 18446744073709551615, auto expire version is 0monad-mpt.service: Deactivated successfully.Finished monad-mpt.service - "Service file for Monad MPT".
```

```prism
ufw allow sshufw allow 8000ufw enableufw status
```

```prism
$ nc -vz 64.31.29.190 8000Connection to 64.31.29.190 8000 port [tcp/*] succeeded!
```

```prism
OTEL_VERSION="0.139.0"OTEL_PACKAGE="https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v${OTEL_VERSION}/otelcol_${OTEL_VERSION}_linux_amd64.deb"
curl -fsSL "$OTEL_PACKAGE" -o /tmp/otelcol_linux_amd64.debdpkg -i /tmp/otelcol_linux_amd64.deb
cp /opt/monad/scripts/otel-config.yaml /etc/otelcol/config.yamlsystemctl restart otelcol
```

```prism
MF_BUCKET=https://bucket.monadinfra.comcurl -o /home/monad/.env $MF_BUCKET/config/mainnet/latest/.env.examplecurl -o /home/monad/monad-bft/config/node.toml $MF_BUCKET/config/mainnet/latest/full-node-node.toml
```

```prism
MF_BUCKET=https://bucket.monadinfra.comcurl -o /home/monad/.env $MF_BUCKET/config/mainnet/latest/.env.examplecurl -o /home/monad/monad-bft/config/node.toml $MF_BUCKET/config/mainnet/latest/node.toml
```

```prism
MF_BUCKET=https://bucket.monadinfra.comcurl -o /home/monad/.env $MF_BUCKET/config/testnet/latest/.env.examplecurl -o /home/monad/monad-bft/config/node.toml $MF_BUCKET/config/testnet/latest/full-node-node.toml
```

```prism
MF_BUCKET=https://bucket.monadinfra.comcurl -o /home/monad/.env $MF_BUCKET/config/testnet/latest/.env.examplecurl -o /home/monad/monad-bft/config/node.toml $MF_BUCKET/config/testnet/latest/node.toml
```

```prism
sed -i "s|^KEYSTORE_PASSWORD=$|KEYSTORE_PASSWORD='$(openssl rand -base64 32)'|" /home/monad/.envsource /home/monad/.env
mkdir -p /opt/monad/backup/echo "Keystore password: ${KEYSTORE_PASSWORD}" > /opt/monad/backup/keystore-password-backup
```

```prism
bash <<'EOF'set -e
source /home/monad/.env
if [[ -z "$KEYSTORE_PASSWORD" || \      -f /home/monad/monad-bft/config/id-secp || \      -f /home/monad/monad-bft/config/id-bls ]]; then  echo "Skipping: missing KEYSTORE_PASSWORD or keys already exist."  exit 1fi
monad-keystore create \  --key-type secp \  --keystore-path /home/monad/monad-bft/config/id-secp \  --password "${KEYSTORE_PASSWORD}" > /opt/monad/backup/secp-backup
monad-keystore create \  --key-type bls \  --keystore-path /home/monad/monad-bft/config/id-bls \  --password "${KEYSTORE_PASSWORD}" > /opt/monad/backup/bls-backup
grep "public key" /opt/monad/backup/secp-backup /opt/monad/backup/bls-backup \  | tee /home/monad/pubkey-secp-bls
echo "Success: New keystores generated"
EOF
```

```prism
beneficiary = "0x0000000000000000000000000000000000000000"
```

```prism
beneficiary = "0x<VALIDATOR_REWARDS_ADDRESS>"
```

```prism
node_name = "full_<PROVIDER>-<OPTIONAL_SUFFIX>"
```

```prism
source /home/monad/.envmonad-sign-name-record \  --address $(curl -s4 ifconfig.me):8000 \  --keystore-path /home/monad/monad-bft/config/id-secp \  --password "${KEYSTORE_PASSWORD}" \  --self-record-seq-num 0
```

```prism
self_address = "12.34.56.78:8000"self_record_seq_num = 0self_name_record_sig = "5995f8dc5af4ca70e3b49ce793e7fe353d72b261c14037272958a9f0cc105fdd4890e56cb99765750ca48bab113cccbb378fc61dff8b23da4a03c07bba60034300"
```

```prism
REMOTE_VALIDATORS_URL='https://bucket.monadinfra.com/validators/mainnet/validators.toml'REMOTE_FORKPOINT_URL='https://bucket.monadinfra.com/forkpoint/mainnet/forkpoint.toml'
```

```prism
REMOTE_VALIDATORS_URL='https://bucket.monadinfra.com/validators/testnet/validators.toml'REMOTE_FORKPOINT_URL='https://bucket.monadinfra.com/forkpoint/testnet/forkpoint.toml'
```

```prism
systemctl edit monad-execution
```

```prism
[Service]Type=simpleExecStart=ExecStart=/usr/local/bin/monad \    ...    --trace_calls    ...
```

```prism
# Example: Add retention configuration to /home/monad/.envRETENTION_LEDGER=600RETENTION_WAL=300RETENTION_FORKPOINT=300RETENTION_VALIDATORS=43200
```

```prism
echo "RETENTION_LEDGER=1200" >> /home/monad/.env
```

```prism
chown -R monad:monad /home/monad/
```

```prism
systemctl enable monad-bft monad-execution monad-rpc
```

```prism
systemctl start monad-bft monad-execution monad-rpc
```

---

## Full Replay

> Source: https://docs.monad.xyz/node-ops/node-recovery/full-replay

On this page

Full Replay allows a node to catch up on missed blocks by simply retrieving and replaying them
serially. This is helpful for nodes that want all intermediary state and transactional artifacts
to be generated. For example, an RPC provider would probably want this to ensure that they can
respond to requests like eth_call, eth_getBalance, or eth_estimateGas for blocks
that were skipped.
Context​
A node that has not locally executed block forkpoint.root - delay will statesync on startup. Also, nodes don’t serve blocksync requests more than statesync_threshold (600) blocks ago. Statesync is the only in-protocol way for that node to recover.
This document describes an alternate way to recover a node while backfilling historical state in the event that a node has been down for longer than the blocksync provision window (600 blocks).
Note that if statesync_threshold in node.toml is set to a value larger than that, blocksync will fail.
Access to a healthy node requiredIn order to recover the faulty node with complete historical state, the below
procedure requires SSH access to a node that was healthy throughout the faulty node's downtime.Let REMOTE_HOST be the healthy node that can be used for recovery.
Procedure​

SSH into the faulty node as monad user.
Ensure statesync_threshold = 600 in node.toml

$ grep statesync_threshold /home/monad/monad-bft/config/node.tomlstatesync_threshold = 600

Stop the monad services

sudo systemctl stop monad-bft monad-execution monad-rpc


Run this script to copy missing blocks, then run execution up to that point. You will need to run it several times since the tip of the chain will continue advancing while this script is executing.


NOTE: You will need to manually interrupt the process (Ctrl - C) once output stops.


Copy this script and name it manual-sync.sh
#!/usr/bin/env bashset -euo pipefail
# Load config first so SSH_PORT, REMOTE_HOST, CHAIN etc are setsource .env
: "${SSH_PORT:?SSH_PORT must be set}": "${REMOTE_HOST:?REMOTE_HOST must be set}": "${CHAIN:?CHAIN must be set}"
echo "Reading files from $REMOTE_HOST"echo "Using ssh port: $SSH_PORT"
# Copy proposed and finalized header symlinks firstrsync -avP -e "ssh -p $SSH_PORT" \  "monad@$REMOTE_HOST:/home/monad/monad-bft/ledger/headers/*_head" \  /home/monad/monad-bft/ledger/headers/
# Copy new headers and bodies, but don't overwrite existing onesrsync -avP --ignore-existing -e "ssh -p $SSH_PORT" \  "monad@$REMOTE_HOST:/home/monad/monad-bft/ledger/" \  /home/monad/monad-bft/ledger/
# Note: the --state-sync flag is NOT present/usr/local/bin/monad \  --chain "$CHAIN" \  --db /dev/triedb \  --block_db /home/monad/monad-bft/ledger \  --sq_thread_cpu 1 \  --log_level INFO


Run the script
REMOTE_HOST=node1.<provider>.com SSH_PORT=22 CHAIN=monad_mainnet bash manual-sync-step-1.sh




Once the first script completes in under 1 min, run this script:

Copy this and name it manual-sync-step-2.sh
#!/usr/bin/env bashset -euo pipefail
# Load config first so SSH_PORT, REMOTE_HOST, CHAIN etc are setsource .env
: "${SSH_PORT:?SSH_PORT must be set}": "${REMOTE_HOST:?REMOTE_HOST must be set}": "${CHAIN:?CHAIN must be set}"
# Copy current forkpointrsync -av -e "ssh -p $SSH_PORT" \  "monad@$REMOTE_HOST:/home/monad/monad-bft/config/forkpoint/forkpoint.rlp" \  /home/monad/monad-bft/config/forkpoint/rsync -av -e "ssh -p $SSH_PORT" \  "monad@$REMOTE_HOST:/home/monad/monad-bft/config/forkpoint/forkpoint.toml" \  /home/monad/monad-bft/config/forkpoint/forkpoint.tomlrsync -av -e "ssh -p $SSH_PORT" \  "monad@$REMOTE_HOST:/home/monad/monad-bft/config/validators/validators.toml" \  /home/monad/monad-bft/config/validators/validators.toml
systemctl start monad-bft monad-execution monad-rpc

Run the script
REMOTE_HOST=node1.<provider>.com SSH_PORT=22 CHAIN=monad_mainnet bash manual-sync-step-2.sh




Check​
To check that statesync has been avoided, send an eth_getBlockByNumber RPC request
for blocks finalized while the node was down.
curl http://localhost:8080 \  -X POST \  -H "Content-Type: application/json" \  --data '{"jsonrpc":"2.0","method":"eth_getBlockByNumber","params":["0xdedbeef", false],"id":1}'

### Code Examples

```prism
$ grep statesync_threshold /home/monad/monad-bft/config/node.tomlstatesync_threshold = 600
```

```prism
sudo systemctl stop monad-bft monad-execution monad-rpc
```

```prism
#!/usr/bin/env bashset -euo pipefail
# Load config first so SSH_PORT, REMOTE_HOST, CHAIN etc are setsource .env
: "${SSH_PORT:?SSH_PORT must be set}": "${REMOTE_HOST:?REMOTE_HOST must be set}": "${CHAIN:?CHAIN must be set}"
echo "Reading files from $REMOTE_HOST"echo "Using ssh port: $SSH_PORT"
# Copy proposed and finalized header symlinks firstrsync -avP -e "ssh -p $SSH_PORT" \  "monad@$REMOTE_HOST:/home/monad/monad-bft/ledger/headers/*_head" \  /home/monad/monad-bft/ledger/headers/
# Copy new headers and bodies, but don't overwrite existing onesrsync -avP --ignore-existing -e "ssh -p $SSH_PORT" \  "monad@$REMOTE_HOST:/home/monad/monad-bft/ledger/" \  /home/monad/monad-bft/ledger/
# Note: the --state-sync flag is NOT present/usr/local/bin/monad \  --chain "$CHAIN" \  --db /dev/triedb \  --block_db /home/monad/monad-bft/ledger \  --sq_thread_cpu 1 \  --log_level INFO
```

```prism
REMOTE_HOST=node1.<provider>.com SSH_PORT=22 CHAIN=monad_mainnet bash manual-sync-step-1.sh
```

```prism
#!/usr/bin/env bashset -euo pipefail
# Load config first so SSH_PORT, REMOTE_HOST, CHAIN etc are setsource .env
: "${SSH_PORT:?SSH_PORT must be set}": "${REMOTE_HOST:?REMOTE_HOST must be set}": "${CHAIN:?CHAIN must be set}"
# Copy current forkpointrsync -av -e "ssh -p $SSH_PORT" \  "monad@$REMOTE_HOST:/home/monad/monad-bft/config/forkpoint/forkpoint.rlp" \  /home/monad/monad-bft/config/forkpoint/rsync -av -e "ssh -p $SSH_PORT" \  "monad@$REMOTE_HOST:/home/monad/monad-bft/config/forkpoint/forkpoint.toml" \  /home/monad/monad-bft/config/forkpoint/forkpoint.tomlrsync -av -e "ssh -p $SSH_PORT" \  "monad@$REMOTE_HOST:/home/monad/monad-bft/config/validators/validators.toml" \  /home/monad/monad-bft/config/validators/validators.toml
systemctl start monad-bft monad-execution monad-rpc
```

```prism
REMOTE_HOST=node1.<provider>.com SSH_PORT=22 CHAIN=monad_mainnet bash manual-sync-step-2.sh
```

```prism
curl http://localhost:8080 \  -X POST \  -H "Content-Type: application/json" \  --data '{"jsonrpc":"2.0","method":"eth_getBlockByNumber","params":["0xdedbeef", false],"id":1}'
```

---

## General Operations

> Source: https://docs.monad.xyz/node-ops/general-operations

On this page

Version Information​
View the version and build information for your Monad binaries:
monad-node --version# Example output: monad-node {"commit":"c0cdcaae8eb527e44d72c4638c1f1335025a5132","tag":"v0.12.2-rc","branch":"","modified":true}
CLI Help​
View available command-line arguments for any Monad binary:
monad-rpc --helpmonad --helpmonad-bft --help
warningCLI arguments should not be changed arbitrarily as some configurations may result in unexpected behavior or crashes.
Service Management​
Check the status of Monad services:
# Check all services at oncesystemctl status monad-bft monad-execution monad-rpc --no-pager -l
# Check individual service statussystemctl status monad-bftsystemctl status monad-executionsystemctl status monad-rpc
# View logs for a specific servicejournalctl -u monad-bft -fjournalctl -u monad-execution -fjournalctl -u monad-rpc -f
Monitoring Block Height​
The RPC service will start listening on port 8080 when the statesync is completed.
Check the current block height via RPC:
curl http://localhost:8080/ \  -X POST \  -H "Content-Type: application/json" \  --data '{"method":"eth_blockNumber","params":[],"id":1,"jsonrpc":"2.0"}'
Viewing MonadDB Disk Usage​
Note that MonadDB (TrieDB) will automatically compact when at 80% capacity to preserve
optimal SSD performance. To check MonadDB disk usage and retained block history:
monad-mpt --storage /dev/triedb
Example output:
MPT database on storages:          Capacity           Used      %  Path           3.49 Tb       24.30 Gb  0.68%  "/dev/nvme1n1p1"MPT database internal lists:     Fast: 94 chunks with capacity 23.50 Gb used 23.40 Gb     Slow: 3 chunks with capacity 768.00 Mb used 658.72 Mb     Free: 14207 chunks with capacity 3.47 Tb used 0.00 bytesMPT database has 599928 history, earliest is 36784905 latest is 37384832.     It has been configured to retain no more than 33554432.     Latest proposed is (37384832, 88a5550ba067c2f21cef6b6e8953fbf700fe300905952e5621335fe2bd58729c).     Latest voted is (37384831, 56074c2429909c2966bfe8df55810ec3b8f4f4f599b407ff89ec92b090656ab1).     Latest finalized is 37384830, latest verified is 37384827, auto expire version is 36784905
Log Analysis with monlog​
monlog is a lightweight tool maintained by Category Labs
that scrapes BFT logs and provides useful status information and suggestions. It
examines logs from the last 60 seconds.
Setup (as root user):
First, grant the monad user access to read systemd journal logs:
# Add monad user to systemd-journal groupusermod -a -G systemd-journal monad
Download monlog (as monad user):
cd /home/monadcurl -sSL https://pub-b0d0d7272c994851b4c8af22a766f571.r2.dev/scripts/monlog -Ochmod u+x ./monlog
infoIf you're already logged in as the monad user when the group is added, you'll need to log out and log back in for the group membership to take effect. Alternatively, you can run su - monad to start a new session.
Run monlog (as monad user):
./monlog
# For live updateswatch -d "./monlog"
# Show last 10 lines of grabbed logs./monlog -r
Example output for a healthy node:
Installed version:ii monad 0.12.1~rc amd64 Monad BFT stack (symbols stripped)
No StateSync messages.---No BlockSync messages.---Most recent round: 52268965Most recent epoch: 1001Most recent block: 50041845Blocks processing and being committed ✅
Consensus Information with ledger-tail​
monad-ledger-tail exposes consensus information by directly parsing ledger artifacts
and streams the data in JSON format.
Start the service:
systemctl start monad-ledger-tail
# View outputjournalctl -fu monad-ledger-tail
Example output:
// the real output is all on one line, but we've prettified this for legibility:{  "timestamp": "2025-11-23T03:09:09.534974Z",  "level": "INFO",  "fields": {    "message": "proposed_block",    "round": "53449032",    "parent_round": "53449031",    "epoch": "1024",    "seq_num": "51203516",    "num_tx": "3",    "author": "036daee7750e29e46eb64d86ad1cc7b235d7f1ad9597941a3a77cdd641cead4528",    "block_ts_ms": "1763867349470",    "now_ts_ms": "1763867349534",    "author_address": ""  },  "target": "ledger_tail"}
Node Status with monad-status​
Install monad-status:
curl -sSL https://bucket.monadinfra.com/scripts/monad-status.sh -o /usr/local/bin/monad-statuschmod +x /usr/local/bin/monad-status
Run monad-status to get the status of the node.
This should print similar output:
### Monad Node Status
hostname: monad-nodedate: Wed Nov 26 10:48:26 PM CET 2025uptime: 0d 00h 41m 49sversion: 0.12.2config:  network: mainnet  chain: monad_mainnet  chainId: 143  secpPublicKey: 03831b36b50261011d82f94d58f8aa0edfe058359e2c365c37cce678436b9eb371  blsPublicKey: b9c1905e11e8395a789bece454ec24bed98b96cf9dc04c02c9512fb94900d3e0355383e542c44a0eb1be4d2780a1fb2f  nodeSignature: 4f6e3e47af0e8ff3614e1eb53f9015ef4fc8593e60c13d52c2b458d05385b5f94cff8776ceb8b9401c3647148637d599622353d0631864a23b07f6d7fb55e84f00  selfAddress: 65.109.145.172:8000  recordSeqNum: 0services:  monad-bft: running  monad-execution: running  monad-rpc: running  otelcol: running  monad-cruft:    activated: true    previous: 48min ago    next: 11minpeers:  peersNumber: 1146consensus:  status: in-sync  mode: live  epoch: 764  round: 38259075  blockNumber: 38200041  blockNumberFromExternal: 38200040  blockDifference: 0statesync:  percentage: 100.0000%  progress: 38193694  target: 38193694rpc:  status: active  clientVersion: Monad/0.12.2  netVersion: 143  blockNumber: 38200041

### Code Examples

```prism
monad-node --version# Example output: monad-node {"commit":"c0cdcaae8eb527e44d72c4638c1f1335025a5132","tag":"v0.12.2-rc","branch":"","modified":true}
```

```prism
monad-rpc --helpmonad --helpmonad-bft --help
```

```prism
# Check all services at oncesystemctl status monad-bft monad-execution monad-rpc --no-pager -l
# Check individual service statussystemctl status monad-bftsystemctl status monad-executionsystemctl status monad-rpc
# View logs for a specific servicejournalctl -u monad-bft -fjournalctl -u monad-execution -fjournalctl -u monad-rpc -f
```

```prism
curl http://localhost:8080/ \  -X POST \  -H "Content-Type: application/json" \  --data '{"method":"eth_blockNumber","params":[],"id":1,"jsonrpc":"2.0"}'
```

```prism
monad-mpt --storage /dev/triedb
```

```prism
MPT database on storages:          Capacity           Used      %  Path           3.49 Tb       24.30 Gb  0.68%  "/dev/nvme1n1p1"MPT database internal lists:     Fast: 94 chunks with capacity 23.50 Gb used 23.40 Gb     Slow: 3 chunks with capacity 768.00 Mb used 658.72 Mb     Free: 14207 chunks with capacity 3.47 Tb used 0.00 bytesMPT database has 599928 history, earliest is 36784905 latest is 37384832.     It has been configured to retain no more than 33554432.     Latest proposed is (37384832, 88a5550ba067c2f21cef6b6e8953fbf700fe300905952e5621335fe2bd58729c).     Latest voted is (37384831, 56074c2429909c2966bfe8df55810ec3b8f4f4f599b407ff89ec92b090656ab1).     Latest finalized is 37384830, latest verified is 37384827, auto expire version is 36784905
```

```prism
# Add monad user to systemd-journal groupusermod -a -G systemd-journal monad
```

```prism
cd /home/monadcurl -sSL https://pub-b0d0d7272c994851b4c8af22a766f571.r2.dev/scripts/monlog -Ochmod u+x ./monlog
```

```prism
./monlog
# For live updateswatch -d "./monlog"
# Show last 10 lines of grabbed logs./monlog -r
```

```prism
Installed version:ii monad 0.12.1~rc amd64 Monad BFT stack (symbols stripped)
No StateSync messages.---No BlockSync messages.---Most recent round: 52268965Most recent epoch: 1001Most recent block: 50041845Blocks processing and being committed ✅
```

```prism
systemctl start monad-ledger-tail
# View outputjournalctl -fu monad-ledger-tail
```

```prism
// the real output is all on one line, but we've prettified this for legibility:{  "timestamp": "2025-11-23T03:09:09.534974Z",  "level": "INFO",  "fields": {    "message": "proposed_block",    "round": "53449032",    "parent_round": "53449031",    "epoch": "1024",    "seq_num": "51203516",    "num_tx": "3",    "author": "036daee7750e29e46eb64d86ad1cc7b235d7f1ad9597941a3a77cdd641cead4528",    "block_ts_ms": "1763867349470",    "now_ts_ms": "1763867349534",    "author_address": ""  },  "target": "ledger_tail"}
```

```prism
curl -sSL https://bucket.monadinfra.com/scripts/monad-status.sh -o /usr/local/bin/monad-statuschmod +x /usr/local/bin/monad-status
```

```prism
### Monad Node Status
hostname: monad-nodedate: Wed Nov 26 10:48:26 PM CET 2025uptime: 0d 00h 41m 49sversion: 0.12.2config:  network: mainnet  chain: monad_mainnet  chainId: 143  secpPublicKey: 03831b36b50261011d82f94d58f8aa0edfe058359e2c365c37cce678436b9eb371  blsPublicKey: b9c1905e11e8395a789bece454ec24bed98b96cf9dc04c02c9512fb94900d3e0355383e542c44a0eb1be4d2780a1fb2f  nodeSignature: 4f6e3e47af0e8ff3614e1eb53f9015ef4fc8593e60c13d52c2b458d05385b5f94cff8776ceb8b9401c3647148637d599622353d0631864a23b07f6d7fb55e84f00  selfAddress: 65.109.145.172:8000  recordSeqNum: 0services:  monad-bft: running  monad-execution: running  monad-rpc: running  otelcol: running  monad-cruft:    activated: true    previous: 48min ago    next: 11minpeers:  peersNumber: 1146consensus:  status: in-sync  mode: live  epoch: 764  round: 38259075  blockNumber: 38200041  blockNumberFromExternal: 38200040  blockDifference: 0statesync:  percentage: 100.0000%  progress: 38193694  target: 38193694rpc:  status: active  clientVersion: Monad/0.12.2  netVersion: 143  blockNumber: 38200041
```

---

## Hard Reset Instructions

> Source: https://docs.monad.xyz/node-ops/node-recovery/hard-reset

On this page

Hard reset wipes the local state and downloads the most recent chain snapshot. After the snapshot
is applied, the node catches up using statesync and
blocksync.
Hard reset is the most powerful means of resetting a node. Steps are:

Download a recent snapshot of the network state. As of Nov 2025, this is about 60 GB on testnet
but is very small on mainnet.
Initialize the DB from the snapshot (this can take up to an hour on testnet and a few minutes on mainnet)
Catch up to the tip of the chain via statesync / blocksync (typically 2-5 minutes assuming
snapshot is a few hours old)

Snapshot RestoreMonad Foundation and Category Labs are snapshot providers.
If there is an issue, please refer to Discord validator channels for more snapshot providers.
Prerequisite​

aria2 must be installed on the node

Instructions​


SSH into the node as root user.


Stop the monad services and reset the workspace to delete all runtime data.
bash /opt/monad/scripts/reset-workspace.sh


Download and import TrieDB database snapshot.
MainnetTestnetinfoOn mainnet, database snapshot restoration takes from 1 to 5 minutes.
As the blockchain grows over time, snapshot restoration takes longer.Using Monad Foundation provider:MF_BUCKET=https://bucket.monadinfra.comcurl -sSL $MF_BUCKET/scripts/mainnet/restore-from-snapshot.sh | bashUsing Category Labs provider:CL_BUCKET=https://pub-b0d0d7272c994851b4c8af22a766f571.r2.devcurl -sSL $CL_BUCKET/scripts/mainnet/restore_from_snapshot.sh | bashinfoOn testnet, database snapshot restoration takes up to 1 hour.
As the blockchain grows over time, snapshot restoration takes longer.Using Monad Foundation provider:MF_BUCKET=https://bucket.monadinfra.comcurl -sSL $MF_BUCKET/scripts/testnet/restore-from-snapshot.sh | bashUsing Category Labs provider:CL_BUCKET=https://pub-b0d0d7272c994851b4c8af22a766f571.r2.devcurl -sSL $CL_BUCKET/scripts/testnet/restore_from_snapshot.sh | bash


Fetch latest forkpoint.toml and validators.toml runtime files.
Automatic FetchThis step is optional if automatic remote config fetching is configured (v0.12.1+).
Ensure REMOTE_VALIDATORS_URL and REMOTE_FORKPOINT_URL are defined in your .env file.
See Full Node Installation for configuration details.
If not configured, you may run the below commands.
MainnetTestnetMF_BUCKET=https://bucket.monadinfra.comVALIDATORS_FILE=/home/monad/monad-bft/config/validators/validators.toml 
curl -sSL $MF_BUCKET/scripts/mainnet/download-forkpoint.sh | bashcurl $MF_BUCKET/validators/mainnet/validators.toml -o $VALIDATORS_FILEchown monad:monad $VALIDATORS_FILEMF_BUCKET=https://bucket.monadinfra.comVALIDATORS_FILE=/home/monad/monad-bft/config/validators/validators.toml 
curl -sSL $MF_BUCKET/scripts/testnet/download-forkpoint.sh | bashcurl $MF_BUCKET/validators/testnet/validators.toml -o $VALIDATORS_FILEchown monad:monad $VALIDATORS_FILE


Start all services
systemctl start monad-bft monad-execution monad-rpc

### Code Examples

```prism
bash /opt/monad/scripts/reset-workspace.sh
```

```prism
MF_BUCKET=https://bucket.monadinfra.comcurl -sSL $MF_BUCKET/scripts/mainnet/restore-from-snapshot.sh | bash
```

```prism
CL_BUCKET=https://pub-b0d0d7272c994851b4c8af22a766f571.r2.devcurl -sSL $CL_BUCKET/scripts/mainnet/restore_from_snapshot.sh | bash
```

```prism
MF_BUCKET=https://bucket.monadinfra.comcurl -sSL $MF_BUCKET/scripts/testnet/restore-from-snapshot.sh | bash
```

```prism
CL_BUCKET=https://pub-b0d0d7272c994851b4c8af22a766f571.r2.devcurl -sSL $CL_BUCKET/scripts/testnet/restore_from_snapshot.sh | bash
```

```prism
MF_BUCKET=https://bucket.monadinfra.comVALIDATORS_FILE=/home/monad/monad-bft/config/validators/validators.toml 
curl -sSL $MF_BUCKET/scripts/mainnet/download-forkpoint.sh | bashcurl $MF_BUCKET/validators/mainnet/validators.toml -o $VALIDATORS_FILEchown monad:monad $VALIDATORS_FILE
```

```prism
MF_BUCKET=https://bucket.monadinfra.comVALIDATORS_FILE=/home/monad/monad-bft/config/validators/validators.toml 
curl -sSL $MF_BUCKET/scripts/testnet/download-forkpoint.sh | bashcurl $MF_BUCKET/validators/testnet/validators.toml -o $VALIDATORS_FILEchown monad:monad $VALIDATORS_FILE
```

```prism
systemctl start monad-bft monad-execution monad-rpc
```

---

## Hardware Requirements

> Source: https://docs.monad.xyz/node-ops/hardware-requirements

On this page

warningCloud-based environments are not officially supported.
Requirements​
All requirements are the same between validators (consensus participants) and full nodes
aside from bandwidth:

CPU: 16 core CPU with 4.5 GHz+ base clock speed, e.g. AMD Ryzen 9950x, AMD Ryzen 7950x,
AMD EPYC 4584PX, etc.
Memory: 32 GB+ RAM
Storage:

2TB dedicated disk for TrieDB (Execution)
500GB Disk for MonadBFT / OS
PCIe Gen4x4 NVME SSD or better for both


Bandwidth:

300 Mbit/s (Validators)
100 Mbit/s (Full Nodes)



warningHard drive performance can vary dramatically by manufacturer. Below are results from internal testing:Ranked performance
Samsung 980 / 990 Pro - PCIe 4.0, top class performance
Samsung PM9A1 - PCIe 4.0, pretty good performance and stable performance under load
Micron 7450 - PCIe 4.0, pretty good performance BUT has weird random slowdowns under a lot of load
Known unreliable
Nextorage SSDs - can become unresponsive under load due to overheating, requiring a system reboot.

A community-driven set of hardware recommendations and notes can be found here.
Why Bare Metal?​
Monad nodes must operate on bare metal servers rather than virtualized or cloud-based environments (e.g., AWS EC2, GCP, Azure) due to the system's strict performance and timing requirements.
A bare metal server gives the node direct, stable access to hardware, ensuring smooth operation and synchronization with the network:


Monad’s consensus protocol enforces tight time windows—blocks are proposed and voted on in sub-second intervals, and the network assumes nodes can validate and execute blocks within this budget. In such a situation, cloud-based environments may introduce latency and unpredictability, which can cause nodes to miss deadlines, fall behind in block processing, or become unstable during high-throughput periods.


Even when resources appear sufficient on paper, virtualization adds an additional layer of software between the node and physical hardware. This layer introduces context switching overhead and restricts direct I/O access to SSDs and network interfaces. These effects are negligible for average compute tasks but become significant when sustained high-throughput and low-latency operations are required, as in Monad’s consensus and execution loops.


In summary, a bare metal server provides predictability and determinism, which are crucial for maintaining synchronization and throughput across the network. Cloud-hosted VMs may work under light loads, but they cannot guarantee consistent real-time performance required by Monad consensus at scale.

---

## How Full Nodes Receive Blocks

> Source: https://docs.monad.xyz/node-ops/full-node-block-delivery

On this page

noteSee here for instructions on how to set up a full node.
The RaptorCast protocol is a new method of one-to-many
block propagation that uses an erasure-coded two-level broadcast tree to propagate large blocks
from a message originator to many listeners.
RaptorCast is used both for communication among validators, as well as for validators to
propagate blocks outward to full nodes.
The former is primary RaptorCast - how validators in the active set receive block proposals
from the leader.
The latter is secondary RaptorCast - how each validator pushes a block proposal to downstream
full nodes.
Secondary RaptorCast follows the same mechanism as primary RaptorCast, except the message
originator is fixed, other full nodes serve as the other participants, and all weights on the nodes
are equal rather than stake-weighted.
Secondary RaptorCast allows the network to support a huge set of full nodes. In the
recommended configuration, each validator has a secondary RaptorCast group of size 150, so if the
network has 200 nodes, there is capacity for 30,000 full nodes. After accounting for a redundancy
factor of 3 (full nodes may register for multiple secondary RaptorCast groups), there is still
capacity for 10,000 full nodes.
How full nodes register for secondary RaptorCast​


Full nodes start by peering with some of the validators. They do this by peering with the
bootstrap peers specified in node.toml, then asking them for their peers, and repeating until they
have the name records of the full validator set.


On a recurring basis, each validator (provided that it has enable_publisher = true in
node.toml) sends invites to the full nodes in its routing table up to max_group_size,
inviting the full nodes to join that validator's secondary RaptorCast group.


A full node will accept or reject, rejecting if they are already in too many groups.


The validator will collect these accept/reject responses and confirm a group.


The group will lasts for round_span specified in the validator's node.toml (default: 240
rounds). When one of these intervals is close to finishing, the validator starts sending
invites for its next secondary RaptorCast group.


Full nodes can (and should) join multiple secondary RaptorCast groups for redundancy.
This is controlled by the max_num_group parameter below.


Note that when a full node first statesyncs, it will need to wait a little bit before being added
to a secondary RaptorCast group.
Configuration​
node.toml contains the following settings:
[fullnode_raptorcast]enable_publisher = trueenable_client = trueraptor10_fullnode_redundancy_factor = 3.0max_group_size = 150round_span = 240invite_lookahead = 20max_invite_wait = 10deadline_round_dist = 10init_empty_round_span = 23max_num_group = 3invite_future_dist_min = 1invite_future_dist_max = 600invite_accept_heartbeat_ms = 10000
[fullnode_raptorcast.full_nodes_prioritized]identities = []
Some parameters only affect validators:

enable_publisher = true means that if the full node becomes a validator, it will participate
as a secondary RaptorCast originator.
max_group_size maximum number of full nodes in a group
round_span number of rounds that a group last for
invite_lookahead how far ahead (in rounds) does a validator sends invites to full nodes before the start of the round
max_invite_wait maximum number of rounds that a validator wait for invite response from the full node

Some parameters only affect full nodes:

full nodes should have enable_client = true to participate in secondary RaptorCast
max_num_group indicates the maximum number of groups that the full node will join
invite_future_dist_min and invite_future_dist_max indicates the time range (in rounds) that
the full node will accept the secondary raptorcast group invite
invite_accept_hearbeat_ms is a heartbeat which is used to determine whether the full node is
receiving proposals

Although some parameters only affect full nodes, node operators running validators should still
populate these parameters thoughtfully becasue whenever the validator is not in the active set,
it should still keep up with the chain tip. Operators will likely want to start their validators
as full nodes before activating to avoid missing block proposals.
Additional options​
Prioritized secondary RaptorCast inclusion​
A full node may coordinate with a validator to be explicitly and consistently invited to that
validator's secondary RaptorCast group.
To do this, the full node provides some information for the validator to include in its
[fullnode_raptorcast.full_nodes_prioritized.identities] section.  See
Validator Installation for details on what needs to
be provided. Note that this means the full node doesn't have to rely on peer discovery to peer with
that validator.
Dedicated upstream​
Validators also have the option of specifying full nodes to which they wish to directly forward
all primary RaptorCast chunks.
This utilizes a lot of validator bandwidth, since each registered downstream requires another
copy of all chunks to be sent. It is potentially more reliable for the downstream node than
subscribing via secondary RaptorCast, although in practice secondary RaptorCast is quite reliable.
Note that if a full node is designated by one or more validators for dedicated chunk forwarding,
then it could be configured with enable_client = false. This turns off attempting to participate
in secondary RaptorCast.
Comparison​
ConfigurationRequires validator to whitelist full nodeRaptorCast modeData SourceNormalNoenable_client = trueSecondary RaptorCastPrioritized secondary RaptorCastYesenable_client = trueSecondary RaptorCastChunk forwardingYesenable_client = falsePrimary RaptorCast
Note that these configurations are properties of a relationship between a full node and a
validator, rather than properties of the full node itself.
A full node could coordinate with multiple validators to treat it specially, while
also participating in normal secondary RaptorCast with other validators that it automatically
peers with.
RaptorCast configurations for validators​
Validators can toggle off their participation in secondary RaptorCast by setting
enable_publisher = false.
Although turning secondary RaptorCast off will reduce bandwidth usage,
note that the bandwidth cost of secondary RaptorCast is relatively low; for example, even at
10,000 transactions per second, the expected usage is will be about 6 MB per second (2 MB of
block data with 3x redundancy). Therefore, it is recommended to keep enable_publisher = true.
RaptorCastFor more technical details about the RaptorCast, see the
RaptorCast documentation.

### Code Examples

```prism
[fullnode_raptorcast]enable_publisher = trueenable_client = trueraptor10_fullnode_redundancy_factor = 3.0max_group_size = 150round_span = 240invite_lookahead = 20max_invite_wait = 10deadline_round_dist = 10init_empty_round_span = 23max_num_group = 3invite_future_dist_min = 1invite_future_dist_max = 600invite_accept_heartbeat_ms = 10000
[fullnode_raptorcast.full_nodes_prioritized]identities = []
```

---

## Node Operations

> Source: https://docs.monad.xyz/node-ops/

Hardware RequirementsHigh performance on commodity hardwareFull Node InstallationHow to run a full nodeValidator InstallationHow to run a validatorGeneral OperationsHow to operate a nodeRecovering a nodeProcedures for recovering node operationHow Full Nodes Receive BlocksHow to configure node.toml to receive blocks from validatorsEvents and WebSocketsAdditional setup instructions if you need real-time dataArchive Data SetupHow to configure your node to serve historical transactional data

---

## Recovering a Node

> Source: https://docs.monad.xyz/node-ops/node-recovery/

When a node is stopped (e.g. due to an upgrade or network outage), it may miss some blocks
and fall out of sync with the network. The pages below describe a few options for recovering
and rejoining the tip of the chain.
Each option has tradeoffs:

soft reset is fast but only works if the node tip is close to the network tip. It skips execution
of the intervening blocks, so no artifacts (logs, receipts, traces) will be produced locally for
those blocks
hard reset is slow but works even if the node tip is far from the network tip. It skips everything
before the snapshot, so no artifacts (logs, receipts, traces) will be produced locally for those
blocks.
full replay is more expensive, but it ensures the local archive has no gaps that would have to
be served by S3. Full replay may be desirable
for RPC providers.

Soft ResetUtilizes statesync to catch up to the tip of the chain, skipping
execution of blocks in between.Hard ResetRestores state from a snapshot before resyncing.Full ReplayFetches and replays all missing blocks serially so that all transactional
artifacts are available.

---

## Running an Archive Server

> Source: https://docs.monad.xyz/node-ops/archive-data/running-an-archive-server

On this page

Please see The Data Waterfall for an overview
of the different sources of archive data. This page is dedicated to operational details on
running an Archive Server.
Recommended footprint​
For anyone looking to reliably serve historical transactional data, it is recommended to run
multiple Archive Servers, fed by multiple full nodes running the Archive Writer process.
Suggested configuration:

2 Archive Servers running MongoDB + monad-indexer
2 Archive Writer nodes, aka full node + monad-archiver
Many full nodes serving RPC requests, connected to both Archive Servers for historical
transactional data

Recommended Archive Server host specs​

CPU: 16 cores
RAM: minimum 64GB; prefer >512GB for best performance
Storage: minimum recommended 16TB; preferred 32TB+

NVMe SSD
RAID 10
Minimum 10K IOPS sustained


Network: >1GbE, scale higher as needed when serving more RPC servers

Fresh installation​
These instructions assume an existing full node (for Archive Writer) and a new host (for Archive
Server).
On your Archive Server:​


Add the following section to your ~/.env
# Replace <db username> and <db pwd> with your actual valuesDB_USER="<your db username>"DB_PWD="<your db pwd>"DB_VOLUME="~/archive-db-data"
# Note: source and sink should generally be the same local MongoDB.# Indexer reads from:BLOCK_DATA_SOURCE="mongodb mongodb://${DB_USER}:${DB_PWD}@0.0.0.0:27017 archive-db"# Indexer writes to:ARCHIVE_SINK="mongodb mongodb://${DB_USER}:${DB_PWD}@0.0.0.0:27017 archive-db"OTEL_ENDPOINT="http://0.0.0.0:4317"


Run mongodb. Instructions show how to run in Docker, but operators can run however they choose.
archive-db:  image: mongo:latest  command: mongod --bind_ip 0.0.0.0  networks:    - host  environment:    MONGO_INITDB_ROOT_USERNAME: ${DB_USER}    MONGO_INITDB_ROOT_PASSWORD: ${DB_PWD}  ports:    - "27017:27017"  volumes:    - ${DB_VOLUME}:/data/db  logging:    driver: journald    options:      tag: "mongo"


Start the db
# create directory from .env db volumesource ~/.envsudo mkdir -p $DB_VOLUMEsudo chown -R monad:monad $DB_VOLUMEsudo chmod 700 $DB_VOLUME
docker compose up archive-db -d


On your Archive Writer host:​


Add the following section to your ~/.env
################################################################################## Vars that do not change ################################################################################### Replace with your Archive Server credentialsARCHIVE_DB_USER="<your db username>"ARCHIVE_DB_PWD="<your db pwd>"ARCHIVE_DB_HOST="<your db hostname>"
## Where block data gets written (your Archive Server)ARCHIVE_SINK="mongodb mongodb://${ARCHIVE_DB_USER}:${ARCHIVE_DB_PWD}@${ARCHIVE_DB_HOST}:27017 archive-db"## Change this if your ledger folder is in a different locationBFT_BLOCK_PATH=~/monad-bft/ledgerOTEL_ENDPOINT=http://0.0.0.0:4317## This can be significantly higher during backfillMAX_CONCURRENT_BLOCKS=50

###################################################################### Backfill from Genesis (initial configuration) ########################################################################BLOCK_DATA_SOURCE="aws testnet-ltu-032-0 50" # testnetBLOCK_DATA_SOURCE="aws mainnet-deu-010-0 50" # mainnet## Alternatively you can use your other ArchiveDB if it has already been backfilled## If using another Archive Server, define variables for it and use them:#OTHER_DB_USER="<other db username>"#OTHER_DB_PWD="<other db pwd>"#OTHER_DB_HOST="<other db hostname>"#BLOCK_DATA_SOURCE="mongodb mongodb://${OTHER_DB_USER}:${OTHER_DB_PWD}@${OTHER_DB_HOST}:27017 archive-db"FALLBACK_BLOCK_DATA_SOURCE="aws testnet-ltu-032-0 50" # testnetFALLBACK_BLOCK_DATA_SOURCE="aws mainnet-deu-010-0 50" # mainnet
##################################################################################### Normal Operation ######################################################################################## Archiver checks triedb first for block dataBLOCK_DATA_SOURCE="triedb /dev/triedb 5000"
### FALLBACK_BLOCK_DATA_SOURCE ##### This is used whenever data is missing from BLOCK_DATA_SOURCE## Normally used after state-sync## If you have another Archive Server for redundancy, configure it here:#OTHER_DB_USER="<other db username>"#OTHER_DB_PWD="<other db pwd>"#OTHER_DB_HOST="<other db hostname>"#FALLBACK_BLOCK_DATA_SOURCE="mongodb mongodb://${OTHER_DB_USER}:${OTHER_DB_PWD}@${OTHER_DB_HOST}:27017 archive-db"
## Alternatively you can use category-labs aws bucket## Note: YOU pay for S3 egress costs if pulling from this bucketFALLBACK_BLOCK_DATA_SOURCE="aws testnet-ltu-032-0 50" # testnetFALLBACK_BLOCK_DATA_SOURCE="aws mainnet-deu-010-0 50" # mainnet


Backfilling:
sudo systemctl start monad-archiver# Should show it running# Double check the arguments look correct based on the above ^systemctl status monad-archiver# Expect many:# > INFO: Successfully archived block block_num=Xjournalctl -u monad-archiver -o cat


Once monad-archiver has caught up to the chain tip you will see:

INFO: Nothing to process



This means backfilling is done and you should

Comment out BACKFILL section in your .env and uncomment Normal Operation
Restart: systemctl restart monad-archiver
Verify status and logs as above



On your ArchiveDB host​


Start monad-indexer
sudo systemctl start monad-indexersystemctl status monad-indexer# Expect many:# > INFO: Indexing block...# > INFO: Index spot-check successfuljournalctl -u monad-indexer -o cat


[Optional] Set up monad-archive-checker​
Typically only 1 checker is run per organization, but more can be run if desired


Add the following systemd override to monad-archive-checker
sudo systemctl edit monad-archive-checker
[Service]ExecStart=ExecStart=/usr/local/bin/monad-archive-checker \    # Example --bucket my-org-mainnet-checker    # Note: storing checker state in local mongo or filesystem    #       will be supported in a future release    --bucket <S3 Bucket for storing checker state>    checker    # Example of comparing a local self-hosted mongo against a Category Labs aws bucket    # --init-replicas "<aws mainnet-deu-009-0 50,mongodb mongodb://<username>:<pwd>@<db hostname>:27017 archive-db>,mongodb mongodb://<username>:<pwd>@<second db hostname>:27017 archive-db>"    --init-replicas "<ArchiveDB 1>,<ArchiveDB 2>"


Reload and Restart
sudo systemctl daemon-reloadsudo systemctl restart monad-archive-checkersystemctl status monad-archive-checker
# Check for errorsjournalctl -u monad-archive-checker -o cat -f

### Code Examples

```prism
# Replace <db username> and <db pwd> with your actual valuesDB_USER="<your db username>"DB_PWD="<your db pwd>"DB_VOLUME="~/archive-db-data"
# Note: source and sink should generally be the same local MongoDB.# Indexer reads from:BLOCK_DATA_SOURCE="mongodb mongodb://${DB_USER}:${DB_PWD}@0.0.0.0:27017 archive-db"# Indexer writes to:ARCHIVE_SINK="mongodb mongodb://${DB_USER}:${DB_PWD}@0.0.0.0:27017 archive-db"OTEL_ENDPOINT="http://0.0.0.0:4317"
```

```prism
archive-db:  image: mongo:latest  command: mongod --bind_ip 0.0.0.0  networks:    - host  environment:    MONGO_INITDB_ROOT_USERNAME: ${DB_USER}    MONGO_INITDB_ROOT_PASSWORD: ${DB_PWD}  ports:    - "27017:27017"  volumes:    - ${DB_VOLUME}:/data/db  logging:    driver: journald    options:      tag: "mongo"
```

```prism
# create directory from .env db volumesource ~/.envsudo mkdir -p $DB_VOLUMEsudo chown -R monad:monad $DB_VOLUMEsudo chmod 700 $DB_VOLUME
docker compose up archive-db -d
```

```prism
################################################################################## Vars that do not change ################################################################################### Replace with your Archive Server credentialsARCHIVE_DB_USER="<your db username>"ARCHIVE_DB_PWD="<your db pwd>"ARCHIVE_DB_HOST="<your db hostname>"
## Where block data gets written (your Archive Server)ARCHIVE_SINK="mongodb mongodb://${ARCHIVE_DB_USER}:${ARCHIVE_DB_PWD}@${ARCHIVE_DB_HOST}:27017 archive-db"## Change this if your ledger folder is in a different locationBFT_BLOCK_PATH=~/monad-bft/ledgerOTEL_ENDPOINT=http://0.0.0.0:4317## This can be significantly higher during backfillMAX_CONCURRENT_BLOCKS=50

###################################################################### Backfill from Genesis (initial configuration) ########################################################################BLOCK_DATA_SOURCE="aws testnet-ltu-032-0 50" # testnetBLOCK_DATA_SOURCE="aws mainnet-deu-010-0 50" # mainnet## Alternatively you can use your other ArchiveDB if it has already been backfilled## If using another Archive Server, define variables for it and use them:#OTHER_DB_USER="<other db username>"#OTHER_DB_PWD="<other db pwd>"#OTHER_DB_HOST="<other db hostname>"#BLOCK_DATA_SOURCE="mongodb mongodb://${OTHER_DB_USER}:${OTHER_DB_PWD}@${OTHER_DB_HOST}:27017 archive-db"FALLBACK_BLOCK_DATA_SOURCE="aws testnet-ltu-032-0 50" # testnetFALLBACK_BLOCK_DATA_SOURCE="aws mainnet-deu-010-0 50" # mainnet
##################################################################################### Normal Operation ######################################################################################## Archiver checks triedb first for block dataBLOCK_DATA_SOURCE="triedb /dev/triedb 5000"
### FALLBACK_BLOCK_DATA_SOURCE ##### This is used whenever data is missing from BLOCK_DATA_SOURCE## Normally used after state-sync## If you have another Archive Server for redundancy, configure it here:#OTHER_DB_USER="<other db username>"#OTHER_DB_PWD="<other db pwd>"#OTHER_DB_HOST="<other db hostname>"#FALLBACK_BLOCK_DATA_SOURCE="mongodb mongodb://${OTHER_DB_USER}:${OTHER_DB_PWD}@${OTHER_DB_HOST}:27017 archive-db"
## Alternatively you can use category-labs aws bucket## Note: YOU pay for S3 egress costs if pulling from this bucketFALLBACK_BLOCK_DATA_SOURCE="aws testnet-ltu-032-0 50" # testnetFALLBACK_BLOCK_DATA_SOURCE="aws mainnet-deu-010-0 50" # mainnet
```

```prism
sudo systemctl start monad-archiver# Should show it running# Double check the arguments look correct based on the above ^systemctl status monad-archiver# Expect many:# > INFO: Successfully archived block block_num=Xjournalctl -u monad-archiver -o cat
```

```prism
sudo systemctl start monad-indexersystemctl status monad-indexer# Expect many:# > INFO: Indexing block...# > INFO: Index spot-check successfuljournalctl -u monad-indexer -o cat
```

```prism
sudo systemctl edit monad-archive-checker
```

```prism
[Service]ExecStart=ExecStart=/usr/local/bin/monad-archive-checker \    # Example --bucket my-org-mainnet-checker    # Note: storing checker state in local mongo or filesystem    #       will be supported in a future release    --bucket <S3 Bucket for storing checker state>    checker    # Example of comparing a local self-hosted mongo against a Category Labs aws bucket    # --init-replicas "<aws mainnet-deu-009-0 50,mongodb mongodb://<username>:<pwd>@<db hostname>:27017 archive-db>,mongodb mongodb://<username>:<pwd>@<second db hostname>:27017 archive-db>"    --init-replicas "<ArchiveDB 1>,<ArchiveDB 2>"
```

```prism
sudo systemctl daemon-reloadsudo systemctl restart monad-archive-checkersystemctl status monad-archive-checker
# Check for errorsjournalctl -u monad-archive-checker -o cat -f
```

---

## Soft Reset Instructions

> Source: https://docs.monad.xyz/node-ops/node-recovery/soft-reset

On this page

A soft reset is typically required when node is (re-)joining the network and the node tip is close to the network tip. Soft reset utilizes statesync to
determine the difference between the current state and the chain tip and to skip ahead.
Automated Remote Configuration Fetching (v0.12.1+)In v0.12.1+, the node will automatically attempt to fetch remote configuration files on startup if env variables are defined:
forkpoint.toml: Changes every round
validators.toml: Changes every epoch
This simplifies node operations by automating configuration updates. The remote fetching includes threshold logic to determine when remote configs should be used.Note: For automatic remote config fetching (v0.12.1+), ensure REMOTE_VALIDATORS_URL and REMOTE_FORKPOINT_URL are defined in your .env file. See Full Node Installation for configuration details.
Automated Soft Reset (v0.12.1+)​
Starting with v0.12.1, soft resets are largely automated if the appropriate variables are defined in .env:

SSH into the node as monad user
Restart monad-related services (monad-bft will auto-fetch configs on startup):
systemctl restart monad-bft monad-execution monad-rpc

Verify the systemd services are running:
systemctl list-units --type=service monad-bft.service monad-execution.service monad-rpc.serviceUNIT                    LOAD   ACTIVE SUB     DESCRIPTIONmonad-bft.service       loaded active running "Service file for Monad BFT"monad-execution.service loaded active running "Service file for Monad Execution"monad-rpc.service       loaded active running "Service file for Monad RPC"
# Check logs for a specific process to verify config fetchingjournalctl -u monad-bft


Manual Soft Reset​
To disable the automated fetching, remove any existing definitions (and remove from /home/monad/.env if desired)
unset REMOTE_VALIDATORS_URLunset REMOTE_FORKPOINT_URL


SSH into the node as monad user


Stop monad-related services
systemctl stop monad-bft monad-execution monad-rpc


Fetch new forkpoint.toml and validators.toml.
# testnetMF_BUCKET=https://bucket.monadinfra.comcurl -sSL $MF_BUCKET/scripts/testnet/download-forkpoint.sh | bashcurl -o /home/monad/monad-bft/config/validators/validators.toml $MF_BUCKET/validators/testnet/validators.toml
# mainnetcurl -sSL $MF_BUCKET/scripts/mainnet/download-forkpoint.sh | bashcurl -o /home/monad/monad-bft/config/validators/validators.toml $MF_BUCKET/validators/mainnet/validators.toml
You may see the following log message:
failed to fetch remote configs, using local forkpoint and validators config


Start monad-related services
systemctl start monad-bft monad-execution monad-rpc


Verify the systemd services are running:
systemctl list-units --type=service monad-bft.service monad-execution.service monad-rpc.serviceUNIT                    LOAD   ACTIVE SUB     DESCRIPTIONmonad-bft.service       loaded active running "Service file for Monad BFT"monad-execution.service loaded active running "Service file for Monad Execution"monad-rpc.service       loaded active running "Service file for Monad RPC"
# Check logs for a specific process, e.g. bftjournalctl -u monad-bft


Configuration Details​
Forkpoint Serialization​
Starting with v0.12.1, forkpoints are serialized in both TOML and RLP formats:

RLP format: Source of truth
TOML format: Maintained for backward compatibility
If TOML serialization fails, the node will no longer panic
Nodes can start from either format for operational backwards compatibility

### Code Examples

```prism
systemctl restart monad-bft monad-execution monad-rpc
```

```prism
systemctl list-units --type=service monad-bft.service monad-execution.service monad-rpc.serviceUNIT                    LOAD   ACTIVE SUB     DESCRIPTIONmonad-bft.service       loaded active running "Service file for Monad BFT"monad-execution.service loaded active running "Service file for Monad Execution"monad-rpc.service       loaded active running "Service file for Monad RPC"
# Check logs for a specific process to verify config fetchingjournalctl -u monad-bft
```

```prism
unset REMOTE_VALIDATORS_URLunset REMOTE_FORKPOINT_URL
```

```prism
systemctl stop monad-bft monad-execution monad-rpc
```

```prism
# testnetMF_BUCKET=https://bucket.monadinfra.comcurl -sSL $MF_BUCKET/scripts/testnet/download-forkpoint.sh | bashcurl -o /home/monad/monad-bft/config/validators/validators.toml $MF_BUCKET/validators/testnet/validators.toml
# mainnetcurl -sSL $MF_BUCKET/scripts/mainnet/download-forkpoint.sh | bashcurl -o /home/monad/monad-bft/config/validators/validators.toml $MF_BUCKET/validators/mainnet/validators.toml
```

```prism
failed to fetch remote configs, using local forkpoint and validators config
```

```prism
systemctl start monad-bft monad-execution monad-rpc
```

```prism
systemctl list-units --type=service monad-bft.service monad-execution.service monad-rpc.serviceUNIT                    LOAD   ACTIVE SUB     DESCRIPTIONmonad-bft.service       loaded active running "Service file for Monad BFT"monad-execution.service loaded active running "Service file for Monad Execution"monad-rpc.service       loaded active running "Service file for Monad RPC"
# Check logs for a specific process, e.g. bftjournalctl -u monad-bft
```

---

## The Data Waterfall

> Source: https://docs.monad.xyz/node-ops/archive-data/data-waterfall

On this page

Background​
As a high throughput blockchain with frequent blocks, Monad generates a lot of data - both
transactional data (blocks, transactions, receipts, logs, and traces), and state data
(the full state trie at the end of each block).
Full nodes and validators store as much of both kinds of data as possible in MonadDB, overwriting
the oldest data when the storage capacity hits 80%. If an RPC call requests data older than
whatever is locally available, the node must reference an
external source.
For transactional data, the waterfall is:

Chain State Buffer (in-memory cache)
MonadDb
Archive Server (if configured)
Object Storage (if configured)

MonadDB​
MonadDB, also called TrieDB, is a local state database run by each full node and validator. It
maintains the most recent state tries, as well as the corresponding transactional data.
Once the storage capacity of MonadDB reaches 80%, the node begins overwriting the oldest data.
Because of this mechanism, and because of frequent blocks and high chain throughput, most MonadDB
instances don't store the entire blockchain history.
Archive Server (MongoDB)​
An Archive Server is a standalone server that stores historical transactional data in MongoDB.
Note that Archive Servers don't store state data - see
here for a discussion why.
An Archive Server is fed this data by an ordinary full node running an additional process called
the Archive Writer.
Monad Archive Server architecture
Many full nodes and validators can point to the same Archive Server.
For instructions on running an Archive Server, please refer to
Running an Archive Server.
Archive Servers store the following data types:

blocks
transactions
receipts
logs
traces

Note: We call this an "Archive Server" rather than an "Archive Node" to reduce confusion.
Archive Servers typically don't host a Monad full node (consensus and execution).
Object Storage​
Archive data can also be stored in an object storage service (e.g., AWS S3).
While MongoDB is preferred for performance and query efficiency, object storage provides a viable
fallback option for users who prefer off-site or cloud-based data retention.
Like ArchiveDB, the object storage can also be configured in the RPC client as a  source of
historical data.
Object Storage stores the following data types:

blocks
transactions
receipts
logs
traces

infoArchive Server is given preference over Object Storage if both are configured. Configuring both is
recommended to ensure that there is a fallback mechanism in case of any issues with the Archive
Server instance.
infoFor more details about historical data, see the
Historical Data page.

---

## Validator Installation

> Source: https://docs.monad.xyz/node-ops/validator-installation

On this page

Setting up a validator is very similar to setting up a full node with a few extra steps.
Start by configuring a node according to the full node installation
instructions.
When the full node is fully operational and synced to the network tip, you can register your node
as a prospective validator by calling
addValidator on the staking
precompile. This function requires passing at least MIN_VALIDATE_STAKE = 100_000 MON (the
minimum self-stake).
After registering, your validator must also satisfy the following conditions, described in
greater depth in the staking docs:

Must have a total stake of at least ACTIVE_VALIDATOR_STAKE = 10_000_000 MON
Must be in the top ACTIVE_VALSET_SIZE = 200 validators by stake weight
Must continue to have a self-stake of MIN_VALIDATE_STAKE = 100_000 MON

When all three conditions are achieved, the validator will become active in the next epoch.
Staking CLI​
staking-sdk-cli is an open-source
staking CLI tool for interfacing with the staking precompile. Start with the
onboarding workflow.
Configure node.toml​
When following the full node instructions, when you got to
this section
you should have downloaded the Validator-themed node.toml.
From that template, the following should be configured:


(Important) Review the beneficiary address. This is the address that will receive block rewards.
beneficiary = "0x<INSERT_BENEFICIARY_ADDRESS>"


(Optional) - Double check node_name makes sense after transition from full node (for example,
remove any full_ prefix). Please choose a unique identifier to avoid confusion.


(Optional) - Configure dedicated or prioritized connections:


Dedicated full node
# Use the following to broadcast blocks to downstream full nodes# [[bootstrap.peers]]# address = "<ip>:<port>"# record_seq_num = "<record_seq_num>"# name_record_sig = "<name_record_sig>"# secp256k1_pubkey = "<full node pubkey>"# [[fullnode_dedicated.identities]]# secp256k1_pubkey = "<full node pubkey>"


Prioritized full node
# Use the following to broadcast blocks to downstream full nodes# [[bootstrap.peers]]# address = "<ip>:<port>"# record_seq_num = "<record_seq_num>"# name_record_sig = "<name_record_sig>"# secp256k1_pubkey = "<full node pubkey>"# [[fullnode_raptorcast.full_nodes_prioritized.identities]]# secp256k1_pubkey = "<full node pubkey>"


To apply these full node configuration changes without restarting monad-bft, run the following command:
monad-debug-node --control-panel-ipc-path /home/monad/monad-bft/controlpanel.sock reload-config

### Code Examples

```prism
beneficiary = "0x<INSERT_BENEFICIARY_ADDRESS>"
```

```prism
# Use the following to broadcast blocks to downstream full nodes# [[bootstrap.peers]]# address = "<ip>:<port>"# record_seq_num = "<record_seq_num>"# name_record_sig = "<name_record_sig>"# secp256k1_pubkey = "<full node pubkey>"# [[fullnode_dedicated.identities]]# secp256k1_pubkey = "<full node pubkey>"
```

```prism
# Use the following to broadcast blocks to downstream full nodes# [[bootstrap.peers]]# address = "<ip>:<port>"# record_seq_num = "<record_seq_num>"# name_record_sig = "<name_record_sig>"# secp256k1_pubkey = "<full node pubkey>"# [[fullnode_raptorcast.full_nodes_prioritized.identities]]# secp256k1_pubkey = "<full node pubkey>"
```

```prism
monad-debug-node --control-panel-ipc-path /home/monad/monad-bft/controlpanel.sock reload-config
```

---



# Section: official-links

---

## Official Links

> Source: https://docs.monad.xyz/official-links

On this page

Mainnet Network​
WhatWhereBlock Explorer (MonadVision)https://monadvision.comBlock Explorer (Monadscan)https://monadscan.comBlock Explorer (SocialScan)https://monad.socialscan.ioNetwork Visualizationhttps://gmonads.com
Announcements and Socials​
WhatWhereWebsitehttps://monad.xyzBloghttps://blog.monad.xyzXhttps://x.com/monadMonad Ecosytem on Xhttps://x.com/monad_ecoThe Pipeline on Xhttps://x.com/pipeline_xyzAnnouncement Telegramhttps://t.me/monad_xyzYoutubehttps://www.youtube.com/@MonadFoundationNewsletterhttps://news.monad.xyzCommunity Discordhttps://discord.gg/monadr/Monad Subreddithttps://reddit.com/r/Monad
Developer Community​
WhatWheremonad-developers Githubhttps://github.com/monad-developersDevNads on Xhttps://x.com/monad_devDeveloper Discordhttps://discord.gg/monaddevResearch Forumhttps://forum.monad.xyz
Tech​
WhatWhereConsensus Client Githubhttps://github.com/category-labs/monad-bftExecution Client Githubhttps://github.com/category-labs/monad
Opportunities​
WhatWhereMonad Foundation Jobshttps://jobs.ashbyhq.com/monad.foundationMonad Ecosystem Jobshttps://eco-jobs.monad.xyz/jobs
Testnet​
WhatWhereBlock Explorer (MonadVision)https://testnet.monadvision.comTestnet Hubhttps://testnet.monad.xyz

---



# Section: reference

---

## JSON-RPC API

> Source: https://docs.monad.xyz/reference/json-rpc/

On this page

This section provides an interactive reference for the Monad's JSON-RPC API.
For a simple example, try getting the latest block.
Debug methods​

debug_getRawBlock - returns an RLP-encoded block
debug_getRawHeader - returns an RLP-encoded header
debug_getRawReceipts - returns an array of EIP-2718 binary-encoded receipts
debug_getRawTransaction - returns an EIP-2718 binary-encoded transaction
debug_traceBlockByHash -
returns the tracing result by executing all transactions in the block; supports callTracer or prestateTracer
debug_traceBlockByNumber - same
debug_traceCall - returns the tracing result by executing an eth_call
debug_traceTransaction -
returns all the traces of a given transaction

Eth methods​

eth_blockNumber - returns the most recent block number
eth_call - simulates calling a smart contract without writing a transaction
eth_chainId - returns the chainId in hex
eth_createAccessList - returns an access list
containing all addresses and storage slots accessed during a simulated transaction
eth_estimateGas -
estimates the gasLimit for a smart contract call to run successfully, using simulation and binary search
eth_feeHistory - returns transaction base fee per gas and
effective priority fee per gas for the block range
eth_gasPrice - returns the current price per gas in MON-wei in hex
eth_getBalance - returns the balance of an account in MON-wei in hex
eth_getBlockByHash - returns a block
eth_getBlockByNumber - returns a block
eth_getBlockReceipts - returns the receipts of a block
eth_getBlockTransactionCountByHash -
returns the number of transactions in a block
eth_getBlockTransactionCountByNumber -
returns the number of transactions in a block
eth_getTransactionByBlockHashAndIndex - returns a transaction
eth_getTransactionByBlockNumberAndIndex - returns a transaction
eth_getTransactionByHash - returns a transaction
eth_getTransactionCount - returns the nonce of an address
eth_getTransactionReceipt - returns the receipt for a transaction
eth_maxPriorityFeePerGas - returns the current maxPriorityFeePerGas in MON-wei
eth_sendRawTransaction
eth_syncing - indicates if node is currently syncing (RPC providers should ensure no node that returns true for this call is serving users)

Other methods​

admin_ethCallStatistics - ignore, for internal purposes
net_version - always returns the chain id
txpool_statusByAddress - returns the status of
pending transactions this RPC server is aware of from this sender. Since there is no global
mempool, the RPC would typically be aware of a transaction
because it was submitted through this RPC
txpool_statusByHash - returns the status of
pending transactions this RPC is aware of with this hash
web3_clientVersion - returns the Monad version

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/admin_ethCallStatistics

admin_ethCallStatistics Returns statistics about eth_call capacity including inactive executors and queued requestsNetwork:TestnetMainnetTry itReturnsobject▶Properties (7 required)📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "admin_ethCallStatistics",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/debug_getRawHeader

debug_getRawHeader Returns an RLP-encoded header.Network:TestnetMainnetParametersblock*Type: oneOf: Quantity (hex) | stringTry itReturnsstring📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "debug_getRawHeader",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/debug_getRawBlock

debug_getRawBlock Returns an RLP-encoded block.Network:TestnetMainnetParametersblock*Type: oneOf: Quantity (hex) | stringTry itReturnsstring📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "debug_getRawBlock",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/debug_getRawTransaction

debug_getRawTransaction Returns an array of EIP-2718 binary-encoded transactions.Network:TestnetMainnetParameterstx_hash*Type: stringTry itReturnsstring📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "debug_getRawTransaction",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/debug_getRawReceipts

debug_getRawReceipts Returns an array of EIP-2718 binary-encoded receipts.Network:TestnetMainnetParametersblock*Type: oneOf: Quantity (hex) | stringTry itReturnsarrayItems Type: string▶Array Items📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "debug_getRawReceipts",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/debug_traceBlockByNumber

debug_traceBlockByNumber Returns the tracing result by executing all transactions in the block specified by the block number with a tracer.Network:TestnetMainnetParametersblock_number*Type: oneOf: Quantity (hex) | stringtracer*Type: object { tracer: Tracer (enum: [callTracer | prestateTracer]), tracerConfig: TracerConfig (object { onlyTopCall: boolean, diffMode: boolean, withLog: boolean }) }tracer (string)Select tracercallTracerprestateTracertracerConfig (object)Try itReturnsobject▶Properties (2 required)📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "debug_traceBlockByNumber",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/debug_traceBlockByHash

debug_traceBlockByHash Returns the tracing result by executing all transactions in the block specified by the block hash with a tracer.Network:TestnetMainnetParametersblock_hash*Type: stringtracer*Type: object { tracer: Tracer (enum: [callTracer | prestateTracer]), tracerConfig: TracerConfig (object { onlyTopCall: boolean, diffMode: boolean, withLog: boolean }) }tracer (string)Select tracercallTracerprestateTracertracerConfig (object)Try itReturnsobject▶Properties (2 required)📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "debug_traceBlockByHash",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/debug_traceTransaction

debug_traceTransaction Returns all traces of a given transaction.Network:TestnetMainnetParameterstx_hash*Type: stringtracer*Type: object { tracer: Tracer (enum: [callTracer | prestateTracer]), tracerConfig: TracerConfig (object { onlyTopCall: boolean, diffMode: boolean, withLog: boolean }) }tracer (string)Select tracercallTracerprestateTracertracerConfig (object)Try itReturnsobject▶Properties (7 required)📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "debug_traceTransaction",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/debug_traceCall

debug_traceCall Returns the tracing result result by executing an eth call.Network:TestnetMainnetParameterstransaction*Type: object { from: unknown, to: unknown, gas: unknown, maxFeePerGas: string,null, maxPriorityFeePerGas: string,null, value: unknown, input: unknown, data: unknown, nonce: unknown, chainId: unknown, accessList: unknown, authorizationList: unknown }from (string)to (string)gas (string)maxFeePerGas (stringnull)maxPriorityFeePerGas (stringnull)value (string)input (string)data (string)nonce (string)chainId (string)accessList (string)authorizationList (string)block*Type: oneOf: BlockTags (oneOf: Quantity (hex) | string) | FixedData_for_32 (string)tracer*Type: object { tracer: Tracer (enum: [callTracer | prestateTracer]), tracerConfig: TracerConfig (object { onlyTopCall: boolean, diffMode: boolean, withLog: boolean }) }tracer (string)Select tracercallTracerprestateTracertracerConfig (object)Try itReturns📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "debug_traceCall",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/eth_call

eth_call Executes a new message call immediately without creating a transaction on the block chain.Network:TestnetMainnetParameterstransaction*Type: object { from: unknown, to: unknown, gas: unknown, maxFeePerGas: string,null, maxPriorityFeePerGas: string,null, value: unknown, input: unknown, data: unknown, nonce: unknown, chainId: unknown, accessList: unknown, authorizationList: unknown }from (string)to (string)gas (string)maxFeePerGas (stringnull)maxPriorityFeePerGas (stringnull)value (string)input (string)data (string)nonce (string)chainId (string)accessList (string)authorizationList (string)block*Type: oneOf: BlockTags (oneOf: Quantity (hex) | string) | FixedData_for_32 (string)Try itReturnsstring📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "eth_call",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/eth_blockNumber

eth_blockNumber Returns the number of most recent block.Network:TestnetMainnetTry itReturnsinteger📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "eth_blockNumber",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/eth_chainId

eth_chainId Returns the chain ID of the current network.Network:TestnetMainnetTry itReturnsinteger📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "eth_chainId",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/eth_createAccessList

eth_createAccessList Returns an access list containing all addresses and storage slots accessed during a simulated transaction.Network:TestnetMainnetParameterstransaction*Type: object { from: unknown, to: unknown, gas: unknown, maxFeePerGas: string,null, maxPriorityFeePerGas: string,null, value: unknown, input: unknown, data: unknown, nonce: unknown, chainId: unknown, accessList: unknown, authorizationList: unknown }from (string)to (string)gas (string)maxFeePerGas (stringnull)maxPriorityFeePerGas (stringnull)value (string)input (string)data (string)nonce (string)chainId (string)accessList (string)authorizationList (string)block*Type: oneOf: BlockTags (oneOf: Quantity (hex) | string) | FixedData_for_32 (string)Try itReturns📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "eth_createAccessList",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/eth_estimateGas

eth_estimateGas Generates and returns an estimate of how much gas is necessary to allow the transaction to complete.Network:TestnetMainnetParameterstx*Type: object { from: unknown, to: unknown, gas: unknown, maxFeePerGas: string,null, maxPriorityFeePerGas: string,null, value: unknown, input: unknown, data: unknown, nonce: unknown, chainId: unknown, accessList: unknown, authorizationList: unknown }from (string)to (string)gas (string)maxFeePerGas (stringnull)maxPriorityFeePerGas (stringnull)value (string)input (string)data (string)nonce (string)chainId (string)accessList (string)authorizationList (string)block*Type: oneOf: Quantity (hex) | stringTry itReturnsinteger📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "eth_estimateGas",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/eth_feeHistory

eth_feeHistory Transaction fee history
 Returns transaction base fee per gas and effective priority fee per gas for the requested/supported block range.Network:TestnetMainnetParametersblock_count*Type: integernewest_block*Type: oneOf: Quantity (hex) | stringreward_percentiles*Type: arraynullEnter values (comma separated)Example: $number1, $number2, $number3Try itReturnsobject▶Properties Examples:{
  "gasUsedRatio": [],
  "oldestBlock": "0x0"
}📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "eth_feeHistory",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/eth_getBalance

eth_getBalance Returns the balance of the account of given address.Network:TestnetMainnetParametersaccount*Type: stringblock_number*Type: oneOf: BlockTags (oneOf: Quantity (hex) | string) | FixedData_for_32 (string)Try itReturnsstring📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "eth_getBalance",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/eth_gasPrice

eth_gasPrice Returns the current price per gas in wei.Network:TestnetMainnetTry itReturnsinteger📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "eth_gasPrice",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/eth_getBlockByHash

eth_getBlockByHash Returns information about a block by hash.Network:TestnetMainnetParametersblock_hash*Type: stringreturn_full_txns*Type: booleanSelect return_full_txnstruefalseTry itReturnsobject▶Properties Examples:{
  "hash": "0x0000000000000000000000000000000000000000000000000000000000000000",
  "parentHash": "0x0000000000000000000000000000000000000000000000000000000000000000",
  "sha3Uncles": "0x1dcc4de8dec75d7aab85b567b6ccd41ad312451b948a7413f0a142fd40d49347",
  "miner": "0x0000000000000000000000000000000000000000",
  "stateRoot": "0x56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421",
  "transactionsRoot": "0x56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421",
  "receiptsRoot": "0x56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421",
  "logsBloom": "0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000",
  "difficulty": "0x0",
  "number": "0x0",
  "gasLimit": "0x0",
  "gasUsed": "0x0",
  "timestamp": "0x0",
  "extraData": "0x",
  "mixHash": "0x0000000000000000000000000000000000000000000000000000000000000000",
  "nonce": "0x0000000000000000",
  "uncles": [],
  "transactions": []
}📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "eth_getBlockByHash",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/eth_getBlockByNumber

eth_getBlockByNumber Returns information about a block by number.Network:TestnetMainnetParametersblock_number*Type: oneOf: Quantity (hex) | stringreturn_full_txns*Type: booleanSelect return_full_txnstruefalseTry itReturnsobject▶Properties Examples:{
  "hash": "0x0000000000000000000000000000000000000000000000000000000000000000",
  "parentHash": "0x0000000000000000000000000000000000000000000000000000000000000000",
  "sha3Uncles": "0x1dcc4de8dec75d7aab85b567b6ccd41ad312451b948a7413f0a142fd40d49347",
  "miner": "0x0000000000000000000000000000000000000000",
  "stateRoot": "0x56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421",
  "transactionsRoot": "0x56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421",
  "receiptsRoot": "0x56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421",
  "logsBloom": "0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000",
  "difficulty": "0x0",
  "number": "0x0",
  "gasLimit": "0x0",
  "gasUsed": "0x0",
  "timestamp": "0x0",
  "extraData": "0x",
  "mixHash": "0x0000000000000000000000000000000000000000000000000000000000000000",
  "nonce": "0x0000000000000000",
  "uncles": [],
  "transactions": []
}📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "eth_getBlockByNumber",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/eth_getBlockReceipts

eth_getBlockReceipts Returns the receipts of a block by number or hash.Network:TestnetMainnetParametersblock*Type: oneOf: BlockTags (oneOf: Quantity (hex) | string) | FixedData_for_32 (string)Try itReturnsarrayItems Type: ▶Array Items📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "eth_getBlockReceipts",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/eth_getBlockTransactionCountByHash

eth_getBlockTransactionCountByHash Returns the number of transactions in a block from a block matching the given block hash.Network:TestnetMainnetParametersblock_hash*Type: stringTry itReturnsstring📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "eth_getBlockTransactionCountByHash",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/eth_getCode

eth_getCode Returns code at a given address.Network:TestnetMainnetParametersaccount*Type: stringblock*Type: oneOf: BlockTags (oneOf: Quantity (hex) | string) | FixedData_for_32 (string)Try itReturnsstring📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "eth_getCode",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/eth_getBlockTransactionCountByNumber

eth_getBlockTransactionCountByNumber Returns the number of transactions in a block matching the given block number.Network:TestnetMainnetParametersblock_tag*Type: oneOf: Quantity (hex) | stringTry itReturnsstring📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "eth_getBlockTransactionCountByNumber",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/eth_getStorageAt

eth_getStorageAt Returns the value from a storage position at a given address.Network:TestnetMainnetParametersaccount*Type: stringposition*Type: integerblock*Type: oneOf: BlockTags (oneOf: Quantity (hex) | string) | FixedData_for_32 (string)Try itReturnsstring📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "eth_getStorageAt",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/eth_getLogs

eth_getLogs Returns an array of all logs matching filter with given id.Network:TestnetMainnetParametersfilters*Type: objectfromBlock (string)toBlock (string)address (string)topics (array)Try itReturnsarrayItems Type: ▶Array Items📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "eth_getLogs",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/eth_getTransactionByBlockNumberAndIndex

eth_getTransactionByBlockNumberAndIndex Returns information about a transaction by block number and transaction index position.Network:TestnetMainnetParametersblock_tag*Type: oneOf: Quantity (hex) | stringindex*Type: integerTry itReturnsobject▶Properties Examples:{
  "type": "0x2",
  "chainId": "0x1",
  "nonce": "0x16d",
  "gas": "0x46a02",
  "maxFeePerGas": "0x7fc1a20a8",
  "maxPriorityFeePerGas": "0x59682f00",
  "to": "0x68b3465833fb72a70ecdf485e0e4c7bd8665fc45",
  "value": "0x4a6ed55bbcc180",
  "accessList": [],
  "input": "0x5ae401dc00000000000000000000000000000000000000000000000000000000628ced5b000000000000000000000000000000000000000000000000000000000000004000000000000000000000000000000000000000000000000000000000000000020000000000000000000000000000000000000000000000000000000000000040000000000000000000000000000000000000000000000000000000000000016000000000000000000000000000000000000000000000000000000000000000e442712a6700000000000000000000000000000000000000000000b3ff1489674e11c40000000000000000000000000000000000000000000000000000004a6ed55bbcc18000000000000000000000000000000000000000000000000000000000000000800000000000000000000000003cf412d970474804623bb4e3a42de13f9bca54360000000000000000000000000000000000000000000000000000000000000002000000000000000000000000c02aaa39b223fe8d0a0e5c4f27ead9083c756cc20000000000000000000000003a75941763f31c930b19c041b709742b0b31ebb600000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000412210e8a00000000000000000000000000000000000000000000000000000000",
  "r": "0x7f2153019a74025d83a73effdd91503ceecefac7e35dd933adc1901c875539aa",
  "s": "0x334ab2f714796d13c825fddf12aad01438db3a8152b2fe3ef7827707c25ecab3",
  "yParity": "0x0",
  "v": "0x0",
  "hash": "0x0e07d8b53ed3d91314c80e53cf25bcde02084939395845cbb625b029d568135c",
  "blockHash": "0x883f974b17ca7b28cb970798d1c80f4d4bb427473dc6d39b2a7fe24edc02902d",
  "blockNumber": "0xe26e6d",
  "transactionIndex": "0xad",
  "from": "0x3cf412d970474804623bb4e3a42de13f9bca5436",
  "gasPrice": "0x50101df3a"
}📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "eth_getTransactionByBlockNumberAndIndex",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/eth_getTransactionByBlockHashAndIndex

eth_getTransactionByBlockHashAndIndex Returns information about a transaction by block hash and transaction index position.Network:TestnetMainnetParametersblock_hash*Type: stringindex*Type: integerTry itReturnsobject▶Properties Examples:{
  "type": "0x2",
  "chainId": "0x1",
  "nonce": "0x16d",
  "gas": "0x46a02",
  "maxFeePerGas": "0x7fc1a20a8",
  "maxPriorityFeePerGas": "0x59682f00",
  "to": "0x68b3465833fb72a70ecdf485e0e4c7bd8665fc45",
  "value": "0x4a6ed55bbcc180",
  "accessList": [],
  "input": "0x5ae401dc00000000000000000000000000000000000000000000000000000000628ced5b000000000000000000000000000000000000000000000000000000000000004000000000000000000000000000000000000000000000000000000000000000020000000000000000000000000000000000000000000000000000000000000040000000000000000000000000000000000000000000000000000000000000016000000000000000000000000000000000000000000000000000000000000000e442712a6700000000000000000000000000000000000000000000b3ff1489674e11c40000000000000000000000000000000000000000000000000000004a6ed55bbcc18000000000000000000000000000000000000000000000000000000000000000800000000000000000000000003cf412d970474804623bb4e3a42de13f9bca54360000000000000000000000000000000000000000000000000000000000000002000000000000000000000000c02aaa39b223fe8d0a0e5c4f27ead9083c756cc20000000000000000000000003a75941763f31c930b19c041b709742b0b31ebb600000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000412210e8a00000000000000000000000000000000000000000000000000000000",
  "r": "0x7f2153019a74025d83a73effdd91503ceecefac7e35dd933adc1901c875539aa",
  "s": "0x334ab2f714796d13c825fddf12aad01438db3a8152b2fe3ef7827707c25ecab3",
  "yParity": "0x0",
  "v": "0x0",
  "hash": "0x0e07d8b53ed3d91314c80e53cf25bcde02084939395845cbb625b029d568135c",
  "blockHash": "0x883f974b17ca7b28cb970798d1c80f4d4bb427473dc6d39b2a7fe24edc02902d",
  "blockNumber": "0xe26e6d",
  "transactionIndex": "0xad",
  "from": "0x3cf412d970474804623bb4e3a42de13f9bca5436",
  "gasPrice": "0x50101df3a"
}📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "eth_getTransactionByBlockHashAndIndex",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/eth_getTransactionByHash

eth_getTransactionByHash Returns the information about a transaction requested by transaction hash.Network:TestnetMainnetParameterstx_hash*Type: stringTry itReturnsobject▶Properties Examples:{
  "type": "0x2",
  "chainId": "0x1",
  "nonce": "0x16d",
  "gas": "0x46a02",
  "maxFeePerGas": "0x7fc1a20a8",
  "maxPriorityFeePerGas": "0x59682f00",
  "to": "0x68b3465833fb72a70ecdf485e0e4c7bd8665fc45",
  "value": "0x4a6ed55bbcc180",
  "accessList": [],
  "input": "0x5ae401dc00000000000000000000000000000000000000000000000000000000628ced5b000000000000000000000000000000000000000000000000000000000000004000000000000000000000000000000000000000000000000000000000000000020000000000000000000000000000000000000000000000000000000000000040000000000000000000000000000000000000000000000000000000000000016000000000000000000000000000000000000000000000000000000000000000e442712a6700000000000000000000000000000000000000000000b3ff1489674e11c40000000000000000000000000000000000000000000000000000004a6ed55bbcc18000000000000000000000000000000000000000000000000000000000000000800000000000000000000000003cf412d970474804623bb4e3a42de13f9bca54360000000000000000000000000000000000000000000000000000000000000002000000000000000000000000c02aaa39b223fe8d0a0e5c4f27ead9083c756cc20000000000000000000000003a75941763f31c930b19c041b709742b0b31ebb600000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000412210e8a00000000000000000000000000000000000000000000000000000000",
  "r": "0x7f2153019a74025d83a73effdd91503ceecefac7e35dd933adc1901c875539aa",
  "s": "0x334ab2f714796d13c825fddf12aad01438db3a8152b2fe3ef7827707c25ecab3",
  "yParity": "0x0",
  "v": "0x0",
  "hash": "0x0e07d8b53ed3d91314c80e53cf25bcde02084939395845cbb625b029d568135c",
  "blockHash": "0x883f974b17ca7b28cb970798d1c80f4d4bb427473dc6d39b2a7fe24edc02902d",
  "blockNumber": "0xe26e6d",
  "transactionIndex": "0xad",
  "from": "0x3cf412d970474804623bb4e3a42de13f9bca5436",
  "gasPrice": "0x50101df3a"
}📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "eth_getTransactionByHash",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/eth_getTransactionCount

eth_getTransactionCount Returns the number of transactions sent from an address.Network:TestnetMainnetParametersaccount*Type: stringblock*Type: oneOf: BlockTags (oneOf: Quantity (hex) | string) | FixedData_for_32 (string)Try itReturnsstring📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "eth_getTransactionCount",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/eth_getTransactionReceipt

eth_getTransactionReceipt Returns the receipt of a transaction by transaction hash.Network:TestnetMainnetParameterstx_hash*Type: stringTry itReturnsobject▶Properties Examples:{
  "type": "0x2",
  "status": "0x1",
  "cumulativeGasUsed": "0xa42aec",
  "logs": [
    {
      "address": "0xdac17f958d2ee523a2206206994597c13d831ec7",
      "topics": [
        "0x8c5be1e5ebec7d5bd14f71427d1e84f3dd0314c0f7b2291e5b200ac8c7c3b925",
        "0x0000000000000000000000009a53bfba35269414f3b2d20b52ca01b15932c7b2",
        "0x00000000000000000000000039e5dbb9d2fead31234d7c647d6ce77d85826f76"
      ],
      "data": "0x00000000000000000000000000000000000000000052b7d2dcc80cd2e4000000",
      "blockHash": "0x4acbdefb861ef4adedb135ca52865f6743451bfbfa35db78076f881a40401a5e",
      "blockNumber": "0x129f4b9",
      "transactionHash": "0x21f6554c28453a01e7276c1db2fc1695bb512b170818bfa98fa8136433100616",
      "transactionIndex": "0x7f",
      "logIndex": "0x118",
      "removed": false
    }
  ],
  "logsBloom": "0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000000000000000000000000200000000000000000040000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000400000800000000000000000000000000000000004000000000000000000800000000100000020000000000000000000080000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000010000000000000000000000000000000010000000000000000000000000000",
  "transactionHash": "0x21f6554c28453a01e7276c1db2fc1695bb512b170818bfa98fa8136433100616",
  "transactionIndex": "0x7f",
  "blockHash": "0x4acbdefb861ef4adedb135ca52865f6743451bfbfa35db78076f881a40401a5e",
  "blockNumber": "0x129f4b9",
  "gasUsed": "0xbde1",
  "effectiveGasPrice": "0xfb0f6e8c9",
  "from": "0x9a53bfba35269414f3b2d20b52ca01b15932c7b2",
  "to": "0xdac17f958d2ee523a2206206994597c13d831ec7",
  "contractAddress": null
}📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "eth_getTransactionReceipt",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/eth_maxPriorityFeePerGas

eth_maxPriorityFeePerGas Returns the current maxPriorityFeePerGas per gas in wei.Network:TestnetMainnetTry itReturnsinteger📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "eth_maxPriorityFeePerGas",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/eth_sendRawTransaction

eth_sendRawTransaction Submits a raw transaction. For EIP-4844 transactions, the raw form must be the network form.
 This means it includes the blobs, KZG commitments, and KZG proofs.Network:TestnetMainnetParametershex_tx*Type: array of integerEnter values (comma separated)Example: $integer1, $integer2, $integer3Try itReturnsstring📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "eth_sendRawTransaction",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/eth_syncing

eth_syncing Returns an object with data about the sync status or false.Network:TestnetMainnetTry itReturnsboolean📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "eth_syncing",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/net_version

net_versionNetwork:TestnetMainnetTry itReturnsstring📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "net_version",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/txpool_statusByAddress

txpool_statusByAddressNetwork:TestnetMainnetParametersaddress*Type: stringTry itReturnsobject📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "txpool_statusByAddress",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/txpool_statusByHash

txpool_statusByHashNetwork:TestnetMainnetParametershash*Type: stringTry itReturnsobject▶Properties (1 required)📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "txpool_statusByHash",
  "params": []
}
'

---

## Monad Developer Documentation

> Source: https://docs.monad.xyz/reference/json-rpc/web3_clientVersion

web3_clientVersionNetwork:TestnetMainnetTry itReturnsstring📤 RequestCopycurl --request POST \
     --url https://rpc-mainnet.monadinfra.com \
     --header 'accept: application/json' \
     --header 'content-type: application/json' \
     --data '
{
  "id": 0,
  "jsonrpc": "2.0",
  "method": "web3_clientVersion",
  "params": []
}
'

---

## RPC Differences

> Source: https://docs.monad.xyz/reference/rpc-differences

On this page

Monad aims to match the RPC behavior as close as possible to Geth’s behavior, but due to
fundamental architectural differences, there are some differences listed below.
Logs​

eth_getLogs has a maximum block range, configured by RPC provider but typically set to 1000.
Because Monad blocks are much larger than Ethereum blocks, we recommend using small block
ranges (e.g. 1-10 blocks) for optimal performance. When requesting a longer range, requests
can take a long time to be fulfilled, and may time out.

Transactions​


eth_sendRawTransaction may not immediately reject transactions with a nonce gap or insufficient
gas balance as they would on Ethereum. The RPC server was designed with asynchronous execution
in mind, and under asynchronous execution, the RPC server may not have the latest account state.
Thus, these transactions are initially allowed, as they may become valid transactions during
block creation.


eth_sendRawTransaction, eth_call and eth_estimateGas do not accept EIP-4844 transaction
type, because EIP-4844 is not supported.


eth_getTransactionByHash does not return pending transactions. This method will only return
transactions that have been included in a block. If you query for a transaction that is still
in the mempool, the method will return null.


eth_call​

eth_calls that are reliant on old state (i.e. with an old block number) may fail, because
full nodes do not provide access to arbitrary historic state. See
Historical Data for a fuller discussion.

Fee-related methods​

eth_maxPriorityFeePerGas currently returns a hardcoded suggested fee of 2 gwei. This is
temporary.
eth_feeHistory handling of the case where newest_block = latest: by convention, this
method returns not only the fee history for the requested range, but also one extra
fee - the projected fee for the next block after that range. In Monad, we do not have all the
inputs required to compute the base fee for the next block, so if newest block requested is
latest, we will return the latest baseFeePerGas twice.

WebSocket (eth_subscribe) behavior​
Parent page: WebSocket Guide

eth_subscribe does not support the syncing or newPendingTransactions subscription types
Reorganizations never occur in the newHeads and logs subscription types, because only
real-time data for finalized blocks is presented
Monad-specific extensions to the newHeads and logs subcription types (called
monadNewHeads and monadLogs) are provided to offer
better latency

Debug/Trace Methods​


debug_traceCall, debug_traceTransaction, and related debug_trace* methods require the trace options object parameter to be explicitly provided. Unlike standard EVM clients where this parameter is optional, Monad RPC will return an error (-32602 Invalid params) if the parameter is omitted entirely.
Workaround: Always include the trace options parameter, even if empty:
{  "method": "debug_traceCall",  "params": [    {      "to": "0x6b175474e89094c44da98b954eedeac495271d0f"    },    "latest",    {}  ]}


When an empty trace options object {} is provided, Monad defaults to the callTracer instead of the struct logs tracer that is typical in other EVM clients. This is because Monad does not currently support opcode-level struct logs at the VM level.

### Code Examples

```prism
{  "method": "debug_traceCall",  "params": [    {      "to": "0x6b175474e89094c44da98b954eedeac495271d0f"    },    "latest",    {}  ]}
```

---

## RPC Error Codes

> Source: https://docs.monad.xyz/reference/rpc-error-codes

On this page

Monad supports a JSON-RPC interface for interacting with the blockchain.
Monad JSON-RPC aims to be equivalent to Ethereum JSON-RPC, however some error codes slightly deviate due to lack of standardization across Ethereum clients.
Monad Error Codes Reference​
Error CodeMessageExplanation-32601Parse errorUnable to parse JSON-RPC request-32601Invalid requestInvalid request such as request that exceeds size limit-32601Method not foundMethod that is not part of the JSON-RPC spec-32601Method not supportedMethod that is part of the JSON-RPC spec but not yet supported by Monad-32602Invalid block rangeMaximum eth_getLogs block range is configured per RPC provider, but is typically
limited to 1000 blocks-32602Invalid paramsRequest contains incorrect parameters associated to the particular method-32603Internal errorRequest that cannot be fulfilled due to internal error-32603Execution revertedeth_call and eth_estimateGas simulates transaction to revert-32603Transaction decoding errorRequest contains raw transaction that cannot be decoded

---

## RPC Limits

> Source: https://docs.monad.xyz/reference/rpc-limits

On this page

eth_call / eth_estimateGas​
Gas limit (per call)​
ProviderPublic RPCGas limitQuickNoderpc.monad.xyz200M gasAlchemyrpc1.monad.xyz200M gasAnkrrpc3.monad.xyz1B gasMonad Foundationrpc-mainnet.monadinfra.com200M gas
node operator configThese limits are configured by the node operator with
--eth-call-provider-gas-limit and --eth-estimate-gas-provider-gas-limit.--eth-call-provider-gas-limit <ETH_CALL_PROVIDER_GAS_LIMIT>    Set the gas limit for eth_call [default: 30000000]--eth-estimate-gas-provider-gas-limit <ETH_ESTIMATE_GAS_PROVIDER_GAS_LIMIT>    Set the gas limit for eth_estimateGas [default: 30000000]
Behavior when gas price is specified​
Typically, eth_call and eth_estimateGas calls don't have gas price  (gasPrice for
legacy transactions and maxFeePerGas for non legacy transactions) specified.
Therefore, when the user goes out of their way to populate this parameter, special logic is
utilized:
If a eth_call or eth_estimateGas request has the gas price populated, the gas limit
for the call will be the min(gas limit allowance, provider gas limit), where the gas limit
allowance is the maximum gas limit given the user's gas balance and specified gas price.
This is consistent with Geth's behaviour.
Behavior when gas price is not specified​
If the eth_call or eth_estimateGasrequest does not have the gas price populated, the gas
limit for the call will be provider gas limit. This is consistent with Geth's behavior.
Request routing by gas limit​
eth_call and eth_estimateGas requests are executed via a dual-pool execution model based on
the user-specified gas limit, if present:

Low-gas pool: For calls with gas limit ≤ 8,100,000.
High-gas pool: For calls with gas limit > 8,100,000.

When a caller does not specify the gas limit, the system initially executes the call in the low-gas pool.
If execution runs out of gas in that pool, it automatically retries the call in the high-gas pool.
node operator configThroughput of the above two pools is determined by the following RPC CLI parameters:--eth-call-max-concurrent-requests <ETH_CALL_MAX_CONCURRENT_REQUESTS>    Set the max concurrent requests for eth_call and eth_estimateGas [default: 1000]--eth-call-high-max-concurrent-requests <ETH_CALL_HIGH_MAX_CONCURRENT_REQUESTS>    Set the max concurrent requests for eth_call and eth_estimateGas with high gas cost [default: 20]
eth_getLogs​
Block range limit (per call)​
ProviderPublic RPCBlock range limitQuickNoderpc.monad.xyz100 blocksAlchemyrpc1.monad.xyz1000 blocks and 10,000 logs (whichever is more constraining)Ankrrpc3.monad.xyz1000 blocksMonad Foundationrpc-mainnet.monadinfra.com100 blocks
Note: these are configured by the node operator with
--eth-get-logs-max-block-range.
Why do these limits exist?​
Monad produces a block every 400ms and can accommodate up to 5,000 transactions per block with
computation up to 200M gas. This means that not only are blocks extremely frequent, but each block
can also contain significantly more data.  This is the main motivation for keeping the block
range limits low.
Recommended query strategy​
Based on recent internal testing, when indexing the chain we recommend adjusting your pipeline to
use a 100-block range with high concurrency (for example, 100 workers). This configuration should
give you extremely fast results.
Further improvements to eth_getLogs are being explored for the near future.

### Code Examples

```prism
--eth-call-provider-gas-limit <ETH_CALL_PROVIDER_GAS_LIMIT>    Set the gas limit for eth_call [default: 30000000]--eth-estimate-gas-provider-gas-limit <ETH_ESTIMATE_GAS_PROVIDER_GAS_LIMIT>    Set the gas limit for eth_estimateGas [default: 30000000]
```

```prism
--eth-call-max-concurrent-requests <ETH_CALL_MAX_CONCURRENT_REQUESTS>    Set the max concurrent requests for eth_call and eth_estimateGas [default: 1000]--eth-call-high-max-concurrent-requests <ETH_CALL_HIGH_MAX_CONCURRENT_REQUESTS>    Set the max concurrent requests for eth_call and eth_estimateGas with high gas cost [default: 20]
```

---

## RPC Reference

> Source: https://docs.monad.xyz/reference/

Monad supports a JSON-RPC interface for interacting
with the blockchain.
See Network Information for public RPC endpoints.
JSON-RPC API ReferenceAPI reference + playgroundRPC DifferencesDifferences between Monad and Ethereum JSON-RPCRPC LimitsProvider-specific limits for certain RPC methodsRPC Error CodesError codes and explanationsWebSocket GuideUsing WebSockets to subscribe to real-time data

---

## WebSocket Guide

> Source: https://docs.monad.xyz/reference/websockets

On this page

Monad's RPC server supports JSON-RPC over WebSocket connections. This feature
allows JSON-RPC calls to occur over a persistent connection instead of as
individual HTTP requests, but the primary reason for using it is to subscribe
to real-time data feeds using
the eth_subscribe call.
eth_subscribe behaves similarly to
how it does
in the Geth Ethereum client:

subscription types newHeads and logs are supported (returning updates as soon as the block
is Finalized)
subscription types syncing and newPendingTransactions are not supported.

Additionally, two new variants, monadNewHeads and monadLogs are supported. These behave
similarly to newHeads and logs but return as soon as the node sees the block and has a chance
to speculatively execute.
So in summary:
subscription typedescriptionnewHeadsFires a notification each time a new header is appended to the chain, after the block is Finalized. Unlike in geth, no reorgs are possible.logsReturns logs (that match the given filter criteria) in a new block, after the block is Finalized. Unlike in geth, no reorgs are possible.monadNewHeadsSame as newHeads, but as soon as the block is Proposed and the node has a chance to speculatively execute.monadLogsSame as logs, but as soon as the block is Proposed and the node has a chance to speculatively execute.
Getting started with real-time data​

The real-time data feeds available over WebSockets are described here
You can access them via these public RPC endpoints
Real-time data is often exposed in a high-level way in your Ethereum
blockchain interface library; we show examples using Python's
web3.py and JavaScript's
ethers.js below

web3.py (Python) example​
Start by installing web3.py if you
haven't already. In this example we'll use pip directly:
pip install web3
Save the following code to the file block-counter.py:
import asyncio
from web3 import AsyncWeb3from web3.providers.persistent import WebSocketProvider
ws_url = 'wss://testnet-rpc.monad.xyz'
async def print_latest():  async with AsyncWeb3(WebSocketProvider(ws_url)) as w3:    subscription_id = await w3.eth.subscribe('newHeads', {})    async for payload in w3.socket.process_subscriptions():      print(f"New block received: {payload['result']['number']}")
if __name__ == "__main__":  asyncio.run(print_latest())
Finally, run:
python block-counter.py
After a few seconds, you should see output similar to:
New block received: 29165925New block received: 29165926New block received: 29165927
ethers.js (JavaScript) example​
Start by installing ethers.js if you haven't
already. In this example we'll use Node.js and
npm:
npm install ethers
Save the following code to the file block-counter.js:
import { WebSocketProvider } from "ethers/providers";
const wsUrl = "wss://testnet-rpc.monad.xyz"
const provider = new WebSocketProvider(wsUrl);
provider.on("block", (blockNumber) => {  console.log("New block received:", blockNumber);});
Finally, run
node block-counter.js
After a few seconds, you should see output similar to:
New block received: 29165925New block received: 29165926New block received: 29165927
Real-time data protocol vs data streaming API​
The formal protocol for real-time data used in the above examples is documented
by Geth as the real-time events protocol.
Its specification describes:

The JSON-RPC calls needed to create and destroy subscriptions
(eth_subscribe and eth_unsubscribe)
The kinds of subscriptions available (newHeads, logs, etc.)
The structure of the JSON objects pushed when new data arrives

This documentation generally describes Monad's WebSocket support in these
terms.
Notice that in the Python example, you explicitly see the subscription name
'newHeads' and call an API function named subscribe: the API design
matches the protocol design very closely. The JavaScript example, on the other
hand, is different: you see nothing about newHeads or "subscribing."
Internally, this JavaScript library uses the newHeads subscription just like
the Python version, but it presents real-time data using different choices in
API design space. Some of the most popular libraries in other languages (e.g.,
alloy in Rust) use newHeads or logs internally in
some of their APIs, although sometimes it's an implementation detail and they
don't explicitly say so.
The next section of this page documents the eth_subscribe data feeds which
are Monad extensions (monadNewHeads and monadLogs). If you want to access
these extensions, you need to use an API that has a style like the web3
library in the Python example. Because it is a very thin layer on top of the
underlying protocol, it is also naturally extensible: the Monad-specific data
feeds will work without the library being changed, because the API is
low-level enough (e.g., returning JSON responses as generic dictionary
objects) that it can work with our new feeds without any modification.
monadNewHeads and monadLogs​
These publish almost the same data as their standardized counterparts
(newHeads and logs), except the data is published sooner -- by about
one second on average -- but on a speculative basis.
To consume this data, the user needs to understand speculative execution
and how it affects real-time data. The necessary background you need to
know is described here.
The remainder of this section explains how those concepts appear in the
data that's published.
As explained in the section on
block ids,
you need to know two things about a block:

What commit state the block is in
What the block's unique ID is, because its block number is not unique
prior to finalization

Consequently, a monadNewHeads update looks the same as a newHeads update
except that it contains the additional blockId and commitState fields:
{  "blockId": "0x71ce47f39a1eb490354166f762d78bf6e2acaf80b24b4bcd756118d93ef81be0",  "commitState": "Proposed",  "hash": "0x7a7d7c23bb8c5e340eead8537bb5e2f3e125bfa0b588cf07e4aa140ba374295e",  "parentHash": "0x9a71a95be3fe957457b11817587e5af4c7e24836d5b383c430ff25b9286a457f",  "sha3Uncles": "0x1dcc4de8dec75d7aab85b567b6ccd41ad312451b948a7413f0a142fd40d49347",  "miner": "0x1ad91ee08f21be3de0ba2ba6918e714da6b45836",  "stateRoot": "0x5e215f13dce86552d9083116be9f2b71f639d014fa9694f3dca9fb579bf4a717",  "transactionsRoot": "0xfe490e456649550c9f94cb46104da1d3eda87f06a1c33e578137d8cf1ef06fe6",  "receiptsRoot": "0x9ae198972e011bf3617a28ec72bef9a515f66d1d15988d92191eb3c7f231640a",  "logsBloom": "0x09e3c42e60df6a823da47b9b9e73b3a563ffddc9fb59802a087d92bf7e5bc92d7477f504864e1446cc46fb89c1bd63207f3f9bfbfba378f444f5895f53fee0fc10dbd395f546ffbefedfeef9712c4cf66ed3cf24df4f720b7bf67c2994337c607fa56e49ab6acd5efd7bb61428f8edcfa3e2d66dae3b8fd3c6942d36e8ea7403d107f7d97a57dfb50de96601410af486c7f5f6c55357a6fd2b30a979fb99d1a7bb9bbdbd1b227cbcdc9fff81ef73ab2bdc470a4bb9772eb658755fce551869a1f35b2e6338d06acd94e4dff638cf7dd74e5613ef178f16bbb0253f8f06eb7c64f6bbfffbeb165965d06f532da10edf63e54782c7ed9b05ca41efec457a95782f",  "difficulty": "0x310db4075e35d4",  "number": "0xe4e1c1",  "gasLimit": "0x1c9c380",  "gasUsed": "0x1579362",  "timestamp": "0x62b12cf8",  "extraData": "0x486976656f6e2072752d6865617679",  "mixHash": "0xc808debc77a41b82b5a6780fb288a47593ec636cdedab4feaeb65d91322f30b6",  "nonce": "0xdff7aec95842e5ed",  "baseFeePerGas": "0x3b541e0b1",  "totalDifficulty": "0x0",  "size": "0x2fe"}
The block above is first seen in the "Proposed"
state.1 This means it has been speculatively executed, before the local consensus node has
discovered its ultimate fate.
This exact same update might be seen several more times -- with all data
exactly the same as above -- except that the "commitState" will change.
In the "normal" life-cycle of a block,
you would see this update three more times, but with "commitState" changing to
"Voted", then
"Finalized", and finally to
"Verified".
A few notes about block commit state transitions:


A block may skip the "Voted" state and go directly from "Proposed"
to "Finalized". This happens when consensus is far ahead of execution2


You could see multiple blocks that are "Proposed" or "Voted" for the
same block number, as explained in the section on
block ids.
Although it's possible, one nice property of Monad's consensus algorithm is that
it should be extremely rare for this to happen once a block becomes
"Voted"


When failure-to-finalize does occur, blocks are abandoned implicitly,
not explicitly; that is, the finalization of some block number N
implicitly abandons all competing blocks for that same block number, but
no explicit update is published for those block ids to mark them as
abandoned (i.e., there is no explicit "Abandoned" commit state)


There is currently no way to say something like "don't tell me about
a block until it enters the "Voted" state", although this feature will
be added before the mainnet release of Monad.
Checking if WebSocket support is enabled​
WebSocket support is an extra feature which may not be enabled on an RPC
server. A quick way to check if WebSocket connectivity is working is to use
a general purpose command-line tool that can act as WebSocket client, such
as websocat.
websocat is a powerful command-line "swiss army knife" tool, like nc or
the original socat. If it is not available through your system's package
manager, it can be installed with cargo install websocat, as it is a Rust
utility.
Here is an example of running it in verbose mode (-v):
> websocat -v wss://testnet-rpc.monad.xyz[INFO  websocat::lints] Auto-inserting the line mode[INFO  websocat::stdio_threaded_peer] get_stdio_peer (threaded)[INFO  websocat::ws_client_peer] get_ws_client_peer[INFO  websocat::net_peer] Connected to TCP 208.115.212.142:8081[INFO  websocat::ws_client_peer] Connected to ws
To subscribe, type the subscription JSON-RPC call for eth_subscribe into
your terminal's stdin and press enter:
{ "id": 1, "jsonrpc": "2.0", "method": "eth_subscribe", "params": ["newHeads"] }
Every half-second or so, you should see updates about new blocks.

Footnotes​


In the current implementation, blocks are always first seen in the
Proposed state, but you shouldn't write your software assuming this will
always be the case. If the consensus daemon is running far ahead of
execution, it would be possible to propagate a more accurate commit state
from consensus to execution. This is an optimization that no implementation
currently does, but a future implementation might do so. ↩


In the consensus algorithm itself, a block cannot skip directly
from Voted to Finalized. However, the real-time data stream you see is based
on the execution service's slightly-delayed view of what consensus is doing.
If execution starts lagging behind consensus for whatever reason, it might
discover that a block has already been Finalized by the time it sees the next
update for that block. In this case, it won't publish a notification of the
voted state transition, but will move the block directly to Finalized. ↩

### Code Examples

```prism
pip install web3
```

```prism
import asyncio
from web3 import AsyncWeb3from web3.providers.persistent import WebSocketProvider
ws_url = 'wss://testnet-rpc.monad.xyz'
async def print_latest():  async with AsyncWeb3(WebSocketProvider(ws_url)) as w3:    subscription_id = await w3.eth.subscribe('newHeads', {})    async for payload in w3.socket.process_subscriptions():      print(f"New block received: {payload['result']['number']}")
if __name__ == "__main__":  asyncio.run(print_latest())
```

```prism
python block-counter.py
```

```prism
New block received: 29165925New block received: 29165926New block received: 29165927
```

```prism
npm install ethers
```

```prism
import { WebSocketProvider } from "ethers/providers";
const wsUrl = "wss://testnet-rpc.monad.xyz"
const provider = new WebSocketProvider(wsUrl);
provider.on("block", (blockNumber) => {  console.log("New block received:", blockNumber);});
```

```prism
node block-counter.js
```

```prism
New block received: 29165925New block received: 29165926New block received: 29165927
```

```prism
{  "blockId": "0x71ce47f39a1eb490354166f762d78bf6e2acaf80b24b4bcd756118d93ef81be0",  "commitState": "Proposed",  "hash": "0x7a7d7c23bb8c5e340eead8537bb5e2f3e125bfa0b588cf07e4aa140ba374295e",  "parentHash": "0x9a71a95be3fe957457b11817587e5af4c7e24836d5b383c430ff25b9286a457f",  "sha3Uncles": "0x1dcc4de8dec75d7aab85b567b6ccd41ad312451b948a7413f0a142fd40d49347",  "miner": "0x1ad91ee08f21be3de0ba2ba6918e714da6b45836",  "stateRoot": "0x5e215f13dce86552d9083116be9f2b71f639d014fa9694f3dca9fb579bf4a717",  "transactionsRoot": "0xfe490e456649550c9f94cb46104da1d3eda87f06a1c33e578137d8cf1ef06fe6",  "receiptsRoot": "0x9ae198972e011bf3617a28ec72bef9a515f66d1d15988d92191eb3c7f231640a",  "logsBloom": "0x09e3c42e60df6a823da47b9b9e73b3a563ffddc9fb59802a087d92bf7e5bc92d7477f504864e1446cc46fb89c1bd63207f3f9bfbfba378f444f5895f53fee0fc10dbd395f546ffbefedfeef9712c4cf66ed3cf24df4f720b7bf67c2994337c607fa56e49ab6acd5efd7bb61428f8edcfa3e2d66dae3b8fd3c6942d36e8ea7403d107f7d97a57dfb50de96601410af486c7f5f6c55357a6fd2b30a979fb99d1a7bb9bbdbd1b227cbcdc9fff81ef73ab2bdc470a4bb9772eb658755fce551869a1f35b2e6338d06acd94e4dff638cf7dd74e5613ef178f16bbb0253f8f06eb7c64f6bbfffbeb165965d06f532da10edf63e54782c7ed9b05ca41efec457a95782f",  "difficulty": "0x310db4075e35d4",  "number": "0xe4e1c1",  "gasLimit": "0x1c9c380",  "gasUsed": "0x1579362",  "timestamp": "0x62b12cf8",  "extraData": "0x486976656f6e2072752d6865617679",  "mixHash": "0xc808debc77a41b82b5a6780fb288a47593ec636cdedab4feaeb65d91322f30b6",  "nonce": "0xdff7aec95842e5ed",  "baseFeePerGas": "0x3b541e0b1",  "totalDifficulty": "0x0",  "size": "0x2fe"}
```

```prism
> websocat -v wss://testnet-rpc.monad.xyz[INFO  websocat::lints] Auto-inserting the line mode[INFO  websocat::stdio_threaded_peer] get_stdio_peer (threaded)[INFO  websocat::ws_client_peer] get_ws_client_peer[INFO  websocat::net_peer] Connected to TCP 208.115.212.142:8081[INFO  websocat::ws_client_peer] Connected to ws
```

```prism
{ "id": 1, "jsonrpc": "2.0", "method": "eth_subscribe", "params": ["newHeads"] }
```

---



# Section: root

---

## Introduction

> Source: https://docs.monad.xyz/

On this page

Quick hits
Network Information
Deployment Summary for Developers

Monad is a Layer-1 blockchain delivering high performance, true decentralization, and EVM
compatibility.
Monad's north star is making decentralization more powerful, and eliminating the perceived
tradeoff between decentralization and performance.
Monad supports a large globally distributed network
(see the validator map), with intentionally minimal
hardware requirements so that anyone may run a node.
Performance comes from software architecture improvements rather than reliance on heavy hardware
or node colocation.
Monad's codebase is fully open source (consensus,
execution) and is built for extreme performance in
C++ and rust.
Monad introduces novel architectures in five major areas:

MonadBFT, a frontier BFT consensus mechanism solving the
tail-forking problem
RaptorCast for efficient block transmission
Asynchronous Execution for pipelining
consensus and execution to raise the time budget for execution
Parallel Execution and JIT Compilation for efficient transaction
execution
MonadDb for efficient storage of Ethereum state

Monad's improvements address existing bottlenecks while preserving seamless compatibility for
application developers (full EVM bytecode compatibility) and users (Ethereum
RPC API compatibility).
The result is an Ethereum-compatible Layer-1 blockchain with 10,000 tps of throughput,
400ms block frequency, and 800ms finality.
Select a level of detail by visiting either Monad for Users or
Monad for Developers.
Deploying on Monad​
See Deployment Summary for Developers for everything you need to
know as a developer deploying on Monad.
Monad features first-class support for many leading Ethereum developer tools and infra providers.
See Tooling and Infrastructure for a summary.
Architecture​
Monad is designed with a focus on performance and scalability with commodity hardware.
The subsequent pages survey the major architectural changes in Monad as well as the
interface for users.
The first Monad client is built by
Category Labs and is written from scratch in C++ and Rust.
monad-bft, Category Labs's implementation of
a Monad consensus client, and
monad, Category Labs's implementation of a Monad
execution client, are both open-source under GPL-3.0.
Mainnet​
Public mainnet launched on Nov 24, 2025.
See Network Information for access, or check out the
MonadVision block explorer, the gmonads.com
network visualization, or app.monad.xyz.

---



# Section: templates

---

## Farcaster Mini Apps

> Source: https://docs.monad.xyz/templates/farcaster-miniapp/

On this page

Mini Apps enable developers to distribute native-like apps to Farcaster users. Mini Apps are the easiest way to deliver engaging, high-retention, and easy-to-monetize applications!
Mini Apps are web apps built with HTML, CSS, and Javascript that can be discovered and used within Farcaster.
Guides​
Getting StartedSending NotificationsPublishing Mini AppGenerating custom shareable imagesHaptics

---

## How to add haptics to a Farcaster Mini App

> Source: https://docs.monad.xyz/templates/farcaster-miniapp/haptics

On this page

Haptics are a way to add tactile feedback to your app to enhance user interaction and responsiveness.
This guide walks you through implementing haptics in a Farcaster Mini App for a more intuitive and engaging user experience.
Implementing haptics in a Farcaster Mini App​
If you are using the Monad Mini App template, you can use haptics from the useFrame hook.
If you are not using the Monad Mini App template, you can inspect the useFrame hook to check out the implementation details.
Below is an example of how to implement haptics in a Farcaster Mini App:
...
export default function MyComponent() {  const { haptics } = useFrame();
  return (    <div>      <button onClick={() => haptics.impactOccurred('light')}>Light Impact</button>    </div>  );}
Supported haptics​
The following haptics are supported:
Haptic TypeCodeLight Impacthaptics.impactOccurred('light')Medium Impacthaptics.impactOccurred('medium')Heavy Impacthaptics.impactOccurred('heavy')Soft Impacthaptics.impactOccurred('soft')Rigid Impacthaptics.impactOccurred('rigid')Success Notificationhaptics.notificationOccurred('success')Warning Notificationhaptics.notificationOccurred('warning')Error Notificationhaptics.notificationOccurred('error')Selection Changehaptics.selectionChanged()

### Code Examples

```prism
...
export default function MyComponent() {  const { haptics } = useFrame();
  return (    <div>      <button onClick={() => haptics.impactOccurred('light')}>Light Impact</button>    </div>  );}
```

---

## How to build a Farcaster Mini App

> Source: https://docs.monad.xyz/templates/farcaster-miniapp/getting-started

On this page

In this guide, you will learn how to use the Monad Farcaster Mini App Template to build apps.
The template demonstrates all Mini App capabilities and lets you easily modify it, so you can build Mini Apps.
Cloning the Template​
You can the following command to clone the Mini App template to your local machine:
git clone https://github.com/monad-developers/monad-miniapp-template.git
Install the dependencies​
yarn
Copy .env.example over to .env.local​
cp .env.example .env.local
Run the template​
yarn run dev
View the App in Farcaster Embed tool​
Farcaster has a neat Embed tool that you can use to inspect the Mini App before you publish it.
Unfortunately, the embed tool can only work with remote URL. Inputting a localhost URL does not work.
As a workaround, you may make the local app accessible remotely using a tool like cloudflared or ngrok. In this guide we will use cloudflared.
Install Cloudflared​
brew install cloudflared
For more installation options see the official docs.
Expose localhost​
Run the following command in your terminal:
cloudflared tunnel --url http://localhost:3000
Be sure to specify the correct port for your local server.
Set NEXT_PUBLIC_URL environment variable in .env.local file​
NEXT_PUBLIC_URL=<url-from-cloudflared-or-ngrok>
Use the provided url​
cloudflared will generate a random subdomain and print it in the terminal for you to use. Any traffic to this URL will get sent to your local server.
Enter the provided URL in the Farcaster Embed tool.

Let's investigate the various components of the template.
Customizing the Mini App Embed​
Mini App Embed is how the Mini App shows up in the feed or in a chat conversation when the URL of the app is shared.
The Mini App Embed looks like this:

You can customize this by editing the file app/page.tsx:
page.tsxapp1234567891011121314151617181920...
const appUrl = env.NEXT_PUBLIC_URL;
const frame = {  version: "next",  imageUrl: `${appUrl}/images/feed.png`, // Embed image URL (3:2 image ratio)  button: {    title: "Template", // Text on the embed button    action: {      type: "launch_frame",      name: "Monad Farcaster Mini App Template",      url: appUrl, // URL that is opened when the embed button is tapped or clicked.      splashImageUrl: `${appUrl}/images/splash.png`,      splashBackgroundColor: "#f7f7f7",    },  },};
...
You can either edit the URLs for the images or replace the images in public/images folder in the template.
Once you are happy with the changes, click Refetch in the Embed tool to get the latest configuration.
noteIf you are developing locally, ensure that your Next.js app is running locally and the cloudflare tunnel is open.
Customizing the Splash Screen​
Upon opening the Mini App, the first thing the user will see is the Splash screen:

You can edit the app/page.tsx file to customize the Splash screen.
page.tsxapp1234567891011121314151617181920...
const appUrl = env.NEXT_PUBLIC_URL;
const frame = {  version: "next",  imageUrl: `${appUrl}/images/feed.png`,  button: {    title: "Launch Template",    action: {      type: "launch_frame",      name: "Monad Farcaster Mini App Template",      url: appUrl,      splashImageUrl: `${appUrl}/images/splash.png`, // App icon in the splash screen (200px * 200px)      splashBackgroundColor: "#f7f7f7", // Splash screen background color    },  },};
...
For splashImageUrl, you can either change the URL or replace the image in public/images folder in the template.
Modifying the Mini App​
Upon opening the template Mini App, you should see a screen like this:

The code for this screen is in the components/pages/app.tsx file:
app.tsxcomponents > pages12345678910export default function Home() {  const { context } = useMiniAppContext();  return (    // SafeAreaContainer component makes sure that the app margins are rendered properly depending on which client is being used.    <SafeAreaContainer insets={context?.client.safeAreaInsets}>      {/* You replace the Demo component with your home component */}      <Demo />    </SafeAreaContainer>  )}
You can remove or edit the code in this file to build your Mini App.
Accessing User Context​

Your Mini App receives various information about the user, including username, fid, displayName, pfpUrl and other fields.
The template provides a helpful hook useMiniAppContext that you can use to access these fields:
User.tsxcomponents > Home1234export function User() {    const { context } = useMiniAppContext();    return <p>{context.user.username}</p>}
The template also provide an example of the same in components/Home/User.tsx file.
You can learn more about Context here.
Performing App Actions​

Mini Apps have the capability to perform native actions that enhance the user experience!
Actions like:

addFrame: Allows the user to save (bookmark) the app in a dedicated section
composeCast: Allows the Mini App to prompt the user to cast with prefilled text and media
viewProfile: Presents a profile of a Farcaster user in a client native UI

Learn more about Mini App actions here
The template provides an easy way to access the actions via the useMiniAppContext hook!
FarcasterActions.tsxcomponents > Homeconst { actions } = useMiniAppContext();
An example for the same can be found in components/Home/FarcasterActions.tsx file.
Prompting Wallet Actions​

Every user of Farcaster has a Farcaster wallet with Monad Testnet support.
Mini Apps can prompt the user to perform onchain actions!
The template provides an example for the same in components/Home/WalletActions.tsx file.
WalletActions.tsxcomponents > Home123456789101112export function WalletActions() {    ...
    async function sendTransactionHandler() {        sendTransaction({            to: "0x7f748f154B6D180D35fA12460C7E4C631e28A9d7",            value: parseEther("1"),        });    }
    ...}
warningThe Farcaster wallet supports multiple networks. It is recommended that you ensure that the right network is connected before prompting wallet actions.You can use viem's switchChain or equivalent to prompt a chain switch.WalletActions.tsxcomponents > Home// Switching to Monad TestnetswitchChain({ chainId: 10143 });The template has an example for the same in the components/Home/WalletActions.tsx file.
Conclusion​
In this guide, you explored Farcaster Mini Apps — the simplest way to create engaging, high-retention, and easily monetizable applications!
You also discovered the key capabilities of Mini Apps and how you can use the Monad Farcaster Mini App Template to build your own.
For more details, check out the official Mini App documentation here.
Explore more Farcaster Mini App guides​
Sending NotificationsGenerating custom shareable imagesPublishing Mini App

### Code Examples

```prism
git clone https://github.com/monad-developers/monad-miniapp-template.git
```

```prism
yarn
```

```prism
cp .env.example .env.local
```

```prism
yarn run dev
```

```prism
brew install cloudflared
```

```prism
cloudflared tunnel --url http://localhost:3000
```

```prism
NEXT_PUBLIC_URL=<url-from-cloudflared-or-ngrok>
```

```prism
...
const appUrl = env.NEXT_PUBLIC_URL;
const frame = {  version: "next",  imageUrl: `${appUrl}/images/feed.png`, // Embed image URL (3:2 image ratio)  button: {    title: "Template", // Text on the embed button    action: {      type: "launch_frame",      name: "Monad Farcaster Mini App Template",      url: appUrl, // URL that is opened when the embed button is tapped or clicked.      splashImageUrl: `${appUrl}/images/splash.png`,      splashBackgroundColor: "#f7f7f7",    },  },};
...
```

```prism
...
const appUrl = env.NEXT_PUBLIC_URL;
const frame = {  version: "next",  imageUrl: `${appUrl}/images/feed.png`,  button: {    title: "Launch Template",    action: {      type: "launch_frame",      name: "Monad Farcaster Mini App Template",      url: appUrl,      splashImageUrl: `${appUrl}/images/splash.png`, // App icon in the splash screen (200px * 200px)      splashBackgroundColor: "#f7f7f7", // Splash screen background color    },  },};
...
```

```prism
export default function Home() {  const { context } = useMiniAppContext();  return (    // SafeAreaContainer component makes sure that the app margins are rendered properly depending on which client is being used.    <SafeAreaContainer insets={context?.client.safeAreaInsets}>      {/* You replace the Demo component with your home component */}      <Demo />    </SafeAreaContainer>  )}
```

```prism
export function User() {    const { context } = useMiniAppContext();    return <p>{context.user.username}</p>}
```

```prism
const { actions } = useMiniAppContext();
```

```prism
export function WalletActions() {    ...
    async function sendTransactionHandler() {        sendTransaction({            to: "0x7f748f154B6D180D35fA12460C7E4C631e28A9d7",            value: parseEther("1"),        });    }
    ...}
```

```prism
// Switching to Monad TestnetswitchChain({ chainId: 10143 });
```

---

## How to generate user specific images in the Farcaster Mini App

> Source: https://docs.monad.xyz/templates/farcaster-miniapp/generating-custom-og-images

On this page

Creating shareable moments in the Farcaster Mini App is a great way to engage with your users.
You can generate custom shareable user specific images in the Farcaster Mini App and make it easy for the user to share them!

In this guide we setup a dedicated endpoint /api/og for generating images and we use @vercel/og package to generate the images.
Generating images​
If you are using the Monad Mini App template, you can simply
edit app/api/og/route.tsx
to generate images of your choice.
route.tsxapp > api > og12345678910111213141516171819202122232425262728...
export async function GET(request: NextRequest) {  try {    const { searchParams } = new URL(request.url);
    // The below is dependent on whether the username and image are passed as query params or not.    const username = searchParams.get('username') || 'User'; // Username of the user    const imageUrl = searchParams.get('image') || ''; // Image url of the user        const backgroundGradient = '#2D1B69'; // Background color of the image        // Load Inter font from the public folder    const interFontData = await fetch(      `${request.nextUrl.origin}/Inter.ttf`    ).then((res) => res.arrayBuffer());        return new ImageResponse(    (        // Generate the image here    );  } catch (e) {    console.error('Error generating OG image:', e);    return new Response('Failed to generate image', { status: 500 });  }}
...
If you are not using the template, you need to install @vercel/og package.
npm install @vercel/og
Create a new file app/api/og/route.tsx, if you are using Next.js 14 or higher.
route.tsxapp > api > og1234567891011121314151617181920212223import { ImageResponse } from '@vercel/og';import { NextRequest } from 'next/server';
// Generate the image for every requestexport const dynamic = "force-dynamic";
export async function GET(request: NextRequest) {  try {    const { searchParams } = new URL(request.url);        // The below is dependent on whether the username and image are passed as query params or not.    const username = searchParams.get('username') || 'User'; // Username of the user    const imageUrl = searchParams.get('image') || ''; // Image url of the user        return new ImageResponse(    (        // Generate the image here    );  } catch (e) {    console.error('Error generating OG image:', e);    return new Response('Failed to generate image', { status: 500 });  }}
If you are not using Next.js, you can setup an endpoint or dedicated microservice to generate the images.
Sharing images via the Mini App​
Example from EGGS Mini App, prompting the user to cast a custom generated image
Add shareable elements to your Mini App, so the user can share the generated images via the Mini App.
Below is an example of a button that can be used to generate and share a custom image:
1234567891011121314151617181920212223242526272829303132333435export default function GenerateAndShareCustomImage() {
...
    const handleGenerateCustomOGImage = () => {        // Generate the image using the endpoint        const ogImageUrl = `${APP_URL}/api/og?username=${username}&image=${pfpUrl}`;
        // Programmatically compose a cast with the generated image        actions?.composeCast({            // Text to be displayed in the cast            text: "I generated a custom OG image using Monad Mini App template",             // Image to be displayed in the cast            embeds: [ogImageUrl],        });    };
...
    return (        <button            type="button"            className="bg-white text-black rounded-md p-2 text-sm"            /**             * When the button is clicked, the shareable image is generated              * and the cast is composed.            */            onClick={() => handleGenerateCustomOGImage()}            disabled={!fid}        >            Generate Custom Image        </button>    );
}

### Code Examples

```prism
...
export async function GET(request: NextRequest) {  try {    const { searchParams } = new URL(request.url);
    // The below is dependent on whether the username and image are passed as query params or not.    const username = searchParams.get('username') || 'User'; // Username of the user    const imageUrl = searchParams.get('image') || ''; // Image url of the user        const backgroundGradient = '#2D1B69'; // Background color of the image        // Load Inter font from the public folder    const interFontData = await fetch(      `${request.nextUrl.origin}/Inter.ttf`    ).then((res) => res.arrayBuffer());        return new ImageResponse(    (        // Generate the image here    );  } catch (e) {    console.error('Error generating OG image:', e);    return new Response('Failed to generate image', { status: 500 });  }}
...
```

```prism
npm install @vercel/og
```

```prism
import { ImageResponse } from '@vercel/og';import { NextRequest } from 'next/server';
// Generate the image for every requestexport const dynamic = "force-dynamic";
export async function GET(request: NextRequest) {  try {    const { searchParams } = new URL(request.url);        // The below is dependent on whether the username and image are passed as query params or not.    const username = searchParams.get('username') || 'User'; // Username of the user    const imageUrl = searchParams.get('image') || ''; // Image url of the user        return new ImageResponse(    (        // Generate the image here    );  } catch (e) {    console.error('Error generating OG image:', e);    return new Response('Failed to generate image', { status: 500 });  }}
```

```prism
export default function GenerateAndShareCustomImage() {
...
    const handleGenerateCustomOGImage = () => {        // Generate the image using the endpoint        const ogImageUrl = `${APP_URL}/api/og?username=${username}&image=${pfpUrl}`;
        // Programmatically compose a cast with the generated image        actions?.composeCast({            // Text to be displayed in the cast            text: "I generated a custom OG image using Monad Mini App template",             // Image to be displayed in the cast            embeds: [ogImageUrl],        });    };
...
    return (        <button            type="button"            className="bg-white text-black rounded-md p-2 text-sm"            /**             * When the button is clicked, the shareable image is generated              * and the cast is composed.            */            onClick={() => handleGenerateCustomOGImage()}            disabled={!fid}        >            Generate Custom Image        </button>    );
}
```

---

## How to publish a Farcaster Mini App

> Source: https://docs.monad.xyz/templates/farcaster-miniapp/publishing-miniapp

On this page

Publishing the Mini App makes it discoverable in the Farcaster app. However, the Mini App has to be hosted on a domain before it can be published.
Since Farcaster is a decentralized network with multiple clients, a standard has been adopted wherein the Farcaster clients look for the farcaster.json file on the Mini App hosted domain for information about the Mini App.
Hosting the farcaster.json file​
The farcaster.json has to be placed in /.well-known/farcaster.json endpoint.
If you are using the Monad Mini App template you can edit the farcaster.json file with your app details before publishing the app!
If you are not using the template then you have to make sure you have a farcaster.json file hosted on your domain at [domain]/.well-known/farcaster.json endpoint.
route.tsapp > .well-known > farcaster.json12345678910111213141516171819202122232425262728...
const appUrl = process.env.NEXT_PUBLIC_URL;const farcasterConfig = {    // accountAssociation details are required to associate the published app with it's author    // instructions on how to get these values are provided later in this guide.    accountAssociation: {        "header": "",        "payload": "",        "signature": ""    },    frame: {        version: "1",        name: "Monad Farcaster Mini App Template", // Name of your Mini App        iconUrl: `${appUrl}/images/icon.png`, // Icon of the app in the app store        homeUrl: `${appUrl}`, // Default launch URL        imageUrl: `${appUrl}/images/feed.png`, // Default image to show if shared in a feed.        screenshotUrls: [], // Visual previews of the app        tags: ["monad", "farcaster", "miniapp", "template"], // Descriptive tags for search        primaryCategory: "developer-tools",        buttonTitle: "Launch Template",        splashImageUrl: `${appUrl}/images/splash.png`, // URL of image to show on loading screen.	        splashBackgroundColor: "#ffffff", // Hex color code to use on loading screen.        webhookUrl: `${appUrl}/api/webhook` // Webhook url for notifications    }};
...
The above example is a partial representation of the farcaster.json file. The full reference for the farcaster.json file can be found here.
Generating accountAssociation using the Farcaster Mobile App.​
The accountAssociation object in the farcaster.json file is used to associate the Mini App with the publisher's Farcaster account.
To generate the accountAssociation object you can use the Farcaster Mobile App.
Go to Settings (under Developer) > Domains, enter the domain where the Mini App is hosted and click Generate Domain Manifest.
Can't see Developer options?For the Developer options to be visible you will need to have Developer mode enabled in Farcaster.You can enable it by going to Settings (under Profile and Account) > Advanced > scroll down and enable Developer mode.
The accountAssociation object will be generated it will be available in your clipboard you can then paste the values in the farcaster.json file.
route.tsapp > .well-known > farcaster.json12345678910111213...
const appUrl = process.env.NEXT_PUBLIC_URL;const farcasterConfig = {    accountAssociation: {        header: "eyJmaWQiOjE3OTc5LCJ0eXBlIjoiY3VzdG9keSIsImtleSI6IjB4MGMxNWE5QkVmRTg3RjY0N0IwMDNhMjI0MTY4NDYwMzYyODQ0M2Y4YiJ9",        payload: "eyJkb21haW4iOiJtb25hZC1taW5pYXBwLXRlbXBsYXRlLXNldmVuLnZlcmNlbC5hcHAifQ",        signature: "MHgwYzY2NDdjZDhjOWJiY2JmYzg2NGIzZjVjYWVjY2ExMTdlOTY4ZGQwMWIzMmM0NGViMjU5ZDhlOGQyMzdhZTZiMDU1MmNmNWRiMDU1MDMwNTZmNTNhZmEwZDZlZTBlZmIyMmJmNDNmMDQ4NTdhMzk2NmY0YmMzODk2N2NlZDI5ZjFi"    },    ...};
...

You can find the farcaster.json file for Monad Mini App Template app here.
Once the farcaster.json file is hosted, your Mini App is now discoverable in the Farcaster app, you can test it by searching for the Mini App in the Farcaster app!

### Code Examples

```prism
...
const appUrl = process.env.NEXT_PUBLIC_URL;const farcasterConfig = {    // accountAssociation details are required to associate the published app with it's author    // instructions on how to get these values are provided later in this guide.    accountAssociation: {        "header": "",        "payload": "",        "signature": ""    },    frame: {        version: "1",        name: "Monad Farcaster Mini App Template", // Name of your Mini App        iconUrl: `${appUrl}/images/icon.png`, // Icon of the app in the app store        homeUrl: `${appUrl}`, // Default launch URL        imageUrl: `${appUrl}/images/feed.png`, // Default image to show if shared in a feed.        screenshotUrls: [], // Visual previews of the app        tags: ["monad", "farcaster", "miniapp", "template"], // Descriptive tags for search        primaryCategory: "developer-tools",        buttonTitle: "Launch Template",        splashImageUrl: `${appUrl}/images/splash.png`, // URL of image to show on loading screen.	        splashBackgroundColor: "#ffffff", // Hex color code to use on loading screen.        webhookUrl: `${appUrl}/api/webhook` // Webhook url for notifications    }};
...
```

```prism
...
const appUrl = process.env.NEXT_PUBLIC_URL;const farcasterConfig = {    accountAssociation: {        header: "eyJmaWQiOjE3OTc5LCJ0eXBlIjoiY3VzdG9keSIsImtleSI6IjB4MGMxNWE5QkVmRTg3RjY0N0IwMDNhMjI0MTY4NDYwMzYyODQ0M2Y4YiJ9",        payload: "eyJkb21haW4iOiJtb25hZC1taW5pYXBwLXRlbXBsYXRlLXNldmVuLnZlcmNlbC5hcHAifQ",        signature: "MHgwYzY2NDdjZDhjOWJiY2JmYzg2NGIzZjVjYWVjY2ExMTdlOTY4ZGQwMWIzMmM0NGViMjU5ZDhlOGQyMzdhZTZiMDU1MmNmNWRiMDU1MDMwNTZmNTNhZmEwZDZlZTBlZmIyMmJmNDNmMDQ4NTdhMzk2NmY0YmMzODk2N2NlZDI5ZjFi"    },    ...};
...
```

---

## How to send notifications to users of the Farcaster Mini App

> Source: https://docs.monad.xyz/templates/farcaster-miniapp/sending-notifications

On this page

This guide walks you through how you can send notifications to your Mini App users.
This guide uses Monad Mini App template, which already has the code for sending notifications; all you have to do is modify a few lines of code.
If you aren't using the template, you can still follow the guide; feel free to copy code as needed from the template.
Demo​
If you want to try the Mini App notification experience, you can try the Monad Mini App Template app.
Modifying the Mini App manifest​
noteMini App account association process has to be completed before the Mini App can send notifications.
Mini Apps can send notifications to the user when:

The user has added the Mini App and not disabled notifications manually
The user has explicitly subscribed to notifications from the Mini App

Farcaster app or clients send events like miniapp_added, miniapp_removed, notifications_disabled and notifications_enabled to the Mini App's webhook endpoint, this allows the Mini App to keep track of which users the Mini App can send notifications to.
The webhookUrl has to be specified in the Mini App manifest file:
route.tsapp > .well-known > farcaster.json...
export async function GET() {  const farcasterConfig = {    // TODO: Add your own account association    frame: {        version: "1",        name: "Monad Farcaster Mini App Template",        ...        splashBackgroundColor: "#ffffff",        webhookUrl: `${APP_URL}/api/webhook`, // <--- Edit this    },};
...
If you are using the Monad Mini App Template, you don't need to edit the webhookUrl.
Processing Farcaster client events​
The code for processing webhook events can be found in the file /app/api/webhook/route.ts.
Verifying webhook events​
Events are signed by the app key of a user with a JSON Farcaster Signature. This allows Mini Apps to verify the Farcaster client that generated the notification and the Farcaster user they generated it for.
It is important to verify events in order to make sure the Mini App is correctly tracking which users it can send notifications to.
If you are using the Monad Mini App template, the code for verifying events is already available in /app/api/webhook/route.ts. If not, you can copy code from the same file.
infoA Neynar API key is required to verify webhook events. You can sign up to the Neynar service and get an API key for free.Once done, add a environment variable named NEYNAR_API_KEY to your .env file.
Processing webhook payload​
Once the webhookUrl is specified, Farcaster app and clients will send client events to the webhook endpoint.
The miniapp_added and notifications_enabled events are received by the Mini App along with fid and notificationDetails.
notificationDetails has a url and a token that can be used to send notifications to a specific Farcaster user.
Example of webhook payload:
{    "fid": 17979,    "event": {        "event": "notifications_enabled",        "notificationDetails": {            "url": "https://api.farcaster.xyz/v1/frame-notifications",            "token": "a05059ef2415c67b08ecceb539201cbc6"        }    }}
You can find the code, handling the Farcaster client events in /app/api/webhook/route.ts.
The Mini App can use any database service of choice to store the url and token and use it when sending notifications.
The Monad Mini App template uses Upstash's Redis service for storing the notificationDetails, if you wish to use a different database you can modify it in /lib/kv.ts.
noteSince the Monad Mini App template uses Redis for storing notification url and token, environment variables UPSTASH_REDIS_REST_URL and UPSTASH_REDIS_REST_TOKEN are required in .env.Once you sign up for the Upstash service and create a Redis database you will be able to get these environment variables.If you plan to use some other database, adjust environment variables accordingly.
Example of storing notification details in Redis:
kv.tslib...
const redis = new Redis({  url: process.env.UPSTASH_REDIS_REST_URL,  token: process.env.UPSTASH_REDIS_REST_TOKEN,});
...
export async function setUserNotificationDetails(    fid: number,    notificationDetails: MiniAppNotificationDetails): Promise<void> {    // Modify lines that use redis to use your own database implementation    await redis.set(getUserNotificationDetailsKey(fid), notificationDetails);  }
...
Sending notifications​
Example of a notification sent from a Farcaster Mini App
Once you have a notification token for a user, you can send them a notification by sending a POST request to the url associated with that token.
If you are using the Monad Mini App template the code for sending notification is already available in the file /app/api/send-notification/route.ts. If not, you can copy code from /lib/notifs.ts and /app/api/send-notification/route.ts.
Personalizing notification content​
You can change a few lines of code in /app/api/send-notification/route.ts file to personalize the notification:
route.tsapp > api > send-notification...
// This function sends the notificationconst sendResult = await sendFrameNotification({    fid: requestBody.data.fid,    // You can modify/personalize the below line to make the title of the notification dynamic based on the fid (user)    title: "Test notification",    // You can modify/personalize the below line to make the body of the notification dynamic based on the fid (user)    body: "Sent at " + new Date().toISOString(),});
...
warningNotification Rate Limits​The standard rate limits, which are enforced by Farcaster, are:
1 notification per 30 seconds per token
100 notifications per day per token

If you are using the Monad Mini App template, you can send notifications from the server or the Mini App by making a POST to /api/send-notification endpoint!
That's all you need to send notifications to your Mini App users!

### Code Examples

```prism
...
export async function GET() {  const farcasterConfig = {    // TODO: Add your own account association    frame: {        version: "1",        name: "Monad Farcaster Mini App Template",        ...        splashBackgroundColor: "#ffffff",        webhookUrl: `${APP_URL}/api/webhook`, // <--- Edit this    },};
...
```

```prism
{    "fid": 17979,    "event": {        "event": "notifications_enabled",        "notificationDetails": {            "url": "https://api.farcaster.xyz/v1/frame-notifications",            "token": "a05059ef2415c67b08ecceb539201cbc6"        }    }}
```

```prism
...
const redis = new Redis({  url: process.env.UPSTASH_REDIS_REST_URL,  token: process.env.UPSTASH_REDIS_REST_TOKEN,});
...
export async function setUserNotificationDetails(    fid: number,    notificationDetails: MiniAppNotificationDetails): Promise<void> {    // Modify lines that use redis to use your own database implementation    await redis.set(getUserNotificationDetailsKey(fid), notificationDetails);  }
...
```

```prism
...
// This function sends the notificationconst sendResult = await sendFrameNotification({    fid: requestBody.data.fid,    // You can modify/personalize the below line to make the title of the notification dynamic based on the fid (user)    title: "Test notification",    // You can modify/personalize the below line to make the body of the notification dynamic based on the fid (user)    body: "Sent at " + new Date().toISOString(),});
...
```

---

## How to use the Next.js PWA Privy embedded wallet template

> Source: https://docs.monad.xyz/templates/next-serwist-privy-embedded-wallet

On this page

This guide walks you through using the template which uses Next.js, Serwist (offline capabilities), and Privy embedded wallet to build a Progressive Web App (PWA) on Monad.
infoThis template also has a no-privy branch that you can switch to in order to start without Privy.You can switch using the following command:git checkout no-privy
Prerequisites​

Node.js (v18 or higher)
a Privy account

Setting up Privy
Create your Privy app:
Select "Web" as the platform. Then, click "Create app".On the next screen, make sure to save your App ID.
Set up login methods:

Disable External Wallets:

Scroll down and enable "Automatically create embedded wallets on login" and select "EVM Wallets":
tipYou can enable "Test Accounts" for testing purposes:
Setup​


Clone the repository:
git clone https://github.com/monad-developers/next-serwist-privy-embedded-wallet.git


cd into the project directory:
cd next-serwist-privy-embedded-wallet


Install dependencies:
npm install


Create a .env.local file in the root directory:
cp .env.example .env.local


Start adding your environment variables to the .env.local file:
# PrivyNEXT_PUBLIC_PRIVY_APP_ID=your_privy_app_id_hereNEXT_PUBLIC_PRIVY_CLIENT_ID= # optional, you can leave this empty
# VAPID Keys for push notificationsNEXT_PUBLIC_VAPID_PUBLIC_KEY=your_vapid_public_key_hereVAPID_PRIVATE_KEY=your_vapid_private_key_here
If you lost your Privy App ID, you can find it in the Privy dashboard.


Generate VAPID keys for web push notifications:
npx web-push generate-vapid-keys --json
Copy the generated keys to your .env.local file (replace the placeholder values from step 5).


Running the Application:
Development Mode:
npm run dev
The application will be available at http://localhost:3000.
Production Mode:
For full PWA functionality (including install prompts):
npm run build && npm run start


Folder structure of the template​
next-serwist-privy-embedded-wallet/├── app/│   ├── components/         # React components│   │   ├── InstallPWA.tsx  # PWA install prompt│   │   └── ...│   ├── ~offline/           # Offline page│   └── ...├── public/                 # Static assets└── ...
Changing the app name​

Edit public/manifest.json:

Change the name and short_name fields


Run npm run build to update the app

Notification Setup​
Enable notifications for the best experience!To receive push notifications from this app, you need to enable notifications in your browser and/or system settings:
Browser Settings​
Chrome/Edge
Click the lock icon 🔒 in the address bar
Set "Notifications" to "Allow"
Or go to Settings → Privacy and security → Site Settings → Notifications

Firefox
Click the shield icon 🛡️ in the address bar
Turn off "Enhanced Tracking Protection" for this site (if needed)
Allow notifications when prompted
Or go to Settings → Privacy & Security → Permissions → Notifications

Safari
Go to Safari → Settings → Websites → Notifications
Find your site and set it to "Allow"

System Settings​
macOS
System Preferences → Notifications & Focus
Find your browser and ensure notifications are enabled
Check "Allow notifications from websites" in browser settings

Windows
Settings → System → Notifications & actions
Ensure your browser can send notifications
Check browser notification settings

iOS
Settings → Notifications → [Your Browser]
Enable "Allow Notifications"
Also enable in browser settings

Android
Settings → Apps → [Your Browser] → Notifications
Enable notifications
Check browser notification permissions

Backend Integration Required​
The SendNotification.tsx component is sample codeSendNotification.tsx requires backend implementation:
Save subscription data when users subscribe (see TODO comments in code)
Delete subscription data when users unsubscribe
Implement /notification endpoint to send actual push notifications
Use web-push library or similar for server-side notification delivery

Customizing Notification Content​
To customize your push notification content, edit app/notification/route.ts and modify the title, message, icon, and other properties in the sendNotification call.
Modifying the App Icon & Splash Screen​
App Icons​
Replace the icon files in the public/icons/ directory with your custom icons:

icon-512x512.png - Main app icon (512×512px)
android-chrome-192x192.png - Android icon (192×192px)
apple-touch-icon.png - iOS home screen icon (180×180px)

Also update the favicon:

public/favicon.ico - Browser favicon
app/favicon.ico - Next.js app favicon

Splash Screen​
Splash screens are automatically generated from your app icon and theme colors defined in public/manifest.json. To customize:

Update the theme_color and background_color in public/manifest.json
Ensure your main icon (icon-512x512.png) represents your brand
Run npm run build to apply changes

tipUse tools like PWA Asset Generator to create all required icon sizes from a single source image.
Deploying to Vercel​
Using Vercel Dashboard​


Connect your repository:

Push your code to GitHub
Visit vercel.com and import your repository



Configure environment variables:

In your Vercel project dashboard, go to Settings → Environment Variables
Add the same variables from your .env.local:
NEXT_PUBLIC_PRIVY_APP_IDNEXT_PUBLIC_PRIVY_CLIENT_IDNEXT_PUBLIC_VAPID_PUBLIC_KEYVAPID_PRIVATE_KEY




Deploy: Vercel will automatically build and deploy your app


Update Privy settings: In your Privy dashboard, add your Vercel domain (e.g., your-app.vercel.app) to the allowed origins


tipPWA features (install prompts, offline support, push notifications) work automatically on HTTPS domains like Vercel deployments.
Using Vercel CLI​
Alternatively, deploy using the Vercel CLI:


Install Vercel CLI:
npm i -g vercel


Login to Vercel:
vercel login


Deploy:
vercel
Follow the prompts to configure your project.


Add environment variables:
vercel env add NEXT_PUBLIC_PRIVY_APP_IDvercel env add NEXT_PUBLIC_PRIVY_CLIENT_ID  vercel env add NEXT_PUBLIC_VAPID_PUBLIC_KEYvercel env add VAPID_PRIVATE_KEY
Or you can go to the Vercel dashboard and add the environment variables there.


Redeploy with environment variables:
vercel --prod


Learn more​

Serwist: docs | guides
Privy: create a wallet | send a transaction | sign a transaction
Monad: supported tooling and infra

### Code Examples

```prism
git checkout no-privy
```

```prism
git clone https://github.com/monad-developers/next-serwist-privy-embedded-wallet.git
```

```prism
cd next-serwist-privy-embedded-wallet
```

```prism
npm install
```

```prism
cp .env.example .env.local
```

```prism
# PrivyNEXT_PUBLIC_PRIVY_APP_ID=your_privy_app_id_hereNEXT_PUBLIC_PRIVY_CLIENT_ID= # optional, you can leave this empty
# VAPID Keys for push notificationsNEXT_PUBLIC_VAPID_PUBLIC_KEY=your_vapid_public_key_hereVAPID_PRIVATE_KEY=your_vapid_private_key_here
```

```prism
npx web-push generate-vapid-keys --json
```

```prism
npm run dev
```

```prism
npm run build && npm run start
```

```prism
next-serwist-privy-embedded-wallet/├── app/│   ├── components/         # React components│   │   ├── InstallPWA.tsx  # PWA install prompt│   │   └── ...│   ├── ~offline/           # Offline page│   └── ...├── public/                 # Static assets└── ...
```

```prism
NEXT_PUBLIC_PRIVY_APP_IDNEXT_PUBLIC_PRIVY_CLIENT_IDNEXT_PUBLIC_VAPID_PUBLIC_KEYVAPID_PRIVATE_KEY
```

```prism
npm i -g vercel
```

```prism
vercel login
```

```prism
vercel
```

```prism
vercel env add NEXT_PUBLIC_PRIVY_APP_IDvercel env add NEXT_PUBLIC_PRIVY_CLIENT_ID  vercel env add NEXT_PUBLIC_VAPID_PUBLIC_KEYvercel env add VAPID_PRIVATE_KEY
```

```prism
vercel --prod
```

---

## How to use the Next.js PWA sponsored transactions template

> Source: https://docs.monad.xyz/templates/next-serwist-privy-smart-wallet

On this page

This guide walks you through using the template which uses Next.js, Serwist (offline capabilities), and Privy smart wallet (authentication and transaction sponsorship) to build a Progressive Web Application (PWA) on Monad.
Prerequisites​

Node.js (v18 or higher)
a Privy account
a Pimlico account

Setting up Privy

Create your Privy app:

Select "Web" as the platform. Then, click "Create app".

On the next screen, make sure to save your App ID.


Set up login methods:



Disable External Wallets:



Scroll down and enable "Automatically create embedded wallets on login" and select "EVM Wallets":


tipYou can enable "Test Accounts" for testing purposes:
Setting up Pimlico

Sign up for a Pimlico account and go to "API Keys"



Create a new API key:



Click on RPC URLs, then Select "Monad Testnet", and copy the RPC URL:



Copy the RPC URL and save it to your .env.local file as NEXT_PUBLIC_PIMLICO_BUNDLER_URL.


Setup​


Clone the repository:
git clone https://github.com/monad-developers/next-serwist-privy-smart-wallet.git


cd into the project directory:
cd next-serwist-privy-smart-wallet


Install dependencies:
npm install


Create a .env.local file in the root directory:
cp .env.example .env.local


Start adding your environment variables to the .env.local file:
# Privy NEXT_PUBLIC_PRIVY_APP_ID=your_privy_app_id_hereNEXT_PUBLIC_PRIVY_CLIENT_ID= # optional, you can leave this empty
# Web PushWEB_PUSH_EMAIL=user@example.comWEB_PUSH_PRIVATE_KEY=your_vapid_private_keyNEXT_PUBLIC_WEB_PUSH_PUBLIC_KEY=your_vapid_public_key
# PimlicoNEXT_PUBLIC_PIMLICO_BUNDLER_URL=your_pimlico_bundler_url
If you lost your Privy App ID, you can find it in the Privy dashboard.


Generate VAPID keys for web push notifications:
npx web-push generate-vapid-keys --json
Copy the generated keys to your .env.local file (replace the placeholder values from step 5).


Running the Application:
Development Mode:
npm run dev
The application will be available at http://localhost:3000.
Production Mode:
For full PWA functionality (including install prompts):
npm run build && npm run start


Send sponsored transactions​
Below is an example of how to use the useSmartWallet hook to send sponsored transactions. You can either modify the code to send your own transactions or integrate it into your existing project.
// Use `useSmartWallet` hookconst { smartAccountAddress, smartAccountClient, smartAccountReady } = useSmartWallet();
// Send sponsored transactionconst txHash = await smartAccountClient?.sendTransaction({  account: smartAccountClient?.account,  chain: monadTestnet, // Import this from `viem/chains`  to: NFT_CONTRACT_ADDRESS,  data,});
Send batch sponsored transactions​
You can also send batches of sponsored transactions:
const txHash = await smartAccountClient?.sendTransaction({  calls: [    {      to: NFT_CONTRACT_ADDRESS,      data,    },    {      to: NFT_CONTRACT_ADDRESS,      data,    },  ],});
This example uses the Kernel smart account with Entrypoint v7. See useSmartWallet.tsx to inspect the implementation details.
Folder structure of the template​
next-serwist-privy-smart-wallet/├── app/│   ├── components/         # React components│   │   ├── InstallPWA.tsx  # PWA install prompt│   │   └── ...│   ├── hooks/                  # Custom React hooks│   │   └── useSmartWallet.tsx  # Smart wallet management hook│   ├── ~offline/           # Offline page│   └── ...├── public/                 # Static assets└── ...
Changing the app name​

Edit public/manifest.json:

Change the name and short_name fields


Run npm run build to update the app

Notification Setup​
Enable notifications for the best experience!To receive push notifications from this app, you need to enable notifications in your browser and/or system settings:
Browser Settings​
Chrome/Edge
Click the lock icon 🔒 in the address bar
Set "Notifications" to "Allow"
Or go to Settings → Privacy and security → Site Settings → Notifications

Firefox
Click the shield icon 🛡️ in the address bar
Turn off "Enhanced Tracking Protection" for this site (if needed)
Allow notifications when prompted
Or go to Settings → Privacy & Security → Permissions → Notifications

Safari
Go to Safari → Settings → Websites → Notifications
Find your site and set it to "Allow"

System Settings​
macOS
System Preferences → Notifications & Focus
Find your browser and ensure notifications are enabled
Check "Allow notifications from websites" in browser settings

Windows
Settings → System → Notifications & actions
Ensure your browser can send notifications
Check browser notification settings

iOS
Settings → Notifications → [Your Browser]
Enable "Allow Notifications"
Also enable in browser settings

Android
Settings → Apps → [Your Browser] → Notifications
Enable notifications
Check browser notification permissions

Backend Integration Required​
The SendNotification.tsx component is sample codeSendNotification.tsx requires backend implementation:
Save subscription data when users subscribe (see TODO comments in code)
Delete subscription data when users unsubscribe
Implement /notification endpoint to send actual push notifications
Use web-push library or similar for server-side notification delivery

Customizing Notification Content​
To customize your push notification content, edit app/notification/route.ts and modify the title, message, icon, and other properties in the sendNotification call.
Modifying the App Icon & Splash Screen​
App Icons​
Replace the icon files in the public/icons/ directory with your custom icons:

icon-512x512.png - Main app icon (512×512px)
android-chrome-192x192.png - Android icon (192×192px)
apple-touch-icon.png - iOS home screen icon (180×180px)

Also update the favicon:

public/favicon.ico - Browser favicon
app/favicon.ico - Next.js app favicon

Splash Screen​
Splash screens are automatically generated from your app icon and theme colors defined in public/manifest.json. To customize:

Update the theme_color and background_color in public/manifest.json
Ensure your main icon (icon-512x512.png) represents your brand
Run npm run build to apply changes

tipUse tools like PWA Asset Generator to create all required icon sizes from a single source image.
Deploying to Vercel​
Using Vercel Dashboard​


Connect your repository:

Push your code to GitHub
Visit vercel.com and import your repository



Configure environment variables:

In your Vercel project dashboard, go to Settings → Environment Variables
Add the same variables from your .env.local:
NEXT_PUBLIC_PRIVY_APP_IDNEXT_PUBLIC_PRIVY_CLIENT_IDWEB_PUSH_EMAILWEB_PUSH_PRIVATE_KEYNEXT_PUBLIC_WEB_PUSH_PUBLIC_KEYNEXT_PUBLIC_PIMLICO_BUNDLER_URL




Deploy: Vercel will automatically build and deploy your app


Update Privy settings: In your Privy dashboard, add your Vercel domain (e.g., your-app.vercel.app) to the allowed origins


tipPWA features (install prompts, offline support, push notifications) work automatically on HTTPS domains like Vercel deployments.
Using Vercel CLI​
Alternatively, deploy using the Vercel CLI:


Install Vercel CLI:
npm i -g vercel


Login to Vercel:
vercel login


Deploy:
vercel
Follow the prompts to configure your project.


Add environment variables:
vercel env add NEXT_PUBLIC_PRIVY_APP_IDvercel env add NEXT_PUBLIC_PRIVY_CLIENT_IDvercel env add WEB_PUSH_EMAILvercel env add WEB_PUSH_PRIVATE_KEYvercel env add NEXT_PUBLIC_WEB_PUSH_PUBLIC_KEYvercel env add NEXT_PUBLIC_PIMLICO_BUNDLER_URL
Or you can go to the Vercel dashboard and add the environment variables there.


Redeploy with environment variables:
vercel --prod


Learn more​

Serwist: docs | guides
Privy: create a wallet | send a transaction | sign a transaction
Pimlico: docs | guides
Monad: supported tooling and infra

### Code Examples

```prism
git clone https://github.com/monad-developers/next-serwist-privy-smart-wallet.git
```

```prism
cd next-serwist-privy-smart-wallet
```

```prism
npm install
```

```prism
cp .env.example .env.local
```

```prism
# Privy NEXT_PUBLIC_PRIVY_APP_ID=your_privy_app_id_hereNEXT_PUBLIC_PRIVY_CLIENT_ID= # optional, you can leave this empty
# Web PushWEB_PUSH_EMAIL=user@example.comWEB_PUSH_PRIVATE_KEY=your_vapid_private_keyNEXT_PUBLIC_WEB_PUSH_PUBLIC_KEY=your_vapid_public_key
# PimlicoNEXT_PUBLIC_PIMLICO_BUNDLER_URL=your_pimlico_bundler_url
```

```prism
npx web-push generate-vapid-keys --json
```

```prism
npm run dev
```

```prism
npm run build && npm run start
```

```prism
// Use `useSmartWallet` hookconst { smartAccountAddress, smartAccountClient, smartAccountReady } = useSmartWallet();
// Send sponsored transactionconst txHash = await smartAccountClient?.sendTransaction({  account: smartAccountClient?.account,  chain: monadTestnet, // Import this from `viem/chains`  to: NFT_CONTRACT_ADDRESS,  data,});
```

```prism
const txHash = await smartAccountClient?.sendTransaction({  calls: [    {      to: NFT_CONTRACT_ADDRESS,      data,    },    {      to: NFT_CONTRACT_ADDRESS,      data,    },  ],});
```

```prism
next-serwist-privy-smart-wallet/├── app/│   ├── components/         # React components│   │   ├── InstallPWA.tsx  # PWA install prompt│   │   └── ...│   ├── hooks/                  # Custom React hooks│   │   └── useSmartWallet.tsx  # Smart wallet management hook│   ├── ~offline/           # Offline page│   └── ...├── public/                 # Static assets└── ...
```

```prism
NEXT_PUBLIC_PRIVY_APP_IDNEXT_PUBLIC_PRIVY_CLIENT_IDWEB_PUSH_EMAILWEB_PUSH_PRIVATE_KEYNEXT_PUBLIC_WEB_PUSH_PUBLIC_KEYNEXT_PUBLIC_PIMLICO_BUNDLER_URL
```

```prism
npm i -g vercel
```

```prism
vercel login
```

```prism
vercel
```

```prism
vercel env add NEXT_PUBLIC_PRIVY_APP_IDvercel env add NEXT_PUBLIC_PRIVY_CLIENT_IDvercel env add WEB_PUSH_EMAILvercel env add WEB_PUSH_PRIVATE_KEYvercel env add NEXT_PUBLIC_WEB_PUSH_PUBLIC_KEYvercel env add NEXT_PUBLIC_PIMLICO_BUNDLER_URL
```

```prism
vercel --prod
```

---

## How to use the Next.js Serwist 0x Privy embedded wallet template

> Source: https://docs.monad.xyz/templates/next-serwist-0x-privy-embedded-wallet

On this page

This guide walks you through using the template which uses Next.js, Serwist (offline capabilities), 0x (token trading), and Privy embedded wallet (authentication) to build a Progressive Web Application (PWA) on Monad.
Prerequisites​

Node.js (v18 or higher)
a Privy account
a 0x account

Setting up Privy

Create your Privy app:

Select "Web" as the platform. Then, click "Create app".

On the next screen, make sure to save your App ID.


Set up login methods:



Disable External Wallets:



Scroll down and enable "Automatically create embedded wallets on login" and select "EVM Wallets":


tipYou can enable "Test Accounts" for testing purposes.
Setting up 0x

Create your 0x account:
Go to 0x dashboard and create your account.
On the next screen, make sure to save your API Key.


Get your API Key:
To get your API key, create an app and then go to API Keys.
Copy the API key and save it for later.


Setup​


Clone the repository:
git clone https://github.com/monad-developers/next-serwist-privy-0x.git


cd into the project directory:
cd next-serwist-privy-0x


Install dependencies:
npm install


Create a .env.local file in the root directory:
cp .env.example .env.local


Start adding your environment variables to the .env.local file:
# PrivyNEXT_PUBLIC_PRIVY_APP_ID=your_privy_app_id_hereNEXT_PUBLIC_PRIVY_CLIENT_ID= # optional, you can leave this empty
# VAPID Keys for push notificationsNEXT_PUBLIC_VAPID_PUBLIC_KEY=your_vapid_public_key_hereVAPID_PRIVATE_KEY=your_vapid_private_key_here
# 0x ConfigurationZEROX_API_KEY=your_0x_api_key_here
If you lost your Privy App ID, you can find it in the Privy dashboard.


Generate VAPID keys for web push notifications:
npx web-push generate-vapid-keys --json
Copy the generated keys to your .env.local file (replace the placeholder values from step 5).


Running the Application:
Development Mode:
npm run dev
The application will be available at http://localhost:3000.
Production Mode:
For full PWA functionality (including install prompts):
npm run build && npm run start


Folder structure of the template​
next-serwist-privy-0x/├── app/│   ├── components/          # React components│   │   ├── 0x/             # 0x Protocol integration│   │   ├── InstallPWA.tsx  # PWA install prompt│   │   ├── SwapComponent.tsx # Token swap interface│   │   └── ...│   ├── api/                # API routes│   │   ├── price/          # Token price endpoints│   │   └── quote/          # Swap quote endpoints│   ├── ~offline/           # Offline page│   └── ...├── public/                 # Static assets├── utils/                  # Utility functions└── ...
Changing the app name​

Edit public/manifest.json:

Change the name and short_name fields


Run npm run build to update the app

Notification Setup​
Enable notifications for the best experience!To receive push notifications from this app, you need to enable notifications in your browser and/or system settings:
Browser Settings​
Chrome/Edge
Click the lock icon 🔒 in the address bar
Set "Notifications" to "Allow"
Or go to Settings → Privacy and security → Site Settings → Notifications

Firefox
Click the shield icon 🛡️ in the address bar
Turn off "Enhanced Tracking Protection" for this site (if needed)
Allow notifications when prompted
Or go to Settings → Privacy & Security → Permissions → Notifications

Safari
Go to Safari → Settings → Websites → Notifications
Find your site and set it to "Allow"

System Settings​
macOS
System Preferences → Notifications & Focus
Find your browser and ensure notifications are enabled
Check "Allow notifications from websites" in browser settings

Windows
Settings → System → Notifications & actions
Ensure your browser can send notifications
Check browser notification settings

iOS
Settings → Notifications → [Your Browser]
Enable "Allow Notifications"
Also enable in browser settings

Android
Settings → Apps → [Your Browser] → Notifications
Enable notifications
Check browser notification permissions

Backend Integration Required​
The SendNotification.tsx component is sample codeThis requires backend implementation:
Save subscription data when users subscribe (see TODO comments in code)
Delete subscription data when users unsubscribe
Implement /notification endpoint to send actual push notifications
Use web-push library or similar for server-side notification delivery

Customizing Notification Content​
To customize your push notification content, edit app/notification/route.ts and modify the title, message, icon, and other properties in the sendNotification call.
Modifying the App Icon & Splash Screen​
App Icons​
Replace the icon files in the public/icons/ directory with your custom icons:

icon-512x512.png - Main app icon (512×512px)
android-chrome-192x192.png - Android icon (192×192px)
apple-touch-icon.png - iOS home screen icon (180×180px)

Also update the favicon:

public/favicon.ico - Browser favicon
app/favicon.ico - Next.js app favicon

Splash Screen​
Splash screens are automatically generated from your app icon and theme colors defined in manifest.json. To customize:

Update the theme_color and background_color in manifest.json
Ensure your main icon (icon-512x512.png) represents your brand
Run npm run build to apply changes

tipUse tools like PWA Asset Generator to create all required icon sizes from a single source image.
Adding More Tokens​
The template currently supports WMON and USDT tokens. To add more tokens for trading, follow these steps:
1. Find Token Information​
Before adding a token, you'll need the following information:

Contract Address: The token's smart contract address
Symbol: The token's symbol (e.g., "ETH", "USDC")
Name: The full name of the token
Decimals: Number of decimal places (usually 18 for most ERC-20 tokens)
Logo URI: URL to the token's logo image

You can find this information on the DEXes that 0x Swap API supports.
To get the DEXes that 0x Swap API supports, you can query the sources endpoint. For reference, see getSources page.
2. Update Token Constants​
Edit utils/constants.ts and add your new token to three places:
A. Add to MONAD_TESTNET_TOKENS array​
constants.tsutilsexport const MONAD_TESTNET_TOKENS: Token[] = [  // ... existing tokens ...  {    chainId: 1,    name: "Your Token Name",    symbol: "YOUR_SYMBOL",    decimals: 18,    address: "0xYourTokenContractAddress",    logoURI: "https://your-token-logo-url.png",  },];
B. Add to MONAD_TESTNET_TOKENS_BY_SYMBOL record​
constants.tsutilsexport const MONAD_TESTNET_TOKENS_BY_SYMBOL: Record<string, Token> = {  // ... existing tokens ...  your_symbol: {    // lowercase key    chainId: 1,    name: "Your Token Name",    symbol: "YOUR_SYMBOL",    decimals: 18,    address: "0xYourTokenContractAddress",    logoURI: "https://your-token-logo-url.png",  },};
C. Add to MONAD_TESTNET_TOKENS_BY_ADDRESS record​
constants.tsutilsexport const MONAD_TESTNET_TOKENS_BY_ADDRESS: Record<string, Token> = {  // ... existing tokens ...  "0xyourtokencontractaddress": {    // lowercase address    chainId: 1,    name: "Your Token Name",    symbol: "YOUR_SYMBOL",    decimals: 18,    address: "0xYourTokenContractAddress", // original case    logoURI: "https://your-token-logo-url.png",  },};
3. Example: Adding shMON​
Here's a complete example of adding USDC:
constants.tsutils// In MONAD_TESTNET_TOKENS array{  chainId: 1,  name: "shMonad",  symbol: "shMON",  decimals: 18,  address: "0x3a98250F98Dd388C211206983453837C8365BDc1",  logoURI: "put_your_logo_url_here_or_use_the_default_logo",},
// In MONAD_TESTNET_TOKENS_BY_SYMBOL recordshmon: {  chainId: 1,  name: "shMonad",  symbol: "shMON",  decimals: 18,  address: "0x3a98250F98Dd388C211206983453837C8365BDc1",  logoURI: "put_your_logo_url_here_or_use_the_default_logo",},
// In MONAD_TESTNET_TOKENS_BY_ADDRESS record"0x3a98250F98Dd388C211206983453837C8365BDc1": {  chainId: 1,  name: "shMonad",  symbol: "shMON",  decimals: 18,  address: "0x3a98250F98Dd388C211206983453837C8365BDc1",  logoURI: "put_your_logo_url_here_or_use_the_default_logo",},
4. Important Notes​

Decimals: Most tokens use 18 decimals, but some (like USDT, USDC) use 6
Logo URLs: Use permanent, reliable image URLs. Consider hosting logos yourself for better reliability
Testing: Test thoroughly with small amounts before using in production
0x Protocol Support: Ensure the token is supported by 0x Protocol for your target network

5. Rebuild and Test​
After adding tokens:
npm run buildnpm run start
The new tokens will automatically appear in the token selector dropdowns in the swap interface.
Configuring Slippage Tolerance​
Slippage tolerance determines how much price movement you're willing to accept during a trade. The app currently uses the 0x API's default slippage tolerance of 1% (100 basis points).
Adding Slippage Configuration​
1. Update Constants​
Add slippage options to utils/constants.ts:
constants.tsutilsexport const DEFAULT_SLIPPAGE_BPS = 100; // 1% in basis points
export const SLIPPAGE_OPTIONS = [  { label: "0.1%", value: 10 },  { label: "0.5%", value: 50 },  { label: "1%", value: 100 },  { label: "2%", value: 200 },  { label: "3%", value: 300 },];
2. Update API Routes​
Add slippageBps parameter to both API routes:
app/api/price/route.ts and app/api/quote/route.ts:
route.tsapp > api > priceexport async function GET(request: NextRequest) {  const searchParams = request.nextUrl.searchParams;
  // Add default slippage if not provided  if (!searchParams.has("slippageBps")) {    searchParams.set("slippageBps", "100"); // 1% default  }
  const res = await fetch(    `https://api.0x.org/swap/permit2/price?${searchParams}`, // or /quote    {      headers: {        "0x-api-key": process.env.ZEROX_API_KEY as string,        "0x-version": "v2",      },    }  );  const data = await res.json();  return Response.json(data);}
3. Add Slippage to Components​
Update the price/quote requests to include slippageBps parameter:
In app/components/0x/price.tsx:
price.tsxapp > components > 0xconst [slippageBps, setSlippageBps] = useState(DEFAULT_SLIPPAGE_BPS);
// Add slippageBps to your API request parametersconst priceRequest = useMemo(  () => ({    chainId,    sellToken: sellTokenObject.address,    buyToken: buyTokenObject.address,    sellAmount: parsedSellAmount,    taker,    slippageBps, // Add this    // ... other params  }),  [...dependencies, slippageBps]);
Slippage Parameter Details​

Range: 0-10000 basis points (0%-100%)
Default: 100 (1%)
Format: Basis points (100 bps = 1%)

Reference: 0x API Documentation
Deploying to Vercel​
Using Vercel Dashboard​


Connect your repository:

Push your code to GitHub
Visit vercel.com and import your repository



Configure environment variables:

In your Vercel project dashboard, go to Settings → Environment Variables
Add the same variables from your .env.local:
NEXT_PUBLIC_PRIVY_APP_IDNEXT_PUBLIC_PRIVY_CLIENT_IDNEXT_PUBLIC_VAPID_PUBLIC_KEYVAPID_PRIVATE_KEYZEROX_API_KEY




Deploy: Vercel will automatically build and deploy your app


Update Privy settings: In your Privy dashboard, add your Vercel domain (e.g., your-app.vercel.app) to the allowed origins


tipPWA features (install prompts, offline support, push notifications) work automatically on HTTPS domains like Vercel deployments.
Using Vercel CLI​
Alternatively, deploy using the Vercel CLI:


Install Vercel CLI:
npm i -g vercel


Login to Vercel:
vercel login


Deploy:
vercel
Follow the prompts to configure your project.


Add environment variables:
vercel env add NEXT_PUBLIC_PRIVY_APP_IDvercel env add NEXT_PUBLIC_PRIVY_CLIENT_IDvercel env add NEXT_PUBLIC_VAPID_PUBLIC_KEYvercel env add VAPID_PRIVATE_KEYvercel env add ZEROX_API_KEY
Or you can go to the Vercel dashboard and add the environment variables there.


Redeploy with environment variables:
vercel --prod


Learn more​

Serwist: docs | guides
Privy: create a wallet | send a transaction | sign a transaction
0x: docs | guides
Monad: supported tooling and infra

### Code Examples

```prism
git clone https://github.com/monad-developers/next-serwist-privy-0x.git
```

```prism
cd next-serwist-privy-0x
```

```prism
npm install
```

```prism
cp .env.example .env.local
```

```prism
# PrivyNEXT_PUBLIC_PRIVY_APP_ID=your_privy_app_id_hereNEXT_PUBLIC_PRIVY_CLIENT_ID= # optional, you can leave this empty
# VAPID Keys for push notificationsNEXT_PUBLIC_VAPID_PUBLIC_KEY=your_vapid_public_key_hereVAPID_PRIVATE_KEY=your_vapid_private_key_here
# 0x ConfigurationZEROX_API_KEY=your_0x_api_key_here
```

```prism
npx web-push generate-vapid-keys --json
```

```prism
npm run dev
```

```prism
npm run build && npm run start
```

```prism
next-serwist-privy-0x/├── app/│   ├── components/          # React components│   │   ├── 0x/             # 0x Protocol integration│   │   ├── InstallPWA.tsx  # PWA install prompt│   │   ├── SwapComponent.tsx # Token swap interface│   │   └── ...│   ├── api/                # API routes│   │   ├── price/          # Token price endpoints│   │   └── quote/          # Swap quote endpoints│   ├── ~offline/           # Offline page│   └── ...├── public/                 # Static assets├── utils/                  # Utility functions└── ...
```

```prism
export const MONAD_TESTNET_TOKENS: Token[] = [  // ... existing tokens ...  {    chainId: 1,    name: "Your Token Name",    symbol: "YOUR_SYMBOL",    decimals: 18,    address: "0xYourTokenContractAddress",    logoURI: "https://your-token-logo-url.png",  },];
```

```prism
export const MONAD_TESTNET_TOKENS_BY_SYMBOL: Record<string, Token> = {  // ... existing tokens ...  your_symbol: {    // lowercase key    chainId: 1,    name: "Your Token Name",    symbol: "YOUR_SYMBOL",    decimals: 18,    address: "0xYourTokenContractAddress",    logoURI: "https://your-token-logo-url.png",  },};
```

```prism
export const MONAD_TESTNET_TOKENS_BY_ADDRESS: Record<string, Token> = {  // ... existing tokens ...  "0xyourtokencontractaddress": {    // lowercase address    chainId: 1,    name: "Your Token Name",    symbol: "YOUR_SYMBOL",    decimals: 18,    address: "0xYourTokenContractAddress", // original case    logoURI: "https://your-token-logo-url.png",  },};
```

```prism
// In MONAD_TESTNET_TOKENS array{  chainId: 1,  name: "shMonad",  symbol: "shMON",  decimals: 18,  address: "0x3a98250F98Dd388C211206983453837C8365BDc1",  logoURI: "put_your_logo_url_here_or_use_the_default_logo",},
// In MONAD_TESTNET_TOKENS_BY_SYMBOL recordshmon: {  chainId: 1,  name: "shMonad",  symbol: "shMON",  decimals: 18,  address: "0x3a98250F98Dd388C211206983453837C8365BDc1",  logoURI: "put_your_logo_url_here_or_use_the_default_logo",},
// In MONAD_TESTNET_TOKENS_BY_ADDRESS record"0x3a98250F98Dd388C211206983453837C8365BDc1": {  chainId: 1,  name: "shMonad",  symbol: "shMON",  decimals: 18,  address: "0x3a98250F98Dd388C211206983453837C8365BDc1",  logoURI: "put_your_logo_url_here_or_use_the_default_logo",},
```

```prism
npm run buildnpm run start
```

```prism
export const DEFAULT_SLIPPAGE_BPS = 100; // 1% in basis points
export const SLIPPAGE_OPTIONS = [  { label: "0.1%", value: 10 },  { label: "0.5%", value: 50 },  { label: "1%", value: 100 },  { label: "2%", value: 200 },  { label: "3%", value: 300 },];
```

```prism
export async function GET(request: NextRequest) {  const searchParams = request.nextUrl.searchParams;
  // Add default slippage if not provided  if (!searchParams.has("slippageBps")) {    searchParams.set("slippageBps", "100"); // 1% default  }
  const res = await fetch(    `https://api.0x.org/swap/permit2/price?${searchParams}`, // or /quote    {      headers: {        "0x-api-key": process.env.ZEROX_API_KEY as string,        "0x-version": "v2",      },    }  );  const data = await res.json();  return Response.json(data);}
```

```prism
const [slippageBps, setSlippageBps] = useState(DEFAULT_SLIPPAGE_BPS);
// Add slippageBps to your API request parametersconst priceRequest = useMemo(  () => ({    chainId,    sellToken: sellTokenObject.address,    buyToken: buyTokenObject.address,    sellAmount: parsedSellAmount,    taker,    slippageBps, // Add this    // ... other params  }),  [...dependencies, slippageBps]);
```

```prism
NEXT_PUBLIC_PRIVY_APP_IDNEXT_PUBLIC_PRIVY_CLIENT_IDNEXT_PUBLIC_VAPID_PUBLIC_KEYVAPID_PRIVATE_KEYZEROX_API_KEY
```

```prism
npm i -g vercel
```

```prism
vercel login
```

```prism
vercel
```

```prism
vercel env add NEXT_PUBLIC_PRIVY_APP_IDvercel env add NEXT_PUBLIC_PRIVY_CLIENT_IDvercel env add NEXT_PUBLIC_VAPID_PUBLIC_KEYvercel env add VAPID_PRIVATE_KEYvercel env add ZEROX_API_KEY
```

```prism
vercel --prod
```

---

## How to use the Next.js Serwist Thirdweb embedded wallet template

> Source: https://docs.monad.xyz/templates/next-serwist-thirdweb

On this page

This guide walks you through using the template which uses Next.js, Serwist (offline capabilities), and Thirdweb embedded wallet to build a Progressive Web Application (PWA) on Monad.
Prerequisites​

Node.js (v18 or higher)
a Thirdweb account

Setup​


Clone the repository:
git clone https://github.com/monad-developers/next-serwist-thirdweb.git


cd into the project directory:
cd next-serwist-thirdweb


Install dependencies:
npm install


Create a .env.local file in the root directory:
cp .env.example .env.local


Start adding your environment variables to the .env.local file:
# Thirdweb Configuration (Required)NEXT_PUBLIC_THIRDWEB_CLIENT_ID=your_thirdweb_client_id_here
# Web Push (Required)WEB_PUSH_EMAIL=user@example.comWEB_PUSH_PRIVATE_KEY=your_vapid_private_keyNEXT_PUBLIC_WEB_PUSH_PUBLIC_KEY=your_vapid_public_key
If you lost your Thirdweb Client ID, you can find it in the Thirdweb dashboard.


Generate VAPID keys for web push notifications:
npx web-push generate-vapid-keys --json
Copy the generated keys to your .env.local file (replace the placeholder values from step 5).


Running the Application:
Development Mode:
npm run dev
The application will be available at http://localhost:3000.
Production Mode:
For full PWA functionality (including install prompts):
npm run build && npm run start


Folder structure of the template​
next-serwist-thirdweb/├── app/│   ├── components/         # React components│   │   ├── InstallPWA.tsx  # PWA install prompt│   │   └── ...│   ├── ~offline/           # Offline page│   └── ...├── public/                 # Static assets└── ...
Changing the app name​

Edit public/manifest.json:

Change the name and short_name fields


Run npm run build to update the app

Notification Setup​
Enable notifications for the best experience!To receive push notifications from this app, you need to enable notifications in your browser and/or system settings.
Browser Settings​
Chrome/Edge
Click the lock icon 🔒 in the address bar
Set "Notifications" to "Allow"
Or go to Settings → Privacy and security → Site Settings → Notifications

Firefox
Click the shield icon 🛡️ in the address bar
Turn off "Enhanced Tracking Protection" for this site (if needed)
Allow notifications when prompted
Or go to Settings → Privacy & Security → Permissions → Notifications

Safari
Go to Safari → Settings → Websites → Notifications
Find your site and set it to "Allow"

System Settings​
macOS
System Preferences → Notifications & Focus
Find your browser and ensure notifications are enabled
Check "Allow notifications from websites" in browser settings

Windows
Settings → System → Notifications & actions
Ensure your browser can send notifications
Check browser notification settings

iOS
Settings → Notifications → [Your Browser]
Enable "Allow Notifications"
Also enable in browser settings

Android
Settings → Apps → [Your Browser] → Notifications
Enable notifications
Check browser notification permissions

Backend Integration Required​
The SendNotification.tsx component is sample codeSendNotification.tsx requires backend implementation:
Save subscription data when users subscribe (see TODO comments in code)
Delete subscription data when users unsubscribe
Implement /notification endpoint to send actual push notifications
Use web-push library or similar for server-side notification delivery

Customizing Notification Content​
To customize your push notification content, edit app/notification/route.ts and modify the title, message, icon, and other properties in the sendNotification call.
Modifying the App Icon & Splash Screen​
App Icons​
Replace the icon files in the public/icons/ directory with your custom icons:

icon-512x512.png - Main app icon (512×512px)
android-chrome-192x192.png - Android icon (192×192px)
apple-touch-icon.png - iOS home screen icon (180×180px)

Also update the favicon:

public/favicon.ico - Browser favicon
app/favicon.ico - Next.js app favicon

Splash Screen​
Splash screens are automatically generated from your app icon and theme colors defined in public/manifest.json. To customize:

Update the theme_color and background_color in public/manifest.json
Ensure your main icon (icon-512x512.png) represents your brand
Run npm run build to apply changes

tipUse tools like PWA Asset Generator to create all required icon sizes from a single source image.
Deploying to Vercel​
Using Vercel Dashboard​


Connect your repository:

Push your code to GitHub
Visit vercel.com and import your repository



Configure environment variables:

In your Vercel project dashboard, go to Settings → Environment Variables
Add the same variables from your .env.local:
NEXT_PUBLIC_THIRDWEB_CLIENT_IDWEB_PUSH_EMAILWEB_PUSH_PRIVATE_KEYNEXT_PUBLIC_WEB_PUSH_PUBLIC_KEY




Deploy: Vercel will automatically build and deploy your app


Update Thirdweb settings: In your Thirdweb dashboard, add your Vercel domain (e.g., your-app.vercel.app) to the allowed origins


tipPWA features (install prompts, offline support, push notifications) work automatically on HTTPS domains like Vercel deployments.
Using Vercel CLI​
Alternatively, deploy using the Vercel CLI:


Install Vercel CLI:
npm i -g vercel


Login to Vercel:
vercel login


Deploy:
vercel
Follow the prompts to configure your project.


Add environment variables:
vercel env add NEXT_PUBLIC_THIRDWEB_CLIENT_IDvercel env add WEB_PUSH_EMAILvercel env add WEB_PUSH_PRIVATE_KEYvercel env add NEXT_PUBLIC_WEB_PUSH_PUBLIC_KEY
Or you can go to the Vercel dashboard and add the environment variables there.


Redeploy with environment variables:
vercel --prod


Learn more​

Serwist: docs | guides
Thirdweb: docs | guides
Monad: supported tooling and infra

### Code Examples

```prism
git clone https://github.com/monad-developers/next-serwist-thirdweb.git
```

```prism
cd next-serwist-thirdweb
```

```prism
npm install
```

```prism
cp .env.example .env.local
```

```prism
# Thirdweb Configuration (Required)NEXT_PUBLIC_THIRDWEB_CLIENT_ID=your_thirdweb_client_id_here
# Web Push (Required)WEB_PUSH_EMAIL=user@example.comWEB_PUSH_PRIVATE_KEY=your_vapid_private_keyNEXT_PUBLIC_WEB_PUSH_PUBLIC_KEY=your_vapid_public_key
```

```prism
npx web-push generate-vapid-keys --json
```

```prism
npm run dev
```

```prism
npm run build && npm run start
```

```prism
next-serwist-thirdweb/├── app/│   ├── components/         # React components│   │   ├── InstallPWA.tsx  # PWA install prompt│   │   └── ...│   ├── ~offline/           # Offline page│   └── ...├── public/                 # Static assets└── ...
```

```prism
NEXT_PUBLIC_THIRDWEB_CLIENT_IDWEB_PUSH_EMAILWEB_PUSH_PRIVATE_KEYNEXT_PUBLIC_WEB_PUSH_PUBLIC_KEY
```

```prism
npm i -g vercel
```

```prism
vercel login
```

```prism
vercel
```

```prism
vercel env add NEXT_PUBLIC_THIRDWEB_CLIENT_IDvercel env add WEB_PUSH_EMAILvercel env add WEB_PUSH_PRIVATE_KEYvercel env add NEXT_PUBLIC_WEB_PUSH_PUBLIC_KEY
```

```prism
vercel --prod
```

---

## How to use the React Native Privy embedded wallet template

> Source: https://docs.monad.xyz/templates/react-native-privy-embedded-wallet

On this page

This guide walks you through using the wallet template which uses Expo, React Native, and Privy embedded wallet to build a mobile app on Monad.
Start developing by editing the files inside the app directory. This project uses file-based routing.
infoThis template also has a demo branch that you can switch to in order to view the demo project.You can switch using the following command:git checkout demo
Prerequisites​

Node.js
NPM
Expo CLI (Install using the following command: npm i -g expo-cli)
a Privy account

For Android
Android Studio (API version 35 and above)

Guide to setup Android Studio for Expo is available here



For iOS
XCode

Guide to setup iOS Simulator for Expo is available here



Setting up the Privy account
Create app:

Set up login methods:

Enable email:

Enable "Automatically create embedded wallets on login" and select "EVM Wallets":


Disable everything in Socials.


Go to "Advanced" and Make sure only "Web2: Email, SMS, and socials" under "Prioritize options displayed" is enabled:


Tip: You can enable "Test Accounts" for testing purposes:

A few more steps are required but we will continue once the dependencies for the project are installed.

Get started​
infoThis template also has a demo branch that you can switch to in order to view the demo project.You can switch using the following command:git checkout demo
Install dependencies​
npm install
Set up the environment variables​

Create a copy of .env.example

cp .env.example .env

Add the following environment variables to it

EXPO_PUBLIC_PRIVY_APP_ID=EXPO_PUBLIC_PRIVY_CLIENT_ID=
How to get EXPO_PUBLIC_PRIVY_APP_ID
Go to your Privy Dashboard and click on Home for your Privy app and click on Retrieve API keys.

You will find App ID under API keys.

How to get EXPO_PUBLIC_PRIVY_CLIENT_ID
Go to your Privy Dashboard and click on "Home" for your Privy app and click on Retrieve API keys.

Click on the Clients tab at the top and click on Edit.

Under Allowed app identifiers paste the name of the app bundle and click Add
You can find the app bundle name in app.json for Android it is package property and iOS it is the bundleIdentifier property
You can copy the Client ID and use as the value for EXPO_PUBLIC_PRIVY_CLIENT_ID.

Start the app​
The below commands will start the app in Expo Go app on respective devices.
For iOS:
npm run ios
For Android:
npm run android
For native app builds use the following commands
For iOS:
npx expo run:ios
For Android:
npx expo run:android
Folder structure of the template​
react-native-privy-embedded-wallet-template/  ├── app/                                   # Expo router entrypoint  │   ├── _layout.tsx                        # Root Layout  │   └── index.tsx                          # First screen  ├── assets/  │   ├── fonts/                             # Custom fonts go here  │   └── images/   │       ├── adaptive-icon.png  │       ├── favicon.png  │       ├── icon.png  │       ├── monad-logo-inverted.png  │       └── monad-logo.png  │   └── readme/                            # images for the readme, you can delete this  ├── constants/  │   └── Colors.ts  ├── app.json                               # App properties  ├── babel.config.js  ├── eas.json  ├── entrypoint.js  ├── eslint.config.js  ├── metro.config.js                        # Configuration for Hermes and Polyfills  ├── package-lock.json  ├── package.json  ├── README.md  ├── tsconfig.json  ├── types/  │   └── react-native-qrcode-styled.d.ts
Modifying the app name​
iOSAndroid
Edit the name property in the app.json file.
{   "expo": {      "name": "wallet-app", <--- Edit this      ...   }}  
Modifying the App Icon & Splash Screen​
App Icon​
iOSAndroid
You can edit the app icon by replacing the assets/images/icon.png file.
Recommended App Icon size is 1024x1024.
If you name the icon file something else then edit the icon property in app.json accordingly.
{   "expo": {      "name": "rn-wallet-app",      ...      "icon": "./assets/images/icon.png", <--- Change this      ...   }}
Splash Screen​
iOSAndroid
Edit the splash object in app.json to modify the splash screen.
{   "expo": {      "name": "rn-wallet-app",      ...      "splash": { <--- Edit this object         "image": "./assets/images/icon.png",         "backgroundColor": "#ffffff"      }   }  }
Modifying fonts for the app​
You can create a fonts folder inside assets folder and keep your custom font files in the fonts folder.
To use the custom font, load the font in the app/_layout.tsx file.
Example:
const [loaded] = useFonts({  "SF-Pro-Rounded-Black": require("../assets/fonts/SF_Pro_Rounded/SF-Pro-Rounded-Black.otf"),  "SF-Pro-Rounded-Bold": require("../assets/fonts/SF_Pro_Rounded/SF-Pro-Rounded-Bold.otf"),  "SF-Pro-Rounded-Heavy": require("../assets/fonts/SF_Pro_Rounded/SF-Pro-Rounded-Heavy.otf"),  "SF-Pro-Rounded-Medium": require("../assets/fonts/SF_Pro_Rounded/SF-Pro-Rounded-Medium.otf"),  "SF-Pro-Rounded-Regular": require("../assets/fonts/SF_Pro_Rounded/SF-Pro-Rounded-Regular.otf"),  "SF-Pro-Rounded-Semibold": require("../assets/fonts/SF_Pro_Rounded/SF-Pro-Rounded-Semibold.otf"),  Inter_400Regular,  Inter_500Medium,  Inter_600SemiBold,});
Modifying the deeplinking scheme​
Edit the scheme property in app.json file, for your custom deeplinking scheme.
{  "expo": {    ...    "scheme": "rnwalletapp",    ...  }}
For example, if you set this to rnwalletapp, then rnwalletapp:// URLs would open your app when tapped.
This is a build-time configuration, it has no effect in Expo Go.
Editing the landing screen​
iOSAndroid
You can edit the landing page by editing the code in the file app/index.tsx.
Wallet Actions​
The template has example code for the following Wallet Actions:

Send USDC
Sign Message

Modifying the package/bundle identifier​
When publishing app to the app store you need to have a unique package/bundle identifier you can change it in in app.json.
warningDon't forget to the change the identifier in Privy dashboard
{  "expo": {    "name": "rn-wallet-app",    ...    "ios": {      "bundleIdentifier": "com.anonymous.rn-wallet-app", <--- Edit this      ...    },    "android": {      ...      "package": "com.anonymous.rnwalletapp" <--- Edit this    },  }}
Check out the demo app​
If you want try the demo app before you start developing you can switch to the demo branch available with the repo:
git checkout demo
Folder structure of the demo project (Change to demo branch to view this)​
react-native-privy-embedded-wallet-template/  ├── app/  │   ├── _layout.tsx                        # Root layout of the project  │   ├── +not-found.tsx  │   ├── demo/                              # This is entrypoint for the Wallet related code.  │   │   ├── _layout.tsx  │   │   ├── app/                           # If Authenticated the user can access route /app  │   │   │   ├── _layout.tsx  │   │   │   └── index.tsx  │   │   └── sign-in/                       # Unauthenticated user gets redirected to /sign-in  │   └── index.tsx                          # This is the landing page  ├── assets/  │   ├── fonts/                             # Custom fonts go here  │   │   └── SF_Pro_Rounded/                # Custom Font example  │   └── images/  │       ├── adaptive-icon.png  │       ├── favicon.png  │       ├── icon.png  │       ├── monad-icon.png  │       ├── monad-logo-inverted.png  │       ├── monad-logo.png  │       ├── partial-react-logo.png  │       └── splash-icon.png  ├── components/  │   ├── sheets/                            # All the bottom sheets are here  │   └── ui/  ├── config/  │   ├── privyConfig.ts                     # Privy related config  │   ├── providers.tsx   │   └── wagmiConfig.ts                     # Monad Testnet related config  ├── constants/  ├── context/  │   ├── AuthContext.tsx  │   └── WalletContext.tsx                  # Wallet actions implementations are here  ├── hooks/  ├── screens/  │   ├── Email/                             # Screen that asks for Email  │   ├── Home/                              # Wallet Home screen (Authenticated users only)  │   ├── Landing/                           # Screen with info on how to use the template  │   └── OTP/                               # Screen that asks for the OTP code sent to email  ├── types/  ├── utils.ts  ├── entrypoint.ts  ├── app.json  ├── babel.config.js  ├── eas.json  ├── eslint.config.js  ├── metro.config.js  ├── package.json  ├── package-lock.json  ├── README.md  ├── tsconfig.json
Learn more​
To learn more about developing your project with Expo, Privy, and Monad, check out the following resources:

Expo docs | guides | tutorial
Privy: create a wallet | send a transaction | sign a transaction
Monad: supported tooling and infra

Please report any issues here.

### Code Examples

```prism
git checkout demo
```

```prism
git checkout demo
```

```prism
npm install
```

```prism
cp .env.example .env
```

```prism
EXPO_PUBLIC_PRIVY_APP_ID=EXPO_PUBLIC_PRIVY_CLIENT_ID=
```

```prism
npm run ios
```

```prism
npm run android
```

```prism
npx expo run:ios
```

```prism
npx expo run:android
```

```prism
react-native-privy-embedded-wallet-template/  ├── app/                                   # Expo router entrypoint  │   ├── _layout.tsx                        # Root Layout  │   └── index.tsx                          # First screen  ├── assets/  │   ├── fonts/                             # Custom fonts go here  │   └── images/   │       ├── adaptive-icon.png  │       ├── favicon.png  │       ├── icon.png  │       ├── monad-logo-inverted.png  │       └── monad-logo.png  │   └── readme/                            # images for the readme, you can delete this  ├── constants/  │   └── Colors.ts  ├── app.json                               # App properties  ├── babel.config.js  ├── eas.json  ├── entrypoint.js  ├── eslint.config.js  ├── metro.config.js                        # Configuration for Hermes and Polyfills  ├── package-lock.json  ├── package.json  ├── README.md  ├── tsconfig.json  ├── types/  │   └── react-native-qrcode-styled.d.ts
```

```prism
{   "expo": {      "name": "wallet-app", <--- Edit this      ...   }}
```

```prism
{   "expo": {      "name": "rn-wallet-app",      ...      "icon": "./assets/images/icon.png", <--- Change this      ...   }}
```

```prism
{   "expo": {      "name": "rn-wallet-app",      ...      "splash": { <--- Edit this object         "image": "./assets/images/icon.png",         "backgroundColor": "#ffffff"      }   }  }
```

```prism
const [loaded] = useFonts({  "SF-Pro-Rounded-Black": require("../assets/fonts/SF_Pro_Rounded/SF-Pro-Rounded-Black.otf"),  "SF-Pro-Rounded-Bold": require("../assets/fonts/SF_Pro_Rounded/SF-Pro-Rounded-Bold.otf"),  "SF-Pro-Rounded-Heavy": require("../assets/fonts/SF_Pro_Rounded/SF-Pro-Rounded-Heavy.otf"),  "SF-Pro-Rounded-Medium": require("../assets/fonts/SF_Pro_Rounded/SF-Pro-Rounded-Medium.otf"),  "SF-Pro-Rounded-Regular": require("../assets/fonts/SF_Pro_Rounded/SF-Pro-Rounded-Regular.otf"),  "SF-Pro-Rounded-Semibold": require("../assets/fonts/SF_Pro_Rounded/SF-Pro-Rounded-Semibold.otf"),  Inter_400Regular,  Inter_500Medium,  Inter_600SemiBold,});
```

```prism
{  "expo": {    ...    "scheme": "rnwalletapp",    ...  }}
```

```prism
{  "expo": {    "name": "rn-wallet-app",    ...    "ios": {      "bundleIdentifier": "com.anonymous.rn-wallet-app", <--- Edit this      ...    },    "android": {      ...      "package": "com.anonymous.rnwalletapp" <--- Edit this    },  }}
```

```prism
git checkout demo
```

```prism
react-native-privy-embedded-wallet-template/  ├── app/  │   ├── _layout.tsx                        # Root layout of the project  │   ├── +not-found.tsx  │   ├── demo/                              # This is entrypoint for the Wallet related code.  │   │   ├── _layout.tsx  │   │   ├── app/                           # If Authenticated the user can access route /app  │   │   │   ├── _layout.tsx  │   │   │   └── index.tsx  │   │   └── sign-in/                       # Unauthenticated user gets redirected to /sign-in  │   └── index.tsx                          # This is the landing page  ├── assets/  │   ├── fonts/                             # Custom fonts go here  │   │   └── SF_Pro_Rounded/                # Custom Font example  │   └── images/  │       ├── adaptive-icon.png  │       ├── favicon.png  │       ├── icon.png  │       ├── monad-icon.png  │       ├── monad-logo-inverted.png  │       ├── monad-logo.png  │       ├── partial-react-logo.png  │       └── splash-icon.png  ├── components/  │   ├── sheets/                            # All the bottom sheets are here  │   └── ui/  ├── config/  │   ├── privyConfig.ts                     # Privy related config  │   ├── providers.tsx   │   └── wagmiConfig.ts                     # Monad Testnet related config  ├── constants/  ├── context/  │   ├── AuthContext.tsx  │   └── WalletContext.tsx                  # Wallet actions implementations are here  ├── hooks/  ├── screens/  │   ├── Email/                             # Screen that asks for Email  │   ├── Home/                              # Wallet Home screen (Authenticated users only)  │   ├── Landing/                           # Screen with info on how to use the template  │   └── OTP/                               # Screen that asks for the OTP code sent to email  ├── types/  ├── utils.ts  ├── entrypoint.ts  ├── app.json  ├── babel.config.js  ├── eas.json  ├── eslint.config.js  ├── metro.config.js  ├── package.json  ├── package-lock.json  ├── README.md  ├── tsconfig.json
```

---

## How to use the React Native sponsored transactions template

> Source: https://docs.monad.xyz/templates/react-native-privy-pimlico-sponsored-transactions

On this page

Sponsored transactions enable users to interact with blockchain applications without needing to pay gas fees themselves, improving accessibility, user experience, and onboarding - especially for newcomers unfamiliar with crypto.
This guide walks you through using the sponsored transactions template which uses Expo, React Native, Privy embedded wallet and Pimlico paymaster to build a mobile app with sponsored transactions on Monad.
You can start developing by editing the files inside the app directory. This project uses file-based routing.
infoThis repo also has a demo branch that you can switch to if you'd like to inspect a completed version of the app first.
Prerequisites​

Node.js
NPM
a Privy account
a Pimlico account

For Android
Android Studio (API version 35 and above)

Guide to setup Android Studio for Expo is available here



For iOS
XCode

Guide to setup iOS Simulator for Expo is available here



Setting up the Privy account
Create app:

Set up login methods:

Enable email:

Enable "Automatically create embedded wallets on login" and select "EVM Wallets":


Disable everything in Socials.


Go to "Advanced" and Make sure only "Web2: Email, SMS, and socials" under "Prioritize options displayed" is enabled:

tipYou can enable "Test Accounts" for testing purposesA few more steps are required but we will continue once the dependencies for the project are installed.
Get started​
infoThis template also has a demo branch that you can switch to in order to view the demo project.You can switch using the following command:git checkout demo
Install dependencies​
npm install
Set up the environment variables​


Create a copy of .env.example:
cp .env.example .env


Add the following environment variables to it
EXPO_PUBLIC_PRIVY_APP_ID=EXPO_PUBLIC_PRIVY_CLIENT_ID=EXPO_PUBLIC_PIMLICO_BUNDLER_URL=


How to get EXPO_PUBLIC_PRIVY_APP_ID
Go to your Privy Dashboard and click on Home for your Privy app and click on Retrieve API keys.

You will find App ID under API keys.

How to get EXPO_PUBLIC_PRIVY_CLIENT_ID
Go to your Privy Dashboard, click Home for your Privy app, and click Retrieve API keys.

Click on the Clients tab at the top, then click Edit.

Under Allowed app identifiers, paste the name of the app bundle and click Add.
You will find the app bundle name in app.json. For Android, it is the package property. For iOS, it is the bundleIdentifier property.
Copy the Client ID and use it as the value for EXPO_PUBLIC_PRIVY_CLIENT_ID.

How to get EXPO_PUBLIC_PIMLICO_BUNDLER_URL
Sign up on Pimlico and go to "API Keys":

Create a new API key:

Click on "RPC URLs":

Search for Monad Testnet and copy the URL. Use this as EXPO_PUBLIC_PIMLICO_BUNDLER_URL:

Start the app​
Start the app either in the Expo Go app, or natively.
In the Expo Go app:


For iOS:
npm run ios


For Android:
npm run android


As a native app build:


For iOS:
npx expo run:ios


For Android:
npx expo run:android


Template folder structure​
react-native-privy-pimlico-gas-sponsorship-template/  ├── app/                                   # Expo router entrypoint  │   ├── _layout.tsx                        # Root layout  │   └── index.tsx                          # First screen  ├── assets/  │   ├── images/   │   │   ├── adaptive-icon.png  │   │   ├── favicon.png  │   │   ├── icon.png  │   │   ├── monad-logo-inverted.png  │   │   └── monad-logo.png  │   └── readme/                              ├── constants/  │   └── Colors.ts  ├── hooks/  │   └── useSmartWallet.tsx                 # Smart wallet utilities  ├── screens/  │   └── Home.tsx                           # Start here  ├── types/  │   └── react-native-qrcode-styled.d.ts  ├── app.json                               # App properties  ├── babel.config.js  ├── eas.json  ├── entrypoint.js  ├── eslint.config.js  ├── metro.config.js                        # Configuration for Hermes and Polyfills  ├── package-lock.json  ├── package.json  ├── README.md  └── tsconfig.json
Send sponsored transactions​
Below is an example of how to use the useSmartWallet hook to send sponsored transactions. You can either modify the code to send your own transactions or integrate it into your existing project.
...
// Use `useSmartWallets` hookconst { smartAccountAddress, smartAccountClient, smartAccountReady } = useSmartWallet();
...
// Send sponsored transactionconst txHash = await smartAccountClient?.sendTransaction({  account: smartAccountClient?.account,  chain: monadTestnet,  to: NFT_CONTRACT_ADDRESS,  data,});
...
Send batch sponsored transactions​
You can also send batches of sponsored transactions:
const txHash = await smartAccountClient?.sendTransaction({  calls: [    {      to: NFT_CONTRACT_ADDRESS,      data,    },    {      to: NFT_CONTRACT_ADDRESS,      data,    },  ],});
This example uses the Kernel smart account with Entrypoint v7. See useSmartWallet.tsx to inspect the implementation details.
Modify the app name​
iOSAndroid
Edit the name property in app.json:
app.json{   "expo": {      "name": "wallet-app", <--- Edit this      ...   }}  
Modify the app icon and splash screen​
App icon​
iOSAndroid
You can edit the app icon by replacing assets/images/icon.png.
Recommended app icon size is 1024x1024.
If you name the icon file something else, then edit the icon property in app.json accordingly.
app.json{   "expo": {      "name": "rn-wallet-app",      ...      "icon": "./assets/images/icon.png", <--- Change this      ...   }}
Splash screen​
iOSAndroid
Edit the splash object in app.json to modify the splash screen.
app.json{   "expo": {      "name": "rn-gas-sponsorship-app",      ...      "splash": { <--- Edit this object         "image": "./assets/images/icon.png",         "backgroundColor": "#ffffff"      }   }  }
Change fonts​
You can create a fonts folder inside assets to store your custom font files.
To use the custom font, load the font in app/_layout.tsx.
Example:
_layout.tsxappconst [loaded] = useFonts({  "SF-Pro-Rounded-Black": require("../assets/fonts/SF_Pro_Rounded/SF-Pro-Rounded-Black.otf"),  "SF-Pro-Rounded-Bold": require("../assets/fonts/SF_Pro_Rounded/SF-Pro-Rounded-Bold.otf"),  "SF-Pro-Rounded-Heavy": require("../assets/fonts/SF_Pro_Rounded/SF-Pro-Rounded-Heavy.otf"),  "SF-Pro-Rounded-Medium": require("../assets/fonts/SF_Pro_Rounded/SF-Pro-Rounded-Medium.otf"),  "SF-Pro-Rounded-Regular": require("../assets/fonts/SF_Pro_Rounded/SF-Pro-Rounded-Regular.otf"),  "SF-Pro-Rounded-Semibold": require("../assets/fonts/SF_Pro_Rounded/SF-Pro-Rounded-Semibold.otf"),  Inter_400Regular,  Inter_500Medium,  Inter_600SemiBold,});
Modify the deeplinking scheme​
Edit the scheme property in app.json to select your custom deeplinking scheme:
app.json{  "expo": {    ...    "scheme": "rnwalletapp",    ...  }}
For example, if you set this to rnwalletapp, then rnwalletapp:// URLs would open your app when tapped.
This is a build-time configuration; it has no effect in Expo Go.
Edit the landing screen​
You can edit the landing page by editing screens/Home.tsx.
In the demo branch, we ended up adding more complex functionality, which is why Home.tsx became a folder.
Modify the package/bundle identifier​
When publishing app to the app store, you need to have a unique package/bundle identifier, which you may set in app.json.
warningDon't forget to change the identifier in Privy dashboard
app.json{  "expo": {    "name": "rn-gas-sponsorship-app",    ...    "ios": {      "bundleIdentifier": "com.anonymous.rn-wallet-app", <--- Edit this      ...    },    "android": {      ...      "package": "com.anonymous.rnwalletapp" <--- Edit this    },  }}
Check out the demo app​
If you'd like to try a completed version of the app before you start developing, switch to the demo branch:
git checkout demo
Demo app folder structure​
react-native-privy-pimlico-gas-sponsorship-template/  ├── app/  │   ├── _layout.tsx                        # Root layout of the project  │   └── index.tsx                          # This is the landing page  │   └── sign-in/                           # Unauthenticated user gets redirected to /sign-in  ├── assets/  │   ├── fonts/                             # Custom fonts go here  │   │   └── SF_Pro_Rounded/                # Custom font example  │   └── images/  │       ├── adaptive-icon.png  │       ├── favicon.png  │       ├── icon.png  │       ├── monad-icon.png  │       ├── monad-logo-inverted.png  │       ├── monad-logo.png  │       ├── partial-react-logo.png  │       └── splash-icon.png  ├── components/  │   └── ui/  ├── constants/  │   ├── abi.json                           # NFT smart contract ABI  ├── context/  │   ├── AuthContext.tsx  ├── hooks/  │   ├── useSmartWallet.tsx                 # Hook with smart wallet related functions  ├── screens/  │   ├── Email/                             # Screen that asks for email  │   ├── Home/                              # NFT minting screen (Authenticated users only)  │   └── OTP/                               # Screen that asks for the OTP code sent to email  ├── types/  ├── utils.ts  ├── entrypoint.js  ├── app.json  ├── babel.config.js  ├── eas.json  ├── eslint.config.js  ├── metro.config.js  ├── package.json  ├── package-lock.json  ├── README.md  ├── tsconfig.json
Learn more​
To learn more about developing your project with Expo, Privy, and Monad, check out the following resources:

Expo docs | guides | tutorial
Privy: create a wallet | send a transaction | sign a transaction
Permissionless: smart wallet client | sending transactions
Monad: supported tooling and infra

Please report any issues here.

### Code Examples

```prism
git checkout demo
```

```prism
npm install
```

```prism
cp .env.example .env
```

```prism
EXPO_PUBLIC_PRIVY_APP_ID=EXPO_PUBLIC_PRIVY_CLIENT_ID=EXPO_PUBLIC_PIMLICO_BUNDLER_URL=
```

```prism
npm run ios
```

```prism
npm run android
```

```prism
npx expo run:ios
```

```prism
npx expo run:android
```

```prism
react-native-privy-pimlico-gas-sponsorship-template/  ├── app/                                   # Expo router entrypoint  │   ├── _layout.tsx                        # Root layout  │   └── index.tsx                          # First screen  ├── assets/  │   ├── images/   │   │   ├── adaptive-icon.png  │   │   ├── favicon.png  │   │   ├── icon.png  │   │   ├── monad-logo-inverted.png  │   │   └── monad-logo.png  │   └── readme/                              ├── constants/  │   └── Colors.ts  ├── hooks/  │   └── useSmartWallet.tsx                 # Smart wallet utilities  ├── screens/  │   └── Home.tsx                           # Start here  ├── types/  │   └── react-native-qrcode-styled.d.ts  ├── app.json                               # App properties  ├── babel.config.js  ├── eas.json  ├── entrypoint.js  ├── eslint.config.js  ├── metro.config.js                        # Configuration for Hermes and Polyfills  ├── package-lock.json  ├── package.json  ├── README.md  └── tsconfig.json
```

```prism
...
// Use `useSmartWallets` hookconst { smartAccountAddress, smartAccountClient, smartAccountReady } = useSmartWallet();
...
// Send sponsored transactionconst txHash = await smartAccountClient?.sendTransaction({  account: smartAccountClient?.account,  chain: monadTestnet,  to: NFT_CONTRACT_ADDRESS,  data,});
...
```

```prism
const txHash = await smartAccountClient?.sendTransaction({  calls: [    {      to: NFT_CONTRACT_ADDRESS,      data,    },    {      to: NFT_CONTRACT_ADDRESS,      data,    },  ],});
```

```prism
{   "expo": {      "name": "wallet-app", <--- Edit this      ...   }}
```

```prism
{   "expo": {      "name": "rn-wallet-app",      ...      "icon": "./assets/images/icon.png", <--- Change this      ...   }}
```

```prism
{   "expo": {      "name": "rn-gas-sponsorship-app",      ...      "splash": { <--- Edit this object         "image": "./assets/images/icon.png",         "backgroundColor": "#ffffff"      }   }  }
```

```prism
const [loaded] = useFonts({  "SF-Pro-Rounded-Black": require("../assets/fonts/SF_Pro_Rounded/SF-Pro-Rounded-Black.otf"),  "SF-Pro-Rounded-Bold": require("../assets/fonts/SF_Pro_Rounded/SF-Pro-Rounded-Bold.otf"),  "SF-Pro-Rounded-Heavy": require("../assets/fonts/SF_Pro_Rounded/SF-Pro-Rounded-Heavy.otf"),  "SF-Pro-Rounded-Medium": require("../assets/fonts/SF_Pro_Rounded/SF-Pro-Rounded-Medium.otf"),  "SF-Pro-Rounded-Regular": require("../assets/fonts/SF_Pro_Rounded/SF-Pro-Rounded-Regular.otf"),  "SF-Pro-Rounded-Semibold": require("../assets/fonts/SF_Pro_Rounded/SF-Pro-Rounded-Semibold.otf"),  Inter_400Regular,  Inter_500Medium,  Inter_600SemiBold,});
```

```prism
{  "expo": {    ...    "scheme": "rnwalletapp",    ...  }}
```

```prism
{  "expo": {    "name": "rn-gas-sponsorship-app",    ...    "ios": {      "bundleIdentifier": "com.anonymous.rn-wallet-app", <--- Edit this      ...    },    "android": {      ...      "package": "com.anonymous.rnwalletapp" <--- Edit this    },  }}
```

```prism
git checkout demo
```

```prism
react-native-privy-pimlico-gas-sponsorship-template/  ├── app/  │   ├── _layout.tsx                        # Root layout of the project  │   └── index.tsx                          # This is the landing page  │   └── sign-in/                           # Unauthenticated user gets redirected to /sign-in  ├── assets/  │   ├── fonts/                             # Custom fonts go here  │   │   └── SF_Pro_Rounded/                # Custom font example  │   └── images/  │       ├── adaptive-icon.png  │       ├── favicon.png  │       ├── icon.png  │       ├── monad-icon.png  │       ├── monad-logo-inverted.png  │       ├── monad-logo.png  │       ├── partial-react-logo.png  │       └── splash-icon.png  ├── components/  │   └── ui/  ├── constants/  │   ├── abi.json                           # NFT smart contract ABI  ├── context/  │   ├── AuthContext.tsx  ├── hooks/  │   ├── useSmartWallet.tsx                 # Hook with smart wallet related functions  ├── screens/  │   ├── Email/                             # Screen that asks for email  │   ├── Home/                              # NFT minting screen (Authenticated users only)  │   └── OTP/                               # Screen that asks for the OTP code sent to email  ├── types/  ├── utils.ts  ├── entrypoint.js  ├── app.json  ├── babel.config.js  ├── eas.json  ├── eslint.config.js  ├── metro.config.js  ├── package.json  ├── package-lock.json  ├── README.md  ├── tsconfig.json
```

---

## How to use the React Native Thirdweb embedded wallet template

> Source: https://docs.monad.xyz/templates/react-native-thirdweb-embedded-wallet

On this page

This guide walks you through using the embedded wallet template which uses Expo, React Native, and Thirdweb embedded wallet to build a mobile app on Monad.
Start developing by editing the files inside the app directory. This project uses file-based routing.
Prerequisites​

Node.js
Yarn or NPM
a thirdweb account

For Android
JDK 17 (Java Development Kit version 17)

Set the JAVA_HOME environment variable to point to your JDK 17 installation
Example: export JAVA_HOME=/Library/Java/JavaVirtualMachines/microsoft-17.jdk/Contents/Home


Android Studio (API version 35 and above)

See this guide to set up Android Studio for Expo
Configure Gradle JDK in Android Studio:

Open Android Studio Settings/Preferences
Navigate to Build, Execution, Deployment → Build Tools → Gradle
Set Gradle JDK to JDK 17 (e.g., JAVA_HOME 17.0.13 - aarch64 /Library/Java/JavaVirtualMachines/microsoft-17.jdk/Contents/Home)





For iOS
Xcode (Xcode 16 requires OpenSSL version 3.3.2000)

See this guide to set up iOS Simulator for Expo



Get started​
Install dependencies​
yarn install
Set up the environment variables​
Create a copy of .env.example:
cp .env.example .env
Add your thirdweb client ID to the .env file:
EXPO_PUBLIC_THIRDWEB_CLIENT_ID=your_client_id_here
How to get EXPO_PUBLIC_THIRDWEB_CLIENT_ID
Navigate to thirdweb dashboard
Sign in or create a new account
Create a new project

Copy your Client ID from the project settings; Client ID is the value for EXPO_PUBLIC_THIRDWEB_CLIENT_ID.

Start the app​
noteThis template comes with a simple transfer example screen, which you can edit by editing the index.tsx file in the app folder.
Prebuild for native modules​
noteThe thirdweb SDK uses native modules, which means it cannot run on Expo Go. You must build the iOS and Android apps to link the native modules.npx expo prebuild
For iOS:
yarn ios
For Android:
yarn android
Folder structure of the template​
expo-thirdweb-example/  ├── app/                                   # Expo router entrypoint   │   ├── +html.tsx                          # Web HTML configuration  │   ├── +native-intent.tsx                 # Deep link handling  │   ├── +not-found.tsx                     # 404 page  │   ├── _layout.tsx                        # Root layout with ThirdwebProvider  │   └── index.tsx                          # Main screen  ├── assets/  │   ├── fonts/                             # Custom fonts  │   └── images/                            # App images and icons  │       ├── adaptive-icon.png  │       ├── icon.png  │       ├── monad-logo.png  │       └── splash.png  ├── components/                            # Reusable UI components  │   ├── ThemedButton.tsx                   # Themed button component  │   ├── ThemedText.tsx                     # Themed text component  │   ├── ThemedView.tsx                     # Themed view component  │   ├── SocialProfileCard.tsx              # Social profile display  │   └── navigation/  │       └── TabBarIcon.tsx                 # Tab bar icons  ├── constants/  │   ├── Colors.ts                          # App color scheme  │   └── thirdweb.ts                        # Blockchain configuration  ├── hooks/                                 # Custom React hooks  │   ├── useColorScheme.ts                  # Theme detection  │   └── useThemeColor.ts                   # Theme color utilities  ├── app.json                               # Expo app configuration  ├── babel.config.js  ├── metro.config.js                        # Metro bundler config  ├── package.json  ├── tsconfig.json  └── yarn.lock
Customizing your app​
Modifying the app name​
Edit the name property in the app.json file:
{   "expo": {      "name": "your-app-name", // ← Edit this      ...   }}  
Modifying the app icon​
You can edit the app icon by replacing the assets/images/icon.png file.
Recommended App Icon size is 1024x1024.
If you name the icon file something else, edit the icon property in app.json accordingly:
{   "expo": {      "name": "your-app-name",      ...      "icon": "./assets/images/icon.png", // ← Change this      ...   }}
Modifying the splash screen​
Edit the splash object in app.json to modify the splash screen:
{   "expo": {      "name": "your-app-name",      ...      "splash": { // ← Edit this object         "image": "./assets/images/splash.png",         "backgroundColor": "#ffffff"      }   }  }
Modifying the deep linking scheme​
Edit the scheme property in app.json file for your custom deep linking scheme:
{  "expo": {    ...    "scheme": "your-app-scheme",    ...  }}
For example, if you set this to mywalletapp, then mywalletapp:// URLs would open your app when tapped.
This is a build-time configuration and has no effect in Expo Go.
Modifying the package/bundleIdentifier​
When publishing to the app store, you need a unique package/bundleIdentifier. Change it in app.json:
{  "expo": {    "name": "your-app-name",    ...    "ios": {      "bundleIdentifier": "com.yourcompany.yourapp", // ← Edit this      ...    },    "android": {      ...      "package": "com.yourcompany.yourapp" // ← Edit this    },  }}
notethirdweb Bundle ID Configuration: Your bundleIdentifier and package must match the Bundle ID Restrictions configured in your thirdweb project settings.
Go to the thirdweb dashboard
Select your project
Navigate to Settings → Bundle ID Restrictions
Add your iOS bundleIdentifier and Android package to the allowed bundle IDs
This ensures your app can properly authenticate with thirdweb services.
Learn More​
To learn more about developing your project with Expo, thirdweb, and Monad, look at the following resources:

Expo: documentation | guides | tutorial
thirdweb: documentation | templates | YouTube
Monad: supported tooling and infra

Join the Community​
Chat with fellow Monad developers and ask questions in Monad Developer Discord

### Code Examples

```prism
yarn install
```

```prism
cp .env.example .env
```

```prism
EXPO_PUBLIC_THIRDWEB_CLIENT_ID=your_client_id_here
```

```prism
npx expo prebuild
```

```prism
yarn ios
```

```prism
yarn android
```

```prism
expo-thirdweb-example/  ├── app/                                   # Expo router entrypoint   │   ├── +html.tsx                          # Web HTML configuration  │   ├── +native-intent.tsx                 # Deep link handling  │   ├── +not-found.tsx                     # 404 page  │   ├── _layout.tsx                        # Root layout with ThirdwebProvider  │   └── index.tsx                          # Main screen  ├── assets/  │   ├── fonts/                             # Custom fonts  │   └── images/                            # App images and icons  │       ├── adaptive-icon.png  │       ├── icon.png  │       ├── monad-logo.png  │       └── splash.png  ├── components/                            # Reusable UI components  │   ├── ThemedButton.tsx                   # Themed button component  │   ├── ThemedText.tsx                     # Themed text component  │   ├── ThemedView.tsx                     # Themed view component  │   ├── SocialProfileCard.tsx              # Social profile display  │   └── navigation/  │       └── TabBarIcon.tsx                 # Tab bar icons  ├── constants/  │   ├── Colors.ts                          # App color scheme  │   └── thirdweb.ts                        # Blockchain configuration  ├── hooks/                                 # Custom React hooks  │   ├── useColorScheme.ts                  # Theme detection  │   └── useThemeColor.ts                   # Theme color utilities  ├── app.json                               # Expo app configuration  ├── babel.config.js  ├── metro.config.js                        # Metro bundler config  ├── package.json  ├── tsconfig.json  └── yarn.lock
```

```prism
{   "expo": {      "name": "your-app-name", // ← Edit this      ...   }}
```

```prism
{   "expo": {      "name": "your-app-name",      ...      "icon": "./assets/images/icon.png", // ← Change this      ...   }}
```

```prism
{   "expo": {      "name": "your-app-name",      ...      "splash": { // ← Edit this object         "image": "./assets/images/splash.png",         "backgroundColor": "#ffffff"      }   }  }
```

```prism
{  "expo": {    ...    "scheme": "your-app-scheme",    ...  }}
```

```prism
{  "expo": {    "name": "your-app-name",    ...    "ios": {      "bundleIdentifier": "com.yourcompany.yourapp", // ← Edit this      ...    },    "android": {      ...      "package": "com.yourcompany.yourapp" // ← Edit this    },  }}
```

---



# Section: tooling-and-infra

---

## Account Abstraction Providers

> Source: https://docs.monad.xyz/tooling-and-infra/wallet-infra/account-abstraction

On this page

Account Abstraction Providers provide bundler and paymaster services, enabling features like
sponsored transactions or payment via custom tokens.
Definitions​
ServiceDescriptionBundlerOperates a custom mempool for UserOperations; simulates and assembles bundles of UserOperationsPaymasterEnables sponsored transactions; enables users to pay for gas with a custom token
Provider Summary​
MainnetTestnetProviderStatusDocsSupported servicesHow to get startedAlchemy✅DocsGas Manager (aka Paymaster)
BundlerDashboardBiconomy✅DocsMEEGetting startedFastLane❓DocsPaymaster and BundlerDashboardOpenfort✅DocsPaymaster and BundlerQuickstartPimlico✅DocsPaymaster
BundlerTutorialSequence✅DocsRelayer: gasless, batched, parallelized transactionsQuickstartthirdweb✅DocsPaymaster and BundlerQuickstartZeroDev✅DocsMeta AA infrastructure for bundlers and paymastersDashboard✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't supportProviderStatusDocsSupported servicesHow to get startedAlchemy✅DocsGas Manager (aka Paymaster)
BundlerDashboardBiconomy✅DocsMEEGetting startedFastLane✅DocsPaymaster and BundlerDashboardGelato✅DocsPaymaster and BundlerQuickstartOpenfort✅DocsPaymaster and BundlerQuickstartPimlico✅DocsPaymaster
BundlerTutorialSequence✅DocsRelayer: gasless, batched, parallelized transactionsQuickstartthirdweb✅DocsPaymaster and BundlerQuickstartZeroDev✅DocsMeta AA infrastructure for bundlers and paymastersDashboard✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't support
Provider Details​
Alchemy​
Alchemy powers the #1 most used smart accounts today with account abstraction that eliminates gas fees and signing for users. Their accounts support ERC-4337, EIP-7702, and ERC-6900, a modular account standard co-authored with the Ethereum Foundation, Circle, and Trust Wallet.
To get started, sign up for an Alchemy account, visit the documentation, follow the quickstart guide. To learn more, check out their smart wallets and demo here.
Biconomy​
Biconomy is the most comprehensive smart account and execution infrastructure platform that enables seamless, user-friendly experiences across single or multiple chains. With Biconomy, developers can build superior onchain UX through gas abstraction, sessions, batching, and one-click signatures for complex actions on any number of networks.
To get started, visit the documentation.
FastLane​
FastLane is an MEV protocol for validators + apps with an integrated 4337 bundler, an on-chain task scheduler, and the first holistic LST.
To get started, vist the shMonad Documentation or try the shMonad bundler using the following example project.
Gelato​
Gelato provides Paymaster and Bundler services that enable sponsored transactions and Account Abstraction, allowing you to cover gas costs on behalf of users and enable seamless onchain experiences.
To get started, visit the documentation or follow the quickstart guide.
Openfort​
Openfort is a developer platform that helps projects onboard and and activates wallets. It does so by creating wallets with it’s SSS and passkeys,sending transactions via sponsored paymasters and session keys or directly using backend wallets for automated onchain actions.
To get started, visit the documentation or follow the quickstart guide.
Pimlico​
Pimlico is the world's most advanced ERC-4337 account abstraction infrastructure platform. Pimlico provides a suite of tools and services to help you build, deploy, and manage smart accounts on Ethereum and other EVM-compatible chains.
To get started, visit the documentation or follow the quickstart guide.
Sequence​
The Sequence
Transaction API is a unified
relayer that dispatches transactions on EVM chains with:

Gas sponsorship
Fee abstraction
Batching
Parallel processing

It manages nonces, estimates optimal gas, and resubmits transactions when needed, so you can focus
on your business logic. Sequence Builder offers a Gas Sponsorship feature
that allows project owners to easily sponsor gas for their users in web3 apps. By covering
transaction fees, users can enjoy a seamless experience without worrying about obtaining crypto
for fees which is seamlessly integrated with our suite of smart contract wallets.
To get started, visit the gas sponsorship docs.
thirdweb​
thirdweb offers a complete platform to leverage account abstraction.
Remove the clunky user experience of requiring gas & signatures for every onchain action:

Abstract away gas
Pre-audited account factory contracts
Built-in infra:
Sponsorship policies

To get started:

Sign up for a free thirdweb account
Visit Account Abstraction Documentation and Account Abstraction Playground

Zerodev​
ZeroDev is the most powerful smart account development platform. With ZeroDev, you can build Web3 experiences without gas, confirmations, seed phrases, and bridging.
To get started, visit the documentation or follow the quickstart guide.

---

## Analytics

> Source: https://docs.monad.xyz/tooling-and-infra/analytics

On this page

Provider Summary​
MainnetTestnetServiceStatusDocsDescriptionBubblemaps✅DocsVisual analytics platform to investigate wallets, trace funds, and map token activity in real timeCoinGecko✅DocsComprehensive crypto price & market data provider with on-chain DEX data, token discovery, and trading analyticsDeBank✅DocsDeFi portfolio tracker and analytics platformDeFiLlama✅DocsOpen-source DeFi TVL and analytics platform aggregating data from thousands of protocols across multiple chains. See How to list a DeFi projectDune✅DocsDatasets and dashboards about on-chain activityFlipside✅DocsAI-powered analytics for on-chain activityInsightX✅DocsWeb3 transparency and security platform combining smart contract scanning with real-time holder maps for on-chain tradingNansen✅DocsBlockchain analytics platform providing wallet profiling, smart money tracking, and on-chain insightsPhalcon Explorer by Blocksec✅DocsExplorer for understanding transaction details with fund flow, balance changes, invocation flow, gas usage, and moreTenderly✅DocsComprehensive toolkit including virtual testnets, explorer, debugger, transaction simulator, and monitoring✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't supportServiceStatusDocsDescriptionCoinGecko✅DocsComprehensive crypto price & market data provider with on-chain DEX data, token discovery, and trading analyticsDune✅DocsDatasets and dashboards about on-chain activityFlipside✅DocsAI-powered analytics for on-chain activityNansen❓DocsBlockchain analytics platform providing wallet profiling, smart money tracking, and on-chain insightsPhalcon✅DocsExplorer for understanding transaction details with fund flow, balance changes, invocation flow, gas usage, and more✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't support
Provider Details​
Bubblemaps​
Bubblemaps is a visual analytics platform to investigate wallets,
trace funds, and map token activity in real time across all chains.
To get started, check out the docs or launch the
app.
CoinGecko​
CoinGecko API is one of the most comprehensive and reliable crypto price & market data providers, serving on-chain DEX data across 250+ blockchain networks. CoinGecko provides real-time token prices, market statistics, trading data, OHLCV charts, and token discovery tools including trending pools, new pools, and advanced filtering capabilities.
To get started, visit the documentation for full details, or sign up for a free API key.
DeBank​
DeBank is a DeFi portfolio tracker and analytics platform that helps users manage their crypto assets across multiple chains. It provides comprehensive portfolio tracking, transaction history, and protocol analytics.
To get started, check out the DeBank documentation
DeFiLlama​
DeFiLlama is the largest open-source Total Value Locked (TVL) and DeFi analytics platform. It aggregates data from thousands of DeFi protocols across multiple chains, providing comprehensive insights into protocol TVL, token prices, yields, and DeFi trends. DeFiLlama offers both a user-friendly dashboard and a robust API for developers.
To get started, visit the DeFiLlama platform or check out the API documentation.
Dune​
Dune is a blockchain analytics platform that empowers users to query, visualize, and share on-chain data across dozens of blockchains. It uses SQL as its primary query language, enabling analysts, developers, and researchers to build custom dashboards and explore everything from DeFi protocols to NFT markets. With a large library of community-created dashboards and visualizations, Dune fosters collaboration and open access to blockchain intelligence, while also offering premium features such as faster queries and private dashboards for professional teams.
To get started, check out the Dune documentation
Flipside​
Flipside generates the most reliable and comprehensive blockchain data. All for free.
To get started, check out the Flipside documentation.
InsightX​
InsightX delivers actionable transparency and security insights across multiple chains, enabling traders to rapidly assess the risk and potential of on-chain assets in real time.
To get started, check out the docs or launch the app.
Nansen​
Nansen is a blockchain analytics platform that combines on-chain data with millions of wallet labels to provide actionable insights. It offers features like smart money tracking, wallet profiling, token analytics, and real-time alerts to help users discover opportunities and understand blockchain activity.
To get started, visit the Nansen platform or check out the Nansen documentation.
Phalcon​
Blocksec Phalcon Explorer is a powerful transaction explorer designed for the DeFi community. It provides comprehensive data on invocation flow, source code, balance changes, transaction fund flows, gas profiler, and state changes. It also supports transaction debugging and transaction simulation. This tool aims to help developers, security researchers, and traders intuitively understand transactions.
To get started, check out the explorer or the Phalcon documentation.
Tenderly​
Tenderly is a comprehensive toolkit for smart contract developers. The
platform offers features like real-time transaction monitoring, advanced debugging with detailed
stack traces, gas profiling, smart contract verification, and simulation environments that allow
developers to fork mainnets and test contract interactions without deploying to live networks.
To get started, check out the explorer or the
documentation.

---

## Block Explorers

> Source: https://docs.monad.xyz/tooling-and-infra/block-explorers

On this page

Block Explorer Summary​
MainnetTestnetBlock explorerPowered byStatusURLVerifier Type & URLMonadVisionBlockVision✅https://monadvision.com/Sourcify: https://sourcify-api-monad.blockvision.orgMonadscanEtherscan✅https://monadscan.com/Etherscan: https://api.monadscan.com/apiSocialScan - MonadHemera✅https://monad.socialscan.io/Etherscan: https://api.socialscan.io/monad-mainnet/v1/explorer/command_api/contract✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't supportBlock explorerPowered byStatusURLVerifier Type & URLMonadVisionBlockVision✅https://testnet.monadvision.com/Sourcify: https://sourcify-api-monad.blockvision.orgMonadscanEtherscan✅https://testnet.monadscan.com/Etherscan: https://api-testnet.monadscan.com/apiSocialScan - MonadHemera✅https://monad-testnet.socialscan.io/Etherscan: https://api.socialscan.io/monad-testnet/v1/explorer/command_api/contract✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't support
UserOp Explorers​
UserOp ExplorerStatusURLNotesJiffyScan✅https://jiffyscan.xyz/?network=monadUserOp explorer for EIP-4337
Detailed Transaction Explorers​
Transaction ExplorerStatusURLNotesTenderly Explorer✅https://dashboard.tenderly.co/explorerDetailed transaction analyzer featuring call stack, balance changes, gas usage, and moreBlocksec Phalcon Explorer✅https://blocksec.com/explorerDetailed transaction analyzer featuring call stack, balance changes, fund flows, and more
Provider Details​
BlockVision​
MonadVision is built by BlockVision, a
leading provider of next-gen data infrastructure and enterprise solutions for the blockchain.
BlockVision is supports the EVM and Sui and specializes in explorer service, RPC nodes, indexing
APIs and validator service.
To get started, visit the documentation.
Monadscan​
Monadscan is built by Etherscan to deliver trusted
and high-performance access to on-chain data. Leveraging Etherscan's industry-leading expertise,
MonadScan provides robust explorer tools, developer-friendly APIs, and reliable infrastructure
tailored for the Monad ecosystem.
To get started, visit the documentation.
SocialScan​
Monad SocialScan is a high-performance block explorer built by the
SocialScan team.
To get started, visit the documentation.

---

## Common Data

> Source: https://docs.monad.xyz/tooling-and-infra/indexers/common-data

On this page

Features​
In order to improve developer understanding of feature coverage, we have collected the most common features offered by providers:
FeatureSub-FeatureDescriptionChain dataRaw data (blocks, transactions, logs, traces) in SQL-like format. Transactions and logs may optionally be decoded based on ABIBalancesNativeNative token holdings of an address, real-time or snapshot. May include price annotationsERC20ERC20 holdings of an address, real-time or snapshot. May include price annotationsNFTNFT (ERC721 or ERC1155) holdings of an address, real-time or snapshotTransfersNativeNative token transfers involving a particular address. May include price annotationsERC20ERC20 transfers involving a particular address. May include price annotationsNFTNFT transfers involving a particular addressDEX tradesNormalized trade data across major DEXesMarket dataMarket data for ERC20s
Balances are nontrivial because each ERC20 and NFT collection stores its balances in contract storage. Transfers are nontrivial because they frequently occur as subroutines. Annotating with prices and normalizing across DEXes add additional convenience.
Access models​

APl: Data lives on provider's servers; make queries via API
Stream: Data is replicated to your environment

Provider Summary​
MainnetTestnetProviderStatusDocsSupported servicesAccess modelAllium✅DocsChain data (blocks, transactions, logs, traces, contracts) (via Explorer (historical) and Datastreams (realtime) products)
Transfers (native, ERC20, and NFTs) (via Developer (realtime) product)API, except streaming for Datastreams productCodex✅DocsToken- and trading-centric data:
Token charts, metadata, prices, events, and detailed stats
NFT metadata, events, and detailed statsAPIDune Sim✅DocsChain data: Transactions, logs (raw or decoded)
Balances: Native, ERC20APIGoldRush (by Covalent)✅DocsChain data: Blocks, enriched transactions and logs (raw and decoded)
Balances: native, ERC20, NFTs & Portfolio
Transactions: Full historical with decoded transfer eventsAPIGoldsky✅DocsChain data: blocks, enriched transactions, logs, and traces via Mirror. Fast scan is supportedAPI; StreamingMobula✅DocsChain data
Balances: native, ERC20 and NFT
Transfers: native, ERC20 and NFT
DEX trades
Market data for ERC20sAPIMoralis✅DocsChain Data: blocks, transactions, logs
Balances: native, ERC20, NFTs (with metadata, logos, spam / low-liquidity filtering)
Token Prices: USD valuation included
Transfers: native, ERC20, and NFTs (decoded events), wallet history (categorized transfers + approvals)
Streams: real-time address/contract monitoring via webhooks
Datashare: Export massive crypto datasets
RPC Nodes: Raw blockchain data accessAPIs, Streaming (webhooks)Quicknode✅DocsStreams, WebhooksStreams, WebhooksRarible✅DocsNFT data: metadata; holdings by address (current and historic); trade data; spam scoringAPISequence❓DocsBalances: native, ERC20, and NFT
Transfers: native, ERC20, and NFTs
Other: Transaction history; webhooksAPI; Streaming (webhooks)SonarX✅Chain data: blocks, transactions, logs, traces
Transfers: tokens, NFTs, internal transfers, net internal transfers (with/without pricing)
Balances: PIT and current balances
DEX trades and balances
Other: Approvals and failed transactionsCloud Platforms Data Shares (Snowflake, BigQuery, Azure, Databricks); Streaming (Kafka); File delivery (CSV, Parquet, Iceberg); APIthirdweb✅DocsChain data: blocks, transactions, logs, contracts
Balances: native, ERC20, NFTs
Other: NFTsAPIUnmarshal❓DocsBalances: ERC20 and NFT
Transactions with price annotations
NFT API (transactions and metadata)APIZerion✅DocsWallet info
Balances (native, ERC20, and NFTs)
Transactions (multichain with prices)
Other: Portfolio, PNL and Historical Positions
Notification WebhooksAPI; Webhooks✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't supportProviderStatusDocsSupported servicesAccess modelAllium✅DocsChain data (blocks, transactions, logs, traces, contracts) (via Explorer (historical) and Datastreams (realtime) products)
Transfers (native, ERC20, and NFTs) (via Developer (realtime) product)API, except streaming for Datastreams productCodex✅DocsToken- and trading-centric data:
Token charts, metadata, prices, events, and detailed stats (see dashboard)
NFT metadata, events, and detailed statsAPIDune Sim✅DocsChain data: Transactions, logs (raw or decoded)
Balances: Native, ERC20APIGoldRush (by Covalent)✅DocsChain data: Blocks, enriched transactions and logs (raw and decoded)
Balances: native, ERC20, NFTs & Portfolio
Transactions: Full historical with decoded transfer eventsAPIGoldsky✅DocsChain data: blocks, enriched transactions, logs, and traces via Mirror. Fast scan is supportedAPI; StreamingMobula✅DocsChain data
Balances: native, ERC20 and NFT
Transfers: native, ERC20 and NFT
DEX trades
Market data for ERC20sAPIMoralis❌DocsChain data
Balances: native, ERC20 and NFT
Transfers: native, ERC20APIQuicknode✅DocsStreams, WebhooksStreams, WebhooksSequence✅DocsBalances: native, ERC20, and NFT
Transfers: native, ERC20, and NFTs
Other: Transaction history; webhooksAPI; Streaming (webhooks)SonarX✅Chain data: blocks, transactions, logs, traces
Transfers: tokens, NFTs, internal transfers, net internal transfers (with/without pricing)
Balances: PIT and current balances
DEX trades and balances
Other: Approvals and failed transactionsCloud Platforms Data Shares (Snowflake, BigQuery, Azure, Databricks); Streaming (Kafka); File delivery (CSV, Parquet, Iceberg); APIthirdweb✅DocsChain data: blocks, transactions, logs, contracts
Balances: native, ERC20, NFTs
Other: NFTsAPIUnmarshal✅DocsBalances: ERC20 and NFT
Transactions with price annotations
NFT API (transactions and metadata)APIZerion✅DocsWallet info
Balances (native, ERC20, and NFTs)
Transactions (multichain with prices)
Other: Portfolio, PNL and Historical Positions
Notification WebhooksAPI; Webhooks✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't support
Provider Details​
Allium​
Allium is an Enterprise Data Platform that serves accurate, fast, and simple blockchain data. Allium offers near real-time Monad Testnet data for infrastructure needs and enriched Monad Testnet data (NFT, DEX, Decoded) for research and analytics.
Allium supports data delivery to multiple destinations, including Snowflake, Bigquery, Databricks, and AWS S3. To get started, contact Allium here.
ProductDescription / mechanismMonad Testnet data supportedExplorerHistorical data (postgres/API)Chain data: blocks, transactions, logs, traces, contractsDeveloperReal-time data (postgres/API)Transfers (native, ERC20, ERC721, ERC1155)DatastreamsReal-time data (streaming - Kafka, PubSub, or SNS)Chain data: blocks, transactions, logs, traces, contracts
Codex​
Codex API provides fast and accurate enriched data, meticulously structured to easily plug straight into your application.
To get started, visit the documentation or sign up for an API key at dashboard.codex.io.
Dune Sim​
Dune Sim makes building multi-chain application seamless. These APIs power
several of the best teams building on crypto.
Available APIs:

Token Balances: Access accurate and fast real time balances of native and ERC20 tokens of
accounts on EVM blockchains.
Transactions: Access transactions for accounts in real time across EVM blockchains.

To get started, visit the documentation.
GoldRush (by Covalent)​
GoldRush provides multichain data APIs and toolkits for easy web3 development across 100+ chains including Monad.
GoldRush offers structured onchain data, including multichain wallet balances, full transaction histories and decoded log events, for building apps and powering AI Agents. Join hundreds of top teams that leverage GoldRush to cut down their development time and scale their multichain offerings with enterprise-grade onchain data.
To get started, visit the documentation or sign up for an API key.
Goldsky​
Goldsky is the go-to data indexer for web3 builders, offering high-performance subgraph hosting and realtime data replication pipelines.
Goldsky offers two core self-serve products that can be used independently or in conjunction to power your data stack.

Subgraphs: Flexible indexing with typescript, with support for webhooks and more.
Mirror: Get live blockchain data in your database or message queues with a single yaml config.

To get started, visit the documentation or follow the quickstart guide.
Mobula​
Mobula provides curated datasets for builders: market data with Octopus, wallets data, metadata with Metacore, alongside with REST, GraphSQL & SQL interfaces to query them.
You can get started playing around with the API endpoints for free, and sign-up to the API dashboard once you need API keys (queries without API keys aren’t production-ready).
To get started, visit the documentation.
Moralis​
Moralis is the unified way to fetch, stream, and export onchain data. Access fast, enriched Data APIs for wallets, tokens, prices, holders, NFTs, transfers, liquidity, and full transaction & wallet history - plus real-time Streams and RPC nodes. Teams use Moralis as their crypto data layer to get complete, reliable onchain data without running indexers or maintaining pipelines.
To get started, visit the documentation or sign up for a free API key.
Quicknode​
Streams is a managed, push-based service for blockchain data streaming with guaranteed delivery of live and sequential historical data. Receive raw or filtered data (e.g., specific contract events) pushed to your destination: webhook, S3, Postgres, or Snowflake.
To get started, visit the documentation for detailed instructions.
Webhooks provide real-time notifications for blockchain events on Monad. Track smart contract activity, wallet transactions, and more using ready-to-use templates or your own custom JavaScript.
To get started, visit the documentation for detailed instructions.
Rarible​
Rarible offers an comprehensive toolkit for anyone interacting with
NFTs, including marketplaces and wallets. Rarible's API for NFT data includes collection/item
metadata, trades, holdings by account (both current and historical), and spam scoring.
Rarible also offers aggregated order books from major NFT marketplaces like OpenSea, Rarible, and
Blur, as well as an NFT trading SDK.
To get started, check out the documentation.
Sequence​
Sequence Indexer
offers real-time balances, transfers, NFTs, prices, and contract events across EVM chains with
webhooks and subscriptions and sub-300 ms queries. Use it as your production read layer for on-chain
apps.
Indexer gives you low-latency reads across EVM chains: balances and portfolio, token and NFT
ownership, transfers and logs, prices, and contract events. It is built for enterprise-grade
production and supports developers of all sizes. Cursor-based pagination, filters, webhooks,
and event subscriptions: All in a scalable, 99.99% uptime service.
To get started, visit the
quickstart guide.
SonarX​
SonarX delivers structured blockchain data with historical and real-time coverage across 100+ blockchains with a focus on data quality, in line with our proprietary Data Quality Framework.
Enterprises, Institutions and Builders can query full historical datasets in their preferred cloud warehouse (Snowflake, BigQuery, Azure), receive file drops in csv, parquet, iceberg formats, or run real-time pipelines with Kafka streaming. Supported services include chain data (blocks, transactions, logs, traces, decoded logs and traces), staking, and DEX trades and balances.
With ready-to-use tables and flexible delivery, SonarX helps power analytics, trading, accounting, and applications without the burden of maintaining indexing pipelines.
To get started, visit the console at console.sonarx.com.
thirdweb​
thirdweb Insight is a fast, reliable and fully customizable way for developers to index, transform & query onchain data across 30+ chains. Insight includes out-of-the-box APIs for transactions, events, tokens. Developers can also define custom API schemas, or blueprints, without the need for ABIs, decoding, RPC, or web3 knowledge to fetch blockchain data.
thirdweb Insight can be used to fetch:

all assets (ERC20, ERC721, ERC115) for a given wallet address
all sales of skins on your in-game marketplace
monthly protocol fees in the last 12 months
the total cost of all accounts created using ERC-4337
metadata for a given token (ERC20, ERC721, ERC115)
daily active wallets for your application or game
and so much more

To get started, sign up for a free thirdweb account and visit the thirdweb Insight documentation
Unmarshal​
Unmarshal is a leading decentralized multi-chain data network, enabling Web3 projects to access accurate, real-time blockchain data across 55+ chains (including Monad Testnet).
Leveraging AI-driven solutions, Unmarshal enhances data accessibility and insights for RWA, DePIN, AI Agents, DeFi, NFT, and GameFi platforms. Through robust APIs, notification services, and no-code indexers, it empowers dApps to deliver seamless user experiences while ensuring transparency, scalability, and innovation at the forefront of Web3 advancements.
To get started, visit the documentation or reach out at support@unmarshal.io.
Zerion​
The Zerion API can be used to build feature-rich web3 apps, wallets, and protocols with ease. Across all major blockchains, you can access wallets, assets, and chain data for web3 portfolios. Zerion's infrastructure supports all major chains!
To get started, visit the documentation.

---

## Cross-Chain

> Source: https://docs.monad.xyz/tooling-and-infra/cross-chain

On this page

Definitions​
At a high level, bridges offer the following features:
FeatureDescriptionArbitrary Messaging Bridge (AMB)Allows arbitrary messages to be securely relayed from a smart contract on chain 1 to a smart contract on chain 2.
AMB provides guarantees that messages delivered to chain 2 represent events finalized on chain 1.Token BridgeAllows user to lock native tokens or ERC20 tokens on chain 1 and mint claim tokens on chain 2.
Bridge maintains the invariant that, for each token minted on chain 2, there exists a corresponding token locked on chain 1.Liquidity LayerAllows user to turn in tokens on one chain and quickly redeem tokens on another chain,
typically relying on drawing on a pool of assets maintained on each side. Provides
greater immediacy relative to waiting for full finality of an AMB.Bridge AggregatorAggregates multiple liquidity layers or token bridges, potentially integrating
swapping as well so that users may receive a different token than the one they input.
Provider Summary​
MainnetTestnetProviderStatusDocsBridge TypeContract AddressesExplorerAxelar✅DocsAMB; Token BridgeSee contract addressesAxelarscanBungee✅DocsBridge AggregatorSee contract addressesChainlink CCIP✅DocsAMB; Token BridgeSee contract addressesCCIP ExplorerCircle CCTP✅DocsToken BridgeSee contract addressesdeBridge✅DocsAMB; Token BridgeSee contract addressesdeExplorerGarden✅DocsToken Bridge for BTCSee contract addressesGas.zip✅DocsToken BridgeSee contract addressesExplorerHyperlane✅DocsAMB; Token BridgeSee contract addressesHyperlane ExplorerJumper✅Bridge aggregatorLayerZero✅DocsAMB; Token BridgeSee contract addressesLayerZeroScanLi.fi✅DocsBridge aggregator SDKSee contract addressesLi.Fi ScanMayan✅DocsBridge AggregatorMayan ExplorerPolymer✅DocsAMBPolyScanRelay✅DocsLiquidity LayerTransactionsSocket✅DocsAMBSocketscanSquid✅DocsLiquidity LayerExplorer (Axelarscan)Stargate✅DocsLiquidity LayerWormhole / Portal✅DocsAMB; Token BridgeSee contract addressesWormholeScan✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't supportProviderStatusDocsBridge TypeContract AddressesExplorerAxelar✅DocsAMB; Token BridgeSee contract addressesAxelarscanChainlink CCIP✅DocsAMB; Token BridgeSee contract addressesCCIP ExplorerGarden✅DocsToken BridgeSee contract addressesHyperlane✅DocsAMB; Token BridgeSee contract addressesHyperlane ExplorerLayerZero✅DocsAMB; Token BridgeSee contract addressesLayerZeroScanPolymer✅DocsAMBSee contract addressesPolyScanWormhole✅DocsAMB; Token BridgeSee contract addressesWormholeScan✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't support
Provider Details​
Axelar​
Axelar is an interchain platform that connects blockchains to enable universal web3 transactions. By integrating with Axelar, applications built on Monad can now easily send messages and assets between the 49+ blockchains connected via Axelar.
To learn more about Axelar visit our docs and GitHub.
To view current transactions and live stats about the Axelar network, please visit the Axelarscan block explorer.
Bungee Exchange​
Bungee provides seamless swaps between any blockchain. With over
$24B in volume and trusted by major wallets and dApps, Bungee makes moving assets between networks
efficient, secure, and accessible to everyone, powered by the SOCKET.
To learn more, check out the docs.
Chainlink CCIP​
Chainlink Cross-Chain Interoperability Protocol (CCIP) is the standard for cross-chain interoperability. CCIP enables developers to build secure cross-chain apps that can transfer tokens, send messages, and initiate actions across blockchains.
Through the Cross-Chain Token (CCT) standard, CCIP enables token developers to integrate new and existing tokens with CCIP in a self-serve manner in minutes, without requiring vendor lock-in, hard-coded functions, or external dependencies that may limit future optionality. CCTs support self-serve deployments, full control and ownership for developers, zero-slippage transfers, and enhanced programmability via configurable rate limits and reliability features such as Smart Execution. CCIP is powered by Chainlink decentralized oracle networks (DONs)—a proven standard with a track record of securing tens of billions of dollars and enabling over $19 trillion in onchain transaction value.
Key CCIP developer tools:

CCIP official documentation: start integrating CCIP into your cross-chain application.
CCIP Token Manager: an intuitive front-end web interface for the deployment of new and management of existing CCTs by their developers, including no-code guided deployments and configuration tools.
CCIP SDK: a software development kit that streamlines the process of integrating CCIP, allowing developers to use JavaScript to create a token transfer frontend dApp.

Contract Addresses:

Router (testnet): 0x5f16e51e3Dcb255480F090157DD01bA962a53E54
Router (mainnet): 0x33566fE5976AAa420F3d5C64996641Fc3858CaDB

Circle CCTP​
Cross-Chain Transfer Protocol (CCTP) by Circle is a permissionless onchain utility that facilitates USDC transfers securely between supported blockchains via native burning and minting.
Circle created CCTP to improve capital efficiency and minimize trust assumptions when using USDC across blockchains.
CCTP enables developers to build multichain applications that allow users to perform 1:1 transfers of USDC securely across blockchains.
To get started, visit the Circle CCTP documentation
deBridge​
Build once, interoperate everywhere. deBridge enables secure, fast, and capital-efficient
connectivity across 20+ chains, so you can swap and transfer assets natively, trigger Cross-Chain
logic in seconds, all with chain abstraction and one unified protocol.
To get started, visit the deBridge documentation or check out the
app.
Garden​
Garden is transforming Bitcoin interoperability with its next-gen bridge. It is built by the renBTC team using an intents based architecture with trustless settlement, enabling cross-chain Bitcoin swaps in as little as 30 seconds with zero custody risk.
In its first year, Garden processed over $1 billion in volume—proving the market's demand for seamless, cost-effective Bitcoin bridging solutions.
Now, Garden is unlocking a new era of interoperability—supporting non-likewise assets, external liquidity, and a wallet-friendly API—to onboard the next wave of partners and users.
To get started, visit the documentation.
Gas.zip​
Gas.zip is a token bridge that enables seamless cross-chain asset transfers.
Contract Address:

Deployment: 0x9E22ebeC84c7e4C4bD6D4aE7FF6f4D436D6D8390

Hyperlane​
Hyperlane is a permissionless interoperability protocol for cross-chain communication. It enables message passing and asset transfers across different chains without relying on centralized intermediaries or requiring any permissions.
To get started, visit the Hyperlane documentation.
Hyperlane Explorer​
To view status of your cross chain transactions, please visit the Hyperlane Explorer.
LayerZero​
LayerZero is an omnichain interoperability protocol that enables cross-chain messaging. Applications built on Monad can use the LayerZero protocol to connect to 35+ supported blockchains seamlessly.
To get started with integrating LayerZero, visit the LayerZero documentation and provided examples on GitHub.
Li.fi​
LI.FI delivers a seamless solution for multi-chain payments and swaps through a single unified API and SDK. By combining access to all liquidity sources—including DEX aggregators, bridges, and solvers—it ensures comprehensive coverage across ecosystems. Its smart routing technology identifies the cheapest and fastest path for any payment or trade, optimizing efficiency and cost.
Additionally, LI.FI offers a plug-and-play widget that enables instant, user-friendly payment flows, making integration simple for developers and intuitive for end users.
To get started, visit Li.fi documentation
Mayan​
Mayan is a cross-chain swap protocol that enables fast and efficient token transfers across multiple blockchains.
Mayan provides seamless token bridging with optimized routing to ensure the best execution for cross-chain transfers.
To get started, visit the Mayan documentation or explore transactions on the Mayan Explorer.
Polymer​
Polymer is an interoperability protocol tailor made for multi-rollup applications. It places control in the hands of the builder, by combining cross-chain merkle proofs and a simple API to allow application builders to flexibly adopt Polymer's infrastructure for their own needs. Prove any action. Cross-chain.
To get started visit the Polymer documentation.
Relay​
Relay is the fastest and cheapest way to bridge and transact across chains, offering a multichain payments network that makes swapping and transacting across hundreds of blockchains delightfully simple. Since its launch in 2024, Relay has served over 5 million users, processed 50 million transactions, and facilitated more than $5 billion in volume across 85+ networks.
At its core, Relay combines two powerful components: instant, low-cost cross-chain intents powered by the Relay Protocol, and comprehensive DEX meta-aggregation spanning 85 chains (including Monad), ensuring users always get the best execution.
To get started, visit the Relay documentation
Socket​
SOCKET Protocol is the first chain-abstraction protocol, empowering
developers to build applications that seamlessly leverage multiple blockchains. It enables the
creation of chain-abstracted apps that interact across chains as if operating on a single one.
To get started, visit the SOCKET documentation.
Squid​
Squid creates unlimited access for anything in crypto. Squid can be used to seamlessly swap tokens from 100+ chains across including Monad.
Squid’s API, SDK, and Widgets offer ease of integration for projects building on any chain to enable cross-chain functionality in just 1 click.
Stargate​
Stargate Finance is a cross-chain bridge protocol that enables users
to transfer native assets between different blockchains with instant guaranteed finality using
unified liquidity pools.
To get started, visit the Stargate documentation.
Wormhole​
Wormhole is a cross-chain interoperability protocol that provides secure communication between blockchains. Monad uses two Wormhole products: Messaging and NTT (Native Token Transfers).
By integrating Wormhole, a Monad application can access users and liquidity on > 30 chains and > 7 different platforms.
Wormhole Messaging​
Wormhole Messaging is a generic messaging protocol that enables secure cross-chain communication and arbitrary data transfer between blockchains.
To get started with Wormhole Messaging:

Quickstart Guide
GitHub Examples

Wormhole NTT (Native Token Transfers)​
Wormhole NTT (Native Token Transfer) framework enables seamless cross-chain token movement without wrapping or liquidity pools, allowing projects to maintain token ownership and customize their cross-chain token deployment.
To get started with Wormhole NTT:

Quickstart Guide
GitHub Examples

For end-users looking to bridge assets, you can use Wormhole Portal Bridge.
For more information on integrating Wormhole, visit their documentation.
Contract Addresses for Monad Testnet:

Core: 0xBB73cB66C26740F31d1FabDC6b7A46a038A300dd
Relayer: 0x362fca37E45fe1096b42021b543f462D49a5C8df

---

## Custody

> Source: https://docs.monad.xyz/tooling-and-infra/custody

On this page

Provider Summary​
The Monad blockchain and MON token are supported by a number of leading custody providers.
ServiceSupported (Mainnet)DocsAnchorage Digital✅BitGo✅DocsCoinbase Custody✅DocsFireblocks✅DocsHexTrust✅
Provider Details​
Anchorage Digital​
As the trusted custodian for leading institutions, Anchorage Digital offers a solution built to
deliver the highest standards of security, mitigating the risk of human error and attack vectors
while offering participation in digital assets through regulated entities.
Clients can access Anchorage Digital's custody services through Anchorage Digital Bank, the only
federally chartered crypto bank in the U.S. and an unequivocal qualified custodian, or Anchorage
Digital Singapore, a licensed Major Payment Institution by the Monetary Authority of Singapore (MAS).
Learn more at anchorage.com.
BitGo​
BitGo is the digital asset infrastructure company, delivering custody, wallets, staking, trading,
financing, and settlement services from regulated cold storage. Since its founding in 2013, BitGo
has been focused on accelerating the transition of the financial system to a digital asset economy.
With a global presence and multiple regulated entities, BitGo serves thousands of institutions,
including many of the industry's top brands, exchanges, platforms, and millions of investors.
For more information, visit bitgo.com.
Coinbase Custody​
Coinbase Custody provides a secure, institutional-grade cold storage solution for digital assets,
enabling institutions to safely store and manage crypto assets with advanced security measures and
operational controls.
Learn more at coinbase.com/custody.
Fireblocks​
Fireblocks is the world's most trusted digital asset infrastructure company, empowering
organizations of all sizes to build, manage and grow their business on the blockchain.
Secure and manage your digital assets with cutting-edge security technology, execute day-to-day
treasury operations with automated workflows and connect seamlessly to exchanges, on/off-ramps,
and DeFi protocols to access liquidity and earn yield.
Learn more at fireblocks.com.
HexTrust​
Hex Trust is a licensed and regulated financial institution for digital assets, providing
institutional-grade Markets, Custody, and Staking solutions. Trusted by builders, investors, and
service providers, Hex Trust integrates directly with protocols and platforms to deliver secure,
compliant, and scalable digital asset infrastructure.
Learn more at hextrust.com.

---

## Debugging Onchain

> Source: https://docs.monad.xyz/tooling-and-infra/debugging-onchain

On this page

Transaction introspection/tracing​

Tenderly
https://openchain.xyz/
Bloxy
https://github.com/naddison36/tx2uml - OS tools for generating UML diagrams
https://github.com/apeworx/evm-trace - tracing tools

Contract Decompilation​

https://oko.palkeo.com/: a hosted version of the Panoramix decompiler

---

## Embedded Wallets

> Source: https://docs.monad.xyz/tooling-and-infra/wallet-infra/embedded-wallets

On this page

Background​
Some developers want to "embed" a wallet into their application. Here are a few possible reasons
they might want to do this:

to allow users to sign in with email or another social sign-in method
to allow users to take actions within the app without signing a new transaction each time.

Generally speaking, embedded wallet services provide this by utilizing advanced cryptographic
techniques to shard keys. Some keys are stored user-side while others are stored on
the application developer's server or the embedded wallet provider's server.
This page attempts a toplogy of authentication and key management features over the set of
providers supporting Monad.
Authentication Features​
FeaturesDescriptionPasskey sign-inAuthentication with WebAuthn (passkey)Social sign-inAuthentication with social accounts (google, X, etc)Email sign-inAuthentication with OTP via emailSMS sign-inAuthentication with OTP via SMS
Key Management Features​
FeaturesDescriptionMPCMulti-party computationSSSShamir's Secret SharingTEEStorage of private keys in a cloud-based Trusted Execution Environment, like AWS Nitro EnclavesTSSThreshold Signature SchemeEmbedded walletA wallet interface local to a website or mobile app, utilizing browser session keys for signingServer-delegated actionsAllow app to request permission to sign on the user's behalfSession keysScoped keys that grant access only for specific apps, useful for bots/AI agents
Provider Summary​
MainnetTestnetProviderStatusDocsSupported servicesSecurity MethodHow to get startedAlchemy⌛️DocsEmbedded wallets
Auth: passkey, social, email sign-inQuickstartCoinbase Developer Platform (CDP)✅DocsEmbedded wallets
Auth: email/social/SMSDevice-based secure enclavesQuickstartDynamic✅DocsEmbedded wallets
Auth: passkey, email/social/SMS sign-inTEE; TSS-MPC (just added)Get startedMetamask Delegation Toolkit⌛️DocsEmbedded Smart Accounts
Auth: multisig, external EOA + passkey
Delegations for automating actionsQuickstartOpenfort✅DocsEmbedded wallets, Backend wallets, Ecosystem wallets
Auth: passkeys, social, emailSSSQuickstartPara✅DocsEmbedded wallets; robust policy engine for sessions
Auth: email and phone, social, SMS sign-inMPC + DKGQuickstartPhantom❓DocsEmbedded wallets (Web SDK & Native Mobile SDK)
Auth: Google sign-inSSSQuickstartPrivy✅DocsEmbedded wallets, server wallets, server-delegated actions
Auth: passkey, social, email, SMSTEE + SSSQuickstartReown (formerly WalletConnect)⌛️DocsPopular UI component for selecting a wallet
Embedded wallet with social/email sign-inOverviewSequence✅DocsEmbedded wallets,
ecosystem walletsAuth: Passkey, Google, Apple, Twitter, email, Facebook, Twitch, Epic Games, Playfab, Stych, Standard OAuthTEE; Sandboxed Smart SessionsEcosystem quickstart
Embedded quickstartthirdweb✅DocsEmbedded wallets
Auth: passkey, social, email, SMS, OIDC, or generic authQuickstartTurnkey✅DocsEmbedded wallet, policy engine, delegated access, signing automation, sessions
Server-side SDKs for auth, wallet management, and policies
Auth: passkey, social, email, SMS loginTEEQuickstartWeb3Auth⌛️DocsEmbedded wallet
Auth: passkey, social, email, SMSMPC-SSS/TSSQuickstart✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't supportProviderStatusDocsSupported servicesSecurity MethodHow to get startedAlchemy✅DocsEmbedded wallets
Auth: passkey, social, email sign-inQuickstartCoinbase Developer Platform (CDP)✅DocsEmbedded wallets
Auth: email/social/SMSDevice-based secure enclavesQuickstartDynamic✅DocsEmbedded wallets
Auth: passkey, email/social/SMS sign-inTEE; TSS-MPC (just added)Get startedMetamask Delegation Toolkit✅DocsEmbedded Smart Accounts
Auth: multisig, external EOA + passkey
Delegations for automating actionsQuickstartOpenfort✅DocsEmbedded wallets, Backend wallets, Ecosystem wallets
Auth: passkeys, social, emailSSSQuickstartPara✅DocsEmbedded wallets; robust policy engine for sessions
Auth: email and phone, social, SMS sign-inMPC + DKGQuickstartPhantom✅DocsEmbedded wallets (Web SDK & Native Mobile SDK)
Auth: Google sign-inSSSQuickstartPrivy✅DocsEmbedded wallets, server wallets, server-delegated actions
Auth: passkey, social, email, SMSTEE + SSSQuickstartReown (formerly WalletConnect)✅DocsPopular UI component for selecting a wallet
Embedded wallet with social/email sign-inOverviewSequence✅DocsEmbedded wallets,
ecosystem walletsAuth: Passkey, Google, Apple, Twitter, email, Facebook, Twitch, Epic Games, Playfab, Stych, Standard OAuthTEE; Sandboxed Smart SessionsEcosystem quickstart
Embedded quickstartthirdweb✅DocsEmbedded wallets
Auth: passkey, social, email, SMS, OIDC, or generic authQuickstartTurnkey✅DocsEmbedded wallet, policy engine, delegated access, signing automation, sessions
Server-side SDKs for auth, wallet management, and policies
Auth: passkey, social, email, SMS loginTEEQuickstartWeb3Auth✅DocsEmbedded wallet
Auth: passkey, social, email, SMSMPC-SSS/TSSQuickstart✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't support
Providers Offering Subsidized Usage​
These WaaS providers are subsidizing usage on Monad Testnet:
ProviderHow to accessPrivySign up, then email the Privy team at monad@privy.ioParaSign up via the Developer Portal and reach out to the team at ops@getpara.comTurnkeyTurnkey is free for developers building on Monad Testnet. All you need to do is sign up!
Provider Details​
Alchemy​
Account Kit is a complete solution for account abstraction. Using Account Kit, you can create a smart contract wallet for every user that leverages account abstraction to simplify every step of your app's onboarding experience. It also offers Gas Manager and Bundler APIs for sponsoring gas and batching transactions.
To get started, sign up for an Alchemy account, visit the documentation, follow the quickstart guide or check out the demo here.
Alchemy helps you to replace 3rd-party pop-up wallets with native in-app auth. Drop in branded sign-in modals for email, passkeys, and social logins with plug-n-play components.
To get started, sign up for an Alchemy account, visit the documentation, follow the quickstart guide. To further streamline UX with no gas fees or signing for users, see Alchemy's AA infra offering and a demo here.
Coinbase Developer Platform​
Coinbase Developer Platform allows developers to
build next-gen on-chain apps. CDP simplifies development by providing services for creating smart
wallets, processing payments, and integrating crypto into existing apps.
With CDP Embedded Wallets, your users can access the full power of blockchains through familiar
authentication methods like email and social logins (no seed phrases, browser extensions, or
pop-ups required).
To get started, visit the documentation
or follow the quickstart guide.
Dynamic​
Dynamic offers smart and beautiful login flows for crypto-native users, simple onboarding flows for everyone else, and powerful developer tools that go beyond authentication.
To get started, visit the documentation or follow the quickstart guide.
MetaKeep​
MetaKeep is the #1 self-custody infra for users & AI. Onboard 300x more users in 1 API call, 5 mins.
To get started, setup an onboarding call with the team.
Metamask Delegation Toolkit​
The MetaMask Delegation Toolkit is a Viem-based collection of tools for integrating embedded smart contract wallets, known as MetaMask smart accounts, into dapps. Developers can create and manage MetaMask smart accounts that delegate specific permissions, such as spending limits or time-based access, to other accounts.
To get started, visit the documentation or follow the quickstart guide.
Para​
infoPara is free for developers building on Monad Testnet!Sign up via the Developer Portal and reach out to the team via the below email.ops@getpara.com
Para is the easiest and most secure way to onboard all your users and support them throughout their crypto journey. We support projects throughout their growth, ranging from personal projects to many of the most trusted teams in crypto and beyond.
Para's cross-app embedded wallets work universally across apps, chains, and ecosystem, so whether users start transacting on EVM, Solana, or Cosmos, they can onboard once and transact forever, all with the same wallet.
To get started, visit the documentation or follow the quickstart guide.
Phantom​
Phantom is the world's leading crypto wallet for managing digital assets and accessing decentralized applications.
Phantom embedded wallets enable seamless, seedless onboarding with in-app, non-custodial access--no app switching or seed phrases required.
To get started, visit the documentation or follow the Introduction guide.
Privy​
infoPrivy is subsidizing all Monad Testnet usage!For more details reach out to the Privy team via the below email.monad@privy.io
Privy helps you onboard any user to crypto no matter how familiar they are with the space. Power flexible, powerful wallets under the hood for any application, securely.
To get started, visit the documentation or follow the quickstart guide.
Reown​
Reown gives developers the tools to build user experiences that make digital ownership effortless, intuitive, and secure.
AppKit​
AppKit is a powerful, free, and fully open-source SDK for developers looking to integrate wallet connections and other Web3 functionalities into their apps on any EVM and non-EVM chain. In just a few simple steps, you can provide your users with seamless wallet access, one-click authentication, social logins, and notifications—streamlining their experience while enabling advanced features like on-ramp functionality, in-app token swaps and smart accounts.
To get started, visit the documentation or follow the quickstart guide.
Sequence​
Sequence provides the industry gold standard in robust open-source,
non-custodial Embedded
and Ecosystem
Wallets.Sequence is the originator of non-custodial smart contract wallets, and authors of
ERC-1271 and ERC-6492.
Embedded and Ecosystem Wallets enable seamless onboarding with user-friendly
email, social, passkey, and guest account logins. Invisible onchain transactions; secure and
compliant non-custodial sovereignty; and cross-platform integrations with SDKs for Unity, Unreal,
Web, and mobile. Fully customizable for developers and ecosystems.
To get started, visit the Ecosystem Wallet Quickstart.
thirdweb​
thirdweb provides client-side SDKs for user onboarding, identity and transactions.

Onboard new users to your apps with every wallet & login method
create a complete picture of all your users via user analytics & identity linking
facilitate onchain transactions via onramps, swaps & bridging

To get started:

Sign up for a free thirdweb account
Visit Connect Documentation and Connect Playground

Turnkey​
infoTurnkey is free for developers building on Monad Testnet!
Turnkey is secure, flexible, and scalable wallet infrastructure. Create millions of embedded wallets, eliminate manual transaction flows, and automate onchain actions - all without compromising on security.
To get started, visit the documentation or follow the quickstart guide.
Web3Auth​
Web3Auth simplifies Web3 access with social logins, customisable wallet UI, and advanced security, with non custodial MPC wallet management.
To get started, visit the documentation or follow the quickstart guide.

---

## Hardware Wallets

> Source: https://docs.monad.xyz/tooling-and-infra/wallets/hardware-wallets

On this page

Provider Summary​
MainnetTestnetWalletStatusOther FeaturesLedger✅Safepal✅Support for multiple cryptocurrencies, Secure element chip✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't supportWalletStatusOther FeaturesD'Cent Wallet✅Biometric authentication, Bluetooth connectivityLedger❌Safepal✅Support for multiple cryptocurrencies, Secure element chip✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't support
Provider Details​
D'Cent Wallet​
D'Cent Wallet is a hardware wallet featuring biometric authentication for enhanced security. It uses a secure chip to protect private keys and offers Bluetooth connectivity for convenient mobile device pairing. D'Cent provides a balance of security and usability with its fingerprint recognition technology and support for multiple cryptocurrencies.
To get started, learn more about D'Cent Wallet here or visit the user guide.
Ledger​
Ledger is a leading company in cryptocurrency security, best known for its hardware wallets that
keep digital assets safe through offline (cold) storage. These wallets use a secure element chip
and custom operating system to protect private keys, while requiring users to confirm transactions
directly on the device for added safety.
Learn more about Ledger here.
Safepal​
Safepal offers hardware wallet solutions that combine security with user-friendly features. Their hardware wallets utilize secure element chips to protect private keys and support a wide range of cryptocurrencies. Safepal hardware wallets are designed to be affordable while maintaining high security standards, making them accessible to both new and experienced crypto users.
To get started, learn more about Safepal hardware wallets here or visit the documentation.

---

## Indexers

> Source: https://docs.monad.xyz/tooling-and-infra/indexers/

On this page

Common DataRaw transactional data and frequently-used derived data like balances, transfers, and DEX tradesIndexing FrameworksTools that allow developers to build custom calculators in response to events

The blockchain can be thought of as a list of blocks, transactions, and logs, as well as a series of global states. Indexers compute common transformations on this data to save downstream consumers the cost and complexity of doing so.
There are two main types of indexer services:

Data for common use cases: raw data (blocks, transactions, logs, traces) and derived data for common use cases (token balances, NFT holdings, DEX trades), computed across the entire blockchain
Indexing Frameworks enable devleopers to build custom calculators for a specific smart contract

Data for common use cases​
Data providers offer raw and transformed data for common use cases via API or by streaming to your local environment.
Raw data includes:

blocks, transactions, logs, traces (potentially decoded using contract ABIs)

Transformed data includes:

balances (native tokens, ERC20s, NFTs)
transfers (native tokens, ERC20s, NFTs)
DEX trades
market data
and more

See Common Data for a fuller list of features and providers.
Indexing Frameworks​
Smart contract indexers are custom off-chain calculators for a specific smart contract. They maintain additional off-chain state and perform additional computation. Since blockchain data is public, anyone may deploy a subgraph involving state or logs from any smart contract.
See Indexing Frameworks for a list of features and providers.

---

## Indexing Frameworks

> Source: https://docs.monad.xyz/tooling-and-infra/indexers/indexing-frameworks

On this page

Background​
Smart contract indexers are off-chain calculators that compute additional metrics specific to one smart contract. Calculators can be thought of as extensions to a smart contract that do additional off-chain computation and maintain additional off-chain state.
Simple example: the UniswapV2Pair contract maintains minimal state for the pool and emits Mint, Burn, and Swap events. If we wanted to know the cumulative number and volume of swaps on the pair, we could write and deploy a custom indexer instead of adding additional state variables and computation to the contract.
Smart contract indexers typically produce object schemas using the GraphQL schema language.
Smart contract indexing services usually provide a hosted service so that users can deploy their indexers without having to run their own infrastructure.
Provider Summary​
MainnetTestnetProviderStatusDocsLanguageFrameworkKnown forHosted serviceDecen- tralized hosted serviceOnchain & offchain dataWeb- socket subscr- iptionsQuery layerEnvio✅DocsJavaScript, TypeScript, RescriptHyperIndexPerformance and scale✅❌✅✅GraphQLGhost✅DocsSolidityGhostGraphSolidity development✅❌❌❌GraphQLGoldsky✅DocsAssembly- Scriptsubgraph✅❌❌❌Custom GraphQLOrmi✅DocsAssembly- ScriptsubgraphHigh performance and custom environments✅❌❌❌Custom GraphQLSentio✅DocsJavaScript, TypeScriptsentio-sdkPerformance; integrated alerting and visualization✅❌✅❌GraphQL & SQLSQD✅DocsTypeScriptsquid-sdkPerformance, decentralization✅Partial1✅✅GraphQLSubQuery✅DocsTypeScriptsubqlDecentral- ization✅✅✅❌GraphQLThe Graph✅DocsAssembly- ScriptsubgraphThe original indexer✅✅❌❌Custom GraphQL✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't supportProviderStatusDocsLanguageFrameworkKnown forHosted serviceDecen- tralized hosted serviceOnchain & offchain dataWeb- socket subscr- iptionsQuery layerEnvio✅DocsJavaScript, TypeScript, RescriptHyperIndexPerformance and scale✅❌✅✅GraphQLGhost✅DocsSolidityGhostGraphSolidity development✅❌❌❌GraphQLGoldsky✅DocsAssembly- Scriptsubgraph✅❌❌❌Custom GraphQLOrmi✅DocsAssembly- ScriptsubgraphHigh performance and custom environments✅❌❌❌Custom GraphQLSentio✅DocsJavaScript, TypeScriptsentio-sdkPerformance; integrated alerting and visualization✅❌✅❌GraphQL & SQLSQD✅DocsTypeScriptsquid-sdkPerformance, decentralization✅Partial1✅✅GraphQLSubQuery✅DocsTypeScriptsubqlDecentral- ization✅✅✅❌GraphQLThe Graph✅DocsAssembly- ScriptsubgraphThe original indexer✅✅❌❌Custom GraphQL✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't support
Provider Details​
Envio​
Envio is a full-featured data indexing solution that provides application developers with a seamless and efficient way to index and aggregate real-time and historical blockchain data for Monad Testnet. The indexed data is easily accessible through custom GraphQL queries, providing developers with the flexibility and power to retrieve specific information.
Envio HyperSync is an indexed layer of the Monad Testnet blockchain for the hyper-speed syncing of historical data (JSON-RPC bypass). What would usually take hours to sync ~100,000 events can now be done in the order of less than a minute.
Designed to optimize the user experience, Envio offers automatic code generation, flexible language support, multi-chain data aggregation, and a reliable, cost-effective hosted service.
To get started, visit the documentation or follow the quickstart guide.
Ghost​
With GhostGraph, you can write your indexers in the same language as your contracts: Solidity. This means less context switching and faster time to market.
To get started, visit the documentation or check out the tutorial.
Services supported:

GhostGraph

Goldsky​
Goldsky is the go-to data indexer for web3 builders, offering high-performance subgraph hosting and realtime data replication pipelines.
Goldsky offers two core self-serve products that can be used independently or in conjunction to power your data stack.

Subgraphs: Flexible indexing with typescript, with support for webhooks and more.
Mirror: Get live blockchain data in your database or message queues with a single yaml config.

To get started, visit the documentation or follow the quickstart guide.
Ormi​
Ormi delivers real-time blockchain data that is fast, accurate, and ready for production.
It keeps data synced to the tip of the chain and makes it instantly accessible through Subgraphs and APIs without the need to manage indexing infrastructure.
Ormi provides two core products:

Subgraphs: Smart contract data at sub-second latency with zero throttling.
Data API: Real-time and historical blockchain data delivered through flexible, high-speed API endpoints.

Ormi supports shared, dedicated, and fully custom environments that provide isolated performance for high-demand workloads.
Start building by exploring the documentation or following the Quickstart Guide.
Sentio​
Sentio offers blazing-fast native processors and seamless subgraph hosting on Monad. With powerful database capabilities, intuitive dashboards, and comprehensive API functionalities, Sentio is built to provide an exceptional developer experience.
To get started, check out the docs or visit the quickstart guide.
SQD​
SQD enables permissionless, cost-efficient access to petabytes of high-value Web3 data.
SQD is a decentralized hyper-scalable data platform optimized for providing efficient, permissionless access to large volumes of data. It currently serves historical on-chain data, including event logs, transaction receipts, traces, and per-transaction state diffs.
To get started, visit the documentation or see this quickstart with examples on how to easily create subgraphs via Subsquid.
SubQuery​
SubQuery is a leading blockchain data indexer that provides developers with fast, flexible, universal, open source and decentralised APIs for web3 projects. SubQuery SDK allows developers to get rich indexed data and build intuitive and immersive decentralised applications in a faster and more efficient way. SubQuery supports many ecosystems including Monad, Ethereum, Cosmos, Near, Polygon, Polkadot, Algorand, and more.
One of SubQuery's advantages is the ability to aggregate data not only within a chain but across multiple blockchains all within a single project. This allows the creation of feature-rich dashboard analytics and multi-chain block scanners.
Useful resources:​

SubQuery Academy (Documentation)
Monad Testnet Starter
Monad Testnet Quick Start Guide

For technical questions and support reach out to us start@subquery.network
The Graph​
The Graph is an indexing protocol that provides an easy way to query blockchain data through APIs known as subgraphs.
With The Graph, you can benefit from:

Decentralized Indexing: Enables indexing blockchain data through multiple indexers, thus eliminating any single point of failure
GraphQL Queries: Provides a powerful GraphQL interface for querying indexed data, making data retrieval super simple.
Customization: Define your own logic for transforming & storing blockchain data. Reuse subgraphs published by other developers on The Graph Network.

Follow this quick-start guide to create, deploy, and query a subgraph within 5 minutes.

Footnotes​


SQD hosted service is semi-decentralized: the data lake is decentralized, but indexers run on proprietary infra. ↩ ↩2

---

## Local Nodes

> Source: https://docs.monad.xyz/tooling-and-infra/local-nodes

Developers often find it helpful to be able to run a 1-node Ethereum network with modified parameters to test interaction with the blockchain:

Anvil is a local Ethereum node packaged in the Foundry toolkit
Hardhat Network is a local Ethereum node packaged in the Hardhat toolkit

Installation is most easily done as part of installing the respective toolkit, described in the next section.

---

## Multisig Wallets

> Source: https://docs.monad.xyz/tooling-and-infra/wallets/multisig-wallets

On this page

Provider Summary​
MainnetTestnetWalletStatusContract addressesOther FeaturesSafe✅See contract addresses✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't supportWalletStatusOther FeaturesSafe✅✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't support
Provider Details​
Safe Wallet​
Safe Wallet is a secure, non-custodial cryptocurrency wallet that
allows users to manage, store, and interact with digital assets like tokens and NFTs. It is built
on the Safe (formerly Gnosis Safe) smart contract infrastructure, offering advanced features like
multisig control, transaction batching, and custom permissions. Designed for both individuals and
organizations, Safe Wallet emphasizes security, transparency, and decentralized asset management.
Access Safe Wallet here.
tipsafe-tx-hashes-util is a tool for
independently computing Safe transaction hashes based on transaction details from the
Safe transaction service UI.safe-tx-hashes-util supports Monad.

---

## Onramps

> Source: https://docs.monad.xyz/tooling-and-infra/onramps

On this page

Onramps are services that allow users to convert fiat currency into cryptocurrency. They serve
as an entrypoint for users who want to participate in the Monad ecosystem.
Provider Summary​
ProviderStatusDocsSupport notesRegions supportedCurrencies & Countries SupportedAlchemy Pay✅DocsOnramp
NFT Checkout
Crypto PaymentAPAC, Africa, LATAMPayment Methodsalfred⌛️DocsAPI EndpointsLATAM, US, EU, APACSupported CurrenciesBanxa✅DocsOnramp API
Offramp APIUS, Canada, UK, EU, AustraliaSupported Currencies
Supported CountriesCapa✅DocsOnramp API
Offramp APILATAMSupported CurrenciesCoindisco✅DocsBuy|Sell Widget
White Label API240+ countries and territoriesSupported Payment Methods
Supported Fiat Currencies
Supported CountriesCoinflow⌛️DocsAPI EndpointsAPAC, LATAM, US, EUSupported Countries - Withdraw
Supported Countries - Global Push CardFinchPay⌛️DocsWidget URL
APIEU, 150+ countriesLocal payment methods: Brazil (PicPay, PIX), Mexico (SPEI and OXXO), Indonesia (virtual accounts BRI & Mandiri, e-wallets DANA/OVO)Fonbnk⌛️DocsOnramp
OfframpAfrica, LATAMSupported Countries & Payment MethodsKoywe✅DocsWidget Ramp DemoLATAMSupported Currencies
Supported CountriesMeld⌛️Docs (pw protected)225+ CountriesMercuryo⌛️DocsOnramp API Endpoints
Offramp API EndpointsUS, EUSupported Currencies
Supported CountriesMoonPay⌛️DocsOnramp
OfframpUS, EU, Canada, LATAM, APAC, AfricaSupported Currencies
Supported Payment Methods
Unsupported CountriesOnramper⌛️DocsAPI Endpoints190+ CountriesPayment MethodsOSL Pay✅DocsOnramp134+ CountriesSupported Currencies & CountriesSwapped✅DocsOnramp Endpoints
Offramp Endpoints150+ countriesSupported Payment Methods
Supported CountriesTransak✅DocsAPI endpointsUS, UK, EU, Australia, Canada, APACSupported CountriesUnlimit⌛️DocsAPI EndpointsLATAM, Africa, India, EU, UK, APACPayment Methods
Payout MethodsUR⌛️DocsAPAC, EUSupported Countries
Restricted CountriesWalapay⌛️DocsAfrica, APAC, EU, US, Canada, LATAMSupported Countries & Currencies
Prohibited Countries
Provider details​
Alchemy Pay​
Alchemy Pay is a payment gateway that seamlessly connects crypto with traditional fiat currencies for businesses, developers, and end users. With its offerings including On & Off Ramp, Crypto Card, Web3 Digital Bank, NFT Checkout, and Crypto Payments, Alchemy Pay supports payments in 173 countries.
To get started, visit the documentation.
alfred​
With alfred, settle international payments in real time. Move money over stablecoin rails and give your business global coverage without the use of intermediary banks resulting in faster transfers at lower costs compared to traditional banking.
To get started, visit the documentation.
Banxa​
Banxa powers one of the largest digital asset platforms by providing payments infrastructure and regulatory compliance across global markets. Banxa's mission and vision is to build the bridge that provides people in every part of the world access to a fairer and more equitable financial system.
To get started, visit the documentation.
Capa​
Capa is your one-stop solution to send and receive payments between Latin America and the world through their all-in-one API, making cross-border transactions fast, simple, and cost-effective.
To get started, visit the documentation.
Coindisco​
Coindisco is an onramp aggregator that provides access to crypto purchases across 240+ countries and territories through a unified widget and white label API integration.
To get started, visit the documentation.
Coinflow​
Coinflow enables businesses to grow faster with instant settlement, fraud & chargeback indemnity, global pay-in, multi-currency FX, and unified payouts---all in one intuitive platform.
To get started, visit the documentation.
FinchPay​
FinchPay is an EU-regulated global fiat on-ramp and payment infrastructure for Web3, that lets users buy crypto with cards or local payment methods in 150+ countries.
To get started, visit the documentation.
Fonbnk​
Fonbnk bridges mobile-first, cash-based economies to Web3 by converting prepaid payments into stablecoins, enabling frictionless FX, cross-border treasury flows, and instant liquidity.
To get started, visit the documentation.
Koywe​
Koywe is services and interface that make it easier and simpler to buy and sell crypto in Latin America for the fairest price while using local currency and payment methods.
To get started, visit the documentation.
Meld​
Meld is an infrastructure to move money across Web2 and Web3 rails. fiat <> fiat | fiat <> crypto
To get started, contact Meld.
Mercuryo​
Mercuryo enables efficient capital flow within the DeFi ecosystem and consolidates various payment and banking solutions into a single, user-centric interface.
To get started, visit the documentation.
MoonPay​
MoonPay simplifies access to buy, sell and trade crypto using everyday payment methods like cards, Apple Pay, PayPal and Venmo, while also providing simple tools to send, receive and manage stablecoins.
To get started, visit the documentation.
Onramper​
Onramper is a fiat onramp aggregator. All fiat onramps in a single integration, unlocking the lowest fees and highest transaction success rates on the market.
To get started, visit the documentation.
OSL Pay​
OSL Pay is the payment infrastructure arm of OSL Group, providing licensed and compliant solutions for seamless conversion between digital assets and fiat currencies.
To get started, visit the documentation.
Swapped​
Swapped offers On-Ramp, Connect, and Commerce solutions, enabling customers to move funds onchain, receive crypto payments, and build full financial platforms, games, and consumer experiences.
To get started, visit the documentation.
Transak​
Transak is a developer integration toolkit that enables you as an app developer to onboard your users to buy/sell crypto in any blockchain app, website or web plugin. With Transak you can onboard mainstream users into your dApp, protocol, game or wallet app and also increase your revenue.
To get started, visit the documentation.
Unlimit​
Unlimit's mission is to provide innovators with a convenient and simple financial interface that enables payments to flow freely and invisibly across borders. They offer a wide range of services, including payment gateway, card acquiring, business accounts, card issuing, alternative payment methods, and more.
To get started, visit the documentation.
UR​
UR is a borderless smart money app built on the blockchain. Your go-to unified crypto and fiat account with 0 off-ramp fees and access to multiple currencies.
To get started, visit the documentation.
Walapay​
Walapay is a global money movement platform that is building the future of cross-border payments.
To get started, visit the documentation.

---

## Oracles

> Source: https://docs.monad.xyz/tooling-and-infra/oracles

On this page

Oracles make off-chain data accessible on chain.
Definitions​
TermDescriptionPush oracleProvider regularly pushes price data to the oracle contract on chainPull (on-demand) oracleUser triggers price data update while calling a smart contractCustom oracleA custom calculatorVRF (Verifiable Random Function)Provides random numbers on chain
Provider Summary​
MainnetTestnetProviderStatusDocsContract addressesLive dataSupport notesChainlink✅DocsSee contract addressesLive data
Push oracle (Price Feeds)
Pull oracle (Data Streams)
Chronicle✅DocsSee contract addressesPush oracle; custom oracleseOracle✅DocsDashboardPush oracleOrochi✅DocsSee contract addresseszkOracle;
VRFPyth✅DocsSee contract addressesLive dataPull oracle;
VRFRedstone✅DocsSee contract addressesLive dataPush oracle;
pull oracleStork✅Docs
See contract addresses
Addresses; APIs; Asset ID Registry
Pull oracleSupra✅DocsSee contract addressesLive dataPush oracle;Pull oracle;dVRFSwitchboard✅Docs
See contract addresses
More info: Deployments
Pull oracle;
Oracle aggregator;
VRF✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't supportProviderStatusDocsContract addressesLive dataSupport notesChainlink✅DocsPrice Feeds [push oracle]:
BTC / USD: 0x2Cd9D7E85494F68F5aF08EF96d6FD5e8F71B4d31
ETH / USD: 0x0c76859E85727683Eeba0C70Bc2e0F5781337818
LINK / USD: 0x4682035965Cd2B88759193ee2660d8A0766e1391
USDC / USD: 0x70BB0758a38ae43418ffcEd9A25273dd4e804D15
USDT / USD: 0x14eE6bE30A91989851Dc23203E41C804D4D71441
general reference 
Data Streams [pull oracle]:
Data stream verifier proxy address: 0xC539169910DE08D237Df0d73BcDa9074c787A4a1
Live data
Push oracle (Price Feeds)
Pull oracle (Data Streams)
Chronicle✅DocsAddress referenceDashboard (toggle dev mode)Push oracle; custom oracleseOracle✅Docs
Address reference
Update conditions: 0.5% deviation & 24h heartbeat
DashboardPush oracleGelato VRF✅DocsVRFOrochi✅Docs
Orocle [oracle] addresses
Orand [VRF] addresses
zkOracle;
VRFPyth✅Docs
Price feeds: 0x2880aB155794e7179c9eE2e38200202908C17B43
Beta price feeds (incl MON/USDC): 0xad2B52D2af1a9bD5c561894Cdd84f7505e1CD0B5
Entropy: 0x36825bf3Fbdf5a29E2d5148bfe7Dcf7B5639e320
Live data
Beta live data (includes MON / USDC)Pull oracle;
VRFRedstone✅Docs
Push oracle addresses
Update conditions for all: 0.5% deviation & 6h heartbeat
Live dataPush oracle;
pull oracleStork✅Docs
Pull oracle (includes MON/USD): 0xacC0a0cF13571d30B4b8637996F5D6D774d4fd62
Addresses; APIs; Asset ID Registry
Pull oracleSupra✅Docs
Push oracle: 0x6Cd59830AAD978446e6cc7f6cc173aF7656Fb917
(5% deviation threshold & 1h update frequency;
Supported pairs: BTC/USDT, SOL/USDT, ETH/USDT)
Pull oracle: 0x443A0f4Da5d2fdC47de3eeD45Af41d399F0E5702
dVRF: 0x6D46C098996AD584c9C40D6b4771680f54cE3726
Live dataPush oracle;Pull oracle;dVRFSwitchboard✅Docs
Pull oracle: 0x33A5066f65f66161bEb3f827A3e40fce7d7A2e6C
More info: Deployments
Live dataPull oracle;
Oracle aggregator;
VRF✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't support
Provider Details​
Chainlink​
Chainlink Data Streams​
Chainlink Data Streams deliver low-latency market data offchain, which can be verified onchain. This approach provides decentralized applications (dApps) with on-demand access to high-frequency market data backed by decentralized, fault-tolerant, and transparent infrastructure.
Traditional push-based oracles update onchain data at set intervals or when certain price thresholds are met. In contrast, Chainlink Data Streams uses a pull-based design that preserves trust-minimization with onchain verification.
To get started, check out the documentation.
Chainlink Price Feeds​
Chainlink Price Feeds are the quickest way to connect your smart contracts to real-world data such as asset prices.
Data Feeds aggregate many data sources and publish them onchain using a combination of the Decentralized Data Model and Offchain Reporting.
To get started, check out the documentation.
Chronicle​
Chronicle's decentralized oracle network was originally built within MakerDAO for the development of DAI and is now available to builders on Monad.

Data Feeds: Builders can choose from 90+ data feeds, including crypto assets, yield rates, and RWAs. Chronicle's data is sourced via custom-built data models, only utilizing Tier 1 sources.
Transparency & Integrity: Chronicle's oracle network is fully transparent and verifiable via the Chronicle dashboard. Users can cryptographically challenge the integrity of every oracle update using the 'verify' feature. Data is independently sourced by a community of Validators including Gitcoin, Etherscan, Infura, DeFi Saver, and MakerDAO.
Gas Efficiency: Pioneering the Schnorr-based oracle architecture, Chronicle's oracles use 60-80% less gas per update than other oracle providers. This lowest cost per update allows Push oracle updates to be made more frequently, enabling granular data reporting.
Every oracle implementation is customized to fit your needs. Implement one of our existing data models or contact Chronicle to develop custom oracle data feeds via Discord.

Developers can dive deeper into Chronicle Protocol's architecture and unique design choices via the docs.
eOracle​
eOracle is an open infrastructure platform that empowers developers to build secure blockchain oracles backed by Ethereum's battle-tested security model. eOracle creates a foundation for specialized data services that combine deep domain expertise with unmatched cryptoeconomic security.
To get started, visit the eOracle documentation.
Orochi​
Orochi Network is the world's first Verifiable Data Infrastructure, addressing scalability, privacy, and data integrity challenges.
To get started, visit the Orochi documentation.
Pyth​
The Pyth Network is one of the largest first-party oracle networks, delivering real-time data across a number of chains. Pyth introduces a low-latency pull oracle design. Data providers push price updates to Pythnet every 400 ms. Users pull aggregated prices from Pythnet onto Monad when needed, enabling everyone in the onchain environment to access that data point most efficiently.
Pyth Price Feeds features:

400ms latency
First-party data sourced directly from financial institutions
Price feeds ranging from crypto, stocks, FX, and metals

See also: beta price feeds (testnet MON/USD is a beta price feed)


Available on many major chains

Contract Addresses for Monad Testnet:

Price feeds: 0x2880aB155794e7179c9eE2e38200202908C17B43

Beta price feeds: 0xad2B52D2af1a9bD5c561894Cdd84f7505e1CD0B5 (testnet MON/USD is a beta price feed)


Entropy: 0x36825bf3Fbdf5a29E2d5148bfe7Dcf7B5639e320

noteThe testnet MON/USD price feed is currently a beta feed on Pyth Network. To use the MON/USD feed, integrate the beta price feed contract instead of the primary price feed contract.To get the MON/USD price feed offchain, use the beta hermes endpoint: https://hermes-beta.pyth.network
Redstone​
RedStone is the fastest-growing modular oracle, specializing in yield-bearing collateral for lending markets, such as LSTs, LRTs and BTCFi.
To get started, visit the Redstone documentation.
Stork​
Stork is an oracle protocol that enables ultra low latency connections between data providers and both on and off-chain applications. The most common use-case for Stork is pulling and consuming market data in the form of real time price feeds for DeFi.
Stork is implemented as a pull oracle. Stork continuously aggregates, verifies, and audits data from trusted publishers, and makes that aggregated data available at sub-second latency and frequency. This data can then be pulled into any on or off-chain application as often as needed.
To learn more about how Stork works, visit Core Concepts and How It Works.
Supra​
Supra provides VRF and decentralized oracle price feeds (push and pull based) that can be used for onchain and offchain use-cases such as spot and perpetual DEXes, lending protocols, and payments protocols.
To get started, visit the Supra documentation
Switchboard​
Switchboard is a permissionless oracle protocol that enables developers to bring any off-chain or cross-chain data onto Monad through verifiable, ultra-low-latency feeds.
Switchboard features:

Fully permissionless feed creation via the Feed Builder: deploy custom oracles in minutes
Switchboard Surge: Low-latency data feeds with sub-10 ms updates for high-performance applications
Enterprise-grade reliability
Aggregator: access multiple oracle sources (like the ones on this page) in a single transaction
Data Feed Variables: bring API-gated or confidential data on-chain without exposing API keys
Customizable feeds: adjust feed parameters (confidence intervals, deviation thresholds, and more) to your dapp's needs
Decentralized oracle network secured by globally distributed validator set
Verifiable Randomness: generate secure, verifiable random numbers for games, lotteries, and more
Supports any data type: prices, prediction markets, sports, weather, RWAs, etc

Contract Address for Monad Mainnet: 0x33A5066f65f66161bEb3f827A3e40fce7d7A2e6C
For more details, check out Switchboard's detailed EVM documentation.

---

## RPC Providers

> Source: https://docs.monad.xyz/tooling-and-infra/rpc-providers

On this page

noteSee also: API reference
Provider Summary​
MainnetTestnetProviderStatusNotesAlchemy✅Alchemy Monad docsAnkr✅Ankr Monad docsBlockdaemon✅Blockdaemon Monad docsBlockPI✅BlockPI Monad docsChainstack✅Chainstack Monad docsdRPC NodeCloud✅dRPC NodeCloud Monad docsEnvio✅HyperRPC is a performant read-only RPC. See docsQuicknode✅Quicknode Monad docsSpectrum✅Tatum✅Tatum Monad docsthirdweb✅thirdweb RPC Edge docsTriton One✅Triton One Monad docsValidation Cloud✅Validation Cloud Monad docs✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't supportProviderStatusNotesAlchemy✅Alchemy Monad docsAnkr✅Ankr Monad docsBlockdaemon✅Blockdaemon Monad docsBlockPI✅BlockPI Monad docsChainstack✅Chainstack Monad docsdRPC NodeCloud✅dRPC NodeCloud Monad docsEnvio✅HyperRPC is a performant read-only RPC. See docsQuicknode✅Quicknode Monad docsSpectrum✅Tatum✅Tatum Monad docsthirdweb✅thirdweb RPC Edge docsValidation Cloud✅Validation Cloud Monad docs✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't support
Provider Details​
Alchemy​
Alchemy is a popular API provider and developer platform. Its robust, free tier offers access to JSON-RPC APIs, and hosted testnet nodes for Monad Testnet.
Ankr​
Ankr provides private and public RPC endpoints for Monad, powered by a globally distributed and decentralized network of nodes.
Blockdaemon​
Blockdaemon provides enterprise-grade web3 infrastructure, including dedicated nodes, APIs, staking, liquid staking, MPC wallets, and more.
To get started, visit the Blockdaemon documentation.
BlockPI​
BlockPI provides enterprise-grade, high-performance RPC services for both Monad Mainnet and Testnet. Whatever you're building on Monad, we offer this premium service at a fraction of the market average price, making high-quality RPC access affordable for everyone.
To get started, visit BlockPI's Monad page.
Chainstack​
Chainstack provides low-latency, highly reliable, and scalable RPC infrastructure for Monad.
You can deploy robust Monad Mainnet and Testnet nodes and access geo-balanced RPC endpoints on a secure, SOC 2–certified platform.
To get started, create a free account with a Monad RPC node.
dRPC NodeCloud​
dRPC NodeCloud delivers robust, low-latency RPC for Monad. Free accounts & paid plans from $10. Full speed. No limits, build confidently.
To get started, visit the dRPC's Monad page.
Envio​
Envio has a free read only RPC that supports a subset of data intensive methods, Envio's purpose built rust node supports historical data allowing you to query past 10,000 blocks into the past.
To get started, visit the Envio documentation
Quicknode​
Quicknode offers access to their Core RPC API for both Monad Testnet and Mainnet. Quicknode provides managed, high-performance RPC endpoints with instant access.
To get started, visit Quicknode's Monad page.
Spectrum​
Spectrum is an enterprise-grade RPC Infrastructure provider that
makes it easy to deploy and manage dedicated RPC endpoints to over 150 networks.  Sign up today
to get started on Monad.
To get started, visit the Spectrum dashboard.
Tatum​
Tatum provides RPC nodes, blockchain data, and real-time notifications.
To get started, visit the Tatum documentation.
thirdweb​
thirdweb's RPC Edge provides an RPC endpoint for developers building on Monad.
To get started, visit the Thirdweb RPC Edge documentation.
Triton One​
Triton One is a reliable, globally distributed Monad RPC provider built
for teams that need consistent performance under load, high throughput, and uninterrupted uptime.
To get started, visit the Triton One Monad docs.
Validation Cloud​
Validation Cloud is the world's fastest node provider according to Compare Nodes. With 50 million compute units available for use without a credit card and a scale tier that never has rate limits, Validation Cloud is built to support your most rigorous and low-latency workloads.
To get started, visit the Validation Cloud Monad documentation.

---

## Smart Account Implementations

> Source: https://docs.monad.xyz/tooling-and-infra/wallet-infra/smart-accounts

On this page

Background​
Under ERC-4337, smart wallets perform authentication (signature verification) inside of a smart
contract.  Depending on the signature scheme, signing may be done locally (on the user's computer)
or in a remote environment (e.g. TEEs).
This page lists notable smart account implementations deployed to Monad.
Provider Summary​
MainnetTestnetProviderStatusDocsSupported servicesHow to get startedBiconomy✅DocsNexus: Smartest & most gas-efficient smart account
External Wallets
Auth: privy, turnkey; session keysQuickstartPimlico✅Docspermissionless.js, a flexible SDK for interfacing with various smart accounts, bundlers/paymasters, and signers.TutorialZeroDev✅DocsSmart contract accounts
Session keys with several options for signature schemes (ECDSA, Passkey, Multisig), policies, and actions.Quickstart✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't supportProviderStatusDocsSupported servicesHow to get startedBiconomy✅DocsNexus: Smartest & most gas-efficient smart account
External Wallets
Auth: privy, turnkey; session keysQuickstartPimlico✅Docspermissionless.js, a flexible SDK for interfacing with various smart accounts, bundlers/paymasters, and signers.TutorialZeroDev✅DocsSmart contract accounts
Session keys with several options for signature schemes (ECDSA, Passkey, Multisig), policies, and actions.Quickstart✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't support
Provider Details​
Biconomy​
Biconomy is the most comprehensive smart account and execution infrastructure platform that enables seamless, user-friendly experiences across single or multiple chains. With Biconomy, developers can build superior onchain UX through gas abstraction, sessions, batching, and one-click signatures for complex actions on any number of networks.
To get started, visit the documentation.
Pimlico​
Pimlico is the world's most advanced ERC-4337 account abstraction infrastructure platform. Pimlico provides a suite of tools and services to help you build, deploy, and manage smart accounts on Ethereum and other EVM-compatible chains.
To get started, visit the documentation or follow the quickstart guide.
Zerodev​
ZeroDev is the most powerful smart account development platform. With ZeroDev, you can build Web3 experiences without gas, confirmations, seed phrases, and bridging.
To get started, visit the documentation or follow the quickstart guide.

---

## Software Wallets

> Source: https://docs.monad.xyz/tooling-and-infra/wallets/software-wallets

On this page

Provider Summary​
MainnetTestnetWalletStatusAvailable onBlinks SupportAutodetect Tokens and NFTsAAOther FeaturesPhantom✅Desktop, Mobile✅Tokens, NFTs❌NFT support, DApp browser, Token swaps, cross-chain swaps, staking optionsBackpack✅Desktop, Mobile✅Tokens, NFTs❌DApp browser, Built-in exchange, Futures trading, Portfolio trackingBitget Wallet✅Desktop, Mobile❌❌❌DApp browser, NFT Market, DApp Browser, and LaunchpadHaHa⌛️Desktop, Mobile❌✅✅DeFi integrations, AA, Monad Native, trading, hardware wallet supportLeap❓Desktop, Mobile❌NFTs❌Portfolio tracking, Open source, Cross-chain swaps, StakingMetaMask✅Desktop, Mobile❌NFTs❌NFT support, DApp browser, Open source, Token swaps, portfolio trackingOKX Wallet⌛️Desktop, Mobile✅✅✅DApp browser, Portfolio tracking, Cross-chain swaps, Biometric LoginRabby Wallet✅Desktop, Mobile❌✅✅Portfolio tracking, Biometric loginSafepal✅Desktop, Mobile❌✅❌NFT support, DApp browser, Token swaps, Hardware wallet supportTrust Wallet✅Desktop, Mobile❌Tokens, NFTs✅Multi-chain support, NFT support, DApp browser, Token swaps, Staking, Buy crypto✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't supportWalletStatusAvailable onBlinks SupportAutodetect Tokens and NFTsAAOther FeaturesPhantom✅Desktop, Mobile✅Tokens, NFTs❌NFT support, DApp browser, Token swaps, cross-chain swaps, staking optionsBackpack✅Desktop, Mobile✅Tokens, NFTs❌DApp browser, Built-in exchange, Futures trading, Portfolio trackingBitget Wallet✅Desktop, Mobile❌❌❌DApp browser, NFT Market, DApp Browser, and LaunchpadCoin98 Wallet✅Desktop, Mobile❌✅❌Multi-chain support, DApp browser, Cross-chain swaps, NFT GalleryCrypto.com Web3 Wallet✅Desktop, Mobile❌✅❌DApp browser, DeFi integrations, Token swaps, StakingHaHa✅Desktop, Mobile❌✅✅DeFi integrations, AA, Monad Native, trading, hardware wallet supportKucoin Web3 Wallet✅Desktop, Mobile❌✅❌DApp browser, Multi-chain support, Portfolio trackingLeap✅Desktop, Mobile❌NFTs❌Portfolio tracking, Open source, Cross-chain swaps, StakingMetaMask✅Desktop, Mobile❌NFTs❌NFT support, DApp browser, Open source, Token swaps, portfolio trackingOKX Wallet✅Desktop, Mobile✅✅✅DApp browser, Portfolio tracking, Cross-chain swaps, Biometric LoginRabby Wallet✅Desktop, Mobile❌✅✅Portfolio tracking, Biometric loginSafepal✅Desktop, Mobile❌✅❌NFT support, DApp browser, Token swaps, Hardware wallet supportTrust Wallet✅Desktop, Mobile❌Tokens, NFTs✅Multi-chain support, NFT support, DApp browser, Token swaps, Staking, Buy crypto✅ = supported, ⌛️ = in progress, ❓ = unknown, ❌ = won't support
Provider Details​
Phantom​
Phantom is a secure and easy-to-use wallet for the Monad Testnet.
To get started, download the phantom wallet here or visit the documentation.
Backpack​
Backpack is a next-level wallet and exchange. Buy tokens, trade futures, and explore on-chain apps—seamlessly and securely. 🎒
To get started, download the Backpack wallet here or visit the documentation.
Bitget Wallet​
Bitget Wallet is a non-custodial wallet with advanced multi-chain capabilities and powerful swap function
To get started, download the Bitget wallet here or visit the documentation.
Coin98 Wallet​
Coin98 Wallet is a multi-chain wallet that connects users to numerous blockchains, allowing for seamless asset management and DeFi interactions. It features cross-chain swaps, an integrated DApp browser, and comprehensive portfolio tracking across multiple networks.
To get started, download Coin98 Wallet here or visit the documentation.
Crypto.com Web3 Wallet​
Crypto.com Web3 Wallet (formerly DeFi Wallet) is a non-custodial wallet that gives users full control of their crypto and private keys. It supports multiple blockchains, offers seamless DeFi integrations, token swaps, and staking capabilities, all while maintaining high security standards.
To get started, download Crypto.com Web3 Wallet here or visit the documentation.
HaHa Wallet​
HaHa is a next-gen smart wallet with DeFi capabilities.
To get started, download the HaHa wallet here.
Kucoin Web3 Wallet​
Kucoin Web3 Wallet is a non-custodial multi-chain wallet developed by KuCoin, one of the leading cryptocurrency exchanges. It provides secure access to DeFi protocols, supports multiple blockchains, and includes features for portfolio tracking and DApp interactions.
To get started, download Kucoin Web3 Wallet here or visit the documentation.
Leap Wallet​
Leap is a multi-chain wallet spanning across Cosmos, EVM & Bitcoin.
To get started, download the Leap wallet here or visit the documentation.
MetaMask​
MetaMask is a secure and easy-to-use wallet for the Monad Testnet.
To get started, download the MetaMask wallet here or visit the documentation.
OKX Wallet​
OKX Wallet is your all-in-one gateway to the Web3 world.
To get started, download the OKX Wallet here or visit the documentation.
Rabby Wallet​
Rabby Wallet is a non-custodial, multi-chain Web3 wallet created by DeBank that makes using decentralized apps easier and safer. It supports Monad and many other blockchains, automatically detects networks, and shows transaction simulations with risk alerts to help prevent mistakes or scams. Users keep full control of their keys.
Download Rabby wallet and learn more about it here.
Safepal​
Safepal is a cryptocurrency wallet that offers both software and hardware wallet solutions. It provides secure storage for digital assets with features like token swaps, NFT management, and DApp browsing. Safepal emphasizes security while maintaining user-friendly access to DeFi and Web3 applications.
To get started, download the Safepal wallet here or visit the documentation.
Trust Wallet​
Trust Wallet is a popular multi-chain cryptocurrency wallet that supports millions of assets and blockchains. It provides a secure, decentralized platform for storing, sending, and receiving cryptocurrencies, with built-in features for staking, NFT management, and accessing DApps.
To get started, download Trust Wallet here or visit the documentation.

---

## Tooling and Infrastructure

> Source: https://docs.monad.xyz/tooling-and-infra/

Many leading Ethereum developer tools support Monad Testnet. The enclosing pages survey each category of tools and attempt a feature comparison.
See also the protocols repo for a listing of contract addresses for each protocol.
AnalyticsTools for understanding app activity on MonadBlock ExplorersView accounts and transactions; read and write contractsCross-ChainBridges and protocols for cross-chain communicationCustodyInstitutional-grade custody solutions for secure asset managementIndexersCommon transformations for blockchain data + custom calculatorsOnrampsWays to convert between fiat and cryptoOraclesData feeds bringing off-chain information on-chainRPC ProvidersEndpoints for interacting with MonadToolkitsDevelopment frameworks and tools for building on MonadWalletsTools for storing private keys, signing transactions, and managing assetsWallet InfrastructureEmbedded wallets and smart accounts

---

## Toolkits

> Source: https://docs.monad.xyz/tooling-and-infra/toolkits

On this page

Summary​
ToolkitStatusNotesFoundry✅Use nightly release: foundryup -i nightlyHardhat✅
Provider Details​
Developers often find it helpful to build their project in the context of a broader framework that organizes external dependencies (i.e. package management), organizes unit and integration tests, defines a deployment procedure (against local nodes, testnet, and mainnet), records gas costs, etc.
Here are the two most popular toolkits for Solidity development:

Foundry is a Solidity framework for both development and testing. Foundry manages your dependencies, compiles your project, runs tests, deploys, and lets you interact with the chain from the command-line and via Solidity scripts. Foundry users typically write their smart contracts and tests in the Solidity language.
Hardhat is a Solidity development framework paired with a JavaScript testing framework. It allows for similar functionality as Foundry, and was the dominant toolchain for EVM developers prior to Foundry.

---

## Wallet Infrastructure

> Source: https://docs.monad.xyz/tooling-and-infra/wallet-infra/

On this page

Summary​
Monad features excellent support for developers looking to refine their users' experience
by utilizing modular wallet infrastructure.
These pages survey the supported infrastructure:

Embedded Wallets
Account Abstraction Providers
Smart Account Implementations

The landscape can be confusing, even to an experienced developer; therefore we include a
rough topology below.
Background​
Wallets allow users to store private keys and sign transactions. The basic setup involves
separation between the wallet and the application: the application presents a transaction
to the wallet for signing, and the wallet submits the transaction to the network, paying
for inclusion and execution with native tokens deducted from its balance.
However, increasingly, developers wish to customize their users' experience, for example by
sponsoring gas for their users or by allowing users to pay fees in an alternate currency. Other
developers want to embed the "wallet" into the app and give the app signing power over that
wallet, so that users don't have to sign a transaction with each action that they take.
Modular wallet infrastructure enables these and other features.
A number of providers are solving for this experience. To simplify understanding of the options,
we suggest the following two-dimensional matrix:
FreestandingEmbeddedEOASee Simple WalletsSee Embedded Wallets.Typically utilizes key sharding, e.g. using MPC, SSS, or TEESmart AccountUtilizes Account Abstraction, i.e. developer needs to choose:AA ProvidersSmart AccountsSee Embedded Wallets and look for "Embedded Smart Accounts"
EOA-based approach​
(EOA, freestanding) is the traditional wallet experience powered by browser extension wallets,
mobile wallets, and hardware wallets. It involves a single private key stored within the wallet.
See Wallets for a survey.
(EOA, embedded): typically uses cryptographic techniques (MPC, SSS, etc) to shard the
signing keys, implementing additional authorization or access control features off-chain, while
presenting to the blockchain as an ordinary EOA. See Embedded Wallets
for a list of providers.
Smart account (account abstraction) approach​
Account Abstraction means using smart contracts in place of simple EOAs. The smart contract
implements the authorization / access control logic, i.e. the logic is on chain.
Historically, smart contracts could not pay for their own transaction costs (although EIP-7702
introduces an exception to this rule). Therefore, the account abstraction path requires
users to sign pseudo-transactions (UserOperations) and submit them to a custom mempool.
Then, a service called the Bundler/Relayer submits UserOperations in a normal Monad transaction
and pays for the execution.
Thus, there are at least two considerations for developers building with smart accounts:

the Bundler/Relayer service; see Account Abstraction Providers
for a list
the Smart Account Implementation

Some embedded wallet providers support smart accounts. See Embedded Wallets
and look out for "Embedded Smart Accounts".

---

## Wallets

> Source: https://docs.monad.xyz/tooling-and-infra/wallets/

Software WalletsBrowser extension wallets and mobile walletsHardware WalletsOffline walletsMultisig Wallets


For developers looking for advanced functionality such as embedded wallets or account
abstraction, see Wallet Infrastructure.

---

